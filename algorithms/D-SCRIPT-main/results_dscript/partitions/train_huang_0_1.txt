[2023-08-18-10:05:46] D-SCRIPT Version 0.2.2
[2023-08-18-10:05:46] Called as: /nfs/home/students/jbernett/miniconda3/envs/dscript/bin/dscript train --train data/partitions/huang_partition_0.txt --test data/partitions/huang_partition_1.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_0_1_dscript_partitions -o ./results_dscript/partitions/train_huang_0_1.txt
[2023-08-18-10:05:49] Loaded 2992 training pairs
[2023-08-18-10:05:49] Loaded 1190 test pairs
[2023-08-18-10:05:49] Loading embeddings...
[2023-08-18-10:06:26] Initializing embedding model with:
[2023-08-18-10:06:26] 	projection_dim: 100
[2023-08-18-10:06:26] 	dropout_p: 0.5
[2023-08-18-10:06:26] Initializing contact model with:
[2023-08-18-10:06:26] 	hidden_dim: 50
[2023-08-18-10:06:26] 	kernel_width: 7
[2023-08-18-10:06:26] Initializing interaction model with:
[2023-08-18-10:06:26] 	do_poool: False
[2023-08-18-10:06:26] 	pool_width: 9
[2023-08-18-10:06:26] 	do_w: True
[2023-08-18-10:06:26] 	do_sigmoid: True
[2023-08-18-10:06:26] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-08-18-10:06:28] Using save prefix "./models/huang_0_1_dscript_partitions"
[2023-08-18-10:06:28] Training with Adam: lr=0.001, weight_decay=0
[2023-08-18-10:06:28] 	num_epochs: 10
[2023-08-18-10:06:28] 	batch_size: 25
[2023-08-18-10:06:28] 	interaction weight: 0.35
[2023-08-18-10:06:28] 	contact map weight: 0.65
[2023-08-18-10:06:32] [1/10] training 3.3%: Loss=1.39492, Accuracy=52.000%, MSE=0.478319
[2023-08-18-10:06:34] [1/10] training 6.7%: Loss=1.42274, Accuracy=50.000%, MSE=0.49799
[2023-08-18-10:06:36] [1/10] training 10.0%: Loss=1.41949, Accuracy=49.667%, MSE=0.501161
[2023-08-18-10:06:39] [1/10] training 13.3%: Loss=1.39621, Accuracy=50.250%, MSE=0.495177
[2023-08-18-10:06:41] [1/10] training 16.7%: Loss=1.39921, Accuracy=50.000%, MSE=0.497606
[2023-08-18-10:06:44] [1/10] training 20.0%: Loss=1.38218, Accuracy=50.333%, MSE=0.494143
[2023-08-18-10:06:46] [1/10] training 23.3%: Loss=1.37762, Accuracy=50.143%, MSE=0.495883
[2023-08-18-10:06:49] [1/10] training 26.7%: Loss=1.37167, Accuracy=50.250%, MSE=0.494766
[2023-08-18-10:06:51] [1/10] training 30.0%: Loss=1.35163, Accuracy=50.667%, MSE=0.490414
[2023-08-18-10:06:53] [1/10] training 33.3%: Loss=1.34155, Accuracy=51.000%, MSE=0.487036
[2023-08-18-10:06:55] [1/10] training 36.7%: Loss=1.34593, Accuracy=50.545%, MSE=0.491444
[2023-08-18-10:06:58] [1/10] training 40.0%: Loss=1.32893, Accuracy=51.000%, MSE=0.486704
[2023-08-18-10:07:00] [1/10] training 43.3%: Loss=1.32073, Accuracy=51.308%, MSE=0.48363
[2023-08-18-10:07:02] [1/10] training 46.7%: Loss=1.31966, Accuracy=51.000%, MSE=0.48651
[2023-08-18-10:07:05] [1/10] training 50.0%: Loss=1.31141, Accuracy=51.133%, MSE=0.485075
[2023-08-18-10:07:07] [1/10] training 53.3%: Loss=1.31407, Accuracy=50.875%, MSE=0.487593
[2023-08-18-10:07:10] [1/10] training 56.7%: Loss=1.32137, Accuracy=50.176%, MSE=0.494337
[2023-08-18-10:07:12] [1/10] training 60.0%: Loss=1.30465, Accuracy=50.778%, MSE=0.488268
[2023-08-18-10:07:15] [1/10] training 63.3%: Loss=1.29633, Accuracy=51.105%, MSE=0.485004
[2023-08-18-10:07:17] [1/10] training 66.7%: Loss=1.28539, Accuracy=51.400%, MSE=0.481943
[2023-08-18-10:07:19] [1/10] training 70.0%: Loss=1.29316, Accuracy=50.762%, MSE=0.48813
[2023-08-18-10:07:22] [1/10] training 73.3%: Loss=1.29278, Accuracy=50.636%, MSE=0.489312
[2023-08-18-10:07:24] [1/10] training 76.7%: Loss=1.28471, Accuracy=50.870%, MSE=0.486913
[2023-08-18-10:07:27] [1/10] training 80.0%: Loss=1.28458, Accuracy=50.667%, MSE=0.488816
[2023-08-18-10:07:29] [1/10] training 83.3%: Loss=1.2822, Accuracy=50.640%, MSE=0.48901
[2023-08-18-10:07:32] [1/10] training 86.7%: Loss=1.28111, Accuracy=50.500%, MSE=0.490301
[2023-08-18-10:07:34] [1/10] training 90.0%: Loss=1.28267, Accuracy=50.185%, MSE=0.493285
[2023-08-18-10:07:36] [1/10] training 93.3%: Loss=1.27843, Accuracy=50.286%, MSE=0.492205
[2023-08-18-10:07:39] [1/10] training 96.7%: Loss=1.27359, Accuracy=50.345%, MSE=0.491519
[2023-08-18-10:07:51] Finished Epoch 1/10: Loss=2.68703, Accuracy=49.583%, MSE=0.493068, Precision=0.424215, Recall=0.00707021, F1=0.0139086, AUPR=0.427958
[2023-08-18-10:07:51] Saving model to ./models/huang_0_1_dscript_partitions_epoch01.sav
[2023-08-18-10:07:53] [2/10] training 3.3%: Loss=1.121, Accuracy=54.000%, MSE=0.45295
[2023-08-18-10:07:55] [2/10] training 6.7%: Loss=1.1499, Accuracy=50.500%, MSE=0.485887
[2023-08-18-10:07:57] [2/10] training 10.0%: Loss=1.19136, Accuracy=49.000%, MSE=0.501433
[2023-08-18-10:08:00] [2/10] training 13.3%: Loss=1.18522, Accuracy=48.500%, MSE=0.50555
[2023-08-18-10:08:02] [2/10] training 16.7%: Loss=1.18238, Accuracy=48.600%, MSE=0.504515
[2023-08-18-10:08:04] [2/10] training 20.0%: Loss=1.18943, Accuracy=48.500%, MSE=0.505678
[2023-08-18-10:08:06] [2/10] training 23.3%: Loss=1.17525, Accuracy=48.857%, MSE=0.501706
[2023-08-18-10:08:09] [2/10] training 26.7%: Loss=1.19095, Accuracy=48.000%, MSE=0.510278
[2023-08-18-10:08:11] [2/10] training 30.0%: Loss=1.17199, Accuracy=48.889%, MSE=0.501381
[2023-08-18-10:08:13] [2/10] training 33.3%: Loss=1.16219, Accuracy=49.100%, MSE=0.499034
[2023-08-18-10:08:15] [2/10] training 36.7%: Loss=1.16838, Accuracy=48.818%, MSE=0.501921
[2023-08-18-10:08:17] [2/10] training 40.0%: Loss=1.16034, Accuracy=49.000%, MSE=0.499812
[2023-08-18-10:08:20] [2/10] training 43.3%: Loss=1.1575, Accuracy=49.000%, MSE=0.499646
[2023-08-18-10:08:22] [2/10] training 46.7%: Loss=1.14556, Accuracy=49.643%, MSE=0.493336
[2023-08-18-10:08:25] [2/10] training 50.0%: Loss=1.14282, Accuracy=49.733%, MSE=0.492408
[2023-08-18-10:08:27] [2/10] training 53.3%: Loss=1.14322, Accuracy=49.500%, MSE=0.494519
[2023-08-18-10:08:29] [2/10] training 56.7%: Loss=1.13724, Accuracy=49.647%, MSE=0.492891
[2023-08-18-10:08:31] [2/10] training 60.0%: Loss=1.13677, Accuracy=49.556%, MSE=0.493687
[2023-08-18-10:08:34] [2/10] training 63.3%: Loss=1.12747, Accuracy=50.000%, MSE=0.48925
[2023-08-18-10:08:36] [2/10] training 66.7%: Loss=1.12425, Accuracy=49.950%, MSE=0.489484
[2023-08-18-10:08:38] [2/10] training 70.0%: Loss=1.12089, Accuracy=50.048%, MSE=0.488431
[2023-08-18-10:08:40] [2/10] training 73.3%: Loss=1.12846, Accuracy=49.455%, MSE=0.494143
[2023-08-18-10:08:43] [2/10] training 76.7%: Loss=1.12148, Accuracy=49.652%, MSE=0.491922
[2023-08-18-10:08:45] [2/10] training 80.0%: Loss=1.12002, Accuracy=49.667%, MSE=0.491713
[2023-08-18-10:08:47] [2/10] training 83.3%: Loss=1.11772, Accuracy=49.600%, MSE=0.492157
[2023-08-18-10:08:50] [2/10] training 86.7%: Loss=1.11436, Accuracy=49.731%, MSE=0.490843
[2023-08-18-10:08:52] [2/10] training 90.0%: Loss=1.11287, Accuracy=49.630%, MSE=0.491548
[2023-08-18-10:08:54] [2/10] training 93.3%: Loss=1.1066, Accuracy=49.857%, MSE=0.489187
[2023-08-18-10:08:56] [2/10] training 96.7%: Loss=1.10044, Accuracy=50.172%, MSE=0.48609
[2023-08-18-10:09:05] Finished Epoch 2/10: Loss=2.19462, Accuracy=49.583%, MSE=0.483569, Precision=0.448372, Recall=0.0169832, F1=0.0327267, AUPR=0.441659
[2023-08-18-10:09:05] Saving model to ./models/huang_0_1_dscript_partitions_epoch02.sav
[2023-08-18-10:09:07] [3/10] training 3.3%: Loss=1.05722, Accuracy=47.000%, MSE=0.504248
[2023-08-18-10:09:10] [3/10] training 6.7%: Loss=1.03853, Accuracy=48.000%, MSE=0.497641
[2023-08-18-10:09:12] [3/10] training 10.0%: Loss=1.01743, Accuracy=49.667%, MSE=0.482907
[2023-08-18-10:09:14] [3/10] training 13.3%: Loss=1.01696, Accuracy=50.000%, MSE=0.480495
[2023-08-18-10:09:16] [3/10] training 16.7%: Loss=1.03072, Accuracy=48.800%, MSE=0.492064
[2023-08-18-10:09:18] [3/10] training 20.0%: Loss=1.01852, Accuracy=49.500%, MSE=0.485453
[2023-08-18-10:09:21] [3/10] training 23.3%: Loss=1.03766, Accuracy=48.571%, MSE=0.494941
[2023-08-18-10:09:23] [3/10] training 26.7%: Loss=1.03143, Accuracy=48.750%, MSE=0.493446
[2023-08-18-10:09:26] [3/10] training 30.0%: Loss=1.027, Accuracy=49.111%, MSE=0.490164
[2023-08-18-10:09:28] [3/10] training 33.3%: Loss=1.00341, Accuracy=50.600%, MSE=0.475994
[2023-08-18-10:09:30] [3/10] training 36.7%: Loss=0.99884, Accuracy=50.273%, MSE=0.477112
[2023-08-18-10:09:32] [3/10] training 40.0%: Loss=1.00266, Accuracy=49.917%, MSE=0.47987
[2023-08-18-10:09:34] [3/10] training 43.3%: Loss=1.00069, Accuracy=49.769%, MSE=0.481086
[2023-08-18-10:09:36] [3/10] training 46.7%: Loss=0.999873, Accuracy=49.786%, MSE=0.480996
[2023-08-18-10:09:39] [3/10] training 50.0%: Loss=0.998051, Accuracy=49.933%, MSE=0.480031
[2023-08-18-10:09:41] [3/10] training 53.3%: Loss=0.984767, Accuracy=50.375%, MSE=0.474669
[2023-08-18-10:09:43] [3/10] training 56.7%: Loss=0.992813, Accuracy=49.882%, MSE=0.479127
[2023-08-18-10:09:46] [3/10] training 60.0%: Loss=0.997051, Accuracy=49.667%, MSE=0.48116
[2023-08-18-10:09:48] [3/10] training 63.3%: Loss=0.995013, Accuracy=49.632%, MSE=0.4814
[2023-08-18-10:09:51] [3/10] training 66.7%: Loss=0.995347, Accuracy=49.500%, MSE=0.482565
[2023-08-18-10:09:53] [3/10] training 70.0%: Loss=0.994824, Accuracy=49.476%, MSE=0.482711
[2023-08-18-10:09:55] [3/10] training 73.3%: Loss=0.990531, Accuracy=49.500%, MSE=0.481596
[2023-08-18-10:09:57] [3/10] training 76.7%: Loss=0.986068, Accuracy=49.609%, MSE=0.480169
[2023-08-18-10:10:00] [3/10] training 80.0%: Loss=0.985037, Accuracy=49.500%, MSE=0.480894
[2023-08-18-10:10:02] [3/10] training 83.3%: Loss=0.983498, Accuracy=49.560%, MSE=0.480353
[2023-08-18-10:10:04] [3/10] training 86.7%: Loss=0.98125, Accuracy=49.538%, MSE=0.480235
[2023-08-18-10:10:06] [3/10] training 90.0%: Loss=0.975479, Accuracy=49.704%, MSE=0.478144
[2023-08-18-10:10:08] [3/10] training 93.3%: Loss=0.975835, Accuracy=49.571%, MSE=0.479298
[2023-08-18-10:10:11] [3/10] training 96.7%: Loss=0.97174, Accuracy=49.759%, MSE=0.477334
[2023-08-18-10:10:20] Finished Epoch 3/10: Loss=1.85782, Accuracy=49.583%, MSE=0.459873, Precision=0.532679, Recall=0.0430851, F1=0.079722, AUPR=0.534613
[2023-08-18-10:10:20] Saving model to ./models/huang_0_1_dscript_partitions_epoch03.sav
[2023-08-18-10:10:22] [4/10] training 3.3%: Loss=1.05727, Accuracy=41.000%, MSE=0.552667
[2023-08-18-10:10:24] [4/10] training 6.7%: Loss=0.950114, Accuracy=47.500%, MSE=0.489526
[2023-08-18-10:10:27] [4/10] training 10.0%: Loss=0.945191, Accuracy=47.333%, MSE=0.49066
[2023-08-18-10:10:29] [4/10] training 13.3%: Loss=0.945332, Accuracy=47.000%, MSE=0.494414
[2023-08-18-10:10:31] [4/10] training 16.7%: Loss=0.909491, Accuracy=49.600%, MSE=0.471019
[2023-08-18-10:10:33] [4/10] training 20.0%: Loss=0.891178, Accuracy=50.667%, MSE=0.461629
[2023-08-18-10:10:35] [4/10] training 23.3%: Loss=0.857997, Accuracy=51.286%, MSE=0.447958
[2023-08-18-10:10:37] [4/10] training 26.7%: Loss=0.856116, Accuracy=51.625%, MSE=0.445693
[2023-08-18-10:10:39] [4/10] training 30.0%: Loss=0.845695, Accuracy=52.778%, MSE=0.435665
[2023-08-18-10:10:42] [4/10] training 33.3%: Loss=0.851853, Accuracy=51.900%, MSE=0.442934
[2023-08-18-10:10:44] [4/10] training 36.7%: Loss=0.854725, Accuracy=51.818%, MSE=0.444605
[2023-08-18-10:10:46] [4/10] training 40.0%: Loss=0.855999, Accuracy=51.833%, MSE=0.444456
[2023-08-18-10:10:49] [4/10] training 43.3%: Loss=0.85293, Accuracy=51.846%, MSE=0.443997
[2023-08-18-10:10:51] [4/10] training 46.7%: Loss=0.846409, Accuracy=51.643%, MSE=0.443185
[2023-08-18-10:10:53] [4/10] training 50.0%: Loss=0.854287, Accuracy=50.933%, MSE=0.448848
[2023-08-18-10:10:56] [4/10] training 53.3%: Loss=0.860419, Accuracy=50.562%, MSE=0.452274
[2023-08-18-10:10:58] [4/10] training 56.7%: Loss=0.857939, Accuracy=50.588%, MSE=0.451066
[2023-08-18-10:11:00] [4/10] training 60.0%: Loss=0.855106, Accuracy=50.722%, MSE=0.449297
[2023-08-18-10:11:02] [4/10] training 63.3%: Loss=0.853776, Accuracy=50.737%, MSE=0.449012
[2023-08-18-10:11:05] [4/10] training 66.7%: Loss=0.851494, Accuracy=50.700%, MSE=0.448709
[2023-08-18-10:11:07] [4/10] training 70.0%: Loss=0.853331, Accuracy=50.429%, MSE=0.450973
[2023-08-18-10:11:09] [4/10] training 73.3%: Loss=0.854437, Accuracy=50.545%, MSE=0.450727
[2023-08-18-10:11:11] [4/10] training 76.7%: Loss=0.856084, Accuracy=50.609%, MSE=0.450897
[2023-08-18-10:11:14] [4/10] training 80.0%: Loss=0.853842, Accuracy=50.375%, MSE=0.451318
[2023-08-18-10:11:16] [4/10] training 83.3%: Loss=0.84734, Accuracy=50.680%, MSE=0.447822
[2023-08-18-10:11:18] [4/10] training 86.7%: Loss=0.847807, Accuracy=50.654%, MSE=0.448368
[2023-08-18-10:11:20] [4/10] training 90.0%: Loss=0.847249, Accuracy=50.370%, MSE=0.449927
[2023-08-18-10:11:23] [4/10] training 93.3%: Loss=0.84638, Accuracy=50.179%, MSE=0.45081
[2023-08-18-10:11:25] [4/10] training 96.7%: Loss=0.848339, Accuracy=50.000%, MSE=0.45197
[2023-08-18-10:11:34] Finished Epoch 4/10: Loss=1.98715, Accuracy=49.583%, MSE=0.473845, Precision=0.526081, Recall=0.0271609, F1=0.0516549, AUPR=0.5204
[2023-08-18-10:11:34] Saving model to ./models/huang_0_1_dscript_partitions_epoch04.sav
[2023-08-18-10:11:37] [5/10] training 3.3%: Loss=0.709311, Accuracy=51.000%, MSE=0.398564
[2023-08-18-10:11:39] [5/10] training 6.7%: Loss=0.699634, Accuracy=49.500%, MSE=0.39766
[2023-08-18-10:11:41] [5/10] training 10.0%: Loss=0.711988, Accuracy=49.333%, MSE=0.400491
[2023-08-18-10:11:43] [5/10] training 13.3%: Loss=0.737275, Accuracy=48.000%, MSE=0.416314
[2023-08-18-10:11:45] [5/10] training 16.7%: Loss=0.734943, Accuracy=47.200%, MSE=0.418142
[2023-08-18-10:11:48] [5/10] training 20.0%: Loss=0.72609, Accuracy=48.000%, MSE=0.411955
[2023-08-18-10:11:50] [5/10] training 23.3%: Loss=0.731459, Accuracy=47.714%, MSE=0.415616
[2023-08-18-10:11:52] [5/10] training 26.7%: Loss=0.741744, Accuracy=47.375%, MSE=0.421086
[2023-08-18-10:11:54] [5/10] training 30.0%: Loss=0.753873, Accuracy=47.444%, MSE=0.425961
[2023-08-18-10:11:57] [5/10] training 33.3%: Loss=0.747401, Accuracy=47.200%, MSE=0.423845
[2023-08-18-10:11:59] [5/10] training 36.7%: Loss=0.732615, Accuracy=48.182%, MSE=0.413146
[2023-08-18-10:12:01] [5/10] training 40.0%: Loss=0.725757, Accuracy=48.083%, MSE=0.410614
[2023-08-18-10:12:03] [5/10] training 43.3%: Loss=0.73096, Accuracy=47.538%, MSE=0.415117
[2023-08-18-10:12:06] [5/10] training 46.7%: Loss=0.744971, Accuracy=47.500%, MSE=0.420056
[2023-08-18-10:12:08] [5/10] training 50.0%: Loss=0.755464, Accuracy=47.133%, MSE=0.425587
[2023-08-18-10:12:10] [5/10] training 53.3%: Loss=0.749236, Accuracy=47.000%, MSE=0.423047
[2023-08-18-10:12:12] [5/10] training 56.7%: Loss=0.742367, Accuracy=47.059%, MSE=0.419678
[2023-08-18-10:12:15] [5/10] training 60.0%: Loss=0.743993, Accuracy=46.833%, MSE=0.421661
[2023-08-18-10:12:17] [5/10] training 63.3%: Loss=0.744288, Accuracy=46.526%, MSE=0.422767
[2023-08-18-10:12:19] [5/10] training 66.7%: Loss=0.737586, Accuracy=46.650%, MSE=0.418479
[2023-08-18-10:12:21] [5/10] training 70.0%: Loss=0.734819, Accuracy=46.857%, MSE=0.416443
[2023-08-18-10:12:24] [5/10] training 73.3%: Loss=0.734946, Accuracy=47.364%, MSE=0.413794
[2023-08-18-10:12:26] [5/10] training 76.7%: Loss=0.73826, Accuracy=47.435%, MSE=0.413482
[2023-08-18-10:12:28] [5/10] training 80.0%: Loss=0.740496, Accuracy=47.292%, MSE=0.415116
[2023-08-18-10:12:30] [5/10] training 83.3%: Loss=0.736056, Accuracy=47.320%, MSE=0.412821
[2023-08-18-10:12:33] [5/10] training 86.7%: Loss=0.732847, Accuracy=47.154%, MSE=0.4116
[2023-08-18-10:12:35] [5/10] training 90.0%: Loss=0.72904, Accuracy=47.074%, MSE=0.409867
[2023-08-18-10:12:38] [5/10] training 93.3%: Loss=0.72652, Accuracy=47.000%, MSE=0.408634
[2023-08-18-10:12:40] [5/10] training 96.7%: Loss=0.726443, Accuracy=47.000%, MSE=0.408662
[2023-08-18-10:12:49] Finished Epoch 5/10: Loss=2.17411, Accuracy=49.583%, MSE=0.446522, Precision=0.635177, Recall=0.0615292, F1=0.112191, AUPR=0.606992
[2023-08-18-10:12:49] Saving model to ./models/huang_0_1_dscript_partitions_epoch05.sav
[2023-08-18-10:12:51] [6/10] training 3.3%: Loss=0.857312, Accuracy=43.000%, MSE=0.487278
[2023-08-18-10:12:54] [6/10] training 6.7%: Loss=0.81683, Accuracy=48.000%, MSE=0.445831
[2023-08-18-10:12:56] [6/10] training 10.0%: Loss=0.799753, Accuracy=48.333%, MSE=0.437025
[2023-08-18-10:12:58] [6/10] training 13.3%: Loss=0.761912, Accuracy=48.750%, MSE=0.419726
[2023-08-18-10:13:01] [6/10] training 16.7%: Loss=0.733105, Accuracy=49.600%, MSE=0.403187
[2023-08-18-10:13:03] [6/10] training 20.0%: Loss=0.710445, Accuracy=50.167%, MSE=0.392869
[2023-08-18-10:13:05] [6/10] training 23.3%: Loss=0.686662, Accuracy=51.571%, MSE=0.376802
[2023-08-18-10:13:08] [6/10] training 26.7%: Loss=0.683173, Accuracy=51.250%, MSE=0.376833
[2023-08-18-10:13:10] [6/10] training 30.0%: Loss=0.684628, Accuracy=50.333%, MSE=0.381037
[2023-08-18-10:13:12] [6/10] training 33.3%: Loss=0.670818, Accuracy=50.500%, MSE=0.372797
[2023-08-18-10:13:14] [6/10] training 36.7%: Loss=0.658062, Accuracy=51.091%, MSE=0.364102
[2023-08-18-10:13:17] [6/10] training 40.0%: Loss=0.642955, Accuracy=52.167%, MSE=0.353925
[2023-08-18-10:13:19] [6/10] training 43.3%: Loss=0.640987, Accuracy=52.000%, MSE=0.353284
[2023-08-18-10:13:21] [6/10] training 46.7%: Loss=0.634608, Accuracy=52.571%, MSE=0.348932
[2023-08-18-10:13:23] [6/10] training 50.0%: Loss=0.636521, Accuracy=52.333%, MSE=0.3502
[2023-08-18-10:13:26] [6/10] training 53.3%: Loss=0.64085, Accuracy=52.062%, MSE=0.352761
[2023-08-18-10:13:28] [6/10] training 56.7%: Loss=0.645807, Accuracy=51.588%, MSE=0.355941
[2023-08-18-10:13:30] [6/10] training 60.0%: Loss=0.646685, Accuracy=51.333%, MSE=0.357632
[2023-08-18-10:13:33] [6/10] training 63.3%: Loss=0.64609, Accuracy=51.211%, MSE=0.35845
[2023-08-18-10:13:35] [6/10] training 66.7%: Loss=0.644947, Accuracy=50.800%, MSE=0.359075
[2023-08-18-10:13:37] [6/10] training 70.0%: Loss=0.640707, Accuracy=50.952%, MSE=0.356798
[2023-08-18-10:13:39] [6/10] training 73.3%: Loss=0.639255, Accuracy=50.909%, MSE=0.356794
[2023-08-18-10:13:41] [6/10] training 76.7%: Loss=0.638649, Accuracy=51.000%, MSE=0.356307
[2023-08-18-10:13:44] [6/10] training 80.0%: Loss=0.635011, Accuracy=51.583%, MSE=0.352767
[2023-08-18-10:13:46] [6/10] training 83.3%: Loss=0.63105, Accuracy=52.120%, MSE=0.349125
[2023-08-18-10:13:48] [6/10] training 86.7%: Loss=0.638458, Accuracy=51.962%, MSE=0.353476
[2023-08-18-10:13:50] [6/10] training 90.0%: Loss=0.646297, Accuracy=51.852%, MSE=0.357243
[2023-08-18-10:13:52] [6/10] training 93.3%: Loss=0.654222, Accuracy=51.714%, MSE=0.361034
[2023-08-18-10:13:54] [6/10] training 96.7%: Loss=0.656849, Accuracy=51.828%, MSE=0.36181
[2023-08-18-10:14:03] Finished Epoch 6/10: Loss=1.4969, Accuracy=50.000%, MSE=0.394299, Precision=0.616115, Recall=0.129757, F1=0.214367, AUPR=0.615699
[2023-08-18-10:14:03] Saving model to ./models/huang_0_1_dscript_partitions_epoch06.sav
[2023-08-18-10:14:06] [7/10] training 3.3%: Loss=0.800718, Accuracy=42.000%, MSE=0.459151
[2023-08-18-10:14:08] [7/10] training 6.7%: Loss=0.737054, Accuracy=43.500%, MSE=0.42415
[2023-08-18-10:14:11] [7/10] training 10.0%: Loss=0.686059, Accuracy=43.667%, MSE=0.400744
[2023-08-18-10:14:13] [7/10] training 13.3%: Loss=0.651849, Accuracy=47.000%, MSE=0.376229
[2023-08-18-10:14:15] [7/10] training 16.7%: Loss=0.628107, Accuracy=49.600%, MSE=0.356913
[2023-08-18-10:14:17] [7/10] training 20.0%: Loss=0.605492, Accuracy=51.333%, MSE=0.340506
[2023-08-18-10:14:19] [7/10] training 23.3%: Loss=0.598708, Accuracy=52.143%, MSE=0.335038
[2023-08-18-10:14:22] [7/10] training 26.7%: Loss=0.602833, Accuracy=51.000%, MSE=0.340039
[2023-08-18-10:14:24] [7/10] training 30.0%: Loss=0.612631, Accuracy=50.556%, MSE=0.346622
[2023-08-18-10:14:26] [7/10] training 33.3%: Loss=0.61533, Accuracy=49.900%, MSE=0.349754
[2023-08-18-10:14:28] [7/10] training 36.7%: Loss=0.607381, Accuracy=50.182%, MSE=0.345229
[2023-08-18-10:14:30] [7/10] training 40.0%: Loss=0.596866, Accuracy=51.417%, MSE=0.336969
[2023-08-18-10:14:32] [7/10] training 43.3%: Loss=0.586102, Accuracy=53.231%, MSE=0.325917
[2023-08-18-10:14:35] [7/10] training 46.7%: Loss=0.601198, Accuracy=53.286%, MSE=0.331661
[2023-08-18-10:14:37] [7/10] training 50.0%: Loss=0.628637, Accuracy=52.467%, MSE=0.346725
[2023-08-18-10:14:39] [7/10] training 53.3%: Loss=0.649708, Accuracy=52.000%, MSE=0.357572
[2023-08-18-10:14:41] [7/10] training 56.7%: Loss=0.659734, Accuracy=52.294%, MSE=0.360527
[2023-08-18-10:14:43] [7/10] training 60.0%: Loss=0.676272, Accuracy=52.000%, MSE=0.368499
[2023-08-18-10:14:46] [7/10] training 63.3%: Loss=0.686737, Accuracy=52.053%, MSE=0.372525
[2023-08-18-10:14:48] [7/10] training 66.7%: Loss=0.698844, Accuracy=51.950%, MSE=0.377702
[2023-08-18-10:14:50] [7/10] training 70.0%: Loss=0.716967, Accuracy=51.333%, MSE=0.387381
[2023-08-18-10:14:53] [7/10] training 73.3%: Loss=0.726118, Accuracy=51.318%, MSE=0.390944
[2023-08-18-10:14:55] [7/10] training 76.7%: Loss=0.737381, Accuracy=51.000%, MSE=0.396871
[2023-08-18-10:14:57] [7/10] training 80.0%: Loss=0.737626, Accuracy=51.375%, MSE=0.39579
[2023-08-18-10:14:59] [7/10] training 83.3%: Loss=0.740499, Accuracy=51.600%, MSE=0.396192
[2023-08-18-10:15:02] [7/10] training 86.7%: Loss=0.744468, Accuracy=51.692%, MSE=0.397571
[2023-08-18-10:15:04] [7/10] training 90.0%: Loss=0.75145, Accuracy=51.519%, MSE=0.401318
[2023-08-18-10:15:06] [7/10] training 93.3%: Loss=0.757193, Accuracy=51.429%, MSE=0.404093
[2023-08-18-10:15:09] [7/10] training 96.7%: Loss=0.760472, Accuracy=51.586%, MSE=0.404602
[2023-08-18-10:15:18] Finished Epoch 7/10: Loss=2.79911, Accuracy=49.583%, MSE=0.492165, Precision=0.462799, Recall=0.00819038, F1=0.0160959, AUPR=0.46414
[2023-08-18-10:15:18] Saving model to ./models/huang_0_1_dscript_partitions_epoch07.sav
[2023-08-18-10:15:21] [8/10] training 3.3%: Loss=0.857458, Accuracy=54.000%, MSE=0.434073
[2023-08-18-10:15:23] [8/10] training 6.7%: Loss=0.88066, Accuracy=51.500%, MSE=0.455666
[2023-08-18-10:15:26] [8/10] training 10.0%: Loss=0.854941, Accuracy=53.333%, MSE=0.43846
[2023-08-18-10:15:28] [8/10] training 13.3%: Loss=0.876577, Accuracy=52.000%, MSE=0.451842
[2023-08-18-10:15:30] [8/10] training 16.7%: Loss=0.875291, Accuracy=52.200%, MSE=0.450291
[2023-08-18-10:15:33] [8/10] training 20.0%: Loss=0.866979, Accuracy=52.500%, MSE=0.44692
[2023-08-18-10:15:35] [8/10] training 23.3%: Loss=0.887895, Accuracy=50.571%, MSE=0.464353
[2023-08-18-10:15:38] [8/10] training 26.7%: Loss=0.892787, Accuracy=49.750%, MSE=0.470766
[2023-08-18-10:15:40] [8/10] training 30.0%: Loss=0.902305, Accuracy=48.889%, MSE=0.478419
[2023-08-18-10:15:42] [8/10] training 33.3%: Loss=0.905344, Accuracy=48.700%, MSE=0.480387
[2023-08-18-10:15:44] [8/10] training 36.7%: Loss=0.895323, Accuracy=49.182%, MSE=0.474842
[2023-08-18-10:15:47] [8/10] training 40.0%: Loss=0.888778, Accuracy=49.500%, MSE=0.471201
[2023-08-18-10:15:49] [8/10] training 43.3%: Loss=0.881816, Accuracy=49.923%, MSE=0.466872
[2023-08-18-10:15:51] [8/10] training 46.7%: Loss=0.871939, Accuracy=50.714%, MSE=0.459447
[2023-08-18-10:15:53] [8/10] training 50.0%: Loss=0.870637, Accuracy=50.533%, MSE=0.460009
[2023-08-18-10:15:55] [8/10] training 53.3%: Loss=0.87132, Accuracy=50.375%, MSE=0.461269
[2023-08-18-10:15:57] [8/10] training 56.7%: Loss=0.872959, Accuracy=50.059%, MSE=0.463739
[2023-08-18-10:15:59] [8/10] training 60.0%: Loss=0.870216, Accuracy=50.056%, MSE=0.463216
[2023-08-18-10:16:01] [8/10] training 63.3%: Loss=0.87325, Accuracy=49.842%, MSE=0.465231
[2023-08-18-10:16:04] [8/10] training 66.7%: Loss=0.869347, Accuracy=49.850%, MSE=0.464062
[2023-08-18-10:16:06] [8/10] training 70.0%: Loss=0.864845, Accuracy=50.190%, MSE=0.460798
[2023-08-18-10:16:08] [8/10] training 73.3%: Loss=0.865305, Accuracy=50.091%, MSE=0.461535
[2023-08-18-10:16:11] [8/10] training 76.7%: Loss=0.869419, Accuracy=49.696%, MSE=0.465125
[2023-08-18-10:16:13] [8/10] training 80.0%: Loss=0.869493, Accuracy=49.542%, MSE=0.466237
[2023-08-18-10:16:15] [8/10] training 83.3%: Loss=0.865056, Accuracy=49.760%, MSE=0.463865
[2023-08-18-10:16:18] [8/10] training 86.7%: Loss=0.861413, Accuracy=49.923%, MSE=0.462005
[2023-08-18-10:16:20] [8/10] training 90.0%: Loss=0.860315, Accuracy=49.926%, MSE=0.461509
[2023-08-18-10:16:22] [8/10] training 93.3%: Loss=0.856512, Accuracy=50.179%, MSE=0.459035
[2023-08-18-10:16:24] [8/10] training 96.7%: Loss=0.855611, Accuracy=50.103%, MSE=0.459311
[2023-08-18-10:16:32] Finished Epoch 8/10: Loss=2.7952, Accuracy=49.583%, MSE=0.492529, Precision=0.409624, Recall=0.00793357, F1=0.0155657, AUPR=0.447768
[2023-08-18-10:16:32] Saving model to ./models/huang_0_1_dscript_partitions_epoch08.sav
[2023-08-18-10:16:35] [9/10] training 3.3%: Loss=0.821844, Accuracy=49.000%, MSE=0.458626
[2023-08-18-10:16:37] [9/10] training 6.7%: Loss=0.827717, Accuracy=48.000%, MSE=0.4653
[2023-08-18-10:16:39] [9/10] training 10.0%: Loss=0.804563, Accuracy=50.333%, MSE=0.444992
[2023-08-18-10:16:41] [9/10] training 13.3%: Loss=0.804955, Accuracy=50.000%, MSE=0.448125
[2023-08-18-10:16:44] [9/10] training 16.7%: Loss=0.80083, Accuracy=50.200%, MSE=0.445725
[2023-08-18-10:16:46] [9/10] training 20.0%: Loss=0.810883, Accuracy=48.500%, MSE=0.457685
[2023-08-18-10:16:48] [9/10] training 23.3%: Loss=0.806503, Accuracy=48.857%, MSE=0.454712
[2023-08-18-10:16:50] [9/10] training 26.7%: Loss=0.789643, Accuracy=50.375%, MSE=0.440996
[2023-08-18-10:16:52] [9/10] training 30.0%: Loss=0.77048, Accuracy=51.778%, MSE=0.426969
[2023-08-18-10:16:55] [9/10] training 33.3%: Loss=0.773655, Accuracy=51.400%, MSE=0.43016
[2023-08-18-10:16:57] [9/10] training 36.7%: Loss=0.777244, Accuracy=50.909%, MSE=0.433794
[2023-08-18-10:16:59] [9/10] training 40.0%: Loss=0.767169, Accuracy=51.417%, MSE=0.427617
[2023-08-18-10:17:02] [9/10] training 43.3%: Loss=0.767328, Accuracy=51.231%, MSE=0.428729
[2023-08-18-10:17:04] [9/10] training 46.7%: Loss=0.762063, Accuracy=51.786%, MSE=0.424033
[2023-08-18-10:17:06] [9/10] training 50.0%: Loss=0.764363, Accuracy=51.467%, MSE=0.426436
[2023-08-18-10:17:09] [9/10] training 53.3%: Loss=0.768945, Accuracy=51.062%, MSE=0.43031
[2023-08-18-10:17:11] [9/10] training 56.7%: Loss=0.76979, Accuracy=50.941%, MSE=0.431261
[2023-08-18-10:17:13] [9/10] training 60.0%: Loss=0.767358, Accuracy=51.111%, MSE=0.429681
[2023-08-18-10:17:16] [9/10] training 63.3%: Loss=0.767199, Accuracy=50.895%, MSE=0.431004
[2023-08-18-10:17:18] [9/10] training 66.7%: Loss=0.763586, Accuracy=51.150%, MSE=0.428414
[2023-08-18-10:17:20] [9/10] training 70.0%: Loss=0.762715, Accuracy=51.190%, MSE=0.428055
[2023-08-18-10:17:22] [9/10] training 73.3%: Loss=0.763838, Accuracy=50.864%, MSE=0.430345
[2023-08-18-10:17:25] [9/10] training 76.7%: Loss=0.765958, Accuracy=50.565%, MSE=0.432603
[2023-08-18-10:17:27] [9/10] training 80.0%: Loss=0.768369, Accuracy=50.292%, MSE=0.434933
[2023-08-18-10:17:29] [9/10] training 83.3%: Loss=0.766613, Accuracy=50.280%, MSE=0.434212
[2023-08-18-10:17:31] [9/10] training 86.7%: Loss=0.7703, Accuracy=49.962%, MSE=0.437252
[2023-08-18-10:17:33] [9/10] training 90.0%: Loss=0.770112, Accuracy=49.778%, MSE=0.438255
[2023-08-18-10:17:36] [9/10] training 93.3%: Loss=0.765291, Accuracy=50.143%, MSE=0.43485
[2023-08-18-10:17:38] [9/10] training 96.7%: Loss=0.765124, Accuracy=50.069%, MSE=0.435403
[2023-08-18-10:17:47] Finished Epoch 9/10: Loss=2.76997, Accuracy=49.583%, MSE=0.491916, Precision=0.422869, Recall=0.0086034, F1=0.0168637, AUPR=0.452265
[2023-08-18-10:17:47] Saving model to ./models/huang_0_1_dscript_partitions_epoch09.sav
[2023-08-18-10:17:49] [10/10] training 3.3%: Loss=0.786309, Accuracy=44.000%, MSE=0.47597
[2023-08-18-10:17:52] [10/10] training 6.7%: Loss=0.78239, Accuracy=44.500%, MSE=0.468979
[2023-08-18-10:17:54] [10/10] training 10.0%: Loss=0.768048, Accuracy=46.333%, MSE=0.455853
[2023-08-18-10:17:56] [10/10] training 13.3%: Loss=0.761759, Accuracy=47.000%, MSE=0.451219
[2023-08-18-10:17:58] [10/10] training 16.7%: Loss=0.737837, Accuracy=48.800%, MSE=0.432875
[2023-08-18-10:18:00] [10/10] training 20.0%: Loss=0.731461, Accuracy=48.833%, MSE=0.430419
[2023-08-18-10:18:03] [10/10] training 23.3%: Loss=0.734477, Accuracy=48.286%, MSE=0.43344
[2023-08-18-10:18:05] [10/10] training 26.7%: Loss=0.718902, Accuracy=49.750%, MSE=0.420427
[2023-08-18-10:18:07] [10/10] training 30.0%: Loss=0.717533, Accuracy=50.111%, MSE=0.418069
[2023-08-18-10:18:10] [10/10] training 33.3%: Loss=0.711631, Accuracy=51.000%, MSE=0.411497
[2023-08-18-10:18:12] [10/10] training 36.7%: Loss=0.712119, Accuracy=51.000%, MSE=0.411915
[2023-08-18-10:18:15] [10/10] training 40.0%: Loss=0.710227, Accuracy=50.750%, MSE=0.412071
[2023-08-18-10:18:17] [10/10] training 43.3%: Loss=0.70559, Accuracy=50.923%, MSE=0.408778
[2023-08-18-10:18:19] [10/10] training 46.7%: Loss=0.701827, Accuracy=51.357%, MSE=0.405296
[2023-08-18-10:18:21] [10/10] training 50.0%: Loss=0.69865, Accuracy=51.600%, MSE=0.403014
[2023-08-18-10:18:24] [10/10] training 53.3%: Loss=0.700277, Accuracy=51.250%, MSE=0.405343
[2023-08-18-10:18:25] [10/10] training 56.7%: Loss=0.700172, Accuracy=51.176%, MSE=0.405981
[2023-08-18-10:18:27] [10/10] training 60.0%: Loss=0.702275, Accuracy=50.722%, MSE=0.408928
[2023-08-18-10:18:30] [10/10] training 63.3%: Loss=0.704651, Accuracy=50.316%, MSE=0.41182
[2023-08-18-10:18:32] [10/10] training 66.7%: Loss=0.704065, Accuracy=50.500%, MSE=0.410695
[2023-08-18-10:18:34] [10/10] training 70.0%: Loss=0.701783, Accuracy=50.524%, MSE=0.409457
[2023-08-18-10:18:36] [10/10] training 73.3%: Loss=0.699631, Accuracy=50.636%, MSE=0.408164
[2023-08-18-10:18:39] [10/10] training 76.7%: Loss=0.699291, Accuracy=50.435%, MSE=0.408921
[2023-08-18-10:18:41] [10/10] training 80.0%: Loss=0.700994, Accuracy=50.125%, MSE=0.410876
[2023-08-18-10:18:43] [10/10] training 83.3%: Loss=0.702543, Accuracy=49.840%, MSE=0.412798
[2023-08-18-10:18:46] [10/10] training 86.7%: Loss=0.702665, Accuracy=49.808%, MSE=0.412944
[2023-08-18-10:18:48] [10/10] training 90.0%: Loss=0.701195, Accuracy=49.815%, MSE=0.412177
[2023-08-18-10:18:50] [10/10] training 93.3%: Loss=0.699367, Accuracy=50.000%, MSE=0.410646
[2023-08-18-10:18:52] [10/10] training 96.7%: Loss=0.699906, Accuracy=49.897%, MSE=0.411374
[2023-08-18-10:19:02] Finished Epoch 10/10: Loss=2.12841, Accuracy=49.833%, MSE=0.471769, Precision=0.510604, Recall=0.0326458, F1=0.061368, AUPR=0.51041
[2023-08-18-10:19:02] Saving model to ./models/huang_0_1_dscript_partitions_epoch10.sav
[2023-08-18-10:19:02] Saving final model to ./models/huang_0_1_dscript_partitions_final.sav
