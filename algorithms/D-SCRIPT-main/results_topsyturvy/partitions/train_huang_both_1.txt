[2023-04-27-11:14:17] D-SCRIPT Version 0.2.2
[2023-04-27-11:14:17] Called as: /nfs/home/students/jbernett/.conda/envs/dscript2/bin/dscript train --topsy-turvy --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_1.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_1_tt_partitions -o ./results_topsyturvy/partitions/train_huang_both_1.txt -d 2
[2023-04-27-11:14:17] Using CUDA device 2 - NVIDIA A40
[2023-04-27-11:14:17] Loaded 4136 training pairs
[2023-04-27-11:14:17] Loaded 1190 test pairs
[2023-04-27-11:14:17] Loading embeddings...
[2023-04-27-11:14:39] Running D-SCRIPT Topsy-Turvy:
[2023-04-27-11:14:39] 	glider_weight: 0.2
[2023-04-27-11:14:39] 	glider_thresh: 92.5th percentile
[2023-04-27-11:14:39] Computing GLIDER matrix...
[2023-04-27-11:14:42] Initializing embedding model with:
[2023-04-27-11:14:42] 	projection_dim: 100
[2023-04-27-11:14:42] 	dropout_p: 0.5
[2023-04-27-11:14:42] Initializing contact model with:
[2023-04-27-11:14:42] 	hidden_dim: 50
[2023-04-27-11:14:42] 	kernel_width: 7
[2023-04-27-11:14:42] Initializing interaction model with:
[2023-04-27-11:14:42] 	do_poool: False
[2023-04-27-11:14:42] 	pool_width: 9
[2023-04-27-11:14:42] 	do_w: True
[2023-04-27-11:14:42] 	do_sigmoid: True
[2023-04-27-11:14:42] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-04-27-11:14:44] Using save prefix "./models/huang_both_1_tt_partitions"
[2023-04-27-11:14:44] Training with Adam: lr=0.001, weight_decay=0
[2023-04-27-11:14:44] 	num_epochs: 10
[2023-04-27-11:14:44] 	batch_size: 25
[2023-04-27-11:14:44] 	interaction weight: 0.35
[2023-04-27-11:14:44] 	contact map weight: 0.65
[2023-04-27-11:14:47] [1/10] training 2.4%: Loss=1.4291, Accuracy=51.000%, MSE=0.488353
[2023-04-27-11:14:49] [1/10] training 4.8%: Loss=1.34306, Accuracy=53.500%, MSE=0.46306
[2023-04-27-11:14:52] [1/10] training 7.2%: Loss=1.34546, Accuracy=53.333%, MSE=0.464691
[2023-04-27-11:14:54] [1/10] training 9.6%: Loss=1.37244, Accuracy=51.500%, MSE=0.482745
[2023-04-27-11:14:56] [1/10] training 12.0%: Loss=1.38679, Accuracy=50.200%, MSE=0.495332
[2023-04-27-11:14:58] [1/10] training 14.5%: Loss=1.38469, Accuracy=50.167%, MSE=0.495644
[2023-04-27-11:15:00] [1/10] training 16.9%: Loss=1.38055, Accuracy=50.143%, MSE=0.495835
[2023-04-27-11:15:02] [1/10] training 19.3%: Loss=1.36604, Accuracy=50.625%, MSE=0.490969
[2023-04-27-11:15:04] [1/10] training 21.7%: Loss=1.36025, Accuracy=50.444%, MSE=0.492586
[2023-04-27-11:15:06] [1/10] training 24.1%: Loss=1.3619, Accuracy=50.200%, MSE=0.49495
[2023-04-27-11:15:09] [1/10] training 26.5%: Loss=1.36059, Accuracy=50.091%, MSE=0.495988
[2023-04-27-11:15:11] [1/10] training 28.9%: Loss=1.3391, Accuracy=50.833%, MSE=0.488484
[2023-04-27-11:15:13] [1/10] training 31.3%: Loss=1.35317, Accuracy=50.077%, MSE=0.495999
[2023-04-27-11:15:15] [1/10] training 33.7%: Loss=1.35823, Accuracy=49.571%, MSE=0.500919
[2023-04-27-11:15:17] [1/10] training 36.1%: Loss=1.34548, Accuracy=50.000%, MSE=0.496594
[2023-04-27-11:15:19] [1/10] training 38.6%: Loss=1.3472, Accuracy=49.750%, MSE=0.499006
[2023-04-27-11:15:21] [1/10] training 41.0%: Loss=1.33569, Accuracy=50.118%, MSE=0.495274
[2023-04-27-11:15:23] [1/10] training 43.4%: Loss=1.33057, Accuracy=50.167%, MSE=0.494708
[2023-04-27-11:15:25] [1/10] training 45.8%: Loss=1.32756, Accuracy=50.211%, MSE=0.494248
[2023-04-27-11:15:27] [1/10] training 48.2%: Loss=1.32784, Accuracy=50.050%, MSE=0.495776
[2023-04-27-11:15:29] [1/10] training 50.6%: Loss=1.32335, Accuracy=50.095%, MSE=0.495262
[2023-04-27-11:15:32] [1/10] training 53.0%: Loss=1.32067, Accuracy=50.091%, MSE=0.495251
[2023-04-27-11:15:33] [1/10] training 55.4%: Loss=1.31847, Accuracy=50.000%, MSE=0.496042
[2023-04-27-11:15:36] [1/10] training 57.8%: Loss=1.31374, Accuracy=50.000%, MSE=0.49592
[2023-04-27-11:15:38] [1/10] training 60.2%: Loss=1.30781, Accuracy=50.160%, MSE=0.494255
[2023-04-27-11:15:40] [1/10] training 62.7%: Loss=1.30635, Accuracy=50.077%, MSE=0.495017
[2023-04-27-11:15:42] [1/10] training 65.1%: Loss=1.30202, Accuracy=50.111%, MSE=0.49458
[2023-04-27-11:15:44] [1/10] training 67.5%: Loss=1.29862, Accuracy=50.071%, MSE=0.494865
[2023-04-27-11:15:46] [1/10] training 69.9%: Loss=1.29524, Accuracy=50.034%, MSE=0.495108
[2023-04-27-11:15:48] [1/10] training 72.3%: Loss=1.29449, Accuracy=49.967%, MSE=0.495738
[2023-04-27-11:15:50] [1/10] training 74.7%: Loss=1.29197, Accuracy=49.871%, MSE=0.496537
[2023-04-27-11:15:52] [1/10] training 77.1%: Loss=1.29443, Accuracy=49.594%, MSE=0.499209
[2023-04-27-11:15:55] [1/10] training 79.5%: Loss=1.29419, Accuracy=49.394%, MSE=0.501068
[2023-04-27-11:15:57] [1/10] training 81.9%: Loss=1.29221, Accuracy=49.324%, MSE=0.501665
[2023-04-27-11:15:59] [1/10] training 84.3%: Loss=1.29007, Accuracy=49.257%, MSE=0.502212
[2023-04-27-11:16:01] [1/10] training 86.7%: Loss=1.28632, Accuracy=49.306%, MSE=0.501646
[2023-04-27-11:16:03] [1/10] training 89.2%: Loss=1.28111, Accuracy=49.459%, MSE=0.500057
[2023-04-27-11:16:05] [1/10] training 91.6%: Loss=1.27515, Accuracy=49.605%, MSE=0.498507
[2023-04-27-11:16:07] [1/10] training 94.0%: Loss=1.27096, Accuracy=49.692%, MSE=0.497565
[2023-04-27-11:16:09] [1/10] training 96.4%: Loss=1.26453, Accuracy=49.875%, MSE=0.495652
[2023-04-27-11:16:11] [1/10] training 98.8%: Loss=1.25933, Accuracy=50.024%, MSE=0.494106
[2023-04-27-11:16:22] Finished Epoch 1/10: Loss=2.39807, Accuracy=49.583%, MSE=0.489344, Precision=0.437975, Recall=0.0108817, F1=0.0212358, AUPR=0.427428
[2023-04-27-11:16:22] Saving model to ./models/huang_both_1_tt_partitions_epoch01.sav
[2023-04-27-11:16:25] [2/10] training 2.4%: Loss=1.26885, Accuracy=41.000%, MSE=0.578165
[2023-04-27-11:16:26] [2/10] training 4.8%: Loss=1.25077, Accuracy=43.000%, MSE=0.559235
[2023-04-27-11:16:28] [2/10] training 7.2%: Loss=1.16659, Accuracy=47.667%, MSE=0.513032
[2023-04-27-11:16:30] [2/10] training 9.6%: Loss=1.19064, Accuracy=46.000%, MSE=0.529176
[2023-04-27-11:16:31] [2/10] training 12.0%: Loss=1.16924, Accuracy=47.400%, MSE=0.515528
[2023-04-27-11:16:33] [2/10] training 14.5%: Loss=1.17048, Accuracy=46.833%, MSE=0.520557
[2023-04-27-11:16:35] [2/10] training 16.9%: Loss=1.18076, Accuracy=46.143%, MSE=0.527329
[2023-04-27-11:16:37] [2/10] training 19.3%: Loss=1.17535, Accuracy=46.375%, MSE=0.524961
[2023-04-27-11:16:39] [2/10] training 21.7%: Loss=1.15909, Accuracy=47.111%, MSE=0.517503
[2023-04-27-11:16:41] [2/10] training 24.1%: Loss=1.15302, Accuracy=47.500%, MSE=0.513655
[2023-04-27-11:16:42] [2/10] training 26.5%: Loss=1.14226, Accuracy=47.818%, MSE=0.51016
[2023-04-27-11:16:44] [2/10] training 28.9%: Loss=1.13549, Accuracy=48.333%, MSE=0.505217
[2023-04-27-11:16:46] [2/10] training 31.3%: Loss=1.1225, Accuracy=49.077%, MSE=0.497818
[2023-04-27-11:16:48] [2/10] training 33.7%: Loss=1.1248, Accuracy=48.786%, MSE=0.500468
[2023-04-27-11:16:50] [2/10] training 36.1%: Loss=1.1204, Accuracy=49.000%, MSE=0.498322
[2023-04-27-11:16:51] [2/10] training 38.6%: Loss=1.11457, Accuracy=49.312%, MSE=0.49521
[2023-04-27-11:16:53] [2/10] training 41.0%: Loss=1.11194, Accuracy=49.235%, MSE=0.495678
[2023-04-27-11:16:55] [2/10] training 43.4%: Loss=1.10702, Accuracy=49.500%, MSE=0.493071
[2023-04-27-11:16:57] [2/10] training 45.8%: Loss=1.10947, Accuracy=49.263%, MSE=0.49535
[2023-04-27-11:16:58] [2/10] training 48.2%: Loss=1.10955, Accuracy=48.950%, MSE=0.49804
[2023-04-27-11:17:00] [2/10] training 50.6%: Loss=1.11387, Accuracy=48.619%, MSE=0.501218
[2023-04-27-11:17:02] [2/10] training 53.0%: Loss=1.10918, Accuracy=48.864%, MSE=0.498741
[2023-04-27-11:17:03] [2/10] training 55.4%: Loss=1.10643, Accuracy=48.913%, MSE=0.498145
[2023-04-27-11:17:05] [2/10] training 57.8%: Loss=1.10087, Accuracy=49.167%, MSE=0.495563
[2023-04-27-11:17:07] [2/10] training 60.2%: Loss=1.0968, Accuracy=49.160%, MSE=0.4953
[2023-04-27-11:17:09] [2/10] training 62.7%: Loss=1.09613, Accuracy=49.231%, MSE=0.494644
[2023-04-27-11:17:10] [2/10] training 65.1%: Loss=1.09235, Accuracy=49.333%, MSE=0.49349
[2023-04-27-11:17:12] [2/10] training 67.5%: Loss=1.08644, Accuracy=49.500%, MSE=0.491581
[2023-04-27-11:17:14] [2/10] training 69.9%: Loss=1.08542, Accuracy=49.552%, MSE=0.491077
[2023-04-27-11:17:16] [2/10] training 72.3%: Loss=1.08007, Accuracy=49.833%, MSE=0.488283
[2023-04-27-11:17:17] [2/10] training 74.7%: Loss=1.07401, Accuracy=50.097%, MSE=0.485598
[2023-04-27-11:17:19] [2/10] training 77.1%: Loss=1.06715, Accuracy=50.344%, MSE=0.482903
[2023-04-27-11:17:21] [2/10] training 79.5%: Loss=1.06602, Accuracy=50.455%, MSE=0.481886
[2023-04-27-11:17:23] [2/10] training 81.9%: Loss=1.06365, Accuracy=50.412%, MSE=0.482042
[2023-04-27-11:17:24] [2/10] training 84.3%: Loss=1.06307, Accuracy=50.314%, MSE=0.482823
[2023-04-27-11:17:26] [2/10] training 86.7%: Loss=1.06236, Accuracy=50.306%, MSE=0.482863
[2023-04-27-11:17:28] [2/10] training 89.2%: Loss=1.0605, Accuracy=50.297%, MSE=0.482787
[2023-04-27-11:17:30] [2/10] training 91.6%: Loss=1.05861, Accuracy=50.263%, MSE=0.482915
[2023-04-27-11:17:31] [2/10] training 94.0%: Loss=1.0568, Accuracy=50.308%, MSE=0.482419
[2023-04-27-11:17:33] [2/10] training 96.4%: Loss=1.05859, Accuracy=50.000%, MSE=0.485134
[2023-04-27-11:17:35] [2/10] training 98.8%: Loss=1.05857, Accuracy=49.902%, MSE=0.485976
[2023-04-27-11:17:42] Finished Epoch 2/10: Loss=1.99534, Accuracy=49.583%, MSE=0.477759, Precision=0.420078, Recall=0.0234446, F1=0.0444106, AUPR=0.40771
[2023-04-27-11:17:42] Saving model to ./models/huang_both_1_tt_partitions_epoch02.sav
[2023-04-27-11:17:44] [3/10] training 2.4%: Loss=0.946948, Accuracy=52.000%, MSE=0.459179
[2023-04-27-11:17:46] [3/10] training 4.8%: Loss=0.96284, Accuracy=51.500%, MSE=0.465615
[2023-04-27-11:17:48] [3/10] training 7.2%: Loss=0.987746, Accuracy=49.000%, MSE=0.488281
[2023-04-27-11:17:49] [3/10] training 9.6%: Loss=0.973775, Accuracy=50.000%, MSE=0.478873
[2023-04-27-11:17:51] [3/10] training 12.0%: Loss=0.951348, Accuracy=51.200%, MSE=0.466678
[2023-04-27-11:17:53] [3/10] training 14.5%: Loss=0.960616, Accuracy=50.667%, MSE=0.4721
[2023-04-27-11:17:55] [3/10] training 16.9%: Loss=0.975054, Accuracy=49.571%, MSE=0.482448
[2023-04-27-11:17:56] [3/10] training 19.3%: Loss=0.972554, Accuracy=49.500%, MSE=0.482504
[2023-04-27-11:17:58] [3/10] training 21.7%: Loss=0.975018, Accuracy=49.333%, MSE=0.484128
[2023-04-27-11:18:00] [3/10] training 24.1%: Loss=0.968355, Accuracy=49.600%, MSE=0.481404
[2023-04-27-11:18:02] [3/10] training 26.5%: Loss=0.97055, Accuracy=49.273%, MSE=0.484235
[2023-04-27-11:18:03] [3/10] training 28.9%: Loss=0.976552, Accuracy=48.750%, MSE=0.489087
[2023-04-27-11:18:05] [3/10] training 31.3%: Loss=0.967, Accuracy=49.385%, MSE=0.482882
[2023-04-27-11:18:06] [3/10] training 33.7%: Loss=0.967712, Accuracy=49.214%, MSE=0.484183
[2023-04-27-11:18:08] [3/10] training 36.1%: Loss=0.963859, Accuracy=49.600%, MSE=0.480672
[2023-04-27-11:18:10] [3/10] training 38.6%: Loss=0.96195, Accuracy=49.438%, MSE=0.481602
[2023-04-27-11:18:12] [3/10] training 41.0%: Loss=0.959152, Accuracy=49.588%, MSE=0.480073
[2023-04-27-11:18:14] [3/10] training 43.4%: Loss=0.947589, Accuracy=50.389%, MSE=0.472566
[2023-04-27-11:18:16] [3/10] training 45.8%: Loss=0.943317, Accuracy=50.474%, MSE=0.471324
[2023-04-27-11:18:17] [3/10] training 48.2%: Loss=0.942016, Accuracy=50.450%, MSE=0.471335
[2023-04-27-11:18:19] [3/10] training 50.6%: Loss=0.935843, Accuracy=50.810%, MSE=0.467778
[2023-04-27-11:18:21] [3/10] training 53.0%: Loss=0.932509, Accuracy=50.818%, MSE=0.467333
[2023-04-27-11:18:23] [3/10] training 55.4%: Loss=0.934035, Accuracy=50.652%, MSE=0.468823
[2023-04-27-11:18:25] [3/10] training 57.8%: Loss=0.934006, Accuracy=50.583%, MSE=0.469312
[2023-04-27-11:18:26] [3/10] training 60.2%: Loss=0.936347, Accuracy=50.440%, MSE=0.470769
[2023-04-27-11:18:28] [3/10] training 62.7%: Loss=0.931918, Accuracy=50.615%, MSE=0.468767
[2023-04-27-11:18:30] [3/10] training 65.1%: Loss=0.935352, Accuracy=50.407%, MSE=0.47083
[2023-04-27-11:18:32] [3/10] training 67.5%: Loss=0.934762, Accuracy=50.357%, MSE=0.471102
[2023-04-27-11:18:33] [3/10] training 69.9%: Loss=0.936979, Accuracy=50.000%, MSE=0.474085
[2023-04-27-11:18:35] [3/10] training 72.3%: Loss=0.939532, Accuracy=49.800%, MSE=0.475826
[2023-04-27-11:18:37] [3/10] training 74.7%: Loss=0.935492, Accuracy=50.032%, MSE=0.473588
[2023-04-27-11:18:38] [3/10] training 77.1%: Loss=0.932408, Accuracy=49.969%, MSE=0.473325
[2023-04-27-11:18:40] [3/10] training 79.5%: Loss=0.931402, Accuracy=50.152%, MSE=0.471749
[2023-04-27-11:18:41] [3/10] training 81.9%: Loss=0.928421, Accuracy=50.382%, MSE=0.46957
[2023-04-27-11:18:43] [3/10] training 84.3%: Loss=0.925086, Accuracy=50.457%, MSE=0.468504
[2023-04-27-11:18:45] [3/10] training 86.7%: Loss=0.927798, Accuracy=50.250%, MSE=0.470446
[2023-04-27-11:18:47] [3/10] training 89.2%: Loss=0.928604, Accuracy=50.081%, MSE=0.471756
[2023-04-27-11:18:49] [3/10] training 91.6%: Loss=0.925069, Accuracy=50.132%, MSE=0.47071
[2023-04-27-11:18:51] [3/10] training 94.0%: Loss=0.923964, Accuracy=50.205%, MSE=0.47008
[2023-04-27-11:18:52] [3/10] training 96.4%: Loss=0.923932, Accuracy=50.025%, MSE=0.471373
[2023-04-27-11:18:54] [3/10] training 98.8%: Loss=0.923256, Accuracy=49.976%, MSE=0.471663
[2023-04-27-11:19:01] Finished Epoch 3/10: Loss=1.82461, Accuracy=49.083%, MSE=0.470491, Precision=0.320486, Recall=0.0414493, F1=0.0734049, AUPR=0.37467
[2023-04-27-11:19:01] Saving model to ./models/huang_both_1_tt_partitions_epoch03.sav
[2023-04-27-11:19:03] [4/10] training 2.4%: Loss=0.834679, Accuracy=50.000%, MSE=0.456853
[2023-04-27-11:19:05] [4/10] training 4.8%: Loss=0.857288, Accuracy=48.000%, MSE=0.475203
[2023-04-27-11:19:07] [4/10] training 7.2%: Loss=0.864818, Accuracy=48.333%, MSE=0.473968
[2023-04-27-11:19:09] [4/10] training 9.6%: Loss=0.848955, Accuracy=50.500%, MSE=0.456149
[2023-04-27-11:19:10] [4/10] training 12.0%: Loss=0.854673, Accuracy=48.800%, MSE=0.468306
[2023-04-27-11:19:12] [4/10] training 14.5%: Loss=0.867525, Accuracy=48.167%, MSE=0.475484
[2023-04-27-11:19:14] [4/10] training 16.9%: Loss=0.879822, Accuracy=47.143%, MSE=0.485254
[2023-04-27-11:19:16] [4/10] training 19.3%: Loss=0.875369, Accuracy=47.000%, MSE=0.48517
[2023-04-27-11:19:18] [4/10] training 21.7%: Loss=0.877091, Accuracy=47.667%, MSE=0.48068
[2023-04-27-11:19:20] [4/10] training 24.1%: Loss=0.883592, Accuracy=47.700%, MSE=0.481685
[2023-04-27-11:19:21] [4/10] training 26.5%: Loss=0.877844, Accuracy=47.636%, MSE=0.480402
[2023-04-27-11:19:23] [4/10] training 28.9%: Loss=0.877863, Accuracy=47.500%, MSE=0.481337
[2023-04-27-11:19:25] [4/10] training 31.3%: Loss=0.88777, Accuracy=47.077%, MSE=0.485841
[2023-04-27-11:19:27] [4/10] training 33.7%: Loss=0.879906, Accuracy=47.429%, MSE=0.482008
[2023-04-27-11:19:28] [4/10] training 36.1%: Loss=0.873689, Accuracy=47.867%, MSE=0.477504
[2023-04-27-11:19:30] [4/10] training 38.6%: Loss=0.872814, Accuracy=48.063%, MSE=0.476262
[2023-04-27-11:19:32] [4/10] training 41.0%: Loss=0.867407, Accuracy=48.235%, MSE=0.473913
[2023-04-27-11:19:34] [4/10] training 43.4%: Loss=0.85576, Accuracy=49.000%, MSE=0.466552
[2023-04-27-11:19:35] [4/10] training 45.8%: Loss=0.851092, Accuracy=49.053%, MSE=0.465155
[2023-04-27-11:19:37] [4/10] training 48.2%: Loss=0.8462, Accuracy=49.550%, MSE=0.460726
[2023-04-27-11:19:38] [4/10] training 50.6%: Loss=0.840536, Accuracy=49.952%, MSE=0.456851
[2023-04-27-11:19:40] [4/10] training 53.0%: Loss=0.840626, Accuracy=49.773%, MSE=0.457982
[2023-04-27-11:19:42] [4/10] training 55.4%: Loss=0.839871, Accuracy=49.739%, MSE=0.458185
[2023-04-27-11:19:44] [4/10] training 57.8%: Loss=0.834149, Accuracy=50.083%, MSE=0.454677
[2023-04-27-11:19:45] [4/10] training 60.2%: Loss=0.82933, Accuracy=50.120%, MSE=0.452835
[2023-04-27-11:19:47] [4/10] training 62.7%: Loss=0.831663, Accuracy=49.846%, MSE=0.455211
[2023-04-27-11:19:48] [4/10] training 65.1%: Loss=0.833392, Accuracy=49.778%, MSE=0.455952
[2023-04-27-11:19:50] [4/10] training 67.5%: Loss=0.832467, Accuracy=49.786%, MSE=0.455772
[2023-04-27-11:19:52] [4/10] training 69.9%: Loss=0.831641, Accuracy=49.690%, MSE=0.456281
[2023-04-27-11:19:53] [4/10] training 72.3%: Loss=0.829011, Accuracy=49.767%, MSE=0.455183
[2023-04-27-11:19:55] [4/10] training 74.7%: Loss=0.831927, Accuracy=49.452%, MSE=0.457868
[2023-04-27-11:19:57] [4/10] training 77.1%: Loss=0.834368, Accuracy=49.125%, MSE=0.460335
[2023-04-27-11:19:59] [4/10] training 79.5%: Loss=0.831638, Accuracy=49.273%, MSE=0.458606
[2023-04-27-11:20:01] [4/10] training 81.9%: Loss=0.831998, Accuracy=49.176%, MSE=0.459275
[2023-04-27-11:20:03] [4/10] training 84.3%: Loss=0.831823, Accuracy=49.229%, MSE=0.458943
[2023-04-27-11:20:05] [4/10] training 86.7%: Loss=0.827761, Accuracy=49.361%, MSE=0.456964
[2023-04-27-11:20:06] [4/10] training 89.2%: Loss=0.823196, Accuracy=49.486%, MSE=0.454843
[2023-04-27-11:20:08] [4/10] training 91.6%: Loss=0.8204, Accuracy=49.737%, MSE=0.452626
[2023-04-27-11:20:10] [4/10] training 94.0%: Loss=0.820346, Accuracy=49.692%, MSE=0.452853
[2023-04-27-11:20:12] [4/10] training 96.4%: Loss=0.817004, Accuracy=49.800%, MSE=0.451192
[2023-04-27-11:20:13] [4/10] training 98.8%: Loss=0.815846, Accuracy=49.829%, MSE=0.450738
[2023-04-27-11:20:20] Finished Epoch 4/10: Loss=1.38318, Accuracy=46.833%, MSE=0.430179, Precision=0.372687, Recall=0.108351, F1=0.167891, AUPR=0.398754
[2023-04-27-11:20:20] Saving model to ./models/huang_both_1_tt_partitions_epoch04.sav
[2023-04-27-11:20:23] [5/10] training 2.4%: Loss=0.711757, Accuracy=51.000%, MSE=0.415252
[2023-04-27-11:20:24] [5/10] training 4.8%: Loss=0.662545, Accuracy=55.500%, MSE=0.375512
[2023-04-27-11:20:26] [5/10] training 7.2%: Loss=0.700662, Accuracy=52.667%, MSE=0.404073
[2023-04-27-11:20:27] [5/10] training 9.6%: Loss=0.690299, Accuracy=54.500%, MSE=0.388622
[2023-04-27-11:20:29] [5/10] training 12.0%: Loss=0.722191, Accuracy=51.600%, MSE=0.414547
[2023-04-27-11:20:32] [5/10] training 14.5%: Loss=0.745682, Accuracy=49.667%, MSE=0.432416
[2023-04-27-11:20:33] [5/10] training 16.9%: Loss=0.752567, Accuracy=49.000%, MSE=0.437529
[2023-04-27-11:20:35] [5/10] training 19.3%: Loss=0.742859, Accuracy=49.125%, MSE=0.432182
[2023-04-27-11:20:37] [5/10] training 21.7%: Loss=0.745361, Accuracy=48.889%, MSE=0.433992
[2023-04-27-11:20:38] [5/10] training 24.1%: Loss=0.749873, Accuracy=48.500%, MSE=0.437494
[2023-04-27-11:20:40] [5/10] training 26.5%: Loss=0.754811, Accuracy=48.545%, MSE=0.438161
[2023-04-27-11:20:42] [5/10] training 28.9%: Loss=0.756947, Accuracy=48.500%, MSE=0.439168
[2023-04-27-11:20:44] [5/10] training 31.3%: Loss=0.759222, Accuracy=47.769%, MSE=0.4438
[2023-04-27-11:20:46] [5/10] training 33.7%: Loss=0.766996, Accuracy=47.286%, MSE=0.449016
[2023-04-27-11:20:48] [5/10] training 36.1%: Loss=0.763057, Accuracy=47.800%, MSE=0.445526
[2023-04-27-11:20:49] [5/10] training 38.6%: Loss=0.755863, Accuracy=48.063%, MSE=0.441761
[2023-04-27-11:20:51] [5/10] training 41.0%: Loss=0.755698, Accuracy=48.000%, MSE=0.442172
[2023-04-27-11:20:53] [5/10] training 43.4%: Loss=0.75841, Accuracy=48.278%, MSE=0.441415
[2023-04-27-11:20:55] [5/10] training 45.8%: Loss=0.752212, Accuracy=48.579%, MSE=0.437684
[2023-04-27-11:20:57] [5/10] training 48.2%: Loss=0.751906, Accuracy=48.600%, MSE=0.437089
[2023-04-27-11:20:58] [5/10] training 50.6%: Loss=0.752675, Accuracy=48.619%, MSE=0.436882
[2023-04-27-11:21:00] [5/10] training 53.0%: Loss=0.751081, Accuracy=48.545%, MSE=0.436661
[2023-04-27-11:21:02] [5/10] training 55.4%: Loss=0.749616, Accuracy=48.739%, MSE=0.435453
[2023-04-27-11:21:03] [5/10] training 57.8%: Loss=0.746883, Accuracy=48.750%, MSE=0.434433
[2023-04-27-11:21:05] [5/10] training 60.2%: Loss=0.742007, Accuracy=49.120%, MSE=0.430734
[2023-04-27-11:21:07] [5/10] training 62.7%: Loss=0.74432, Accuracy=49.115%, MSE=0.431401
[2023-04-27-11:21:08] [5/10] training 65.1%: Loss=0.745291, Accuracy=48.926%, MSE=0.432837
[2023-04-27-11:21:10] [5/10] training 67.5%: Loss=0.74314, Accuracy=48.857%, MSE=0.431934
[2023-04-27-11:21:12] [5/10] training 69.9%: Loss=0.742817, Accuracy=48.931%, MSE=0.431321
[2023-04-27-11:21:14] [5/10] training 72.3%: Loss=0.743687, Accuracy=48.900%, MSE=0.431833
[2023-04-27-11:21:15] [5/10] training 74.7%: Loss=0.743723, Accuracy=48.935%, MSE=0.431872
[2023-04-27-11:21:17] [5/10] training 77.1%: Loss=0.73956, Accuracy=49.188%, MSE=0.429123
[2023-04-27-11:21:19] [5/10] training 79.5%: Loss=0.735061, Accuracy=49.364%, MSE=0.426479
[2023-04-27-11:21:20] [5/10] training 81.9%: Loss=0.730966, Accuracy=49.471%, MSE=0.424316
[2023-04-27-11:21:23] [5/10] training 84.3%: Loss=0.734922, Accuracy=49.143%, MSE=0.427348
[2023-04-27-11:21:24] [5/10] training 86.7%: Loss=0.734262, Accuracy=49.028%, MSE=0.427782
[2023-04-27-11:21:26] [5/10] training 89.2%: Loss=0.733636, Accuracy=48.919%, MSE=0.427795
[2023-04-27-11:21:28] [5/10] training 91.6%: Loss=0.732264, Accuracy=49.079%, MSE=0.42648
[2023-04-27-11:21:29] [5/10] training 94.0%: Loss=0.729513, Accuracy=49.231%, MSE=0.424653
[2023-04-27-11:21:31] [5/10] training 96.4%: Loss=0.729929, Accuracy=49.250%, MSE=0.424959
[2023-04-27-11:21:33] [5/10] training 98.8%: Loss=0.728025, Accuracy=49.415%, MSE=0.423593
[2023-04-27-11:21:40] Finished Epoch 5/10: Loss=1.23438, Accuracy=47.000%, MSE=0.403843, Precision=0.439614, Recall=0.145224, F1=0.218325, AUPR=0.442293
[2023-04-27-11:21:40] Saving model to ./models/huang_both_1_tt_partitions_epoch05.sav
[2023-04-27-11:21:42] [6/10] training 2.4%: Loss=0.660057, Accuracy=51.000%, MSE=0.391384
[2023-04-27-11:21:44] [6/10] training 4.8%: Loss=0.67293, Accuracy=48.000%, MSE=0.411404
[2023-04-27-11:21:45] [6/10] training 7.2%: Loss=0.716383, Accuracy=44.667%, MSE=0.44316
[2023-04-27-11:21:48] [6/10] training 9.6%: Loss=0.719275, Accuracy=45.750%, MSE=0.439091
[2023-04-27-11:21:49] [6/10] training 12.0%: Loss=0.695076, Accuracy=47.200%, MSE=0.42179
[2023-04-27-11:21:51] [6/10] training 14.5%: Loss=0.696537, Accuracy=47.667%, MSE=0.42073
[2023-04-27-11:21:53] [6/10] training 16.9%: Loss=0.705474, Accuracy=47.000%, MSE=0.426527
[2023-04-27-11:21:54] [6/10] training 19.3%: Loss=0.704846, Accuracy=47.000%, MSE=0.426577
[2023-04-27-11:21:56] [6/10] training 21.7%: Loss=0.69884, Accuracy=47.111%, MSE=0.422381
[2023-04-27-11:21:58] [6/10] training 24.1%: Loss=0.705269, Accuracy=46.600%, MSE=0.427139
[2023-04-27-11:21:59] [6/10] training 26.5%: Loss=0.717722, Accuracy=46.727%, MSE=0.431357
[2023-04-27-11:22:01] [6/10] training 28.9%: Loss=0.71302, Accuracy=46.583%, MSE=0.429333
[2023-04-27-11:22:03] [6/10] training 31.3%: Loss=0.702966, Accuracy=47.231%, MSE=0.422539
[2023-04-27-11:22:05] [6/10] training 33.7%: Loss=0.698404, Accuracy=47.786%, MSE=0.418858
[2023-04-27-11:22:06] [6/10] training 36.1%: Loss=0.69365, Accuracy=48.000%, MSE=0.415645
[2023-04-27-11:22:08] [6/10] training 38.6%: Loss=0.695124, Accuracy=48.188%, MSE=0.415671
[2023-04-27-11:22:10] [6/10] training 41.0%: Loss=0.694518, Accuracy=48.059%, MSE=0.415709
[2023-04-27-11:22:12] [6/10] training 43.4%: Loss=0.69876, Accuracy=47.667%, MSE=0.41959
[2023-04-27-11:22:14] [6/10] training 45.8%: Loss=0.698926, Accuracy=47.632%, MSE=0.41994
[2023-04-27-11:22:16] [6/10] training 48.2%: Loss=0.692587, Accuracy=47.850%, MSE=0.415694
[2023-04-27-11:22:17] [6/10] training 50.6%: Loss=0.69281, Accuracy=47.762%, MSE=0.416135
[2023-04-27-11:22:19] [6/10] training 53.0%: Loss=0.69187, Accuracy=48.227%, MSE=0.413588
[2023-04-27-11:22:21] [6/10] training 55.4%: Loss=0.69282, Accuracy=48.130%, MSE=0.414523
[2023-04-27-11:22:22] [6/10] training 57.8%: Loss=0.688572, Accuracy=48.333%, MSE=0.411628
[2023-04-27-11:22:24] [6/10] training 60.2%: Loss=0.685572, Accuracy=48.320%, MSE=0.410283
[2023-04-27-11:22:26] [6/10] training 62.7%: Loss=0.684136, Accuracy=48.231%, MSE=0.409919
[2023-04-27-11:22:28] [6/10] training 65.1%: Loss=0.682294, Accuracy=48.370%, MSE=0.40864
[2023-04-27-11:22:30] [6/10] training 67.5%: Loss=0.681749, Accuracy=48.321%, MSE=0.408967
[2023-04-27-11:22:32] [6/10] training 69.9%: Loss=0.681605, Accuracy=48.241%, MSE=0.409124
[2023-04-27-11:22:33] [6/10] training 72.3%: Loss=0.684061, Accuracy=47.967%, MSE=0.411421
[2023-04-27-11:22:35] [6/10] training 74.7%: Loss=0.684123, Accuracy=48.161%, MSE=0.410669
[2023-04-27-11:22:36] [6/10] training 77.1%: Loss=0.680001, Accuracy=48.312%, MSE=0.408043
[2023-04-27-11:22:38] [6/10] training 79.5%: Loss=0.677831, Accuracy=48.545%, MSE=0.406063
[2023-04-27-11:22:40] [6/10] training 81.9%: Loss=0.678394, Accuracy=48.618%, MSE=0.406016
[2023-04-27-11:22:42] [6/10] training 84.3%: Loss=0.678225, Accuracy=48.771%, MSE=0.405356
[2023-04-27-11:22:43] [6/10] training 86.7%: Loss=0.675594, Accuracy=48.917%, MSE=0.40369
[2023-04-27-11:22:45] [6/10] training 89.2%: Loss=0.672694, Accuracy=49.027%, MSE=0.40189
[2023-04-27-11:22:47] [6/10] training 91.6%: Loss=0.672264, Accuracy=48.974%, MSE=0.40179
[2023-04-27-11:22:48] [6/10] training 94.0%: Loss=0.672974, Accuracy=48.949%, MSE=0.402195
[2023-04-27-11:22:50] [6/10] training 96.4%: Loss=0.672487, Accuracy=48.975%, MSE=0.402159
[2023-04-27-11:22:52] [6/10] training 98.8%: Loss=0.669822, Accuracy=49.000%, MSE=0.400658
[2023-04-27-11:22:59] Finished Epoch 6/10: Loss=1.22691, Accuracy=48.500%, MSE=0.388697, Precision=0.54468, Recall=0.151643, F1=0.237237, AUPR=0.543735
[2023-04-27-11:22:59] Saving model to ./models/huang_both_1_tt_partitions_epoch06.sav
[2023-04-27-11:23:01] [7/10] training 2.4%: Loss=0.667464, Accuracy=47.000%, MSE=0.40368
[2023-04-27-11:23:03] [7/10] training 4.8%: Loss=0.616778, Accuracy=47.000%, MSE=0.374039
[2023-04-27-11:23:05] [7/10] training 7.2%: Loss=0.630293, Accuracy=46.333%, MSE=0.386456
[2023-04-27-11:23:07] [7/10] training 9.6%: Loss=0.637788, Accuracy=46.000%, MSE=0.391723
[2023-04-27-11:23:08] [7/10] training 12.0%: Loss=0.660768, Accuracy=45.400%, MSE=0.405708
[2023-04-27-11:23:10] [7/10] training 14.5%: Loss=0.649422, Accuracy=46.833%, MSE=0.396779
[2023-04-27-11:23:12] [7/10] training 16.9%: Loss=0.634117, Accuracy=48.143%, MSE=0.384842
[2023-04-27-11:23:14] [7/10] training 19.3%: Loss=0.632686, Accuracy=48.250%, MSE=0.383439
[2023-04-27-11:23:15] [7/10] training 21.7%: Loss=0.637657, Accuracy=47.556%, MSE=0.388603
[2023-04-27-11:23:17] [7/10] training 24.1%: Loss=0.640246, Accuracy=47.100%, MSE=0.39185
[2023-04-27-11:23:19] [7/10] training 26.5%: Loss=0.63149, Accuracy=47.727%, MSE=0.384943
[2023-04-27-11:23:20] [7/10] training 28.9%: Loss=0.628142, Accuracy=48.000%, MSE=0.382097
[2023-04-27-11:23:22] [7/10] training 31.3%: Loss=0.633705, Accuracy=47.769%, MSE=0.385628
[2023-04-27-11:23:24] [7/10] training 33.7%: Loss=0.636561, Accuracy=47.286%, MSE=0.389376
[2023-04-27-11:23:25] [7/10] training 36.1%: Loss=0.63527, Accuracy=46.867%, MSE=0.389908
[2023-04-27-11:23:27] [7/10] training 38.6%: Loss=0.641013, Accuracy=46.438%, MSE=0.393527
[2023-04-27-11:23:29] [7/10] training 41.0%: Loss=0.649747, Accuracy=46.176%, MSE=0.398878
[2023-04-27-11:23:31] [7/10] training 43.4%: Loss=0.645278, Accuracy=46.333%, MSE=0.395757
[2023-04-27-11:23:33] [7/10] training 45.8%: Loss=0.638359, Accuracy=46.421%, MSE=0.390949
[2023-04-27-11:23:34] [7/10] training 48.2%: Loss=0.638588, Accuracy=46.450%, MSE=0.391083
[2023-04-27-11:23:36] [7/10] training 50.6%: Loss=0.637045, Accuracy=46.810%, MSE=0.389571
[2023-04-27-11:23:38] [7/10] training 53.0%: Loss=0.633677, Accuracy=46.955%, MSE=0.387279
[2023-04-27-11:23:40] [7/10] training 55.4%: Loss=0.634696, Accuracy=46.957%, MSE=0.387942
[2023-04-27-11:23:42] [7/10] training 57.8%: Loss=0.637588, Accuracy=46.792%, MSE=0.389991
[2023-04-27-11:23:44] [7/10] training 60.2%: Loss=0.63406, Accuracy=47.160%, MSE=0.387259
[2023-04-27-11:23:46] [7/10] training 62.7%: Loss=0.628095, Accuracy=47.615%, MSE=0.382396
[2023-04-27-11:23:48] [7/10] training 65.1%: Loss=0.625632, Accuracy=47.815%, MSE=0.380544
[2023-04-27-11:23:49] [7/10] training 67.5%: Loss=0.626431, Accuracy=47.857%, MSE=0.381117
[2023-04-27-11:23:51] [7/10] training 69.9%: Loss=0.624245, Accuracy=48.000%, MSE=0.37954
[2023-04-27-11:23:52] [7/10] training 72.3%: Loss=0.621559, Accuracy=48.000%, MSE=0.377657
[2023-04-27-11:23:54] [7/10] training 74.7%: Loss=0.622958, Accuracy=48.161%, MSE=0.377923
[2023-04-27-11:23:56] [7/10] training 77.1%: Loss=0.622802, Accuracy=48.594%, MSE=0.376324
[2023-04-27-11:23:58] [7/10] training 79.5%: Loss=0.622004, Accuracy=48.606%, MSE=0.376015
[2023-04-27-11:23:59] [7/10] training 81.9%: Loss=0.620921, Accuracy=48.706%, MSE=0.375389
[2023-04-27-11:24:01] [7/10] training 84.3%: Loss=0.621328, Accuracy=48.543%, MSE=0.37606
[2023-04-27-11:24:03] [7/10] training 86.7%: Loss=0.621838, Accuracy=48.556%, MSE=0.376321
[2023-04-27-11:24:04] [7/10] training 89.2%: Loss=0.619566, Accuracy=48.622%, MSE=0.374942
[2023-04-27-11:24:06] [7/10] training 91.6%: Loss=0.618219, Accuracy=48.500%, MSE=0.374484
[2023-04-27-11:24:08] [7/10] training 94.0%: Loss=0.616812, Accuracy=48.615%, MSE=0.373374
[2023-04-27-11:24:09] [7/10] training 96.4%: Loss=0.615758, Accuracy=48.725%, MSE=0.372276
[2023-04-27-11:24:12] [7/10] training 98.8%: Loss=0.615802, Accuracy=48.805%, MSE=0.37205
[2023-04-27-11:24:18] Finished Epoch 7/10: Loss=1.0897, Accuracy=49.500%, MSE=0.352808, Precision=0.654641, Recall=0.193183, F1=0.298329, AUPR=0.644201
[2023-04-27-11:24:18] Saving model to ./models/huang_both_1_tt_partitions_epoch07.sav
[2023-04-27-11:24:20] [8/10] training 2.4%: Loss=0.606906, Accuracy=44.000%, MSE=0.388622
[2023-04-27-11:24:22] [8/10] training 4.8%: Loss=0.611471, Accuracy=45.500%, MSE=0.383413
[2023-04-27-11:24:24] [8/10] training 7.2%: Loss=0.583438, Accuracy=47.333%, MSE=0.358832
[2023-04-27-11:24:26] [8/10] training 9.6%: Loss=0.556304, Accuracy=50.000%, MSE=0.334934
[2023-04-27-11:24:28] [8/10] training 12.0%: Loss=0.562189, Accuracy=49.000%, MSE=0.341082
[2023-04-27-11:24:29] [8/10] training 14.5%: Loss=0.561049, Accuracy=50.667%, MSE=0.336734
[2023-04-27-11:24:31] [8/10] training 16.9%: Loss=0.564472, Accuracy=49.571%, MSE=0.340697
[2023-04-27-11:24:32] [8/10] training 19.3%: Loss=0.563939, Accuracy=48.875%, MSE=0.341697
[2023-04-27-11:24:34] [8/10] training 21.7%: Loss=0.561432, Accuracy=49.333%, MSE=0.339619
[2023-04-27-11:24:36] [8/10] training 24.1%: Loss=0.561465, Accuracy=49.100%, MSE=0.339555
[2023-04-27-11:24:38] [8/10] training 26.5%: Loss=0.564105, Accuracy=49.364%, MSE=0.341117
[2023-04-27-11:24:39] [8/10] training 28.9%: Loss=0.561853, Accuracy=50.083%, MSE=0.33814
[2023-04-27-11:24:41] [8/10] training 31.3%: Loss=0.563383, Accuracy=49.846%, MSE=0.340049
[2023-04-27-11:24:43] [8/10] training 33.7%: Loss=0.557853, Accuracy=50.500%, MSE=0.335125
[2023-04-27-11:24:44] [8/10] training 36.1%: Loss=0.557859, Accuracy=50.467%, MSE=0.335577
[2023-04-27-11:24:46] [8/10] training 38.6%: Loss=0.556029, Accuracy=50.875%, MSE=0.333667
[2023-04-27-11:24:48] [8/10] training 41.0%: Loss=0.559561, Accuracy=50.412%, MSE=0.336827
[2023-04-27-11:24:50] [8/10] training 43.4%: Loss=0.560589, Accuracy=50.111%, MSE=0.338187
[2023-04-27-11:24:51] [8/10] training 45.8%: Loss=0.560859, Accuracy=50.211%, MSE=0.338131
[2023-04-27-11:24:53] [8/10] training 48.2%: Loss=0.561391, Accuracy=50.000%, MSE=0.338733
[2023-04-27-11:24:55] [8/10] training 50.6%: Loss=0.563358, Accuracy=49.810%, MSE=0.340395
[2023-04-27-11:24:57] [8/10] training 53.0%: Loss=0.565317, Accuracy=49.455%, MSE=0.342522
[2023-04-27-11:24:58] [8/10] training 55.4%: Loss=0.563322, Accuracy=49.565%, MSE=0.340938
[2023-04-27-11:25:00] [8/10] training 57.8%: Loss=0.565207, Accuracy=49.167%, MSE=0.343265
[2023-04-27-11:25:02] [8/10] training 60.2%: Loss=0.564208, Accuracy=49.480%, MSE=0.341862
[2023-04-27-11:25:04] [8/10] training 62.7%: Loss=0.564333, Accuracy=49.577%, MSE=0.341619
[2023-04-27-11:25:05] [8/10] training 65.1%: Loss=0.564406, Accuracy=49.556%, MSE=0.341049
[2023-04-27-11:25:07] [8/10] training 67.5%: Loss=0.563996, Accuracy=49.429%, MSE=0.340956
[2023-04-27-11:25:09] [8/10] training 69.9%: Loss=0.566781, Accuracy=49.517%, MSE=0.342473
[2023-04-27-11:25:11] [8/10] training 72.3%: Loss=0.568179, Accuracy=49.267%, MSE=0.344102
[2023-04-27-11:25:13] [8/10] training 74.7%: Loss=0.567778, Accuracy=49.065%, MSE=0.344127
[2023-04-27-11:25:14] [8/10] training 77.1%: Loss=0.565121, Accuracy=49.344%, MSE=0.341649
[2023-04-27-11:25:16] [8/10] training 79.5%: Loss=0.563711, Accuracy=49.545%, MSE=0.340416
[2023-04-27-11:25:18] [8/10] training 81.9%: Loss=0.562715, Accuracy=49.676%, MSE=0.339422
[2023-04-27-11:25:20] [8/10] training 84.3%: Loss=0.561466, Accuracy=49.829%, MSE=0.338271
[2023-04-27-11:25:22] [8/10] training 86.7%: Loss=0.56193, Accuracy=49.611%, MSE=0.339087
[2023-04-27-11:25:23] [8/10] training 89.2%: Loss=0.560494, Accuracy=49.703%, MSE=0.338102
[2023-04-27-11:25:25] [8/10] training 91.6%: Loss=0.558859, Accuracy=49.789%, MSE=0.336833
[2023-04-27-11:25:27] [8/10] training 94.0%: Loss=0.557171, Accuracy=49.923%, MSE=0.335444
[2023-04-27-11:25:29] [8/10] training 96.4%: Loss=0.556289, Accuracy=49.850%, MSE=0.334949
[2023-04-27-11:25:31] [8/10] training 98.8%: Loss=0.555483, Accuracy=49.805%, MSE=0.334566
[2023-04-27-11:25:38] Finished Epoch 8/10: Loss=0.9871, Accuracy=48.833%, MSE=0.33699, Precision=0.610551, Recall=0.232233, F1=0.336481, AUPR=0.599811
[2023-04-27-11:25:38] Saving model to ./models/huang_both_1_tt_partitions_epoch08.sav
[2023-04-27-11:25:40] [9/10] training 2.4%: Loss=0.604967, Accuracy=43.000%, MSE=0.378819
[2023-04-27-11:25:42] [9/10] training 4.8%: Loss=0.57948, Accuracy=43.500%, MSE=0.359882
[2023-04-27-11:25:44] [9/10] training 7.2%: Loss=0.561895, Accuracy=46.333%, MSE=0.343956
[2023-04-27-11:25:45] [9/10] training 9.6%: Loss=0.556061, Accuracy=48.000%, MSE=0.338093
[2023-04-27-11:25:47] [9/10] training 12.0%: Loss=0.556245, Accuracy=47.400%, MSE=0.339621
[2023-04-27-11:25:49] [9/10] training 14.5%: Loss=0.560232, Accuracy=47.667%, MSE=0.34222
[2023-04-27-11:25:51] [9/10] training 16.9%: Loss=0.555107, Accuracy=48.714%, MSE=0.337475
[2023-04-27-11:25:53] [9/10] training 19.3%: Loss=0.546331, Accuracy=50.000%, MSE=0.329317
[2023-04-27-11:25:55] [9/10] training 21.7%: Loss=0.543962, Accuracy=50.222%, MSE=0.327611
[2023-04-27-11:25:57] [9/10] training 24.1%: Loss=0.540647, Accuracy=49.800%, MSE=0.325569
[2023-04-27-11:25:58] [9/10] training 26.5%: Loss=0.543839, Accuracy=49.364%, MSE=0.328166
[2023-04-27-11:26:00] [9/10] training 28.9%: Loss=0.5436, Accuracy=49.500%, MSE=0.328035
[2023-04-27-11:26:02] [9/10] training 31.3%: Loss=0.540901, Accuracy=49.846%, MSE=0.325542
[2023-04-27-11:26:04] [9/10] training 33.7%: Loss=0.536466, Accuracy=50.214%, MSE=0.321945
[2023-04-27-11:26:05] [9/10] training 36.1%: Loss=0.534789, Accuracy=50.533%, MSE=0.320334
[2023-04-27-11:26:07] [9/10] training 38.6%: Loss=0.533999, Accuracy=50.625%, MSE=0.319514
[2023-04-27-11:26:09] [9/10] training 41.0%: Loss=0.532499, Accuracy=50.882%, MSE=0.318174
[2023-04-27-11:26:11] [9/10] training 43.4%: Loss=0.537217, Accuracy=50.056%, MSE=0.322874
[2023-04-27-11:26:12] [9/10] training 45.8%: Loss=0.53987, Accuracy=49.895%, MSE=0.325307
[2023-04-27-11:26:14] [9/10] training 48.2%: Loss=0.538399, Accuracy=49.700%, MSE=0.324376
[2023-04-27-11:26:16] [9/10] training 50.6%: Loss=0.539199, Accuracy=49.333%, MSE=0.325491
[2023-04-27-11:26:17] [9/10] training 53.0%: Loss=0.535609, Accuracy=49.727%, MSE=0.322185
[2023-04-27-11:26:19] [9/10] training 55.4%: Loss=0.533756, Accuracy=49.783%, MSE=0.320969
[2023-04-27-11:26:21] [9/10] training 57.8%: Loss=0.532541, Accuracy=49.917%, MSE=0.319978
[2023-04-27-11:26:23] [9/10] training 60.2%: Loss=0.531799, Accuracy=50.240%, MSE=0.319062
[2023-04-27-11:26:24] [9/10] training 62.7%: Loss=0.531304, Accuracy=50.346%, MSE=0.318708
[2023-04-27-11:26:26] [9/10] training 65.1%: Loss=0.529274, Accuracy=50.481%, MSE=0.317056
[2023-04-27-11:26:28] [9/10] training 67.5%: Loss=0.529009, Accuracy=50.536%, MSE=0.31674
[2023-04-27-11:26:30] [9/10] training 69.9%: Loss=0.530179, Accuracy=50.483%, MSE=0.317472
[2023-04-27-11:26:32] [9/10] training 72.3%: Loss=0.527319, Accuracy=50.767%, MSE=0.314916
[2023-04-27-11:26:33] [9/10] training 74.7%: Loss=0.523123, Accuracy=51.194%, MSE=0.31108
[2023-04-27-11:26:35] [9/10] training 77.1%: Loss=0.52288, Accuracy=51.219%, MSE=0.310836
[2023-04-27-11:26:37] [9/10] training 79.5%: Loss=0.522365, Accuracy=51.364%, MSE=0.310162
[2023-04-27-11:26:38] [9/10] training 81.9%: Loss=0.522441, Accuracy=51.235%, MSE=0.310592
[2023-04-27-11:26:40] [9/10] training 84.3%: Loss=0.521498, Accuracy=51.171%, MSE=0.310025
[2023-04-27-11:26:42] [9/10] training 86.7%: Loss=0.521532, Accuracy=51.167%, MSE=0.31026
[2023-04-27-11:26:43] [9/10] training 89.2%: Loss=0.522568, Accuracy=51.108%, MSE=0.31132
[2023-04-27-11:26:45] [9/10] training 91.6%: Loss=0.522042, Accuracy=51.053%, MSE=0.311069
[2023-04-27-11:26:47] [9/10] training 94.0%: Loss=0.521425, Accuracy=51.179%, MSE=0.31041
[2023-04-27-11:26:48] [9/10] training 96.4%: Loss=0.520427, Accuracy=51.125%, MSE=0.309776
[2023-04-27-11:26:50] [9/10] training 98.8%: Loss=0.519365, Accuracy=51.171%, MSE=0.308959
[2023-04-27-11:26:57] Finished Epoch 9/10: Loss=1.13898, Accuracy=47.750%, MSE=0.375767, Precision=0.555125, Recall=0.176426, F1=0.267756, AUPR=0.556613
[2023-04-27-11:26:57] Saving model to ./models/huang_both_1_tt_partitions_epoch09.sav
[2023-04-27-11:26:59] [10/10] training 2.4%: Loss=0.47262, Accuracy=57.000%, MSE=0.265476
[2023-04-27-11:27:00] [10/10] training 4.8%: Loss=0.484972, Accuracy=54.500%, MSE=0.280467
[2023-04-27-11:27:02] [10/10] training 7.2%: Loss=0.478269, Accuracy=52.333%, MSE=0.275696
[2023-04-27-11:27:04] [10/10] training 9.6%: Loss=0.486511, Accuracy=51.500%, MSE=0.284591
[2023-04-27-11:27:06] [10/10] training 12.0%: Loss=0.487736, Accuracy=52.200%, MSE=0.284842
[2023-04-27-11:27:08] [10/10] training 14.5%: Loss=0.480353, Accuracy=54.167%, MSE=0.276317
[2023-04-27-11:27:10] [10/10] training 16.9%: Loss=0.480604, Accuracy=54.143%, MSE=0.277134
[2023-04-27-11:27:12] [10/10] training 19.3%: Loss=0.479484, Accuracy=54.000%, MSE=0.277018
[2023-04-27-11:27:14] [10/10] training 21.7%: Loss=0.492619, Accuracy=51.889%, MSE=0.290014
[2023-04-27-11:27:15] [10/10] training 24.1%: Loss=0.496971, Accuracy=51.900%, MSE=0.293462
[2023-04-27-11:27:17] [10/10] training 26.5%: Loss=0.487847, Accuracy=53.000%, MSE=0.284713
[2023-04-27-11:27:19] [10/10] training 28.9%: Loss=0.48453, Accuracy=53.250%, MSE=0.281483
[2023-04-27-11:27:21] [10/10] training 31.3%: Loss=0.483119, Accuracy=53.154%, MSE=0.280673
[2023-04-27-11:27:23] [10/10] training 33.7%: Loss=0.487893, Accuracy=52.571%, MSE=0.284986
[2023-04-27-11:27:24] [10/10] training 36.1%: Loss=0.485813, Accuracy=52.733%, MSE=0.283258
[2023-04-27-11:27:26] [10/10] training 38.6%: Loss=0.487431, Accuracy=52.437%, MSE=0.28497
[2023-04-27-11:27:28] [10/10] training 41.0%: Loss=0.489371, Accuracy=52.059%, MSE=0.287064
[2023-04-27-11:27:30] [10/10] training 43.4%: Loss=0.490316, Accuracy=51.778%, MSE=0.28833
[2023-04-27-11:27:32] [10/10] training 45.8%: Loss=0.492182, Accuracy=51.421%, MSE=0.290039
[2023-04-27-11:27:34] [10/10] training 48.2%: Loss=0.49181, Accuracy=51.400%, MSE=0.289742
[2023-04-27-11:27:35] [10/10] training 50.6%: Loss=0.491607, Accuracy=51.238%, MSE=0.289633
[2023-04-27-11:27:37] [10/10] training 53.0%: Loss=0.491445, Accuracy=51.318%, MSE=0.289364
[2023-04-27-11:27:38] [10/10] training 55.4%: Loss=0.491181, Accuracy=51.261%, MSE=0.289104
[2023-04-27-11:27:40] [10/10] training 57.8%: Loss=0.488586, Accuracy=51.542%, MSE=0.286819
[2023-04-27-11:27:42] [10/10] training 60.2%: Loss=0.489725, Accuracy=51.440%, MSE=0.287819
[2023-04-27-11:27:44] [10/10] training 62.7%: Loss=0.489243, Accuracy=51.462%, MSE=0.287531
[2023-04-27-11:27:45] [10/10] training 65.1%: Loss=0.487697, Accuracy=51.741%, MSE=0.286166
[2023-04-27-11:27:47] [10/10] training 67.5%: Loss=0.488245, Accuracy=51.750%, MSE=0.286564
[2023-04-27-11:27:49] [10/10] training 69.9%: Loss=0.486955, Accuracy=51.897%, MSE=0.285538
[2023-04-27-11:27:50] [10/10] training 72.3%: Loss=0.485302, Accuracy=52.033%, MSE=0.283923
[2023-04-27-11:27:52] [10/10] training 74.7%: Loss=0.485326, Accuracy=51.871%, MSE=0.284198
[2023-04-27-11:27:54] [10/10] training 77.1%: Loss=0.486066, Accuracy=51.812%, MSE=0.284671
[2023-04-27-11:27:55] [10/10] training 79.5%: Loss=0.487949, Accuracy=51.485%, MSE=0.286457
[2023-04-27-11:27:57] [10/10] training 81.9%: Loss=0.487464, Accuracy=51.471%, MSE=0.286108
[2023-04-27-11:27:59] [10/10] training 84.3%: Loss=0.48531, Accuracy=51.857%, MSE=0.284032
[2023-04-27-11:28:00] [10/10] training 86.7%: Loss=0.485982, Accuracy=51.833%, MSE=0.284625
[2023-04-27-11:28:02] [10/10] training 89.2%: Loss=0.4859, Accuracy=51.784%, MSE=0.28462
[2023-04-27-11:28:04] [10/10] training 91.6%: Loss=0.485799, Accuracy=51.763%, MSE=0.284572
[2023-04-27-11:28:06] [10/10] training 94.0%: Loss=0.485984, Accuracy=51.744%, MSE=0.28466
[2023-04-27-11:28:08] [10/10] training 96.4%: Loss=0.485389, Accuracy=51.900%, MSE=0.284041
[2023-04-27-11:28:09] [10/10] training 98.8%: Loss=0.484907, Accuracy=51.902%, MSE=0.283727
[2023-04-27-11:28:16] Finished Epoch 10/10: Loss=1.14752, Accuracy=48.750%, MSE=0.380453, Precision=0.573111, Recall=0.157796, F1=0.247459, AUPR=0.573568
[2023-04-27-11:28:16] Saving model to ./models/huang_both_1_tt_partitions_epoch10.sav
[2023-04-27-11:28:16] Saving final model to ./models/huang_both_1_tt_partitions_final.sav
