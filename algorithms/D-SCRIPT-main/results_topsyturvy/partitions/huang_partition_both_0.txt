[2023-04-23-23:24:16] D-SCRIPT Version 0.2.2
[2023-04-23-23:24:16] Called as: /nfs/home/students/jbernett/.conda/envs/dscript2/bin/dscript train --topsy-turvy --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_0.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_0_tt_partitions -o ./results_topsyturvy/partitions/huang_partition_both_0.txt -d 2
[2023-04-23-23:24:16] Using CUDA device 2 - NVIDIA A40
[2023-04-23-23:24:16] Loaded 3440 training pairs
[2023-04-23-23:24:16] Loaded 652 test pairs
[2023-04-23-23:24:16] Loading embeddings...
[2023-04-23-23:24:34] Running D-SCRIPT Topsy-Turvy:
[2023-04-23-23:24:34] 	glider_weight: 0.2
[2023-04-23-23:24:34] 	glider_thresh: 92.5th percentile
[2023-04-23-23:24:34] Computing GLIDER matrix...
[2023-04-23-23:24:37] Initializing embedding model with:
[2023-04-23-23:24:37] 	projection_dim: 100
[2023-04-23-23:24:37] 	dropout_p: 0.5
[2023-04-23-23:24:37] Initializing contact model with:
[2023-04-23-23:24:37] 	hidden_dim: 50
[2023-04-23-23:24:37] 	kernel_width: 7
[2023-04-23-23:24:37] Initializing interaction model with:
[2023-04-23-23:24:37] 	do_poool: False
[2023-04-23-23:24:37] 	pool_width: 9
[2023-04-23-23:24:37] 	do_w: True
[2023-04-23-23:24:37] 	do_sigmoid: True
[2023-04-23-23:24:37] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-04-23-23:24:38] Using save prefix "./models/huang_both_0_tt_partitions"
[2023-04-23-23:24:38] Training with Adam: lr=0.001, weight_decay=0
[2023-04-23-23:24:38] 	num_epochs: 10
[2023-04-23-23:24:38] 	batch_size: 25
[2023-04-23-23:24:38] 	interaction weight: 0.35
[2023-04-23-23:24:38] 	contact map weight: 0.65
[2023-04-23-23:24:41] [1/10] training 2.9%: Loss=1.52071, Accuracy=47.000%, MSE=0.528218
[2023-04-23-23:24:43] [1/10] training 5.8%: Loss=1.40461, Accuracy=51.000%, MSE=0.488071
[2023-04-23-23:24:45] [1/10] training 8.7%: Loss=1.40131, Accuracy=50.667%, MSE=0.491213
[2023-04-23-23:24:47] [1/10] training 11.6%: Loss=1.38944, Accuracy=50.500%, MSE=0.492594
[2023-04-23-23:24:49] [1/10] training 14.5%: Loss=1.36154, Accuracy=51.400%, MSE=0.483532
[2023-04-23-23:24:51] [1/10] training 17.4%: Loss=1.3641, Accuracy=51.167%, MSE=0.485846
[2023-04-23-23:24:53] [1/10] training 20.3%: Loss=1.34596, Accuracy=51.571%, MSE=0.48161
[2023-04-23-23:24:55] [1/10] training 23.2%: Loss=1.36416, Accuracy=50.375%, MSE=0.493381
[2023-04-23-23:24:57] [1/10] training 26.1%: Loss=1.34975, Accuracy=50.667%, MSE=0.490309
[2023-04-23-23:24:58] [1/10] training 29.0%: Loss=1.35111, Accuracy=50.500%, MSE=0.491932
[2023-04-23-23:25:00] [1/10] training 31.9%: Loss=1.33018, Accuracy=51.364%, MSE=0.483273
[2023-04-23-23:25:02] [1/10] training 34.8%: Loss=1.3318, Accuracy=51.083%, MSE=0.485983
[2023-04-23-23:25:04] [1/10] training 37.7%: Loss=1.33562, Accuracy=50.692%, MSE=0.489767
[2023-04-23-23:25:06] [1/10] training 40.6%: Loss=1.33596, Accuracy=50.429%, MSE=0.492292
[2023-04-23-23:25:08] [1/10] training 43.5%: Loss=1.32727, Accuracy=50.667%, MSE=0.489809
[2023-04-23-23:25:10] [1/10] training 46.4%: Loss=1.32495, Accuracy=50.562%, MSE=0.49074
[2023-04-23-23:25:11] [1/10] training 49.3%: Loss=1.31952, Accuracy=50.529%, MSE=0.490906
[2023-04-23-23:25:13] [1/10] training 52.2%: Loss=1.30793, Accuracy=50.944%, MSE=0.486704
[2023-04-23-23:25:15] [1/10] training 55.1%: Loss=1.31033, Accuracy=50.632%, MSE=0.489727
[2023-04-23-23:25:17] [1/10] training 58.0%: Loss=1.31386, Accuracy=50.250%, MSE=0.493422
[2023-04-23-23:25:19] [1/10] training 60.9%: Loss=1.31169, Accuracy=50.190%, MSE=0.493907
[2023-04-23-23:25:21] [1/10] training 63.8%: Loss=1.31022, Accuracy=50.136%, MSE=0.494392
[2023-04-23-23:25:22] [1/10] training 66.7%: Loss=1.29839, Accuracy=50.565%, MSE=0.490061
[2023-04-23-23:25:24] [1/10] training 69.6%: Loss=1.29284, Accuracy=50.667%, MSE=0.488955
[2023-04-23-23:25:26] [1/10] training 72.5%: Loss=1.28594, Accuracy=50.840%, MSE=0.487142
[2023-04-23-23:25:28] [1/10] training 75.4%: Loss=1.28521, Accuracy=50.692%, MSE=0.488504
[2023-04-23-23:25:30] [1/10] training 78.3%: Loss=1.28281, Accuracy=50.667%, MSE=0.488694
[2023-04-23-23:25:32] [1/10] training 81.2%: Loss=1.28123, Accuracy=50.500%, MSE=0.490203
[2023-04-23-23:25:34] [1/10] training 84.1%: Loss=1.27885, Accuracy=50.448%, MSE=0.490617
[2023-04-23-23:25:36] [1/10] training 87.0%: Loss=1.27887, Accuracy=50.333%, MSE=0.491712
[2023-04-23-23:25:38] [1/10] training 89.9%: Loss=1.27519, Accuracy=50.290%, MSE=0.491987
[2023-04-23-23:25:39] [1/10] training 92.8%: Loss=1.2688, Accuracy=50.531%, MSE=0.489558
[2023-04-23-23:25:41] [1/10] training 95.7%: Loss=1.27147, Accuracy=50.212%, MSE=0.492608
[2023-04-23-23:25:43] [1/10] training 98.6%: Loss=1.269, Accuracy=50.118%, MSE=0.493378
[2023-04-23-23:25:51] Finished Epoch 1/10: Loss=2.70608, Accuracy=48.296%, MSE=0.494333, Precision=0.41734, Recall=0.00574765, F1=0.0113391, AUPR=0.42562
[2023-04-23-23:25:51] Saving model to ./models/huang_both_0_tt_partitions_epoch01.sav
[2023-04-23-23:25:52] [2/10] training 2.9%: Loss=1.16189, Accuracy=52.000%, MSE=0.472319
[2023-04-23-23:25:54] [2/10] training 5.8%: Loss=1.03704, Accuracy=57.000%, MSE=0.421683
[2023-04-23-23:25:55] [2/10] training 8.7%: Loss=1.01024, Accuracy=57.667%, MSE=0.414546
[2023-04-23-23:25:57] [2/10] training 11.6%: Loss=1.06013, Accuracy=55.500%, MSE=0.436483
[2023-04-23-23:25:58] [2/10] training 14.5%: Loss=1.07906, Accuracy=54.600%, MSE=0.445469
[2023-04-23-23:26:00] [2/10] training 17.4%: Loss=1.09149, Accuracy=53.500%, MSE=0.456007
[2023-04-23-23:26:01] [2/10] training 20.3%: Loss=1.12986, Accuracy=51.286%, MSE=0.477831
[2023-04-23-23:26:03] [2/10] training 23.2%: Loss=1.13, Accuracy=51.000%, MSE=0.480476
[2023-04-23-23:26:04] [2/10] training 26.1%: Loss=1.11662, Accuracy=51.556%, MSE=0.474774
[2023-04-23-23:26:06] [2/10] training 29.0%: Loss=1.11531, Accuracy=51.400%, MSE=0.476126
[2023-04-23-23:26:07] [2/10] training 31.9%: Loss=1.10958, Accuracy=51.636%, MSE=0.473864
[2023-04-23-23:26:09] [2/10] training 34.8%: Loss=1.11106, Accuracy=51.250%, MSE=0.477333
[2023-04-23-23:26:11] [2/10] training 37.7%: Loss=1.1091, Accuracy=51.308%, MSE=0.476694
[2023-04-23-23:26:12] [2/10] training 40.6%: Loss=1.1022, Accuracy=51.500%, MSE=0.474604
[2023-04-23-23:26:13] [2/10] training 43.5%: Loss=1.0988, Accuracy=51.467%, MSE=0.474636
[2023-04-23-23:26:15] [2/10] training 46.4%: Loss=1.08922, Accuracy=51.875%, MSE=0.470508
[2023-04-23-23:26:16] [2/10] training 49.3%: Loss=1.09201, Accuracy=51.471%, MSE=0.474197
[2023-04-23-23:26:18] [2/10] training 52.2%: Loss=1.0994, Accuracy=51.056%, MSE=0.478305
[2023-04-23-23:26:19] [2/10] training 55.1%: Loss=1.09968, Accuracy=50.789%, MSE=0.480642
[2023-04-23-23:26:21] [2/10] training 58.0%: Loss=1.1026, Accuracy=50.450%, MSE=0.483739
[2023-04-23-23:26:22] [2/10] training 60.9%: Loss=1.09749, Accuracy=50.619%, MSE=0.481941
[2023-04-23-23:26:24] [2/10] training 63.8%: Loss=1.09608, Accuracy=50.545%, MSE=0.482483
[2023-04-23-23:26:26] [2/10] training 66.7%: Loss=1.09407, Accuracy=50.522%, MSE=0.482589
[2023-04-23-23:26:27] [2/10] training 69.6%: Loss=1.09368, Accuracy=50.417%, MSE=0.483539
[2023-04-23-23:26:29] [2/10] training 72.5%: Loss=1.08739, Accuracy=50.640%, MSE=0.481149
[2023-04-23-23:26:30] [2/10] training 75.4%: Loss=1.08963, Accuracy=50.500%, MSE=0.482504
[2023-04-23-23:26:32] [2/10] training 78.3%: Loss=1.08885, Accuracy=50.259%, MSE=0.484424
[2023-04-23-23:26:33] [2/10] training 81.2%: Loss=1.08425, Accuracy=50.464%, MSE=0.482336
[2023-04-23-23:26:35] [2/10] training 84.1%: Loss=1.08185, Accuracy=50.552%, MSE=0.48145
[2023-04-23-23:26:36] [2/10] training 87.0%: Loss=1.08308, Accuracy=50.267%, MSE=0.483977
[2023-04-23-23:26:38] [2/10] training 89.9%: Loss=1.08139, Accuracy=50.258%, MSE=0.484013
[2023-04-23-23:26:39] [2/10] training 92.8%: Loss=1.08019, Accuracy=50.125%, MSE=0.484995
[2023-04-23-23:26:41] [2/10] training 95.7%: Loss=1.08175, Accuracy=50.030%, MSE=0.485945
[2023-04-23-23:26:42] [2/10] training 98.6%: Loss=1.07765, Accuracy=50.147%, MSE=0.48462
[2023-04-23-23:26:49] Finished Epoch 2/10: Loss=2.18705, Accuracy=48.296%, MSE=0.483382, Precision=0.412999, Recall=0.0176116, F1=0.0337826, AUPR=0.437737
[2023-04-23-23:26:49] Saving model to ./models/huang_both_0_tt_partitions_epoch02.sav
[2023-04-23-23:26:50] [3/10] training 2.9%: Loss=0.918963, Accuracy=57.000%, MSE=0.415418
[2023-04-23-23:26:52] [3/10] training 5.8%: Loss=0.984416, Accuracy=52.500%, MSE=0.45829
[2023-04-23-23:26:53] [3/10] training 8.7%: Loss=0.982749, Accuracy=52.667%, MSE=0.456491
[2023-04-23-23:26:55] [3/10] training 11.6%: Loss=1.00726, Accuracy=50.750%, MSE=0.474921
[2023-04-23-23:26:56] [3/10] training 14.5%: Loss=1.00824, Accuracy=49.600%, MSE=0.484433
[2023-04-23-23:26:58] [3/10] training 17.4%: Loss=1.01992, Accuracy=49.000%, MSE=0.490328
[2023-04-23-23:26:59] [3/10] training 20.3%: Loss=1.00934, Accuracy=49.714%, MSE=0.48362
[2023-04-23-23:27:01] [3/10] training 23.2%: Loss=0.998822, Accuracy=50.250%, MSE=0.47833
[2023-04-23-23:27:02] [3/10] training 26.1%: Loss=1.00583, Accuracy=49.667%, MSE=0.48358
[2023-04-23-23:27:04] [3/10] training 29.0%: Loss=1.00966, Accuracy=49.400%, MSE=0.485988
[2023-04-23-23:27:05] [3/10] training 31.9%: Loss=1.00481, Accuracy=49.455%, MSE=0.485457
[2023-04-23-23:27:07] [3/10] training 34.8%: Loss=1.00014, Accuracy=49.583%, MSE=0.483893
[2023-04-23-23:27:08] [3/10] training 37.7%: Loss=0.988903, Accuracy=50.538%, MSE=0.474979
[2023-04-23-23:27:10] [3/10] training 40.6%: Loss=0.99114, Accuracy=50.000%, MSE=0.479179
[2023-04-23-23:27:11] [3/10] training 43.5%: Loss=0.999403, Accuracy=49.400%, MSE=0.484795
[2023-04-23-23:27:13] [3/10] training 46.4%: Loss=1.00171, Accuracy=49.125%, MSE=0.487159
[2023-04-23-23:27:14] [3/10] training 49.3%: Loss=0.990417, Accuracy=49.647%, MSE=0.481915
[2023-04-23-23:27:16] [3/10] training 52.2%: Loss=0.994779, Accuracy=49.222%, MSE=0.485395
[2023-04-23-23:27:18] [3/10] training 55.1%: Loss=0.993376, Accuracy=49.474%, MSE=0.483382
[2023-04-23-23:27:19] [3/10] training 58.0%: Loss=0.989701, Accuracy=49.400%, MSE=0.483339
[2023-04-23-23:27:21] [3/10] training 60.9%: Loss=0.986626, Accuracy=49.429%, MSE=0.482988
[2023-04-23-23:27:22] [3/10] training 63.8%: Loss=0.984227, Accuracy=49.500%, MSE=0.481998
[2023-04-23-23:27:24] [3/10] training 66.7%: Loss=0.979409, Accuracy=49.783%, MSE=0.479346
[2023-04-23-23:27:25] [3/10] training 69.6%: Loss=0.974949, Accuracy=49.958%, MSE=0.477457
[2023-04-23-23:27:27] [3/10] training 72.5%: Loss=0.975842, Accuracy=49.840%, MSE=0.478516
[2023-04-23-23:27:28] [3/10] training 75.4%: Loss=0.972256, Accuracy=50.038%, MSE=0.476623
[2023-04-23-23:27:30] [3/10] training 78.3%: Loss=0.968672, Accuracy=50.148%, MSE=0.475256
[2023-04-23-23:27:31] [3/10] training 81.2%: Loss=0.969414, Accuracy=49.929%, MSE=0.477077
[2023-04-23-23:27:33] [3/10] training 84.1%: Loss=0.966123, Accuracy=50.034%, MSE=0.475939
[2023-04-23-23:27:34] [3/10] training 87.0%: Loss=0.96568, Accuracy=49.933%, MSE=0.47663
[2023-04-23-23:27:36] [3/10] training 89.9%: Loss=0.964163, Accuracy=49.968%, MSE=0.476189
[2023-04-23-23:27:37] [3/10] training 92.8%: Loss=0.964383, Accuracy=49.719%, MSE=0.47797
[2023-04-23-23:27:38] [3/10] training 95.7%: Loss=0.961939, Accuracy=49.727%, MSE=0.477472
[2023-04-23-23:27:40] [3/10] training 98.6%: Loss=0.958082, Accuracy=49.941%, MSE=0.475306
[2023-04-23-23:27:46] Finished Epoch 3/10: Loss=1.94618, Accuracy=48.296%, MSE=0.473846, Precision=0.389253, Recall=0.0295479, F1=0.0549264, AUPR=0.429824
[2023-04-23-23:27:46] Saving model to ./models/huang_both_0_tt_partitions_epoch03.sav
[2023-04-23-23:27:48] [4/10] training 2.9%: Loss=0.892039, Accuracy=50.000%, MSE=0.462943
[2023-04-23-23:27:50] [4/10] training 5.8%: Loss=0.874268, Accuracy=50.500%, MSE=0.458739
[2023-04-23-23:27:51] [4/10] training 8.7%: Loss=0.847748, Accuracy=51.000%, MSE=0.452948
[2023-04-23-23:27:53] [4/10] training 11.6%: Loss=0.820558, Accuracy=51.750%, MSE=0.43949
[2023-04-23-23:27:54] [4/10] training 14.5%: Loss=0.816994, Accuracy=52.000%, MSE=0.436401
[2023-04-23-23:27:56] [4/10] training 17.4%: Loss=0.846272, Accuracy=50.333%, MSE=0.452521
[2023-04-23-23:27:57] [4/10] training 20.3%: Loss=0.840286, Accuracy=51.143%, MSE=0.446115
[2023-04-23-23:27:59] [4/10] training 23.2%: Loss=0.840404, Accuracy=50.500%, MSE=0.450628
[2023-04-23-23:28:00] [4/10] training 26.1%: Loss=0.848852, Accuracy=49.778%, MSE=0.457706
[2023-04-23-23:28:02] [4/10] training 29.0%: Loss=0.849269, Accuracy=49.800%, MSE=0.457989
[2023-04-23-23:28:03] [4/10] training 31.9%: Loss=0.851132, Accuracy=49.636%, MSE=0.459078
[2023-04-23-23:28:05] [4/10] training 34.8%: Loss=0.857314, Accuracy=48.833%, MSE=0.46557
[2023-04-23-23:28:06] [4/10] training 37.7%: Loss=0.858845, Accuracy=49.000%, MSE=0.46456
[2023-04-23-23:28:08] [4/10] training 40.6%: Loss=0.857186, Accuracy=48.857%, MSE=0.465395
[2023-04-23-23:28:09] [4/10] training 43.5%: Loss=0.849443, Accuracy=48.733%, MSE=0.462698
[2023-04-23-23:28:11] [4/10] training 46.4%: Loss=0.850224, Accuracy=48.875%, MSE=0.461631
[2023-04-23-23:28:12] [4/10] training 49.3%: Loss=0.86272, Accuracy=48.529%, MSE=0.466186
[2023-04-23-23:28:14] [4/10] training 52.2%: Loss=0.862071, Accuracy=48.611%, MSE=0.465227
[2023-04-23-23:28:15] [4/10] training 55.1%: Loss=0.858195, Accuracy=48.842%, MSE=0.462814
[2023-04-23-23:28:17] [4/10] training 58.0%: Loss=0.861085, Accuracy=48.500%, MSE=0.466183
[2023-04-23-23:28:18] [4/10] training 60.9%: Loss=0.865096, Accuracy=48.286%, MSE=0.4684
[2023-04-23-23:28:20] [4/10] training 63.8%: Loss=0.858684, Accuracy=48.500%, MSE=0.465217
[2023-04-23-23:28:22] [4/10] training 66.7%: Loss=0.858037, Accuracy=48.087%, MSE=0.466931
[2023-04-23-23:28:23] [4/10] training 69.6%: Loss=0.857194, Accuracy=48.125%, MSE=0.466468
[2023-04-23-23:28:25] [4/10] training 72.5%: Loss=0.85205, Accuracy=47.920%, MSE=0.465542
[2023-04-23-23:28:26] [4/10] training 75.4%: Loss=0.853697, Accuracy=48.000%, MSE=0.465308
[2023-04-23-23:28:27] [4/10] training 78.3%: Loss=0.854151, Accuracy=48.185%, MSE=0.464214
[2023-04-23-23:28:29] [4/10] training 81.2%: Loss=0.856154, Accuracy=48.250%, MSE=0.464141
[2023-04-23-23:28:30] [4/10] training 84.1%: Loss=0.852292, Accuracy=48.586%, MSE=0.461184
[2023-04-23-23:28:32] [4/10] training 87.0%: Loss=0.847715, Accuracy=48.833%, MSE=0.458879
[2023-04-23-23:28:34] [4/10] training 89.9%: Loss=0.844228, Accuracy=48.903%, MSE=0.457428
[2023-04-23-23:28:35] [4/10] training 92.8%: Loss=0.842818, Accuracy=48.938%, MSE=0.457015
[2023-04-23-23:28:37] [4/10] training 95.7%: Loss=0.842901, Accuracy=48.818%, MSE=0.457891
[2023-04-23-23:28:38] [4/10] training 98.6%: Loss=0.840321, Accuracy=48.824%, MSE=0.45697
[2023-04-23-23:28:44] Finished Epoch 4/10: Loss=1.33677, Accuracy=48.000%, MSE=0.412204, Precision=0.464389, Recall=0.109869, F1=0.177697, AUPR=0.450596
[2023-04-23-23:28:44] Saving model to ./models/huang_both_0_tt_partitions_epoch04.sav
[2023-04-23-23:28:46] [5/10] training 2.9%: Loss=0.591071, Accuracy=46.000%, MSE=0.345603
[2023-04-23-23:28:47] [5/10] training 5.8%: Loss=0.620137, Accuracy=47.500%, MSE=0.359196
[2023-04-23-23:28:49] [5/10] training 8.7%: Loss=0.674668, Accuracy=49.000%, MSE=0.378398
[2023-04-23-23:28:50] [5/10] training 11.6%: Loss=0.686724, Accuracy=51.750%, MSE=0.375088
[2023-04-23-23:28:52] [5/10] training 14.5%: Loss=0.718138, Accuracy=49.600%, MSE=0.400077
[2023-04-23-23:28:53] [5/10] training 17.4%: Loss=0.71596, Accuracy=49.833%, MSE=0.401547
[2023-04-23-23:28:55] [5/10] training 20.3%: Loss=0.710636, Accuracy=49.143%, MSE=0.402424
[2023-04-23-23:28:56] [5/10] training 23.2%: Loss=0.723266, Accuracy=47.625%, MSE=0.414248
[2023-04-23-23:28:58] [5/10] training 26.1%: Loss=0.731558, Accuracy=47.222%, MSE=0.418778
[2023-04-23-23:29:00] [5/10] training 29.0%: Loss=0.730242, Accuracy=47.300%, MSE=0.417547
[2023-04-23-23:29:01] [5/10] training 31.9%: Loss=0.729777, Accuracy=46.909%, MSE=0.42021
[2023-04-23-23:29:03] [5/10] training 34.8%: Loss=0.726678, Accuracy=46.167%, MSE=0.42107
[2023-04-23-23:29:04] [5/10] training 37.7%: Loss=0.71632, Accuracy=46.923%, MSE=0.413919
[2023-04-23-23:29:06] [5/10] training 40.6%: Loss=0.715159, Accuracy=47.214%, MSE=0.412445
[2023-04-23-23:29:08] [5/10] training 43.5%: Loss=0.720515, Accuracy=47.267%, MSE=0.413617
[2023-04-23-23:29:09] [5/10] training 46.4%: Loss=0.722054, Accuracy=47.125%, MSE=0.415053
[2023-04-23-23:29:11] [5/10] training 49.3%: Loss=0.712353, Accuracy=47.294%, MSE=0.409096
[2023-04-23-23:29:12] [5/10] training 52.2%: Loss=0.709621, Accuracy=47.111%, MSE=0.408538
[2023-04-23-23:29:14] [5/10] training 55.1%: Loss=0.719681, Accuracy=47.211%, MSE=0.411964
[2023-04-23-23:29:15] [5/10] training 58.0%: Loss=0.726382, Accuracy=47.650%, MSE=0.411998
[2023-04-23-23:29:16] [5/10] training 60.9%: Loss=0.731396, Accuracy=47.857%, MSE=0.413465
[2023-04-23-23:29:18] [5/10] training 63.8%: Loss=0.732071, Accuracy=47.818%, MSE=0.415226
[2023-04-23-23:29:19] [5/10] training 66.7%: Loss=0.730234, Accuracy=47.826%, MSE=0.414533
[2023-04-23-23:29:21] [5/10] training 69.6%: Loss=0.724884, Accuracy=47.625%, MSE=0.412127
[2023-04-23-23:29:22] [5/10] training 72.5%: Loss=0.720981, Accuracy=47.360%, MSE=0.411172
[2023-04-23-23:29:24] [5/10] training 75.4%: Loss=0.718673, Accuracy=47.154%, MSE=0.410144
[2023-04-23-23:29:25] [5/10] training 78.3%: Loss=0.721296, Accuracy=47.185%, MSE=0.410988
[2023-04-23-23:29:27] [5/10] training 81.2%: Loss=0.721599, Accuracy=47.000%, MSE=0.411738
[2023-04-23-23:29:28] [5/10] training 84.1%: Loss=0.721541, Accuracy=46.828%, MSE=0.412473
[2023-04-23-23:29:30] [5/10] training 87.0%: Loss=0.71835, Accuracy=46.767%, MSE=0.410731
[2023-04-23-23:29:31] [5/10] training 89.9%: Loss=0.713699, Accuracy=46.871%, MSE=0.407886
[2023-04-23-23:29:33] [5/10] training 92.8%: Loss=0.710612, Accuracy=46.938%, MSE=0.406293
[2023-04-23-23:29:34] [5/10] training 95.7%: Loss=0.711487, Accuracy=46.788%, MSE=0.407102
[2023-04-23-23:29:36] [5/10] training 98.6%: Loss=0.70881, Accuracy=46.941%, MSE=0.40535
[2023-04-23-23:29:42] Finished Epoch 5/10: Loss=1.11863, Accuracy=47.852%, MSE=0.354047, Precision=0.548493, Recall=0.214505, F1=0.3084, AUPR=0.539697
[2023-04-23-23:29:42] Saving model to ./models/huang_both_0_tt_partitions_epoch05.sav
[2023-04-23-23:29:44] [6/10] training 2.9%: Loss=0.727343, Accuracy=46.000%, MSE=0.42224
[2023-04-23-23:29:46] [6/10] training 5.8%: Loss=0.706317, Accuracy=50.000%, MSE=0.400772
[2023-04-23-23:29:47] [6/10] training 8.7%: Loss=0.729003, Accuracy=48.667%, MSE=0.414568
[2023-04-23-23:29:49] [6/10] training 11.6%: Loss=0.720788, Accuracy=47.750%, MSE=0.413661
[2023-04-23-23:29:50] [6/10] training 14.5%: Loss=0.679932, Accuracy=48.400%, MSE=0.388962
[2023-04-23-23:29:52] [6/10] training 17.4%: Loss=0.652113, Accuracy=49.333%, MSE=0.37187
[2023-04-23-23:29:54] [6/10] training 20.3%: Loss=0.645161, Accuracy=48.857%, MSE=0.369946
[2023-04-23-23:29:55] [6/10] training 23.2%: Loss=0.664327, Accuracy=49.125%, MSE=0.376843
[2023-04-23-23:29:57] [6/10] training 26.1%: Loss=0.704057, Accuracy=48.222%, MSE=0.39228
[2023-04-23-23:29:58] [6/10] training 29.0%: Loss=0.693938, Accuracy=48.900%, MSE=0.385287
[2023-04-23-23:30:00] [6/10] training 31.9%: Loss=0.678962, Accuracy=48.545%, MSE=0.378405
[2023-04-23-23:30:01] [6/10] training 34.8%: Loss=0.667542, Accuracy=48.833%, MSE=0.372671
[2023-04-23-23:30:03] [6/10] training 37.7%: Loss=0.662531, Accuracy=48.615%, MSE=0.371284
[2023-04-23-23:30:04] [6/10] training 40.6%: Loss=0.659678, Accuracy=48.786%, MSE=0.370577
[2023-04-23-23:30:05] [6/10] training 43.5%: Loss=0.650003, Accuracy=49.067%, MSE=0.365179
[2023-04-23-23:30:07] [6/10] training 46.4%: Loss=0.643688, Accuracy=49.125%, MSE=0.361847
[2023-04-23-23:30:08] [6/10] training 49.3%: Loss=0.641605, Accuracy=48.882%, MSE=0.361509
[2023-04-23-23:30:10] [6/10] training 52.2%: Loss=0.640593, Accuracy=48.611%, MSE=0.361596
[2023-04-23-23:30:12] [6/10] training 55.1%: Loss=0.637297, Accuracy=49.053%, MSE=0.359047
[2023-04-23-23:30:13] [6/10] training 58.0%: Loss=0.633027, Accuracy=49.450%, MSE=0.356318
[2023-04-23-23:30:15] [6/10] training 60.9%: Loss=0.638899, Accuracy=49.143%, MSE=0.360082
[2023-04-23-23:30:16] [6/10] training 63.8%: Loss=0.639743, Accuracy=49.045%, MSE=0.361367
[2023-04-23-23:30:18] [6/10] training 66.7%: Loss=0.636407, Accuracy=49.217%, MSE=0.359401
[2023-04-23-23:30:19] [6/10] training 69.6%: Loss=0.629406, Accuracy=49.792%, MSE=0.354461
[2023-04-23-23:30:21] [6/10] training 72.5%: Loss=0.625486, Accuracy=49.960%, MSE=0.352359
[2023-04-23-23:30:22] [6/10] training 75.4%: Loss=0.618662, Accuracy=50.731%, MSE=0.347156
[2023-04-23-23:30:24] [6/10] training 78.3%: Loss=0.61836, Accuracy=50.593%, MSE=0.347958
[2023-04-23-23:30:25] [6/10] training 81.2%: Loss=0.626715, Accuracy=50.500%, MSE=0.351975
[2023-04-23-23:30:27] [6/10] training 84.1%: Loss=0.63809, Accuracy=50.345%, MSE=0.35667
[2023-04-23-23:30:28] [6/10] training 87.0%: Loss=0.642602, Accuracy=50.133%, MSE=0.35922
[2023-04-23-23:30:30] [6/10] training 89.9%: Loss=0.640407, Accuracy=50.161%, MSE=0.358177
[2023-04-23-23:30:31] [6/10] training 92.8%: Loss=0.635538, Accuracy=50.438%, MSE=0.354805
[2023-04-23-23:30:32] [6/10] training 95.7%: Loss=0.630506, Accuracy=50.697%, MSE=0.351694
[2023-04-23-23:30:34] [6/10] training 98.6%: Loss=0.628138, Accuracy=50.706%, MSE=0.350253
[2023-04-23-23:30:40] Finished Epoch 6/10: Loss=1.06827, Accuracy=48.296%, MSE=0.336035, Precision=0.540319, Recall=0.332792, F1=0.411893, AUPR=0.516467
[2023-04-23-23:30:40] Saving model to ./models/huang_both_0_tt_partitions_epoch06.sav
[2023-04-23-23:30:42] [7/10] training 2.9%: Loss=0.61478, Accuracy=45.000%, MSE=0.357958
[2023-04-23-23:30:43] [7/10] training 5.8%: Loss=0.532736, Accuracy=53.000%, MSE=0.289788
[2023-04-23-23:30:45] [7/10] training 8.7%: Loss=0.514876, Accuracy=57.000%, MSE=0.271692
[2023-04-23-23:30:46] [7/10] training 11.6%: Loss=0.527346, Accuracy=55.250%, MSE=0.28238
[2023-04-23-23:30:48] [7/10] training 14.5%: Loss=0.532734, Accuracy=54.800%, MSE=0.28957
[2023-04-23-23:30:49] [7/10] training 17.4%: Loss=0.527592, Accuracy=56.667%, MSE=0.284097
[2023-04-23-23:30:51] [7/10] training 20.3%: Loss=0.51161, Accuracy=59.143%, MSE=0.269886
[2023-04-23-23:30:53] [7/10] training 23.2%: Loss=0.496731, Accuracy=60.875%, MSE=0.258318
[2023-04-23-23:30:54] [7/10] training 26.1%: Loss=0.502016, Accuracy=59.556%, MSE=0.265164
[2023-04-23-23:30:56] [7/10] training 29.0%: Loss=0.530762, Accuracy=58.800%, MSE=0.280051
[2023-04-23-23:30:57] [7/10] training 31.9%: Loss=0.559611, Accuracy=57.818%, MSE=0.296359
[2023-04-23-23:30:59] [7/10] training 34.8%: Loss=0.577655, Accuracy=56.167%, MSE=0.309005
[2023-04-23-23:31:00] [7/10] training 37.7%: Loss=0.577563, Accuracy=55.231%, MSE=0.312447
[2023-04-23-23:31:02] [7/10] training 40.6%: Loss=0.566138, Accuracy=56.143%, MSE=0.304384
[2023-04-23-23:31:03] [7/10] training 43.5%: Loss=0.557668, Accuracy=56.933%, MSE=0.298651
[2023-04-23-23:31:05] [7/10] training 46.4%: Loss=0.553707, Accuracy=57.188%, MSE=0.296753
[2023-04-23-23:31:06] [7/10] training 49.3%: Loss=0.559123, Accuracy=57.353%, MSE=0.299615
[2023-04-23-23:31:08] [7/10] training 52.2%: Loss=0.566573, Accuracy=56.944%, MSE=0.304573
[2023-04-23-23:31:09] [7/10] training 55.1%: Loss=0.569911, Accuracy=56.105%, MSE=0.308194
[2023-04-23-23:31:11] [7/10] training 58.0%: Loss=0.564499, Accuracy=56.450%, MSE=0.304761
[2023-04-23-23:31:12] [7/10] training 60.9%: Loss=0.558872, Accuracy=57.143%, MSE=0.300679
[2023-04-23-23:31:14] [7/10] training 63.8%: Loss=0.554422, Accuracy=57.273%, MSE=0.298187
[2023-04-23-23:31:15] [7/10] training 66.7%: Loss=0.559699, Accuracy=56.870%, MSE=0.302031
[2023-04-23-23:31:17] [7/10] training 69.6%: Loss=0.564418, Accuracy=56.542%, MSE=0.305307
[2023-04-23-23:31:18] [7/10] training 72.5%: Loss=0.578206, Accuracy=55.760%, MSE=0.313103
[2023-04-23-23:31:20] [7/10] training 75.4%: Loss=0.585516, Accuracy=55.000%, MSE=0.318539
[2023-04-23-23:31:21] [7/10] training 78.3%: Loss=0.587415, Accuracy=54.815%, MSE=0.320676
[2023-04-23-23:31:23] [7/10] training 81.2%: Loss=0.582124, Accuracy=55.107%, MSE=0.317213
[2023-04-23-23:31:24] [7/10] training 84.1%: Loss=0.575999, Accuracy=55.655%, MSE=0.312782
[2023-04-23-23:31:26] [7/10] training 87.0%: Loss=0.572909, Accuracy=55.700%, MSE=0.310977
[2023-04-23-23:31:27] [7/10] training 89.9%: Loss=0.571136, Accuracy=55.677%, MSE=0.310379
[2023-04-23-23:31:29] [7/10] training 92.8%: Loss=0.572528, Accuracy=55.500%, MSE=0.311946
[2023-04-23-23:31:30] [7/10] training 95.7%: Loss=0.57275, Accuracy=55.455%, MSE=0.312537
[2023-04-23-23:31:32] [7/10] training 98.6%: Loss=0.570771, Accuracy=55.765%, MSE=0.311233
[2023-04-23-23:31:38] Finished Epoch 7/10: Loss=1.7623, Accuracy=48.296%, MSE=0.425953, Precision=0.741157, Recall=0.0825594, F1=0.148569, AUPR=0.729107
[2023-04-23-23:31:38] Saving model to ./models/huang_both_0_tt_partitions_epoch07.sav
[2023-04-23-23:31:40] [8/10] training 2.9%: Loss=0.448782, Accuracy=71.000%, MSE=0.205102
[2023-04-23-23:31:41] [8/10] training 5.8%: Loss=0.43283, Accuracy=69.000%, MSE=0.202882
[2023-04-23-23:31:43] [8/10] training 8.7%: Loss=0.52087, Accuracy=61.667%, MSE=0.272038
[2023-04-23-23:31:44] [8/10] training 11.6%: Loss=0.586551, Accuracy=59.750%, MSE=0.306948
[2023-04-23-23:31:46] [8/10] training 14.5%: Loss=0.615283, Accuracy=59.200%, MSE=0.323708
[2023-04-23-23:31:47] [8/10] training 17.4%: Loss=0.648565, Accuracy=57.333%, MSE=0.343532
[2023-04-23-23:31:49] [8/10] training 20.3%: Loss=0.632499, Accuracy=57.143%, MSE=0.33625
[2023-04-23-23:31:50] [8/10] training 23.2%: Loss=0.618048, Accuracy=57.375%, MSE=0.329897
[2023-04-23-23:31:52] [8/10] training 26.1%: Loss=0.600399, Accuracy=57.444%, MSE=0.320718
[2023-04-23-23:31:54] [8/10] training 29.0%: Loss=0.575166, Accuracy=59.700%, MSE=0.302537
[2023-04-23-23:31:55] [8/10] training 31.9%: Loss=0.560709, Accuracy=60.455%, MSE=0.294009
[2023-04-23-23:31:57] [8/10] training 34.8%: Loss=0.555531, Accuracy=60.250%, MSE=0.291573
[2023-04-23-23:31:58] [8/10] training 37.7%: Loss=0.55291, Accuracy=60.231%, MSE=0.291198
[2023-04-23-23:32:00] [8/10] training 40.6%: Loss=0.570392, Accuracy=58.643%, MSE=0.30385
[2023-04-23-23:32:01] [8/10] training 43.5%: Loss=0.581271, Accuracy=57.067%, MSE=0.314356
[2023-04-23-23:32:03] [8/10] training 46.4%: Loss=0.578294, Accuracy=56.562%, MSE=0.314331
[2023-04-23-23:32:04] [8/10] training 49.3%: Loss=0.570853, Accuracy=57.235%, MSE=0.309518
[2023-04-23-23:32:06] [8/10] training 52.2%: Loss=0.568673, Accuracy=57.167%, MSE=0.309272
[2023-04-23-23:32:07] [8/10] training 55.1%: Loss=0.571488, Accuracy=56.842%, MSE=0.312362
[2023-04-23-23:32:09] [8/10] training 58.0%: Loss=0.579442, Accuracy=56.500%, MSE=0.31802
[2023-04-23-23:32:10] [8/10] training 60.9%: Loss=0.586771, Accuracy=56.524%, MSE=0.321385
[2023-04-23-23:32:12] [8/10] training 63.8%: Loss=0.592964, Accuracy=56.273%, MSE=0.325447
[2023-04-23-23:32:13] [8/10] training 66.7%: Loss=0.594629, Accuracy=56.435%, MSE=0.326048
[2023-04-23-23:32:15] [8/10] training 69.6%: Loss=0.600549, Accuracy=56.000%, MSE=0.330445
[2023-04-23-23:32:16] [8/10] training 72.5%: Loss=0.603245, Accuracy=55.600%, MSE=0.333474
[2023-04-23-23:32:17] [8/10] training 75.4%: Loss=0.602437, Accuracy=55.346%, MSE=0.334201
[2023-04-23-23:32:19] [8/10] training 78.3%: Loss=0.599952, Accuracy=55.296%, MSE=0.333475
[2023-04-23-23:32:20] [8/10] training 81.2%: Loss=0.598611, Accuracy=54.929%, MSE=0.333723
[2023-04-23-23:32:22] [8/10] training 84.1%: Loss=0.593489, Accuracy=55.276%, MSE=0.33025
[2023-04-23-23:32:23] [8/10] training 87.0%: Loss=0.586534, Accuracy=55.967%, MSE=0.324456
[2023-04-23-23:32:25] [8/10] training 89.9%: Loss=0.580701, Accuracy=56.710%, MSE=0.319683
[2023-04-23-23:32:27] [8/10] training 92.8%: Loss=0.57479, Accuracy=57.094%, MSE=0.315494
[2023-04-23-23:32:28] [8/10] training 95.7%: Loss=0.57206, Accuracy=57.182%, MSE=0.313933
[2023-04-23-23:32:29] [8/10] training 98.6%: Loss=0.573392, Accuracy=56.912%, MSE=0.315468
[2023-04-23-23:32:36] Finished Epoch 8/10: Loss=1.88632, Accuracy=48.296%, MSE=0.464796, Precision=0.55407, Recall=0.037705, F1=0.0706052, AUPR=0.553597
[2023-04-23-23:32:36] Saving model to ./models/huang_both_0_tt_partitions_epoch08.sav
[2023-04-23-23:32:38] [9/10] training 2.9%: Loss=0.778298, Accuracy=37.000%, MSE=0.469256
[2023-04-23-23:32:39] [9/10] training 5.8%: Loss=0.683943, Accuracy=43.000%, MSE=0.412904
[2023-04-23-23:32:41] [9/10] training 8.7%: Loss=0.6155, Accuracy=47.667%, MSE=0.363183
[2023-04-23-23:32:42] [9/10] training 11.6%: Loss=0.559935, Accuracy=53.500%, MSE=0.319066
[2023-04-23-23:32:44] [9/10] training 14.5%: Loss=0.517692, Accuracy=58.800%, MSE=0.282647
[2023-04-23-23:32:45] [9/10] training 17.4%: Loss=0.495595, Accuracy=60.667%, MSE=0.266241
[2023-04-23-23:32:47] [9/10] training 20.3%: Loss=0.482843, Accuracy=62.429%, MSE=0.2543
[2023-04-23-23:32:48] [9/10] training 23.2%: Loss=0.476308, Accuracy=63.125%, MSE=0.249986
[2023-04-23-23:32:50] [9/10] training 26.1%: Loss=0.472687, Accuracy=63.444%, MSE=0.247377
[2023-04-23-23:32:51] [9/10] training 29.0%: Loss=0.471771, Accuracy=63.900%, MSE=0.246194
[2023-04-23-23:32:53] [9/10] training 31.9%: Loss=0.480218, Accuracy=62.909%, MSE=0.253359
[2023-04-23-23:32:54] [9/10] training 34.8%: Loss=0.475498, Accuracy=63.167%, MSE=0.249601
[2023-04-23-23:32:56] [9/10] training 37.7%: Loss=0.472794, Accuracy=63.615%, MSE=0.247855
[2023-04-23-23:32:57] [9/10] training 40.6%: Loss=0.468694, Accuracy=64.143%, MSE=0.244963
[2023-04-23-23:32:59] [9/10] training 43.5%: Loss=0.472815, Accuracy=63.600%, MSE=0.249067
[2023-04-23-23:33:00] [9/10] training 46.4%: Loss=0.474849, Accuracy=63.500%, MSE=0.250326
[2023-04-23-23:33:02] [9/10] training 49.3%: Loss=0.471598, Accuracy=63.882%, MSE=0.248018
[2023-04-23-23:33:03] [9/10] training 52.2%: Loss=0.465706, Accuracy=64.722%, MSE=0.24268
[2023-04-23-23:33:05] [9/10] training 55.1%: Loss=0.460657, Accuracy=65.316%, MSE=0.238246
[2023-04-23-23:33:06] [9/10] training 58.0%: Loss=0.45728, Accuracy=65.700%, MSE=0.235856
[2023-04-23-23:33:08] [9/10] training 60.9%: Loss=0.456779, Accuracy=65.714%, MSE=0.23588
[2023-04-23-23:33:09] [9/10] training 63.8%: Loss=0.456921, Accuracy=65.591%, MSE=0.236419
[2023-04-23-23:33:11] [9/10] training 66.7%: Loss=0.459629, Accuracy=65.217%, MSE=0.239565
[2023-04-23-23:33:12] [9/10] training 69.6%: Loss=0.460966, Accuracy=65.042%, MSE=0.240584
[2023-04-23-23:33:14] [9/10] training 72.5%: Loss=0.460662, Accuracy=64.960%, MSE=0.241124
[2023-04-23-23:33:15] [9/10] training 75.4%: Loss=0.45681, Accuracy=65.308%, MSE=0.23795
[2023-04-23-23:33:17] [9/10] training 78.3%: Loss=0.453685, Accuracy=65.741%, MSE=0.235217
[2023-04-23-23:33:18] [9/10] training 81.2%: Loss=0.45312, Accuracy=65.821%, MSE=0.234897
[2023-04-23-23:33:20] [9/10] training 84.1%: Loss=0.457635, Accuracy=65.345%, MSE=0.238436
[2023-04-23-23:33:21] [9/10] training 87.0%: Loss=0.466427, Accuracy=64.667%, MSE=0.245086
[2023-04-23-23:33:23] [9/10] training 89.9%: Loss=0.475985, Accuracy=63.871%, MSE=0.252039
[2023-04-23-23:33:24] [9/10] training 92.8%: Loss=0.479694, Accuracy=63.313%, MSE=0.255863
[2023-04-23-23:33:26] [9/10] training 95.7%: Loss=0.476592, Accuracy=63.636%, MSE=0.253244
[2023-04-23-23:33:27] [9/10] training 98.6%: Loss=0.473245, Accuracy=64.000%, MSE=0.250484
[2023-04-23-23:33:34] Finished Epoch 9/10: Loss=1.80175, Accuracy=48.444%, MSE=0.398417, Precision=0.817718, Recall=0.117956, F1=0.206171, AUPR=0.790855
[2023-04-23-23:33:34] Saving model to ./models/huang_both_0_tt_partitions_epoch09.sav
[2023-04-23-23:33:35] [10/10] training 2.9%: Loss=0.31852, Accuracy=81.000%, MSE=0.118498
[2023-04-23-23:33:37] [10/10] training 5.8%: Loss=0.365793, Accuracy=75.000%, MSE=0.16101
[2023-04-23-23:33:38] [10/10] training 8.7%: Loss=0.429154, Accuracy=69.333%, MSE=0.213636
[2023-04-23-23:33:40] [10/10] training 11.6%: Loss=0.468989, Accuracy=65.500%, MSE=0.245158
[2023-04-23-23:33:42] [10/10] training 14.5%: Loss=0.501756, Accuracy=62.000%, MSE=0.273238
[2023-04-23-23:33:43] [10/10] training 17.4%: Loss=0.498403, Accuracy=61.500%, MSE=0.273294
[2023-04-23-23:33:45] [10/10] training 20.3%: Loss=0.48438, Accuracy=62.571%, MSE=0.262808
[2023-04-23-23:33:46] [10/10] training 23.2%: Loss=0.470532, Accuracy=63.875%, MSE=0.25052
[2023-04-23-23:33:48] [10/10] training 26.1%: Loss=0.454015, Accuracy=65.667%, MSE=0.236266
[2023-04-23-23:33:49] [10/10] training 29.0%: Loss=0.449138, Accuracy=66.000%, MSE=0.232046
[2023-04-23-23:33:51] [10/10] training 31.9%: Loss=0.450217, Accuracy=65.818%, MSE=0.233277
[2023-04-23-23:33:52] [10/10] training 34.8%: Loss=0.456531, Accuracy=65.083%, MSE=0.239118
[2023-04-23-23:33:54] [10/10] training 37.7%: Loss=0.464993, Accuracy=63.692%, MSE=0.248416
[2023-04-23-23:33:55] [10/10] training 40.6%: Loss=0.464732, Accuracy=63.786%, MSE=0.248709
[2023-04-23-23:33:57] [10/10] training 43.5%: Loss=0.459463, Accuracy=64.467%, MSE=0.243655
[2023-04-23-23:33:58] [10/10] training 46.4%: Loss=0.452983, Accuracy=65.312%, MSE=0.23809
[2023-04-23-23:34:00] [10/10] training 49.3%: Loss=0.447896, Accuracy=66.000%, MSE=0.2338
[2023-04-23-23:34:01] [10/10] training 52.2%: Loss=0.444181, Accuracy=66.333%, MSE=0.230807
[2023-04-23-23:34:02] [10/10] training 55.1%: Loss=0.443575, Accuracy=66.368%, MSE=0.230529
[2023-04-23-23:34:04] [10/10] training 58.0%: Loss=0.439794, Accuracy=66.900%, MSE=0.226822
[2023-04-23-23:34:06] [10/10] training 60.9%: Loss=0.437055, Accuracy=67.143%, MSE=0.224404
[2023-04-23-23:34:07] [10/10] training 63.8%: Loss=0.435964, Accuracy=67.364%, MSE=0.223314
[2023-04-23-23:34:09] [10/10] training 66.7%: Loss=0.431566, Accuracy=67.913%, MSE=0.219508
[2023-04-23-23:34:10] [10/10] training 69.6%: Loss=0.429756, Accuracy=67.917%, MSE=0.218315
[2023-04-23-23:34:12] [10/10] training 72.5%: Loss=0.432429, Accuracy=67.560%, MSE=0.220644
[2023-04-23-23:34:13] [10/10] training 75.4%: Loss=0.436619, Accuracy=67.231%, MSE=0.22394
[2023-04-23-23:34:15] [10/10] training 78.3%: Loss=0.438729, Accuracy=66.963%, MSE=0.226385
[2023-04-23-23:34:16] [10/10] training 81.2%: Loss=0.435573, Accuracy=67.357%, MSE=0.223723
[2023-04-23-23:34:17] [10/10] training 84.1%: Loss=0.433699, Accuracy=67.517%, MSE=0.222246
[2023-04-23-23:34:19] [10/10] training 87.0%: Loss=0.433585, Accuracy=67.633%, MSE=0.221863
[2023-04-23-23:34:20] [10/10] training 89.9%: Loss=0.436609, Accuracy=67.097%, MSE=0.224889
[2023-04-23-23:34:22] [10/10] training 92.8%: Loss=0.441632, Accuracy=66.500%, MSE=0.229379
[2023-04-23-23:34:23] [10/10] training 95.7%: Loss=0.449633, Accuracy=65.909%, MSE=0.23516
[2023-04-23-23:34:25] [10/10] training 98.6%: Loss=0.454017, Accuracy=65.647%, MSE=0.238092
[2023-04-23-23:34:31] Finished Epoch 10/10: Loss=1.63463, Accuracy=48.296%, MSE=0.438557, Precision=0.670683, Recall=0.0674278, F1=0.122536, AUPR=0.664461
[2023-04-23-23:34:31] Saving model to ./models/huang_both_0_tt_partitions_epoch10.sav
[2023-04-23-23:34:32] Saving final model to ./models/huang_both_0_tt_partitions_final.sav
