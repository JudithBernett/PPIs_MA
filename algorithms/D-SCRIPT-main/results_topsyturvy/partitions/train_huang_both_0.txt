[2023-08-18-18:25:24] D-SCRIPT Version 0.2.2
[2023-08-18-18:25:24] Called as: /nfs/home/students/jbernett/miniconda3/envs/dscript/bin/dscript train --topsy-turvy --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_0.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_0_tt_partitions -o ./results_topsyturvy/partitions/train_huang_both_0.txt
[2023-08-18-18:25:27] Loaded 4136 training pairs
[2023-08-18-18:25:27] Loaded 1496 test pairs
[2023-08-18-18:25:27] Loading embeddings...
[2023-08-18-18:27:23] Running D-SCRIPT Topsy-Turvy:
[2023-08-18-18:27:23] 	glider_weight: 0.2
[2023-08-18-18:27:23] 	glider_thresh: 92.5th percentile
[2023-08-18-18:27:23] Computing GLIDER matrix...
[2023-08-18-18:27:26] Initializing embedding model with:
[2023-08-18-18:27:26] 	projection_dim: 100
[2023-08-18-18:27:26] 	dropout_p: 0.5
[2023-08-18-18:27:26] Initializing contact model with:
[2023-08-18-18:27:26] 	hidden_dim: 50
[2023-08-18-18:27:26] 	kernel_width: 7
[2023-08-18-18:27:26] Initializing interaction model with:
[2023-08-18-18:27:26] 	do_poool: False
[2023-08-18-18:27:26] 	pool_width: 9
[2023-08-18-18:27:26] 	do_w: True
[2023-08-18-18:27:26] 	do_sigmoid: True
[2023-08-18-18:27:26] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-08-18-18:27:29] Using save prefix "./models/huang_both_0_tt_partitions"
[2023-08-18-18:27:29] Training with Adam: lr=0.001, weight_decay=0
[2023-08-18-18:27:29] 	num_epochs: 10
[2023-08-18-18:27:29] 	batch_size: 25
[2023-08-18-18:27:29] 	interaction weight: 0.35
[2023-08-18-18:27:29] 	contact map weight: 0.65
[2023-08-18-18:27:32] [1/10] training 2.4%: Loss=1.48368, Accuracy=50.000%, MSE=0.498534
[2023-08-18-18:27:34] [1/10] training 4.8%: Loss=1.42842, Accuracy=51.500%, MSE=0.483408
[2023-08-18-18:27:36] [1/10] training 7.2%: Loss=1.43783, Accuracy=50.000%, MSE=0.498092
[2023-08-18-18:27:38] [1/10] training 9.6%: Loss=1.44175, Accuracy=49.250%, MSE=0.505394
[2023-08-18-18:27:40] [1/10] training 12.0%: Loss=1.41058, Accuracy=50.000%, MSE=0.497682
[2023-08-18-18:27:42] [1/10] training 14.5%: Loss=1.40567, Accuracy=49.333%, MSE=0.50392
[2023-08-18-18:27:44] [1/10] training 16.9%: Loss=1.40407, Accuracy=49.143%, MSE=0.505751
[2023-08-18-18:27:46] [1/10] training 19.3%: Loss=1.41041, Accuracy=48.250%, MSE=0.514398
[2023-08-18-18:27:48] [1/10] training 21.7%: Loss=1.39378, Accuracy=48.889%, MSE=0.508019
[2023-08-18-18:27:50] [1/10] training 24.1%: Loss=1.36269, Accuracy=50.000%, MSE=0.496828
[2023-08-18-18:27:52] [1/10] training 26.5%: Loss=1.36848, Accuracy=49.273%, MSE=0.50388
[2023-08-18-18:27:54] [1/10] training 28.9%: Loss=1.37592, Accuracy=48.583%, MSE=0.510623
[2023-08-18-18:27:57] [1/10] training 31.3%: Loss=1.37027, Accuracy=48.385%, MSE=0.512365
[2023-08-18-18:27:59] [1/10] training 33.7%: Loss=1.36492, Accuracy=48.429%, MSE=0.511851
[2023-08-18-18:28:01] [1/10] training 36.1%: Loss=1.35999, Accuracy=48.400%, MSE=0.512013
[2023-08-18-18:28:03] [1/10] training 38.6%: Loss=1.34633, Accuracy=48.875%, MSE=0.50721
[2023-08-18-18:28:05] [1/10] training 41.0%: Loss=1.33176, Accuracy=49.294%, MSE=0.50287
[2023-08-18-18:28:07] [1/10] training 43.4%: Loss=1.32953, Accuracy=49.278%, MSE=0.502987
[2023-08-18-18:28:09] [1/10] training 45.8%: Loss=1.32979, Accuracy=48.947%, MSE=0.506076
[2023-08-18-18:28:11] [1/10] training 48.2%: Loss=1.31918, Accuracy=49.300%, MSE=0.502512
[2023-08-18-18:28:13] [1/10] training 50.6%: Loss=1.31914, Accuracy=49.095%, MSE=0.504445
[2023-08-18-18:28:15] [1/10] training 53.0%: Loss=1.31317, Accuracy=49.227%, MSE=0.503053
[2023-08-18-18:28:16] [1/10] training 55.4%: Loss=1.3107, Accuracy=49.087%, MSE=0.504297
[2023-08-18-18:28:18] [1/10] training 57.8%: Loss=1.30203, Accuracy=49.375%, MSE=0.501366
[2023-08-18-18:28:20] [1/10] training 60.2%: Loss=1.29609, Accuracy=49.440%, MSE=0.50058
[2023-08-18-18:28:22] [1/10] training 62.7%: Loss=1.29134, Accuracy=49.538%, MSE=0.499543
[2023-08-18-18:28:24] [1/10] training 65.1%: Loss=1.28903, Accuracy=49.481%, MSE=0.500029
[2023-08-18-18:28:26] [1/10] training 67.5%: Loss=1.28137, Accuracy=49.714%, MSE=0.497642
[2023-08-18-18:28:28] [1/10] training 69.9%: Loss=1.2751, Accuracy=49.897%, MSE=0.495774
[2023-08-18-18:28:30] [1/10] training 72.3%: Loss=1.276, Accuracy=49.600%, MSE=0.498558
[2023-08-18-18:28:32] [1/10] training 74.7%: Loss=1.27357, Accuracy=49.613%, MSE=0.498375
[2023-08-18-18:28:34] [1/10] training 77.1%: Loss=1.27072, Accuracy=49.562%, MSE=0.498757
[2023-08-18-18:28:36] [1/10] training 79.5%: Loss=1.26682, Accuracy=49.606%, MSE=0.498236
[2023-08-18-18:28:38] [1/10] training 81.9%: Loss=1.26321, Accuracy=49.647%, MSE=0.497752
[2023-08-18-18:28:40] [1/10] training 84.3%: Loss=1.25851, Accuracy=49.714%, MSE=0.496972
[2023-08-18-18:28:42] [1/10] training 86.7%: Loss=1.25263, Accuracy=49.861%, MSE=0.495407
[2023-08-18-18:28:44] [1/10] training 89.2%: Loss=1.2513, Accuracy=49.838%, MSE=0.495592
[2023-08-18-18:28:45] [1/10] training 91.6%: Loss=1.24911, Accuracy=49.789%, MSE=0.495969
[2023-08-18-18:28:48] [1/10] training 94.0%: Loss=1.24522, Accuracy=49.846%, MSE=0.495299
[2023-08-18-18:28:49] [1/10] training 96.4%: Loss=1.2446, Accuracy=49.750%, MSE=0.496183
[2023-08-18-18:28:51] [1/10] training 98.8%: Loss=1.23983, Accuracy=49.878%, MSE=0.494825
[2023-08-18-18:29:06] Finished Epoch 1/10: Loss=2.19121, Accuracy=49.867%, MSE=0.486002, Precision=0.443041, Recall=0.0143375, F1=0.027776, AUPR=0.418808
[2023-08-18-18:29:06] Saving model to ./models/huang_both_0_tt_partitions_epoch01.sav
[2023-08-18-18:29:08] [2/10] training 2.4%: Loss=1.05924, Accuracy=52.000%, MSE=0.468189
[2023-08-18-18:29:09] [2/10] training 4.8%: Loss=1.14604, Accuracy=48.500%, MSE=0.504206
[2023-08-18-18:29:11] [2/10] training 7.2%: Loss=1.12659, Accuracy=49.333%, MSE=0.495837
[2023-08-18-18:29:13] [2/10] training 9.6%: Loss=1.12295, Accuracy=49.250%, MSE=0.496236
[2023-08-18-18:29:15] [2/10] training 12.0%: Loss=1.0983, Accuracy=50.800%, MSE=0.481139
[2023-08-18-18:29:16] [2/10] training 14.5%: Loss=1.07687, Accuracy=51.833%, MSE=0.470684
[2023-08-18-18:29:18] [2/10] training 16.9%: Loss=1.0958, Accuracy=50.571%, MSE=0.482925
[2023-08-18-18:29:20] [2/10] training 19.3%: Loss=1.09993, Accuracy=50.125%, MSE=0.487078
[2023-08-18-18:29:22] [2/10] training 21.7%: Loss=1.10806, Accuracy=49.667%, MSE=0.491656
[2023-08-18-18:29:24] [2/10] training 24.1%: Loss=1.10165, Accuracy=50.000%, MSE=0.488377
[2023-08-18-18:29:25] [2/10] training 26.5%: Loss=1.09973, Accuracy=49.909%, MSE=0.489058
[2023-08-18-18:29:27] [2/10] training 28.9%: Loss=1.11213, Accuracy=49.083%, MSE=0.497035
[2023-08-18-18:29:29] [2/10] training 31.3%: Loss=1.10335, Accuracy=49.462%, MSE=0.493209
[2023-08-18-18:29:31] [2/10] training 33.7%: Loss=1.09816, Accuracy=49.714%, MSE=0.490676
[2023-08-18-18:29:33] [2/10] training 36.1%: Loss=1.09537, Accuracy=49.733%, MSE=0.49036
[2023-08-18-18:29:35] [2/10] training 38.6%: Loss=1.09578, Accuracy=49.562%, MSE=0.491858
[2023-08-18-18:29:37] [2/10] training 41.0%: Loss=1.10001, Accuracy=49.176%, MSE=0.495514
[2023-08-18-18:29:39] [2/10] training 43.4%: Loss=1.10099, Accuracy=49.056%, MSE=0.496581
[2023-08-18-18:29:40] [2/10] training 45.8%: Loss=1.10319, Accuracy=48.842%, MSE=0.498593
[2023-08-18-18:29:42] [2/10] training 48.2%: Loss=1.10143, Accuracy=48.800%, MSE=0.498833
[2023-08-18-18:29:44] [2/10] training 50.6%: Loss=1.09766, Accuracy=49.048%, MSE=0.496445
[2023-08-18-18:29:45] [2/10] training 53.0%: Loss=1.0909, Accuracy=49.227%, MSE=0.494338
[2023-08-18-18:29:47] [2/10] training 55.4%: Loss=1.0832, Accuracy=49.652%, MSE=0.490128
[2023-08-18-18:29:49] [2/10] training 57.8%: Loss=1.07735, Accuracy=49.875%, MSE=0.487791
[2023-08-18-18:29:51] [2/10] training 60.2%: Loss=1.07216, Accuracy=50.040%, MSE=0.486006
[2023-08-18-18:29:52] [2/10] training 62.7%: Loss=1.07132, Accuracy=50.038%, MSE=0.485995
[2023-08-18-18:29:54] [2/10] training 65.1%: Loss=1.07512, Accuracy=49.630%, MSE=0.489741
[2023-08-18-18:29:57] [2/10] training 67.5%: Loss=1.07127, Accuracy=49.786%, MSE=0.488103
[2023-08-18-18:29:58] [2/10] training 69.9%: Loss=1.06586, Accuracy=49.931%, MSE=0.486399
[2023-08-18-18:30:00] [2/10] training 72.3%: Loss=1.06896, Accuracy=49.567%, MSE=0.489686
[2023-08-18-18:30:01] [2/10] training 74.7%: Loss=1.06881, Accuracy=49.548%, MSE=0.48986
[2023-08-18-18:30:03] [2/10] training 77.1%: Loss=1.06534, Accuracy=49.562%, MSE=0.489434
[2023-08-18-18:30:05] [2/10] training 79.5%: Loss=1.06301, Accuracy=49.667%, MSE=0.4884
[2023-08-18-18:30:07] [2/10] training 81.9%: Loss=1.05963, Accuracy=49.676%, MSE=0.488005
[2023-08-18-18:30:09] [2/10] training 84.3%: Loss=1.05497, Accuracy=49.800%, MSE=0.486523
[2023-08-18-18:30:10] [2/10] training 86.7%: Loss=1.05154, Accuracy=50.028%, MSE=0.484381
[2023-08-18-18:30:12] [2/10] training 89.2%: Loss=1.05121, Accuracy=49.838%, MSE=0.48589
[2023-08-18-18:30:14] [2/10] training 91.6%: Loss=1.05053, Accuracy=49.789%, MSE=0.486298
[2023-08-18-18:30:16] [2/10] training 94.0%: Loss=1.04743, Accuracy=49.821%, MSE=0.485749
[2023-08-18-18:30:18] [2/10] training 96.4%: Loss=1.04152, Accuracy=50.075%, MSE=0.483118
[2023-08-18-18:30:20] [2/10] training 98.8%: Loss=1.0402, Accuracy=50.073%, MSE=0.482986
[2023-08-18-18:30:33] Finished Epoch 2/10: Loss=1.96579, Accuracy=49.867%, MSE=0.477058, Precision=0.362141, Recall=0.0249436, F1=0.0466724, AUPR=0.376164
[2023-08-18-18:30:33] Saving model to ./models/huang_both_0_tt_partitions_epoch02.sav
[2023-08-18-18:30:35] [3/10] training 2.4%: Loss=0.941637, Accuracy=49.000%, MSE=0.484525
[2023-08-18-18:30:37] [3/10] training 4.8%: Loss=0.881464, Accuracy=52.500%, MSE=0.44828
[2023-08-18-18:30:39] [3/10] training 7.2%: Loss=0.937022, Accuracy=50.667%, MSE=0.46894
[2023-08-18-18:30:40] [3/10] training 9.6%: Loss=0.971182, Accuracy=49.000%, MSE=0.485913
[2023-08-18-18:30:42] [3/10] training 12.0%: Loss=0.961018, Accuracy=49.600%, MSE=0.479759
[2023-08-18-18:30:44] [3/10] training 14.5%: Loss=0.95763, Accuracy=49.667%, MSE=0.478525
[2023-08-18-18:30:46] [3/10] training 16.9%: Loss=0.953956, Accuracy=50.000%, MSE=0.475425
[2023-08-18-18:30:48] [3/10] training 19.3%: Loss=0.960642, Accuracy=49.500%, MSE=0.48002
[2023-08-18-18:30:50] [3/10] training 21.7%: Loss=0.948268, Accuracy=50.000%, MSE=0.474819
[2023-08-18-18:30:52] [3/10] training 24.1%: Loss=0.960009, Accuracy=49.100%, MSE=0.483429
[2023-08-18-18:30:53] [3/10] training 26.5%: Loss=0.948418, Accuracy=50.000%, MSE=0.475008
[2023-08-18-18:30:55] [3/10] training 28.9%: Loss=0.951273, Accuracy=49.500%, MSE=0.479041
[2023-08-18-18:30:57] [3/10] training 31.3%: Loss=0.950452, Accuracy=49.615%, MSE=0.478114
[2023-08-18-18:30:59] [3/10] training 33.7%: Loss=0.951199, Accuracy=49.571%, MSE=0.47872
[2023-08-18-18:31:01] [3/10] training 36.1%: Loss=0.945799, Accuracy=49.733%, MSE=0.476718
[2023-08-18-18:31:02] [3/10] training 38.6%: Loss=0.951507, Accuracy=49.125%, MSE=0.482117
[2023-08-18-18:31:04] [3/10] training 41.0%: Loss=0.955743, Accuracy=49.000%, MSE=0.483434
[2023-08-18-18:31:06] [3/10] training 43.4%: Loss=0.949426, Accuracy=49.278%, MSE=0.480387
[2023-08-18-18:31:08] [3/10] training 45.8%: Loss=0.94473, Accuracy=49.421%, MSE=0.478387
[2023-08-18-18:31:09] [3/10] training 48.2%: Loss=0.943571, Accuracy=49.550%, MSE=0.477361
[2023-08-18-18:31:11] [3/10] training 50.6%: Loss=0.938283, Accuracy=49.667%, MSE=0.475529
[2023-08-18-18:31:13] [3/10] training 53.0%: Loss=0.93636, Accuracy=49.409%, MSE=0.476809
[2023-08-18-18:31:15] [3/10] training 55.4%: Loss=0.937362, Accuracy=49.261%, MSE=0.477964
[2023-08-18-18:31:16] [3/10] training 57.8%: Loss=0.93932, Accuracy=49.000%, MSE=0.480208
[2023-08-18-18:31:18] [3/10] training 60.2%: Loss=0.937231, Accuracy=48.920%, MSE=0.480467
[2023-08-18-18:31:20] [3/10] training 62.7%: Loss=0.933351, Accuracy=49.000%, MSE=0.478996
[2023-08-18-18:31:22] [3/10] training 65.1%: Loss=0.929539, Accuracy=49.222%, MSE=0.476837
[2023-08-18-18:31:23] [3/10] training 67.5%: Loss=0.926427, Accuracy=49.321%, MSE=0.475488
[2023-08-18-18:31:25] [3/10] training 69.9%: Loss=0.922888, Accuracy=49.448%, MSE=0.474012
[2023-08-18-18:31:27] [3/10] training 72.3%: Loss=0.923542, Accuracy=49.300%, MSE=0.475123
[2023-08-18-18:31:29] [3/10] training 74.7%: Loss=0.919667, Accuracy=49.516%, MSE=0.473013
[2023-08-18-18:31:31] [3/10] training 77.1%: Loss=0.916456, Accuracy=49.531%, MSE=0.472207
[2023-08-18-18:31:33] [3/10] training 79.5%: Loss=0.91659, Accuracy=49.515%, MSE=0.472174
[2023-08-18-18:31:34] [3/10] training 81.9%: Loss=0.912938, Accuracy=49.647%, MSE=0.470612
[2023-08-18-18:31:36] [3/10] training 84.3%: Loss=0.911563, Accuracy=49.657%, MSE=0.470413
[2023-08-18-18:31:38] [3/10] training 86.7%: Loss=0.911423, Accuracy=49.611%, MSE=0.470792
[2023-08-18-18:31:40] [3/10] training 89.2%: Loss=0.910207, Accuracy=49.568%, MSE=0.470828
[2023-08-18-18:31:42] [3/10] training 91.6%: Loss=0.906766, Accuracy=49.684%, MSE=0.469436
[2023-08-18-18:31:43] [3/10] training 94.0%: Loss=0.907791, Accuracy=49.590%, MSE=0.470388
[2023-08-18-18:31:45] [3/10] training 96.4%: Loss=0.905878, Accuracy=49.725%, MSE=0.469147
[2023-08-18-18:31:47] [3/10] training 98.8%: Loss=0.902453, Accuracy=49.805%, MSE=0.467739
[2023-08-18-18:32:00] Finished Epoch 3/10: Loss=1.802, Accuracy=49.867%, MSE=0.467055, Precision=0.369253, Recall=0.0377377, F1=0.068477, AUPR=0.38834
[2023-08-18-18:32:00] Saving model to ./models/huang_both_0_tt_partitions_epoch03.sav
[2023-08-18-18:32:02] [4/10] training 2.4%: Loss=0.917671, Accuracy=46.000%, MSE=0.494104
[2023-08-18-18:32:03] [4/10] training 4.8%: Loss=0.882784, Accuracy=48.000%, MSE=0.47679
[2023-08-18-18:32:05] [4/10] training 7.2%: Loss=0.823082, Accuracy=50.333%, MSE=0.447
[2023-08-18-18:32:06] [4/10] training 9.6%: Loss=0.820452, Accuracy=51.000%, MSE=0.440801
[2023-08-18-18:32:08] [4/10] training 12.0%: Loss=0.825271, Accuracy=51.000%, MSE=0.442811
[2023-08-18-18:32:10] [4/10] training 14.5%: Loss=0.830269, Accuracy=50.333%, MSE=0.448129
[2023-08-18-18:32:12] [4/10] training 16.9%: Loss=0.83266, Accuracy=50.429%, MSE=0.448675
[2023-08-18-18:32:14] [4/10] training 19.3%: Loss=0.829398, Accuracy=50.375%, MSE=0.449086
[2023-08-18-18:32:16] [4/10] training 21.7%: Loss=0.81774, Accuracy=50.778%, MSE=0.44414
[2023-08-18-18:32:18] [4/10] training 24.1%: Loss=0.824144, Accuracy=50.400%, MSE=0.448144
[2023-08-18-18:32:19] [4/10] training 26.5%: Loss=0.830768, Accuracy=49.909%, MSE=0.452608
[2023-08-18-18:32:21] [4/10] training 28.9%: Loss=0.83819, Accuracy=49.333%, MSE=0.457958
[2023-08-18-18:32:23] [4/10] training 31.3%: Loss=0.837597, Accuracy=49.000%, MSE=0.459659
[2023-08-18-18:32:25] [4/10] training 33.7%: Loss=0.831267, Accuracy=49.429%, MSE=0.455814
[2023-08-18-18:32:27] [4/10] training 36.1%: Loss=0.826831, Accuracy=50.200%, MSE=0.450175
[2023-08-18-18:32:29] [4/10] training 38.6%: Loss=0.822508, Accuracy=50.250%, MSE=0.448846
[2023-08-18-18:32:31] [4/10] training 41.0%: Loss=0.820297, Accuracy=50.529%, MSE=0.446766
[2023-08-18-18:32:32] [4/10] training 43.4%: Loss=0.823516, Accuracy=50.222%, MSE=0.449493
[2023-08-18-18:32:34] [4/10] training 45.8%: Loss=0.826831, Accuracy=49.842%, MSE=0.452627
[2023-08-18-18:32:36] [4/10] training 48.2%: Loss=0.828793, Accuracy=49.850%, MSE=0.453294
[2023-08-18-18:32:38] [4/10] training 50.6%: Loss=0.828834, Accuracy=49.571%, MSE=0.455253
[2023-08-18-18:32:40] [4/10] training 53.0%: Loss=0.82022, Accuracy=49.955%, MSE=0.450763
[2023-08-18-18:32:42] [4/10] training 55.4%: Loss=0.817736, Accuracy=49.739%, MSE=0.451047
[2023-08-18-18:32:43] [4/10] training 57.8%: Loss=0.817304, Accuracy=49.667%, MSE=0.451055
[2023-08-18-18:32:45] [4/10] training 60.2%: Loss=0.820708, Accuracy=49.200%, MSE=0.454348
[2023-08-18-18:32:47] [4/10] training 62.7%: Loss=0.822488, Accuracy=48.962%, MSE=0.456227
[2023-08-18-18:32:49] [4/10] training 65.1%: Loss=0.820561, Accuracy=49.222%, MSE=0.454298
[2023-08-18-18:32:50] [4/10] training 67.5%: Loss=0.815854, Accuracy=49.429%, MSE=0.451683
[2023-08-18-18:32:52] [4/10] training 69.9%: Loss=0.814999, Accuracy=49.345%, MSE=0.452059
[2023-08-18-18:32:54] [4/10] training 72.3%: Loss=0.810071, Accuracy=49.633%, MSE=0.448799
[2023-08-18-18:32:56] [4/10] training 74.7%: Loss=0.810199, Accuracy=49.677%, MSE=0.448505
[2023-08-18-18:32:58] [4/10] training 77.1%: Loss=0.809989, Accuracy=49.594%, MSE=0.448888
[2023-08-18-18:32:59] [4/10] training 79.5%: Loss=0.807365, Accuracy=49.606%, MSE=0.447852
[2023-08-18-18:33:01] [4/10] training 81.9%: Loss=0.810109, Accuracy=49.412%, MSE=0.449815
[2023-08-18-18:33:03] [4/10] training 84.3%: Loss=0.814696, Accuracy=49.143%, MSE=0.45265
[2023-08-18-18:33:05] [4/10] training 86.7%: Loss=0.813493, Accuracy=49.194%, MSE=0.452097
[2023-08-18-18:33:07] [4/10] training 89.2%: Loss=0.81219, Accuracy=49.027%, MSE=0.452556
[2023-08-18-18:33:09] [4/10] training 91.6%: Loss=0.809361, Accuracy=49.132%, MSE=0.451007
[2023-08-18-18:33:10] [4/10] training 94.0%: Loss=0.805852, Accuracy=49.410%, MSE=0.448497
[2023-08-18-18:33:12] [4/10] training 96.4%: Loss=0.803573, Accuracy=49.275%, MSE=0.448124
[2023-08-18-18:33:14] [4/10] training 98.8%: Loss=0.800996, Accuracy=49.488%, MSE=0.446403
[2023-08-18-18:33:26] Finished Epoch 4/10: Loss=1.30837, Accuracy=49.200%, MSE=0.411933, Precision=0.444414, Recall=0.11998, F1=0.188949, AUPR=0.442268
[2023-08-18-18:33:26] Saving model to ./models/huang_both_0_tt_partitions_epoch04.sav
[2023-08-18-18:33:29] [5/10] training 2.4%: Loss=0.816238, Accuracy=43.000%, MSE=0.485425
[2023-08-18-18:33:30] [5/10] training 4.8%: Loss=0.77409, Accuracy=47.000%, MSE=0.453452
[2023-08-18-18:33:32] [5/10] training 7.2%: Loss=0.729368, Accuracy=51.000%, MSE=0.417894
[2023-08-18-18:33:34] [5/10] training 9.6%: Loss=0.754051, Accuracy=47.750%, MSE=0.443433
[2023-08-18-18:33:36] [5/10] training 12.0%: Loss=0.734935, Accuracy=49.800%, MSE=0.425343
[2023-08-18-18:33:38] [5/10] training 14.5%: Loss=0.745277, Accuracy=49.167%, MSE=0.431524
[2023-08-18-18:33:40] [5/10] training 16.9%: Loss=0.745221, Accuracy=48.857%, MSE=0.432898
[2023-08-18-18:33:41] [5/10] training 19.3%: Loss=0.743944, Accuracy=48.500%, MSE=0.433027
[2023-08-18-18:33:43] [5/10] training 21.7%: Loss=0.747003, Accuracy=48.778%, MSE=0.433304
[2023-08-18-18:33:45] [5/10] training 24.1%: Loss=0.743316, Accuracy=48.800%, MSE=0.431754
[2023-08-18-18:33:47] [5/10] training 26.5%: Loss=0.737664, Accuracy=49.091%, MSE=0.42817
[2023-08-18-18:33:48] [5/10] training 28.9%: Loss=0.731765, Accuracy=49.833%, MSE=0.422545
[2023-08-18-18:33:50] [5/10] training 31.3%: Loss=0.726488, Accuracy=49.769%, MSE=0.420255
[2023-08-18-18:33:53] [5/10] training 33.7%: Loss=0.726978, Accuracy=49.714%, MSE=0.420926
[2023-08-18-18:33:55] [5/10] training 36.1%: Loss=0.724715, Accuracy=49.800%, MSE=0.419691
[2023-08-18-18:33:57] [5/10] training 38.6%: Loss=0.721367, Accuracy=50.000%, MSE=0.417548
[2023-08-18-18:33:58] [5/10] training 41.0%: Loss=0.722946, Accuracy=49.765%, MSE=0.419272
[2023-08-18-18:34:00] [5/10] training 43.4%: Loss=0.726338, Accuracy=49.556%, MSE=0.421673
[2023-08-18-18:34:02] [5/10] training 45.8%: Loss=0.724069, Accuracy=50.000%, MSE=0.418886
[2023-08-18-18:34:04] [5/10] training 48.2%: Loss=0.731835, Accuracy=49.000%, MSE=0.426292
[2023-08-18-18:34:05] [5/10] training 50.6%: Loss=0.733045, Accuracy=48.905%, MSE=0.427294
[2023-08-18-18:34:07] [5/10] training 53.0%: Loss=0.736942, Accuracy=48.455%, MSE=0.430983
[2023-08-18-18:34:09] [5/10] training 55.4%: Loss=0.735707, Accuracy=48.435%, MSE=0.43056
[2023-08-18-18:34:10] [5/10] training 57.8%: Loss=0.730425, Accuracy=48.583%, MSE=0.427662
[2023-08-18-18:34:12] [5/10] training 60.2%: Loss=0.72747, Accuracy=48.440%, MSE=0.42665
[2023-08-18-18:34:14] [5/10] training 62.7%: Loss=0.727721, Accuracy=48.538%, MSE=0.426114
[2023-08-18-18:34:16] [5/10] training 65.1%: Loss=0.732408, Accuracy=48.370%, MSE=0.428285
[2023-08-18-18:34:17] [5/10] training 67.5%: Loss=0.733376, Accuracy=48.071%, MSE=0.429853
[2023-08-18-18:34:19] [5/10] training 69.9%: Loss=0.729882, Accuracy=48.172%, MSE=0.428043
[2023-08-18-18:34:21] [5/10] training 72.3%: Loss=0.728224, Accuracy=48.100%, MSE=0.42738
[2023-08-18-18:34:23] [5/10] training 74.7%: Loss=0.727973, Accuracy=48.129%, MSE=0.427173
[2023-08-18-18:34:25] [5/10] training 77.1%: Loss=0.72757, Accuracy=48.188%, MSE=0.426649
[2023-08-18-18:34:26] [5/10] training 79.5%: Loss=0.725111, Accuracy=48.394%, MSE=0.424873
[2023-08-18-18:34:28] [5/10] training 81.9%: Loss=0.72198, Accuracy=48.412%, MSE=0.423174
[2023-08-18-18:34:30] [5/10] training 84.3%: Loss=0.720596, Accuracy=48.343%, MSE=0.422707
[2023-08-18-18:34:32] [5/10] training 86.7%: Loss=0.720002, Accuracy=48.500%, MSE=0.421607
[2023-08-18-18:34:33] [5/10] training 89.2%: Loss=0.717403, Accuracy=48.811%, MSE=0.419263
[2023-08-18-18:34:35] [5/10] training 91.6%: Loss=0.712224, Accuracy=49.053%, MSE=0.415643
[2023-08-18-18:34:37] [5/10] training 94.0%: Loss=0.708999, Accuracy=49.179%, MSE=0.413478
[2023-08-18-18:34:39] [5/10] training 96.4%: Loss=0.709689, Accuracy=49.125%, MSE=0.414164
[2023-08-18-18:34:41] [5/10] training 98.8%: Loss=0.708584, Accuracy=49.220%, MSE=0.413243
[2023-08-18-18:34:53] Finished Epoch 5/10: Loss=1.16833, Accuracy=49.600%, MSE=0.381789, Precision=0.58715, Recall=0.150081, F1=0.239056, AUPR=0.587683
[2023-08-18-18:34:53] Saving model to ./models/huang_both_0_tt_partitions_epoch05.sav
[2023-08-18-18:34:55] [6/10] training 2.4%: Loss=0.781164, Accuracy=42.000%, MSE=0.474117
[2023-08-18-18:34:57] [6/10] training 4.8%: Loss=0.745867, Accuracy=45.000%, MSE=0.449068
[2023-08-18-18:34:59] [6/10] training 7.2%: Loss=0.714484, Accuracy=47.333%, MSE=0.426311
[2023-08-18-18:35:01] [6/10] training 9.6%: Loss=0.693777, Accuracy=47.500%, MSE=0.415416
[2023-08-18-18:35:02] [6/10] training 12.0%: Loss=0.686027, Accuracy=48.800%, MSE=0.40759
[2023-08-18-18:35:04] [6/10] training 14.5%: Loss=0.686656, Accuracy=48.500%, MSE=0.410066
[2023-08-18-18:35:06] [6/10] training 16.9%: Loss=0.676089, Accuracy=49.571%, MSE=0.400761
[2023-08-18-18:35:08] [6/10] training 19.3%: Loss=0.688247, Accuracy=48.500%, MSE=0.41
[2023-08-18-18:35:10] [6/10] training 21.7%: Loss=0.68266, Accuracy=48.778%, MSE=0.405896
[2023-08-18-18:35:11] [6/10] training 24.1%: Loss=0.673608, Accuracy=48.900%, MSE=0.401228
[2023-08-18-18:35:13] [6/10] training 26.5%: Loss=0.681976, Accuracy=48.909%, MSE=0.40466
[2023-08-18-18:35:15] [6/10] training 28.9%: Loss=0.690132, Accuracy=48.833%, MSE=0.408135
[2023-08-18-18:35:17] [6/10] training 31.3%: Loss=0.683332, Accuracy=49.231%, MSE=0.403123
[2023-08-18-18:35:18] [6/10] training 33.7%: Loss=0.675335, Accuracy=49.214%, MSE=0.39911
[2023-08-18-18:35:20] [6/10] training 36.1%: Loss=0.676661, Accuracy=48.867%, MSE=0.401154
[2023-08-18-18:35:22] [6/10] training 38.6%: Loss=0.677051, Accuracy=49.375%, MSE=0.399078
[2023-08-18-18:35:24] [6/10] training 41.0%: Loss=0.679991, Accuracy=49.294%, MSE=0.401077
[2023-08-18-18:35:26] [6/10] training 43.4%: Loss=0.676305, Accuracy=49.333%, MSE=0.398902
[2023-08-18-18:35:28] [6/10] training 45.8%: Loss=0.673749, Accuracy=49.368%, MSE=0.398072
[2023-08-18-18:35:30] [6/10] training 48.2%: Loss=0.673219, Accuracy=49.300%, MSE=0.398421
[2023-08-18-18:35:31] [6/10] training 50.6%: Loss=0.672805, Accuracy=49.429%, MSE=0.397772
[2023-08-18-18:35:33] [6/10] training 53.0%: Loss=0.670329, Accuracy=49.455%, MSE=0.395992
[2023-08-18-18:35:35] [6/10] training 55.4%: Loss=0.666335, Accuracy=49.739%, MSE=0.392936
[2023-08-18-18:35:37] [6/10] training 57.8%: Loss=0.666085, Accuracy=49.833%, MSE=0.392614
[2023-08-18-18:35:39] [6/10] training 60.2%: Loss=0.665509, Accuracy=49.640%, MSE=0.392954
[2023-08-18-18:35:41] [6/10] training 62.7%: Loss=0.661996, Accuracy=49.692%, MSE=0.391038
[2023-08-18-18:35:43] [6/10] training 65.1%: Loss=0.662087, Accuracy=49.593%, MSE=0.391508
[2023-08-18-18:35:45] [6/10] training 67.5%: Loss=0.661112, Accuracy=49.464%, MSE=0.391419
[2023-08-18-18:35:46] [6/10] training 69.9%: Loss=0.659967, Accuracy=49.448%, MSE=0.390659
[2023-08-18-18:35:48] [6/10] training 72.3%: Loss=0.661417, Accuracy=49.333%, MSE=0.391786
[2023-08-18-18:35:50] [6/10] training 74.7%: Loss=0.660489, Accuracy=49.290%, MSE=0.391517
[2023-08-18-18:35:52] [6/10] training 77.1%: Loss=0.659207, Accuracy=49.250%, MSE=0.391118
[2023-08-18-18:35:54] [6/10] training 79.5%: Loss=0.657819, Accuracy=49.273%, MSE=0.390185
[2023-08-18-18:35:55] [6/10] training 81.9%: Loss=0.655804, Accuracy=49.412%, MSE=0.388797
[2023-08-18-18:35:57] [6/10] training 84.3%: Loss=0.655805, Accuracy=49.314%, MSE=0.389324
[2023-08-18-18:35:59] [6/10] training 86.7%: Loss=0.654544, Accuracy=49.444%, MSE=0.38816
[2023-08-18-18:36:01] [6/10] training 89.2%: Loss=0.652632, Accuracy=49.514%, MSE=0.386698
[2023-08-18-18:36:03] [6/10] training 91.6%: Loss=0.65247, Accuracy=49.289%, MSE=0.387174
[2023-08-18-18:36:04] [6/10] training 94.0%: Loss=0.652049, Accuracy=49.282%, MSE=0.387269
[2023-08-18-18:36:06] [6/10] training 96.4%: Loss=0.651266, Accuracy=49.325%, MSE=0.386608
[2023-08-18-18:36:07] [6/10] training 98.8%: Loss=0.651066, Accuracy=49.244%, MSE=0.386874
[2023-08-18-18:36:20] Finished Epoch 6/10: Loss=1.32844, Accuracy=50.000%, MSE=0.409346, Precision=0.639813, Recall=0.105999, F1=0.181868, AUPR=0.649419
[2023-08-18-18:36:20] Saving model to ./models/huang_both_0_tt_partitions_epoch06.sav
[2023-08-18-18:36:22] [7/10] training 2.4%: Loss=0.580838, Accuracy=51.000%, MSE=0.336903
[2023-08-18-18:36:24] [7/10] training 4.8%: Loss=0.617442, Accuracy=46.500%, MSE=0.378225
[2023-08-18-18:36:26] [7/10] training 7.2%: Loss=0.636349, Accuracy=46.667%, MSE=0.388953
[2023-08-18-18:36:27] [7/10] training 9.6%: Loss=0.629005, Accuracy=48.750%, MSE=0.379273
[2023-08-18-18:36:29] [7/10] training 12.0%: Loss=0.602482, Accuracy=50.200%, MSE=0.358844
[2023-08-18-18:36:31] [7/10] training 14.5%: Loss=0.607927, Accuracy=49.167%, MSE=0.364929
[2023-08-18-18:36:33] [7/10] training 16.9%: Loss=0.60239, Accuracy=49.714%, MSE=0.359448
[2023-08-18-18:36:34] [7/10] training 19.3%: Loss=0.605911, Accuracy=49.875%, MSE=0.361419
[2023-08-18-18:36:36] [7/10] training 21.7%: Loss=0.60815, Accuracy=49.444%, MSE=0.364678
[2023-08-18-18:36:38] [7/10] training 24.1%: Loss=0.610004, Accuracy=49.200%, MSE=0.366345
[2023-08-18-18:36:40] [7/10] training 26.5%: Loss=0.609409, Accuracy=49.636%, MSE=0.365171
[2023-08-18-18:36:42] [7/10] training 28.9%: Loss=0.608584, Accuracy=49.750%, MSE=0.364912
[2023-08-18-18:36:44] [7/10] training 31.3%: Loss=0.606183, Accuracy=50.000%, MSE=0.362966
[2023-08-18-18:36:45] [7/10] training 33.7%: Loss=0.600761, Accuracy=50.643%, MSE=0.357705
[2023-08-18-18:36:47] [7/10] training 36.1%: Loss=0.603711, Accuracy=49.933%, MSE=0.361457
[2023-08-18-18:36:48] [7/10] training 38.6%: Loss=0.601535, Accuracy=50.062%, MSE=0.360183
[2023-08-18-18:36:50] [7/10] training 41.0%: Loss=0.598299, Accuracy=50.471%, MSE=0.35718
[2023-08-18-18:36:52] [7/10] training 43.4%: Loss=0.599125, Accuracy=50.500%, MSE=0.357383
[2023-08-18-18:36:54] [7/10] training 45.8%: Loss=0.594577, Accuracy=50.842%, MSE=0.35358
[2023-08-18-18:36:56] [7/10] training 48.2%: Loss=0.593654, Accuracy=50.900%, MSE=0.352862
[2023-08-18-18:36:58] [7/10] training 50.6%: Loss=0.594875, Accuracy=50.714%, MSE=0.354293
[2023-08-18-18:36:59] [7/10] training 53.0%: Loss=0.594212, Accuracy=50.636%, MSE=0.353806
[2023-08-18-18:37:01] [7/10] training 55.4%: Loss=0.593406, Accuracy=50.739%, MSE=0.352918
[2023-08-18-18:37:03] [7/10] training 57.8%: Loss=0.593027, Accuracy=50.625%, MSE=0.352929
[2023-08-18-18:37:05] [7/10] training 60.2%: Loss=0.589966, Accuracy=50.760%, MSE=0.350675
[2023-08-18-18:37:07] [7/10] training 62.7%: Loss=0.590007, Accuracy=50.808%, MSE=0.350581
[2023-08-18-18:37:08] [7/10] training 65.1%: Loss=0.58974, Accuracy=50.778%, MSE=0.350589
[2023-08-18-18:37:10] [7/10] training 67.5%: Loss=0.589716, Accuracy=50.750%, MSE=0.35087
[2023-08-18-18:37:13] [7/10] training 69.9%: Loss=0.588541, Accuracy=50.793%, MSE=0.350016
[2023-08-18-18:37:14] [7/10] training 72.3%: Loss=0.586821, Accuracy=50.867%, MSE=0.348786
[2023-08-18-18:37:16] [7/10] training 74.7%: Loss=0.586164, Accuracy=50.903%, MSE=0.348294
[2023-08-18-18:37:18] [7/10] training 77.1%: Loss=0.585806, Accuracy=50.906%, MSE=0.348056
[2023-08-18-18:37:20] [7/10] training 79.5%: Loss=0.586549, Accuracy=50.636%, MSE=0.34913
[2023-08-18-18:37:21] [7/10] training 81.9%: Loss=0.588253, Accuracy=50.441%, MSE=0.35066
[2023-08-18-18:37:23] [7/10] training 84.3%: Loss=0.588403, Accuracy=50.400%, MSE=0.350977
[2023-08-18-18:37:25] [7/10] training 86.7%: Loss=0.588032, Accuracy=50.306%, MSE=0.350995
[2023-08-18-18:37:27] [7/10] training 89.2%: Loss=0.587286, Accuracy=50.378%, MSE=0.350388
[2023-08-18-18:37:29] [7/10] training 91.6%: Loss=0.588205, Accuracy=50.395%, MSE=0.35088
[2023-08-18-18:37:30] [7/10] training 94.0%: Loss=0.589309, Accuracy=50.256%, MSE=0.351945
[2023-08-18-18:37:32] [7/10] training 96.4%: Loss=0.589705, Accuracy=50.150%, MSE=0.352419
[2023-08-18-18:37:34] [7/10] training 98.8%: Loss=0.588114, Accuracy=50.317%, MSE=0.351039
[2023-08-18-18:37:47] Finished Epoch 7/10: Loss=1.03503, Accuracy=50.067%, MSE=0.354888, Precision=0.654531, Recall=0.182865, F1=0.285865, AUPR=0.670182
[2023-08-18-18:37:47] Saving model to ./models/huang_both_0_tt_partitions_epoch07.sav
[2023-08-18-18:37:49] [8/10] training 2.4%: Loss=0.602788, Accuracy=46.000%, MSE=0.36877
[2023-08-18-18:37:51] [8/10] training 4.8%: Loss=0.571855, Accuracy=50.000%, MSE=0.339984
[2023-08-18-18:37:52] [8/10] training 7.2%: Loss=0.551865, Accuracy=51.000%, MSE=0.324561
[2023-08-18-18:37:54] [8/10] training 9.6%: Loss=0.544698, Accuracy=51.750%, MSE=0.318688
[2023-08-18-18:37:56] [8/10] training 12.0%: Loss=0.549276, Accuracy=50.800%, MSE=0.324664
[2023-08-18-18:37:58] [8/10] training 14.5%: Loss=0.552529, Accuracy=50.667%, MSE=0.326735
[2023-08-18-18:38:00] [8/10] training 16.9%: Loss=0.550375, Accuracy=51.143%, MSE=0.324713
[2023-08-18-18:38:02] [8/10] training 19.3%: Loss=0.557769, Accuracy=50.625%, MSE=0.330795
[2023-08-18-18:38:04] [8/10] training 21.7%: Loss=0.556576, Accuracy=51.111%, MSE=0.329449
[2023-08-18-18:38:06] [8/10] training 24.1%: Loss=0.556456, Accuracy=51.200%, MSE=0.329074
[2023-08-18-18:38:07] [8/10] training 26.5%: Loss=0.558641, Accuracy=50.727%, MSE=0.331514
[2023-08-18-18:38:09] [8/10] training 28.9%: Loss=0.562478, Accuracy=50.250%, MSE=0.334851
[2023-08-18-18:38:11] [8/10] training 31.3%: Loss=0.560444, Accuracy=50.385%, MSE=0.33299
[2023-08-18-18:38:13] [8/10] training 33.7%: Loss=0.558421, Accuracy=50.429%, MSE=0.331724
[2023-08-18-18:38:14] [8/10] training 36.1%: Loss=0.55745, Accuracy=50.600%, MSE=0.33078
[2023-08-18-18:38:16] [8/10] training 38.6%: Loss=0.556479, Accuracy=50.688%, MSE=0.329606
[2023-08-18-18:38:18] [8/10] training 41.0%: Loss=0.556284, Accuracy=50.647%, MSE=0.329271
[2023-08-18-18:38:20] [8/10] training 43.4%: Loss=0.557843, Accuracy=50.778%, MSE=0.330621
[2023-08-18-18:38:21] [8/10] training 45.8%: Loss=0.557033, Accuracy=50.789%, MSE=0.329833
[2023-08-18-18:38:23] [8/10] training 48.2%: Loss=0.558087, Accuracy=50.500%, MSE=0.331204
[2023-08-18-18:38:25] [8/10] training 50.6%: Loss=0.555598, Accuracy=50.619%, MSE=0.329092
[2023-08-18-18:38:27] [8/10] training 53.0%: Loss=0.555649, Accuracy=50.545%, MSE=0.329273
[2023-08-18-18:38:29] [8/10] training 55.4%: Loss=0.553059, Accuracy=50.913%, MSE=0.326644
[2023-08-18-18:38:31] [8/10] training 57.8%: Loss=0.555567, Accuracy=50.500%, MSE=0.329321
[2023-08-18-18:38:33] [8/10] training 60.2%: Loss=0.553048, Accuracy=50.800%, MSE=0.326969
[2023-08-18-18:38:35] [8/10] training 62.7%: Loss=0.551763, Accuracy=50.769%, MSE=0.326327
[2023-08-18-18:38:36] [8/10] training 65.1%: Loss=0.551681, Accuracy=50.778%, MSE=0.32633
[2023-08-18-18:38:38] [8/10] training 67.5%: Loss=0.550263, Accuracy=50.929%, MSE=0.325215
[2023-08-18-18:38:40] [8/10] training 69.9%: Loss=0.55094, Accuracy=50.828%, MSE=0.325958
[2023-08-18-18:38:42] [8/10] training 72.3%: Loss=0.550719, Accuracy=50.900%, MSE=0.325552
[2023-08-18-18:38:44] [8/10] training 74.7%: Loss=0.54999, Accuracy=50.871%, MSE=0.325064
[2023-08-18-18:38:45] [8/10] training 77.1%: Loss=0.548918, Accuracy=51.000%, MSE=0.324189
[2023-08-18-18:38:47] [8/10] training 79.5%: Loss=0.547146, Accuracy=51.242%, MSE=0.322535
[2023-08-18-18:38:49] [8/10] training 81.9%: Loss=0.543889, Accuracy=51.618%, MSE=0.319669
[2023-08-18-18:38:51] [8/10] training 84.3%: Loss=0.541916, Accuracy=51.800%, MSE=0.31796
[2023-08-18-18:38:52] [8/10] training 86.7%: Loss=0.542522, Accuracy=51.778%, MSE=0.318437
[2023-08-18-18:38:54] [8/10] training 89.2%: Loss=0.542501, Accuracy=51.811%, MSE=0.318344
[2023-08-18-18:38:56] [8/10] training 91.6%: Loss=0.541367, Accuracy=51.842%, MSE=0.317551
[2023-08-18-18:38:58] [8/10] training 94.0%: Loss=0.541291, Accuracy=51.718%, MSE=0.317762
[2023-08-18-18:38:59] [8/10] training 96.4%: Loss=0.540754, Accuracy=51.750%, MSE=0.317487
[2023-08-18-18:39:01] [8/10] training 98.8%: Loss=0.539406, Accuracy=51.902%, MSE=0.316381
[2023-08-18-18:39:13] Finished Epoch 8/10: Loss=1.01032, Accuracy=51.000%, MSE=0.34016, Precision=0.711376, Recall=0.201638, F1=0.314213, AUPR=0.740715
[2023-08-18-18:39:13] Saving model to ./models/huang_both_0_tt_partitions_epoch08.sav
[2023-08-18-18:39:15] [9/10] training 2.4%: Loss=0.475122, Accuracy=55.000%, MSE=0.263148
[2023-08-18-18:39:17] [9/10] training 4.8%: Loss=0.506672, Accuracy=52.500%, MSE=0.291036
[2023-08-18-18:39:19] [9/10] training 7.2%: Loss=0.518407, Accuracy=52.000%, MSE=0.301675
[2023-08-18-18:39:21] [9/10] training 9.6%: Loss=0.504564, Accuracy=54.250%, MSE=0.287848
[2023-08-18-18:39:23] [9/10] training 12.0%: Loss=0.496052, Accuracy=55.000%, MSE=0.280375
[2023-08-18-18:39:25] [9/10] training 14.5%: Loss=0.498242, Accuracy=54.167%, MSE=0.283116
[2023-08-18-18:39:26] [9/10] training 16.9%: Loss=0.495636, Accuracy=54.571%, MSE=0.280615
[2023-08-18-18:39:28] [9/10] training 19.3%: Loss=0.498718, Accuracy=53.750%, MSE=0.284366
[2023-08-18-18:39:30] [9/10] training 21.7%: Loss=0.504785, Accuracy=53.444%, MSE=0.289821
[2023-08-18-18:39:32] [9/10] training 24.1%: Loss=0.503607, Accuracy=53.800%, MSE=0.288303
[2023-08-18-18:39:33] [9/10] training 26.5%: Loss=0.50041, Accuracy=54.182%, MSE=0.285052
[2023-08-18-18:39:35] [9/10] training 28.9%: Loss=0.49833, Accuracy=54.000%, MSE=0.283863
[2023-08-18-18:39:37] [9/10] training 31.3%: Loss=0.500532, Accuracy=53.769%, MSE=0.285946
[2023-08-18-18:39:39] [9/10] training 33.7%: Loss=0.500492, Accuracy=53.929%, MSE=0.285852
[2023-08-18-18:39:41] [9/10] training 36.1%: Loss=0.502082, Accuracy=53.533%, MSE=0.287808
[2023-08-18-18:39:42] [9/10] training 38.6%: Loss=0.505682, Accuracy=53.250%, MSE=0.290927
[2023-08-18-18:39:44] [9/10] training 41.0%: Loss=0.505468, Accuracy=53.059%, MSE=0.290949
[2023-08-18-18:39:46] [9/10] training 43.4%: Loss=0.504657, Accuracy=53.167%, MSE=0.290033
[2023-08-18-18:39:48] [9/10] training 45.8%: Loss=0.50554, Accuracy=53.053%, MSE=0.291015
[2023-08-18-18:39:49] [9/10] training 48.2%: Loss=0.506043, Accuracy=53.050%, MSE=0.291529
[2023-08-18-18:39:52] [9/10] training 50.6%: Loss=0.504597, Accuracy=53.286%, MSE=0.290154
[2023-08-18-18:39:53] [9/10] training 53.0%: Loss=0.503309, Accuracy=53.500%, MSE=0.288863
[2023-08-18-18:39:55] [9/10] training 55.4%: Loss=0.502154, Accuracy=53.696%, MSE=0.287726
[2023-08-18-18:39:57] [9/10] training 57.8%: Loss=0.502595, Accuracy=53.625%, MSE=0.288394
[2023-08-18-18:39:58] [9/10] training 60.2%: Loss=0.502553, Accuracy=53.640%, MSE=0.288138
[2023-08-18-18:40:00] [9/10] training 62.7%: Loss=0.499802, Accuracy=53.846%, MSE=0.285888
[2023-08-18-18:40:02] [9/10] training 65.1%: Loss=0.499587, Accuracy=53.741%, MSE=0.285865
[2023-08-18-18:40:04] [9/10] training 67.5%: Loss=0.500326, Accuracy=53.714%, MSE=0.286492
[2023-08-18-18:40:06] [9/10] training 69.9%: Loss=0.502686, Accuracy=53.483%, MSE=0.288447
[2023-08-18-18:40:08] [9/10] training 72.3%: Loss=0.503722, Accuracy=53.267%, MSE=0.289538
[2023-08-18-18:40:09] [9/10] training 74.7%: Loss=0.503573, Accuracy=53.129%, MSE=0.289597
[2023-08-18-18:40:11] [9/10] training 77.1%: Loss=0.502532, Accuracy=53.219%, MSE=0.288858
[2023-08-18-18:40:13] [9/10] training 79.5%: Loss=0.503405, Accuracy=53.182%, MSE=0.289411
[2023-08-18-18:40:15] [9/10] training 81.9%: Loss=0.502204, Accuracy=53.324%, MSE=0.288356
[2023-08-18-18:40:17] [9/10] training 84.3%: Loss=0.501603, Accuracy=53.229%, MSE=0.287948
[2023-08-18-18:40:18] [9/10] training 86.7%: Loss=0.501413, Accuracy=53.111%, MSE=0.287938
[2023-08-18-18:40:20] [9/10] training 89.2%: Loss=0.502043, Accuracy=53.054%, MSE=0.288641
[2023-08-18-18:40:22] [9/10] training 91.6%: Loss=0.501115, Accuracy=53.289%, MSE=0.287586
[2023-08-18-18:40:24] [9/10] training 94.0%: Loss=0.500908, Accuracy=53.308%, MSE=0.28733
[2023-08-18-18:40:26] [9/10] training 96.4%: Loss=0.501043, Accuracy=53.250%, MSE=0.287505
[2023-08-18-18:40:28] [9/10] training 98.8%: Loss=0.500925, Accuracy=53.341%, MSE=0.28732
[2023-08-18-18:40:40] Finished Epoch 9/10: Loss=0.928348, Accuracy=50.267%, MSE=0.326413, Precision=0.59762, Recall=0.241397, F1=0.343887, AUPR=0.610739
[2023-08-18-18:40:40] Saving model to ./models/huang_both_0_tt_partitions_epoch09.sav
[2023-08-18-18:40:42] [10/10] training 2.4%: Loss=0.492436, Accuracy=50.000%, MSE=0.289678
[2023-08-18-18:40:44] [10/10] training 4.8%: Loss=0.493912, Accuracy=51.000%, MSE=0.286347
[2023-08-18-18:40:46] [10/10] training 7.2%: Loss=0.482966, Accuracy=54.333%, MSE=0.271647
[2023-08-18-18:40:48] [10/10] training 9.6%: Loss=0.480905, Accuracy=54.500%, MSE=0.271367
[2023-08-18-18:40:50] [10/10] training 12.0%: Loss=0.487653, Accuracy=54.200%, MSE=0.277647
[2023-08-18-18:40:52] [10/10] training 14.5%: Loss=0.488721, Accuracy=53.667%, MSE=0.278053
[2023-08-18-18:40:54] [10/10] training 16.9%: Loss=0.48311, Accuracy=54.143%, MSE=0.272695
[2023-08-18-18:40:56] [10/10] training 19.3%: Loss=0.479111, Accuracy=54.750%, MSE=0.269359
[2023-08-18-18:40:57] [10/10] training 21.7%: Loss=0.481154, Accuracy=54.444%, MSE=0.27144
[2023-08-18-18:40:59] [10/10] training 24.1%: Loss=0.477806, Accuracy=54.500%, MSE=0.268332
[2023-08-18-18:41:01] [10/10] training 26.5%: Loss=0.475357, Accuracy=55.091%, MSE=0.266168
[2023-08-18-18:41:03] [10/10] training 28.9%: Loss=0.472475, Accuracy=55.333%, MSE=0.263976
[2023-08-18-18:41:05] [10/10] training 31.3%: Loss=0.475703, Accuracy=55.077%, MSE=0.266255
[2023-08-18-18:41:06] [10/10] training 33.7%: Loss=0.478913, Accuracy=54.357%, MSE=0.269558
[2023-08-18-18:41:08] [10/10] training 36.1%: Loss=0.47914, Accuracy=54.067%, MSE=0.269852
[2023-08-18-18:41:10] [10/10] training 38.6%: Loss=0.479661, Accuracy=53.750%, MSE=0.270565
[2023-08-18-18:41:12] [10/10] training 41.0%: Loss=0.48224, Accuracy=53.647%, MSE=0.272564
[2023-08-18-18:41:14] [10/10] training 43.4%: Loss=0.480165, Accuracy=53.667%, MSE=0.271157
[2023-08-18-18:41:16] [10/10] training 45.8%: Loss=0.480168, Accuracy=53.684%, MSE=0.27114
[2023-08-18-18:41:18] [10/10] training 48.2%: Loss=0.481397, Accuracy=53.350%, MSE=0.272479
[2023-08-18-18:41:20] [10/10] training 50.6%: Loss=0.479905, Accuracy=53.429%, MSE=0.270947
[2023-08-18-18:41:22] [10/10] training 53.0%: Loss=0.479249, Accuracy=53.455%, MSE=0.270475
[2023-08-18-18:41:24] [10/10] training 55.4%: Loss=0.477226, Accuracy=53.739%, MSE=0.268609
[2023-08-18-18:41:25] [10/10] training 57.8%: Loss=0.477174, Accuracy=53.667%, MSE=0.268772
[2023-08-18-18:41:27] [10/10] training 60.2%: Loss=0.476203, Accuracy=53.680%, MSE=0.268102
[2023-08-18-18:41:29] [10/10] training 62.7%: Loss=0.474493, Accuracy=53.962%, MSE=0.266345
[2023-08-18-18:41:30] [10/10] training 65.1%: Loss=0.474633, Accuracy=53.889%, MSE=0.266399
[2023-08-18-18:41:32] [10/10] training 67.5%: Loss=0.473762, Accuracy=54.071%, MSE=0.265369
[2023-08-18-18:41:34] [10/10] training 69.9%: Loss=0.474396, Accuracy=53.931%, MSE=0.266009
[2023-08-18-18:41:36] [10/10] training 72.3%: Loss=0.472783, Accuracy=54.233%, MSE=0.264501
[2023-08-18-18:41:38] [10/10] training 74.7%: Loss=0.47301, Accuracy=54.194%, MSE=0.264805
[2023-08-18-18:41:39] [10/10] training 77.1%: Loss=0.471975, Accuracy=54.250%, MSE=0.263789
[2023-08-18-18:41:41] [10/10] training 79.5%: Loss=0.472427, Accuracy=54.182%, MSE=0.264372
[2023-08-18-18:41:43] [10/10] training 81.9%: Loss=0.471281, Accuracy=54.382%, MSE=0.26327
[2023-08-18-18:41:45] [10/10] training 84.3%: Loss=0.470912, Accuracy=54.514%, MSE=0.262742
[2023-08-18-18:41:47] [10/10] training 86.7%: Loss=0.469748, Accuracy=54.667%, MSE=0.261609
[2023-08-18-18:41:48] [10/10] training 89.2%: Loss=0.468208, Accuracy=54.838%, MSE=0.260185
[2023-08-18-18:41:50] [10/10] training 91.6%: Loss=0.468344, Accuracy=54.868%, MSE=0.260222
[2023-08-18-18:41:51] [10/10] training 94.0%: Loss=0.467217, Accuracy=54.949%, MSE=0.259187
[2023-08-18-18:41:53] [10/10] training 96.4%: Loss=0.465928, Accuracy=55.075%, MSE=0.257755
[2023-08-18-18:41:55] [10/10] training 98.8%: Loss=0.465334, Accuracy=55.220%, MSE=0.257108
[2023-08-18-18:42:07] Finished Epoch 10/10: Loss=1.24151, Accuracy=51.200%, MSE=0.380253, Precision=0.762915, Recall=0.145718, F1=0.244698, AUPR=0.781889
[2023-08-18-18:42:07] Saving model to ./models/huang_both_0_tt_partitions_epoch10.sav
[2023-08-18-18:42:07] Saving final model to ./models/huang_both_0_tt_partitions_final.sav
