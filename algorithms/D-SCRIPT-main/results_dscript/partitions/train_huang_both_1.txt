[2023-04-27-10:59:08] D-SCRIPT Version 0.2.2
[2023-04-27-10:59:08] Called as: /nfs/home/students/jbernett/.conda/envs/dscript2/bin/dscript train --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_1.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_1_dscript_partitions -o ./results_dscript/partitions/train_huang_both_1.txt -d 2
[2023-04-27-10:59:08] Using CUDA device 2 - NVIDIA A40
[2023-04-27-10:59:08] Loaded 4136 training pairs
[2023-04-27-10:59:08] Loaded 1190 test pairs
[2023-04-27-10:59:08] Loading embeddings...
[2023-04-27-10:59:30] Initializing embedding model with:
[2023-04-27-10:59:30] 	projection_dim: 100
[2023-04-27-10:59:30] 	dropout_p: 0.5
[2023-04-27-10:59:30] Initializing contact model with:
[2023-04-27-10:59:30] 	hidden_dim: 50
[2023-04-27-10:59:30] 	kernel_width: 7
[2023-04-27-10:59:30] Initializing interaction model with:
[2023-04-27-10:59:30] 	do_poool: False
[2023-04-27-10:59:30] 	pool_width: 9
[2023-04-27-10:59:30] 	do_w: True
[2023-04-27-10:59:30] 	do_sigmoid: True
[2023-04-27-10:59:30] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-04-27-10:59:31] Using save prefix "./models/huang_both_1_dscript_partitions"
[2023-04-27-10:59:31] Training with Adam: lr=0.001, weight_decay=0
[2023-04-27-10:59:31] 	num_epochs: 10
[2023-04-27-10:59:31] 	batch_size: 25
[2023-04-27-10:59:31] 	interaction weight: 0.35
[2023-04-27-10:59:31] 	contact map weight: 0.65
[2023-04-27-10:59:35] [1/10] training 2.4%: Loss=1.3659, Accuracy=54.000%, MSE=0.458559
[2023-04-27-10:59:37] [1/10] training 4.8%: Loss=1.31095, Accuracy=55.500%, MSE=0.443361
[2023-04-27-10:59:40] [1/10] training 7.2%: Loss=1.27368, Accuracy=56.667%, MSE=0.431551
[2023-04-27-10:59:42] [1/10] training 9.6%: Loss=1.29535, Accuracy=55.000%, MSE=0.447944
[2023-04-27-10:59:44] [1/10] training 12.0%: Loss=1.32762, Accuracy=53.200%, MSE=0.465781
[2023-04-27-10:59:46] [1/10] training 14.5%: Loss=1.32967, Accuracy=52.667%, MSE=0.470926
[2023-04-27-10:59:49] [1/10] training 16.9%: Loss=1.34961, Accuracy=51.429%, MSE=0.48309
[2023-04-27-10:59:51] [1/10] training 19.3%: Loss=1.36931, Accuracy=50.000%, MSE=0.497128
[2023-04-27-10:59:53] [1/10] training 21.7%: Loss=1.35193, Accuracy=50.444%, MSE=0.492553
[2023-04-27-10:59:55] [1/10] training 24.1%: Loss=1.35222, Accuracy=50.200%, MSE=0.494896
[2023-04-27-10:59:57] [1/10] training 26.5%: Loss=1.33732, Accuracy=50.545%, MSE=0.491321
[2023-04-27-10:59:59] [1/10] training 28.9%: Loss=1.33905, Accuracy=50.167%, MSE=0.494966
[2023-04-27-11:00:01] [1/10] training 31.3%: Loss=1.34397, Accuracy=49.769%, MSE=0.498852
[2023-04-27-11:00:03] [1/10] training 33.7%: Loss=1.32599, Accuracy=50.357%, MSE=0.492876
[2023-04-27-11:00:05] [1/10] training 36.1%: Loss=1.3197, Accuracy=50.400%, MSE=0.492334
[2023-04-27-11:00:08] [1/10] training 38.6%: Loss=1.31473, Accuracy=50.500%, MSE=0.49128
[2023-04-27-11:00:23] [1/10] training 41.0%: Loss=1.30113, Accuracy=50.882%, MSE=0.487331
[2023-04-27-11:00:25] [1/10] training 43.4%: Loss=1.2998, Accuracy=50.778%, MSE=0.488305
[2023-04-27-11:00:27] [1/10] training 45.8%: Loss=1.30268, Accuracy=50.368%, MSE=0.49224
[2023-04-27-11:00:29] [1/10] training 48.2%: Loss=1.29274, Accuracy=50.700%, MSE=0.488883
[2023-04-27-11:00:31] [1/10] training 50.6%: Loss=1.29402, Accuracy=50.381%, MSE=0.491917
[2023-04-27-11:00:33] [1/10] training 53.0%: Loss=1.29468, Accuracy=50.136%, MSE=0.494218
[2023-04-27-11:00:35] [1/10] training 55.4%: Loss=1.28852, Accuracy=50.261%, MSE=0.49289
[2023-04-27-11:00:38] [1/10] training 57.8%: Loss=1.28008, Accuracy=50.500%, MSE=0.490418
[2023-04-27-11:00:39] [1/10] training 60.2%: Loss=1.2773, Accuracy=50.440%, MSE=0.490913
[2023-04-27-11:00:42] [1/10] training 62.7%: Loss=1.27208, Accuracy=50.538%, MSE=0.489847
[2023-04-27-11:00:44] [1/10] training 65.1%: Loss=1.27408, Accuracy=50.296%, MSE=0.492184
[2023-04-27-11:00:46] [1/10] training 67.5%: Loss=1.2674, Accuracy=50.429%, MSE=0.490745
[2023-04-27-11:00:48] [1/10] training 69.9%: Loss=1.26171, Accuracy=50.621%, MSE=0.488798
[2023-04-27-11:00:50] [1/10] training 72.3%: Loss=1.2602, Accuracy=50.467%, MSE=0.490171
[2023-04-27-11:00:52] [1/10] training 74.7%: Loss=1.25522, Accuracy=50.613%, MSE=0.48866
[2023-04-27-11:00:54] [1/10] training 77.1%: Loss=1.25203, Accuracy=50.625%, MSE=0.488447
[2023-04-27-11:00:56] [1/10] training 79.5%: Loss=1.24917, Accuracy=50.606%, MSE=0.488523
[2023-04-27-11:00:59] [1/10] training 81.9%: Loss=1.24756, Accuracy=50.559%, MSE=0.488921
[2023-04-27-11:01:01] [1/10] training 84.3%: Loss=1.2481, Accuracy=50.343%, MSE=0.490941
[2023-04-27-11:01:03] [1/10] training 86.7%: Loss=1.24681, Accuracy=50.278%, MSE=0.491506
[2023-04-27-11:01:05] [1/10] training 89.2%: Loss=1.24556, Accuracy=50.135%, MSE=0.492773
[2023-04-27-11:01:07] [1/10] training 91.6%: Loss=1.24551, Accuracy=49.974%, MSE=0.494266
[2023-04-27-11:01:27] [1/10] training 94.0%: Loss=1.24537, Accuracy=49.795%, MSE=0.495898
[2023-04-27-11:01:34] [1/10] training 96.4%: Loss=1.24197, Accuracy=49.825%, MSE=0.495494
[2023-04-27-11:01:36] [1/10] training 98.8%: Loss=1.23612, Accuracy=50.073%, MSE=0.493009
[2023-04-27-11:01:47] Finished Epoch 1/10: Loss=2.3664, Accuracy=49.583%, MSE=0.489698, Precision=0.457938, Recall=0.0104997, F1=0.0205287, AUPR=0.449365
[2023-04-27-11:01:47] Saving model to ./models/huang_both_1_dscript_partitions_epoch01.sav
[2023-04-27-11:01:49] [2/10] training 2.4%: Loss=1.07028, Accuracy=55.000%, MSE=0.442495
[2023-04-27-11:01:51] [2/10] training 4.8%: Loss=1.03881, Accuracy=55.500%, MSE=0.436095
[2023-04-27-11:01:53] [2/10] training 7.2%: Loss=1.08339, Accuracy=52.667%, MSE=0.463806
[2023-04-27-11:01:55] [2/10] training 9.6%: Loss=1.07714, Accuracy=52.500%, MSE=0.464921
[2023-04-27-11:01:57] [2/10] training 12.0%: Loss=1.10434, Accuracy=50.800%, MSE=0.48148
[2023-04-27-11:01:59] [2/10] training 14.5%: Loss=1.10484, Accuracy=50.833%, MSE=0.481261
[2023-04-27-11:02:00] [2/10] training 16.9%: Loss=1.08876, Accuracy=51.429%, MSE=0.475134
[2023-04-27-11:02:02] [2/10] training 19.3%: Loss=1.09207, Accuracy=51.000%, MSE=0.479125
[2023-04-27-11:02:04] [2/10] training 21.7%: Loss=1.10588, Accuracy=50.222%, MSE=0.48682
[2023-04-27-11:02:05] [2/10] training 24.1%: Loss=1.10084, Accuracy=50.200%, MSE=0.486702
[2023-04-27-11:02:07] [2/10] training 26.5%: Loss=1.09152, Accuracy=50.909%, MSE=0.479879
[2023-04-27-11:02:09] [2/10] training 28.9%: Loss=1.10109, Accuracy=50.083%, MSE=0.487698
[2023-04-27-11:02:11] [2/10] training 31.3%: Loss=1.10445, Accuracy=49.692%, MSE=0.491308
[2023-04-27-11:02:12] [2/10] training 33.7%: Loss=1.10877, Accuracy=49.214%, MSE=0.495742
[2023-04-27-11:02:14] [2/10] training 36.1%: Loss=1.10718, Accuracy=49.267%, MSE=0.495224
[2023-04-27-11:02:16] [2/10] training 38.6%: Loss=1.10388, Accuracy=49.250%, MSE=0.495136
[2023-04-27-11:02:17] [2/10] training 41.0%: Loss=1.10738, Accuracy=49.000%, MSE=0.497539
[2023-04-27-11:02:19] [2/10] training 43.4%: Loss=1.09664, Accuracy=49.556%, MSE=0.491996
[2023-04-27-11:02:21] [2/10] training 45.8%: Loss=1.09362, Accuracy=49.684%, MSE=0.490685
[2023-04-27-11:02:23] [2/10] training 48.2%: Loss=1.09313, Accuracy=49.650%, MSE=0.490912
[2023-04-27-11:02:24] [2/10] training 50.6%: Loss=1.09229, Accuracy=49.571%, MSE=0.491544
[2023-04-27-11:02:26] [2/10] training 53.0%: Loss=1.09406, Accuracy=49.409%, MSE=0.493075
[2023-04-27-11:02:28] [2/10] training 55.4%: Loss=1.09071, Accuracy=49.391%, MSE=0.492899
[2023-04-27-11:02:29] [2/10] training 57.8%: Loss=1.08765, Accuracy=49.542%, MSE=0.491406
[2023-04-27-11:02:31] [2/10] training 60.2%: Loss=1.08502, Accuracy=49.520%, MSE=0.491382
[2023-04-27-11:02:33] [2/10] training 62.7%: Loss=1.08278, Accuracy=49.654%, MSE=0.490074
[2023-04-27-11:02:35] [2/10] training 65.1%: Loss=1.0792, Accuracy=49.741%, MSE=0.489046
[2023-04-27-11:02:37] [2/10] training 67.5%: Loss=1.0812, Accuracy=49.464%, MSE=0.491572
[2023-04-27-11:02:38] [2/10] training 69.9%: Loss=1.07654, Accuracy=49.724%, MSE=0.489011
[2023-04-27-11:02:40] [2/10] training 72.3%: Loss=1.07257, Accuracy=49.800%, MSE=0.488064
[2023-04-27-11:02:42] [2/10] training 74.7%: Loss=1.06951, Accuracy=49.839%, MSE=0.487493
[2023-04-27-11:02:44] [2/10] training 77.1%: Loss=1.06507, Accuracy=50.062%, MSE=0.485228
[2023-04-27-11:02:45] [2/10] training 79.5%: Loss=1.05991, Accuracy=50.121%, MSE=0.484212
[2023-04-27-11:02:47] [2/10] training 81.9%: Loss=1.05937, Accuracy=50.118%, MSE=0.484227
[2023-04-27-11:02:49] [2/10] training 84.3%: Loss=1.05756, Accuracy=50.114%, MSE=0.484081
[2023-04-27-11:02:50] [2/10] training 86.7%: Loss=1.05476, Accuracy=50.111%, MSE=0.483812
[2023-04-27-11:02:52] [2/10] training 89.2%: Loss=1.05578, Accuracy=50.027%, MSE=0.484687
[2023-04-27-11:02:54] [2/10] training 91.6%: Loss=1.05299, Accuracy=50.026%, MSE=0.484439
[2023-04-27-11:02:56] [2/10] training 94.0%: Loss=1.05149, Accuracy=49.974%, MSE=0.484734
[2023-04-27-11:02:57] [2/10] training 96.4%: Loss=1.04914, Accuracy=50.075%, MSE=0.483689
[2023-04-27-11:02:59] [2/10] training 98.8%: Loss=1.04676, Accuracy=50.098%, MSE=0.483221
[2023-04-27-11:03:06] Finished Epoch 2/10: Loss=2.06498, Accuracy=49.500%, MSE=0.480968, Precision=0.362161, Recall=0.0212608, F1=0.0401637, AUPR=0.389124
[2023-04-27-11:03:06] Saving model to ./models/huang_both_1_dscript_partitions_epoch02.sav
[2023-04-27-11:03:08] [3/10] training 2.4%: Loss=0.939297, Accuracy=49.000%, MSE=0.481741
[2023-04-27-11:03:10] [3/10] training 4.8%: Loss=0.964046, Accuracy=50.000%, MSE=0.476818
[2023-04-27-11:03:12] [3/10] training 7.2%: Loss=0.997474, Accuracy=47.667%, MSE=0.499664
[2023-04-27-11:03:13] [3/10] training 9.6%: Loss=0.965889, Accuracy=49.500%, MSE=0.481238
[2023-04-27-11:03:15] [3/10] training 12.0%: Loss=0.960085, Accuracy=50.000%, MSE=0.47656
[2023-04-27-11:03:17] [3/10] training 14.5%: Loss=0.982564, Accuracy=48.667%, MSE=0.48981
[2023-04-27-11:03:19] [3/10] training 16.9%: Loss=0.96815, Accuracy=49.143%, MSE=0.484364
[2023-04-27-11:03:20] [3/10] training 19.3%: Loss=0.970407, Accuracy=49.000%, MSE=0.48614
[2023-04-27-11:03:22] [3/10] training 21.7%: Loss=0.968842, Accuracy=49.222%, MSE=0.484706
[2023-04-27-11:03:24] [3/10] training 24.1%: Loss=0.952719, Accuracy=50.000%, MSE=0.476463
[2023-04-27-11:03:26] [3/10] training 26.5%: Loss=0.953228, Accuracy=49.818%, MSE=0.478119
[2023-04-27-11:03:28] [3/10] training 28.9%: Loss=0.955727, Accuracy=49.833%, MSE=0.478417
[2023-04-27-11:03:30] [3/10] training 31.3%: Loss=0.953002, Accuracy=49.769%, MSE=0.478411
[2023-04-27-11:03:31] [3/10] training 33.7%: Loss=0.951942, Accuracy=49.714%, MSE=0.478708
[2023-04-27-11:03:33] [3/10] training 36.1%: Loss=0.951274, Accuracy=49.667%, MSE=0.479125
[2023-04-27-11:03:35] [3/10] training 38.6%: Loss=0.944791, Accuracy=49.938%, MSE=0.476016
[2023-04-27-11:03:37] [3/10] training 41.0%: Loss=0.940094, Accuracy=50.235%, MSE=0.472867
[2023-04-27-11:03:38] [3/10] training 43.4%: Loss=0.939775, Accuracy=50.000%, MSE=0.474425
[2023-04-27-11:03:40] [3/10] training 45.8%: Loss=0.942916, Accuracy=49.632%, MSE=0.477451
[2023-04-27-11:03:42] [3/10] training 48.2%: Loss=0.942148, Accuracy=49.750%, MSE=0.476489
[2023-04-27-11:03:43] [3/10] training 50.6%: Loss=0.938831, Accuracy=49.905%, MSE=0.474845
[2023-04-27-11:03:45] [3/10] training 53.0%: Loss=0.934707, Accuracy=50.091%, MSE=0.472721
[2023-04-27-11:03:47] [3/10] training 55.4%: Loss=0.934571, Accuracy=50.000%, MSE=0.473415
[2023-04-27-11:03:49] [3/10] training 57.8%: Loss=0.93114, Accuracy=50.042%, MSE=0.472487
[2023-04-27-11:03:51] [3/10] training 60.2%: Loss=0.929014, Accuracy=50.080%, MSE=0.471887
[2023-04-27-11:03:52] [3/10] training 62.7%: Loss=0.928835, Accuracy=50.077%, MSE=0.472045
[2023-04-27-11:03:54] [3/10] training 65.1%: Loss=0.928252, Accuracy=49.963%, MSE=0.472923
[2023-04-27-11:03:56] [3/10] training 67.5%: Loss=0.925192, Accuracy=49.857%, MSE=0.472924
[2023-04-27-11:03:58] [3/10] training 69.9%: Loss=0.926231, Accuracy=49.828%, MSE=0.473277
[2023-04-27-11:04:00] [3/10] training 72.3%: Loss=0.927643, Accuracy=49.633%, MSE=0.474996
[2023-04-27-11:04:01] [3/10] training 74.7%: Loss=0.920098, Accuracy=50.032%, MSE=0.470859
[2023-04-27-11:04:03] [3/10] training 77.1%: Loss=0.919422, Accuracy=50.031%, MSE=0.470853
[2023-04-27-11:04:05] [3/10] training 79.5%: Loss=0.91834, Accuracy=50.121%, MSE=0.469977
[2023-04-27-11:04:06] [3/10] training 81.9%: Loss=0.914883, Accuracy=50.235%, MSE=0.468546
[2023-04-27-11:04:08] [3/10] training 84.3%: Loss=0.912165, Accuracy=50.229%, MSE=0.468159
[2023-04-27-11:04:10] [3/10] training 86.7%: Loss=0.914206, Accuracy=50.028%, MSE=0.47
[2023-04-27-11:04:11] [3/10] training 89.2%: Loss=0.913695, Accuracy=49.946%, MSE=0.470587
[2023-04-27-11:04:13] [3/10] training 91.6%: Loss=0.91206, Accuracy=49.974%, MSE=0.470132
[2023-04-27-11:04:15] [3/10] training 94.0%: Loss=0.90971, Accuracy=50.051%, MSE=0.469184
[2023-04-27-11:04:17] [3/10] training 96.4%: Loss=0.908765, Accuracy=50.025%, MSE=0.469198
[2023-04-27-11:04:18] [3/10] training 98.8%: Loss=0.90776, Accuracy=50.000%, MSE=0.469205
[2023-04-27-11:04:25] Finished Epoch 3/10: Loss=1.92631, Accuracy=49.417%, MSE=0.475345, Precision=0.323593, Recall=0.0306317, F1=0.0559656, AUPR=0.37992
[2023-04-27-11:04:25] Saving model to ./models/huang_both_1_dscript_partitions_epoch03.sav
[2023-04-27-11:04:27] [4/10] training 2.4%: Loss=0.87223, Accuracy=46.000%, MSE=0.494929
[2023-04-27-11:04:29] [4/10] training 4.8%: Loss=0.849784, Accuracy=48.000%, MSE=0.471155
[2023-04-27-11:04:31] [4/10] training 7.2%: Loss=0.847349, Accuracy=49.333%, MSE=0.460193
[2023-04-27-11:04:33] [4/10] training 9.6%: Loss=0.850862, Accuracy=48.250%, MSE=0.468623
[2023-04-27-11:04:35] [4/10] training 12.0%: Loss=0.84762, Accuracy=48.600%, MSE=0.46491
[2023-04-27-11:04:36] [4/10] training 14.5%: Loss=0.825092, Accuracy=50.167%, MSE=0.44999
[2023-04-27-11:04:38] [4/10] training 16.9%: Loss=0.827429, Accuracy=49.857%, MSE=0.45335
[2023-04-27-11:04:40] [4/10] training 19.3%: Loss=0.816007, Accuracy=51.000%, MSE=0.443992
[2023-04-27-11:04:41] [4/10] training 21.7%: Loss=0.819374, Accuracy=50.778%, MSE=0.44639
[2023-04-27-11:04:43] [4/10] training 24.1%: Loss=0.825001, Accuracy=50.000%, MSE=0.452373
[2023-04-27-11:04:44] [4/10] training 26.5%: Loss=0.831137, Accuracy=49.818%, MSE=0.454566
[2023-04-27-11:04:46] [4/10] training 28.9%: Loss=0.830532, Accuracy=49.917%, MSE=0.453959
[2023-04-27-11:04:48] [4/10] training 31.3%: Loss=0.830868, Accuracy=49.538%, MSE=0.456716
[2023-04-27-11:04:49] [4/10] training 33.7%: Loss=0.826161, Accuracy=49.714%, MSE=0.454431
[2023-04-27-11:04:51] [4/10] training 36.1%: Loss=0.820773, Accuracy=49.600%, MSE=0.453135
[2023-04-27-11:04:53] [4/10] training 38.6%: Loss=0.820416, Accuracy=49.500%, MSE=0.453821
[2023-04-27-11:04:54] [4/10] training 41.0%: Loss=0.821962, Accuracy=49.294%, MSE=0.4557
[2023-04-27-11:04:56] [4/10] training 43.4%: Loss=0.820572, Accuracy=49.500%, MSE=0.454547
[2023-04-27-11:04:58] [4/10] training 45.8%: Loss=0.8253, Accuracy=49.053%, MSE=0.458304
[2023-04-27-11:04:59] [4/10] training 48.2%: Loss=0.83069, Accuracy=48.700%, MSE=0.461802
[2023-04-27-11:05:01] [4/10] training 50.6%: Loss=0.829934, Accuracy=48.667%, MSE=0.461792
[2023-04-27-11:05:03] [4/10] training 53.0%: Loss=0.823709, Accuracy=49.000%, MSE=0.458121
[2023-04-27-11:05:05] [4/10] training 55.4%: Loss=0.824258, Accuracy=49.130%, MSE=0.457518
[2023-04-27-11:05:06] [4/10] training 57.8%: Loss=0.826769, Accuracy=49.083%, MSE=0.458229
[2023-04-27-11:05:08] [4/10] training 60.2%: Loss=0.822009, Accuracy=49.120%, MSE=0.456227
[2023-04-27-11:05:10] [4/10] training 62.7%: Loss=0.823956, Accuracy=48.923%, MSE=0.457964
[2023-04-27-11:05:12] [4/10] training 65.1%: Loss=0.821851, Accuracy=49.296%, MSE=0.455132
[2023-04-27-11:05:14] [4/10] training 67.5%: Loss=0.824823, Accuracy=48.929%, MSE=0.45804
[2023-04-27-11:05:16] [4/10] training 69.9%: Loss=0.824351, Accuracy=48.931%, MSE=0.457909
[2023-04-27-11:05:18] [4/10] training 72.3%: Loss=0.827526, Accuracy=48.567%, MSE=0.461029
[2023-04-27-11:05:20] [4/10] training 74.7%: Loss=0.827758, Accuracy=48.484%, MSE=0.461791
[2023-04-27-11:05:21] [4/10] training 77.1%: Loss=0.824814, Accuracy=48.438%, MSE=0.461092
[2023-04-27-11:05:23] [4/10] training 79.5%: Loss=0.819493, Accuracy=48.788%, MSE=0.457698
[2023-04-27-11:05:25] [4/10] training 81.9%: Loss=0.815386, Accuracy=48.941%, MSE=0.455541
[2023-04-27-11:05:27] [4/10] training 84.3%: Loss=0.816796, Accuracy=48.743%, MSE=0.456993
[2023-04-27-11:05:29] [4/10] training 86.7%: Loss=0.812707, Accuracy=48.972%, MSE=0.454545
[2023-04-27-11:05:30] [4/10] training 89.2%: Loss=0.810224, Accuracy=49.000%, MSE=0.453573
[2023-04-27-11:05:32] [4/10] training 91.6%: Loss=0.806074, Accuracy=49.132%, MSE=0.451395
[2023-04-27-11:05:34] [4/10] training 94.0%: Loss=0.803964, Accuracy=49.077%, MSE=0.450533
[2023-04-27-11:05:36] [4/10] training 96.4%: Loss=0.800561, Accuracy=49.250%, MSE=0.448261
[2023-04-27-11:05:37] [4/10] training 98.8%: Loss=0.802215, Accuracy=49.268%, MSE=0.448542
[2023-04-27-11:05:44] Finished Epoch 4/10: Loss=1.4591, Accuracy=49.083%, MSE=0.434081, Precision=0.429871, Recall=0.0862034, F1=0.143609, AUPR=0.454752
[2023-04-27-11:05:44] Saving model to ./models/huang_both_1_dscript_partitions_epoch04.sav
[2023-04-27-11:05:46] [5/10] training 2.4%: Loss=0.67266, Accuracy=51.000%, MSE=0.390203
[2023-04-27-11:05:48] [5/10] training 4.8%: Loss=0.813963, Accuracy=50.000%, MSE=0.433865
[2023-04-27-11:05:50] [5/10] training 7.2%: Loss=0.823233, Accuracy=50.000%, MSE=0.44325
[2023-04-27-11:05:52] [5/10] training 9.6%: Loss=0.786296, Accuracy=51.000%, MSE=0.430058
[2023-04-27-11:05:53] [5/10] training 12.0%: Loss=0.79093, Accuracy=49.600%, MSE=0.440113
[2023-04-27-11:05:55] [5/10] training 14.5%: Loss=0.791334, Accuracy=50.000%, MSE=0.439282
[2023-04-27-11:05:57] [5/10] training 16.9%: Loss=0.775656, Accuracy=50.571%, MSE=0.429798
[2023-04-27-11:05:59] [5/10] training 19.3%: Loss=0.766914, Accuracy=49.375%, MSE=0.431045
[2023-04-27-11:06:00] [5/10] training 21.7%: Loss=0.767588, Accuracy=49.333%, MSE=0.432335
[2023-04-27-11:06:02] [5/10] training 24.1%: Loss=0.76333, Accuracy=49.700%, MSE=0.429359
[2023-04-27-11:06:04] [5/10] training 26.5%: Loss=0.758119, Accuracy=49.273%, MSE=0.429021
[2023-04-27-11:06:05] [5/10] training 28.9%: Loss=0.756632, Accuracy=49.750%, MSE=0.426469
[2023-04-27-11:06:07] [5/10] training 31.3%: Loss=0.760147, Accuracy=49.385%, MSE=0.429658
[2023-04-27-11:06:09] [5/10] training 33.7%: Loss=0.755229, Accuracy=49.214%, MSE=0.428545
[2023-04-27-11:06:11] [5/10] training 36.1%: Loss=0.748602, Accuracy=49.667%, MSE=0.424209
[2023-04-27-11:06:12] [5/10] training 38.6%: Loss=0.73866, Accuracy=50.438%, MSE=0.416751
[2023-04-27-11:06:14] [5/10] training 41.0%: Loss=0.7353, Accuracy=50.294%, MSE=0.416277
[2023-04-27-11:06:16] [5/10] training 43.4%: Loss=0.735334, Accuracy=50.500%, MSE=0.415661
[2023-04-27-11:06:17] [5/10] training 45.8%: Loss=0.738874, Accuracy=50.263%, MSE=0.418828
[2023-04-27-11:06:19] [5/10] training 48.2%: Loss=0.73611, Accuracy=49.900%, MSE=0.418469
[2023-04-27-11:06:21] [5/10] training 50.6%: Loss=0.739197, Accuracy=49.714%, MSE=0.420383
[2023-04-27-11:06:23] [5/10] training 53.0%: Loss=0.741594, Accuracy=49.182%, MSE=0.423554
[2023-04-27-11:06:24] [5/10] training 55.4%: Loss=0.742475, Accuracy=48.913%, MSE=0.425229
[2023-04-27-11:06:26] [5/10] training 57.8%: Loss=0.743645, Accuracy=48.750%, MSE=0.426644
[2023-04-27-11:06:28] [5/10] training 60.2%: Loss=0.742138, Accuracy=48.560%, MSE=0.426731
[2023-04-27-11:06:30] [5/10] training 62.7%: Loss=0.745109, Accuracy=48.192%, MSE=0.42962
[2023-04-27-11:06:31] [5/10] training 65.1%: Loss=0.74189, Accuracy=47.963%, MSE=0.428835
[2023-04-27-11:06:33] [5/10] training 67.5%: Loss=0.739898, Accuracy=47.821%, MSE=0.428601
[2023-04-27-11:06:35] [5/10] training 69.9%: Loss=0.741976, Accuracy=47.414%, MSE=0.430797
[2023-04-27-11:06:37] [5/10] training 72.3%: Loss=0.744072, Accuracy=47.367%, MSE=0.431577
[2023-04-27-11:06:39] [5/10] training 74.7%: Loss=0.740936, Accuracy=47.387%, MSE=0.429682
[2023-04-27-11:06:40] [5/10] training 77.1%: Loss=0.73659, Accuracy=47.594%, MSE=0.427133
[2023-04-27-11:06:42] [5/10] training 79.5%: Loss=0.737315, Accuracy=47.697%, MSE=0.426948
[2023-04-27-11:06:44] [5/10] training 81.9%: Loss=0.739689, Accuracy=47.559%, MSE=0.428591
[2023-04-27-11:06:46] [5/10] training 84.3%: Loss=0.735649, Accuracy=47.857%, MSE=0.425785
[2023-04-27-11:06:47] [5/10] training 86.7%: Loss=0.734337, Accuracy=47.861%, MSE=0.425401
[2023-04-27-11:06:49] [5/10] training 89.2%: Loss=0.733028, Accuracy=47.838%, MSE=0.42493
[2023-04-27-11:06:51] [5/10] training 91.6%: Loss=0.732944, Accuracy=47.711%, MSE=0.425609
[2023-04-27-11:06:53] [5/10] training 94.0%: Loss=0.731894, Accuracy=47.744%, MSE=0.424976
[2023-04-27-11:06:54] [5/10] training 96.4%: Loss=0.731168, Accuracy=47.825%, MSE=0.424134
[2023-04-27-11:06:56] [5/10] training 98.8%: Loss=0.730021, Accuracy=47.951%, MSE=0.423033
[2023-04-27-11:07:03] Finished Epoch 5/10: Loss=1.37351, Accuracy=46.750%, MSE=0.423021, Precision=0.432308, Recall=0.11264, F1=0.178715, AUPR=0.459586
[2023-04-27-11:07:03] Saving model to ./models/huang_both_1_dscript_partitions_epoch05.sav
[2023-04-27-11:07:05] [6/10] training 2.4%: Loss=0.629925, Accuracy=48.000%, MSE=0.379905
[2023-04-27-11:07:07] [6/10] training 4.8%: Loss=0.68576, Accuracy=44.000%, MSE=0.419905
[2023-04-27-11:07:08] [6/10] training 7.2%: Loss=0.677446, Accuracy=47.667%, MSE=0.407277
[2023-04-27-11:07:10] [6/10] training 9.6%: Loss=0.684201, Accuracy=46.750%, MSE=0.413993
[2023-04-27-11:07:12] [6/10] training 12.0%: Loss=0.683855, Accuracy=47.200%, MSE=0.410097
[2023-04-27-11:07:14] [6/10] training 14.5%: Loss=0.676596, Accuracy=46.833%, MSE=0.404847
[2023-04-27-11:07:16] [6/10] training 16.9%: Loss=0.662225, Accuracy=48.000%, MSE=0.394222
[2023-04-27-11:07:17] [6/10] training 19.3%: Loss=0.663756, Accuracy=48.250%, MSE=0.395063
[2023-04-27-11:07:19] [6/10] training 21.7%: Loss=0.665044, Accuracy=47.889%, MSE=0.39686
[2023-04-27-11:07:20] [6/10] training 24.1%: Loss=0.672645, Accuracy=47.800%, MSE=0.402245
[2023-04-27-11:07:22] [6/10] training 26.5%: Loss=0.669855, Accuracy=47.545%, MSE=0.400332
[2023-04-27-11:07:24] [6/10] training 28.9%: Loss=0.669555, Accuracy=47.333%, MSE=0.400561
[2023-04-27-11:07:26] [6/10] training 31.3%: Loss=0.666618, Accuracy=47.692%, MSE=0.396966
[2023-04-27-11:07:27] [6/10] training 33.7%: Loss=0.666858, Accuracy=47.571%, MSE=0.397181
[2023-04-27-11:07:29] [6/10] training 36.1%: Loss=0.673, Accuracy=47.067%, MSE=0.402313
[2023-04-27-11:07:31] [6/10] training 38.6%: Loss=0.67226, Accuracy=47.125%, MSE=0.40133
[2023-04-27-11:07:33] [6/10] training 41.0%: Loss=0.673067, Accuracy=46.588%, MSE=0.402876
[2023-04-27-11:07:35] [6/10] training 43.4%: Loss=0.669699, Accuracy=46.667%, MSE=0.401045
[2023-04-27-11:07:37] [6/10] training 45.8%: Loss=0.672617, Accuracy=46.789%, MSE=0.401888
[2023-04-27-11:07:39] [6/10] training 48.2%: Loss=0.671706, Accuracy=46.900%, MSE=0.401257
[2023-04-27-11:07:40] [6/10] training 50.6%: Loss=0.670372, Accuracy=46.952%, MSE=0.400308
[2023-04-27-11:07:42] [6/10] training 53.0%: Loss=0.674657, Accuracy=46.409%, MSE=0.404181
[2023-04-27-11:07:44] [6/10] training 55.4%: Loss=0.671767, Accuracy=46.609%, MSE=0.402066
[2023-04-27-11:07:45] [6/10] training 57.8%: Loss=0.670552, Accuracy=46.625%, MSE=0.401747
[2023-04-27-11:07:47] [6/10] training 60.2%: Loss=0.666094, Accuracy=47.200%, MSE=0.397533
[2023-04-27-11:07:49] [6/10] training 62.7%: Loss=0.665768, Accuracy=46.962%, MSE=0.398167
[2023-04-27-11:07:51] [6/10] training 65.1%: Loss=0.663562, Accuracy=46.852%, MSE=0.397181
[2023-04-27-11:07:52] [6/10] training 67.5%: Loss=0.66094, Accuracy=46.964%, MSE=0.39535
[2023-04-27-11:07:54] [6/10] training 69.9%: Loss=0.660779, Accuracy=47.034%, MSE=0.395187
[2023-04-27-11:07:56] [6/10] training 72.3%: Loss=0.659137, Accuracy=47.400%, MSE=0.393104
[2023-04-27-11:07:58] [6/10] training 74.7%: Loss=0.658515, Accuracy=47.323%, MSE=0.392638
[2023-04-27-11:07:59] [6/10] training 77.1%: Loss=0.65751, Accuracy=47.250%, MSE=0.391967
[2023-04-27-11:08:01] [6/10] training 79.5%: Loss=0.656052, Accuracy=47.364%, MSE=0.390761
[2023-04-27-11:08:03] [6/10] training 81.9%: Loss=0.655032, Accuracy=47.235%, MSE=0.390334
[2023-04-27-11:08:05] [6/10] training 84.3%: Loss=0.652962, Accuracy=47.457%, MSE=0.388473
[2023-04-27-11:08:06] [6/10] training 86.7%: Loss=0.653243, Accuracy=47.417%, MSE=0.388826
[2023-04-27-11:08:08] [6/10] training 89.2%: Loss=0.652319, Accuracy=47.378%, MSE=0.388588
[2023-04-27-11:08:10] [6/10] training 91.6%: Loss=0.653173, Accuracy=47.237%, MSE=0.389688
[2023-04-27-11:08:12] [6/10] training 94.0%: Loss=0.653102, Accuracy=47.410%, MSE=0.388952
[2023-04-27-11:08:13] [6/10] training 96.4%: Loss=0.652567, Accuracy=47.425%, MSE=0.388531
[2023-04-27-11:08:15] [6/10] training 98.8%: Loss=0.651012, Accuracy=47.561%, MSE=0.387336
[2023-04-27-11:08:22] Finished Epoch 6/10: Loss=1.22425, Accuracy=47.750%, MSE=0.39835, Precision=0.542021, Recall=0.135908, F1=0.217324, AUPR=0.553466
[2023-04-27-11:08:22] Saving model to ./models/huang_both_1_dscript_partitions_epoch06.sav
[2023-04-27-11:08:24] [7/10] training 2.4%: Loss=0.629372, Accuracy=45.000%, MSE=0.38662
[2023-04-27-11:08:26] [7/10] training 4.8%: Loss=0.638067, Accuracy=46.000%, MSE=0.390113
[2023-04-27-11:08:28] [7/10] training 7.2%: Loss=0.619624, Accuracy=47.333%, MSE=0.373147
[2023-04-27-11:08:29] [7/10] training 9.6%: Loss=0.599533, Accuracy=49.000%, MSE=0.35607
[2023-04-27-11:08:31] [7/10] training 12.0%: Loss=0.602647, Accuracy=50.200%, MSE=0.35482
[2023-04-27-11:08:33] [7/10] training 14.5%: Loss=0.607502, Accuracy=49.500%, MSE=0.359633
[2023-04-27-11:08:35] [7/10] training 16.9%: Loss=0.599068, Accuracy=50.000%, MSE=0.353968
[2023-04-27-11:08:36] [7/10] training 19.3%: Loss=0.597468, Accuracy=50.500%, MSE=0.351375
[2023-04-27-11:08:38] [7/10] training 21.7%: Loss=0.601776, Accuracy=49.889%, MSE=0.355853
[2023-04-27-11:08:40] [7/10] training 24.1%: Loss=0.600922, Accuracy=49.800%, MSE=0.355427
[2023-04-27-11:08:41] [7/10] training 26.5%: Loss=0.601009, Accuracy=49.273%, MSE=0.355928
[2023-04-27-11:08:43] [7/10] training 28.9%: Loss=0.599228, Accuracy=49.917%, MSE=0.35352
[2023-04-27-11:08:45] [7/10] training 31.3%: Loss=0.597848, Accuracy=50.077%, MSE=0.352071
[2023-04-27-11:08:47] [7/10] training 33.7%: Loss=0.601299, Accuracy=49.786%, MSE=0.354983
[2023-04-27-11:08:48] [7/10] training 36.1%: Loss=0.598244, Accuracy=50.200%, MSE=0.352041
[2023-04-27-11:08:50] [7/10] training 38.6%: Loss=0.595136, Accuracy=50.250%, MSE=0.349924
[2023-04-27-11:08:52] [7/10] training 41.0%: Loss=0.595724, Accuracy=50.059%, MSE=0.35048
[2023-04-27-11:08:54] [7/10] training 43.4%: Loss=0.596237, Accuracy=49.667%, MSE=0.351525
[2023-04-27-11:08:56] [7/10] training 45.8%: Loss=0.594722, Accuracy=49.842%, MSE=0.350424
[2023-04-27-11:08:57] [7/10] training 48.2%: Loss=0.596197, Accuracy=49.550%, MSE=0.352196
[2023-04-27-11:08:59] [7/10] training 50.6%: Loss=0.595955, Accuracy=49.619%, MSE=0.352249
[2023-04-27-11:09:01] [7/10] training 53.0%: Loss=0.594002, Accuracy=49.773%, MSE=0.35085
[2023-04-27-11:09:02] [7/10] training 55.4%: Loss=0.596049, Accuracy=49.435%, MSE=0.352835
[2023-04-27-11:09:04] [7/10] training 57.8%: Loss=0.598976, Accuracy=49.167%, MSE=0.35554
[2023-04-27-11:09:06] [7/10] training 60.2%: Loss=0.597308, Accuracy=49.280%, MSE=0.354398
[2023-04-27-11:09:08] [7/10] training 62.7%: Loss=0.59493, Accuracy=49.346%, MSE=0.352718
[2023-04-27-11:09:09] [7/10] training 65.1%: Loss=0.595463, Accuracy=49.185%, MSE=0.353313
[2023-04-27-11:09:11] [7/10] training 67.5%: Loss=0.595233, Accuracy=49.071%, MSE=0.35372
[2023-04-27-11:09:13] [7/10] training 69.9%: Loss=0.596489, Accuracy=49.000%, MSE=0.354706
[2023-04-27-11:09:15] [7/10] training 72.3%: Loss=0.59801, Accuracy=49.000%, MSE=0.35558
[2023-04-27-11:09:17] [7/10] training 74.7%: Loss=0.597977, Accuracy=48.871%, MSE=0.355751
[2023-04-27-11:09:18] [7/10] training 77.1%: Loss=0.597225, Accuracy=48.781%, MSE=0.355334
[2023-04-27-11:09:20] [7/10] training 79.5%: Loss=0.596641, Accuracy=48.818%, MSE=0.354883
[2023-04-27-11:09:22] [7/10] training 81.9%: Loss=0.59489, Accuracy=48.853%, MSE=0.353603
[2023-04-27-11:09:23] [7/10] training 84.3%: Loss=0.593487, Accuracy=48.943%, MSE=0.35269
[2023-04-27-11:09:25] [7/10] training 86.7%: Loss=0.594625, Accuracy=48.944%, MSE=0.353573
[2023-04-27-11:09:27] [7/10] training 89.2%: Loss=0.595154, Accuracy=48.838%, MSE=0.354066
[2023-04-27-11:09:28] [7/10] training 91.6%: Loss=0.596715, Accuracy=48.737%, MSE=0.355383
[2023-04-27-11:09:30] [7/10] training 94.0%: Loss=0.594376, Accuracy=48.949%, MSE=0.353339
[2023-04-27-11:09:32] [7/10] training 96.4%: Loss=0.594978, Accuracy=48.800%, MSE=0.35402
[2023-04-27-11:09:34] [7/10] training 98.8%: Loss=0.596304, Accuracy=48.634%, MSE=0.355348
[2023-04-27-11:09:41] Finished Epoch 7/10: Loss=1.16, Accuracy=48.083%, MSE=0.380542, Precision=0.610248, Recall=0.161018, F1=0.254805, AUPR=0.620311
[2023-04-27-11:09:41] Saving model to ./models/huang_both_1_dscript_partitions_epoch07.sav
[2023-04-27-11:09:43] [8/10] training 2.4%: Loss=0.559047, Accuracy=53.000%, MSE=0.330592
[2023-04-27-11:09:44] [8/10] training 4.8%: Loss=0.574893, Accuracy=49.000%, MSE=0.344306
[2023-04-27-11:09:46] [8/10] training 7.2%: Loss=0.554228, Accuracy=50.333%, MSE=0.327381
[2023-04-27-11:09:48] [8/10] training 9.6%: Loss=0.553288, Accuracy=49.500%, MSE=0.3282
[2023-04-27-11:09:50] [8/10] training 12.0%: Loss=0.552966, Accuracy=50.200%, MSE=0.326129
[2023-04-27-11:09:51] [8/10] training 14.5%: Loss=0.583322, Accuracy=48.667%, MSE=0.347948
[2023-04-27-11:09:53] [8/10] training 16.9%: Loss=0.575501, Accuracy=49.429%, MSE=0.34219
[2023-04-27-11:09:55] [8/10] training 19.3%: Loss=0.573146, Accuracy=49.125%, MSE=0.341769
[2023-04-27-11:09:56] [8/10] training 21.7%: Loss=0.580927, Accuracy=48.667%, MSE=0.347754
[2023-04-27-11:09:58] [8/10] training 24.1%: Loss=0.584233, Accuracy=48.000%, MSE=0.351792
[2023-04-27-11:10:00] [8/10] training 26.5%: Loss=0.57989, Accuracy=48.636%, MSE=0.347167
[2023-04-27-11:10:01] [8/10] training 28.9%: Loss=0.57928, Accuracy=48.500%, MSE=0.34696
[2023-04-27-11:10:03] [8/10] training 31.3%: Loss=0.575149, Accuracy=49.077%, MSE=0.343094
[2023-04-27-11:10:05] [8/10] training 33.7%: Loss=0.569837, Accuracy=49.500%, MSE=0.338901
[2023-04-27-11:10:07] [8/10] training 36.1%: Loss=0.568808, Accuracy=49.333%, MSE=0.338603
[2023-04-27-11:10:08] [8/10] training 38.6%: Loss=0.576146, Accuracy=48.750%, MSE=0.344227
[2023-04-27-11:10:10] [8/10] training 41.0%: Loss=0.574866, Accuracy=48.706%, MSE=0.343175
[2023-04-27-11:10:12] [8/10] training 43.4%: Loss=0.573831, Accuracy=48.611%, MSE=0.342726
[2023-04-27-11:10:14] [8/10] training 45.8%: Loss=0.574402, Accuracy=48.842%, MSE=0.342635
[2023-04-27-11:10:15] [8/10] training 48.2%: Loss=0.575908, Accuracy=48.500%, MSE=0.344218
[2023-04-27-11:10:17] [8/10] training 50.6%: Loss=0.574916, Accuracy=48.524%, MSE=0.343389
[2023-04-27-11:10:19] [8/10] training 53.0%: Loss=0.573475, Accuracy=48.864%, MSE=0.341749
[2023-04-27-11:10:20] [8/10] training 55.4%: Loss=0.573233, Accuracy=48.913%, MSE=0.341574
[2023-04-27-11:10:22] [8/10] training 57.8%: Loss=0.571878, Accuracy=49.125%, MSE=0.340322
[2023-04-27-11:10:24] [8/10] training 60.2%: Loss=0.568449, Accuracy=49.520%, MSE=0.337214
[2023-04-27-11:10:26] [8/10] training 62.7%: Loss=0.565893, Accuracy=50.038%, MSE=0.334705
[2023-04-27-11:10:27] [8/10] training 65.1%: Loss=0.562217, Accuracy=50.407%, MSE=0.331496
[2023-04-27-11:10:29] [8/10] training 67.5%: Loss=0.561632, Accuracy=50.286%, MSE=0.331655
[2023-04-27-11:10:31] [8/10] training 69.9%: Loss=0.561745, Accuracy=50.241%, MSE=0.331777
[2023-04-27-11:10:33] [8/10] training 72.3%: Loss=0.562462, Accuracy=50.300%, MSE=0.33219
[2023-04-27-11:10:35] [8/10] training 74.7%: Loss=0.56179, Accuracy=50.194%, MSE=0.332028
[2023-04-27-11:10:36] [8/10] training 77.1%: Loss=0.563106, Accuracy=49.875%, MSE=0.333663
[2023-04-27-11:10:38] [8/10] training 79.5%: Loss=0.562275, Accuracy=50.091%, MSE=0.332665
[2023-04-27-11:10:40] [8/10] training 81.9%: Loss=0.560332, Accuracy=50.265%, MSE=0.331089
[2023-04-27-11:10:42] [8/10] training 84.3%: Loss=0.557959, Accuracy=50.400%, MSE=0.329179
[2023-04-27-11:10:43] [8/10] training 86.7%: Loss=0.557595, Accuracy=50.417%, MSE=0.328932
[2023-04-27-11:10:45] [8/10] training 89.2%: Loss=0.557193, Accuracy=50.486%, MSE=0.328634
[2023-04-27-11:10:47] [8/10] training 91.6%: Loss=0.555666, Accuracy=50.579%, MSE=0.327332
[2023-04-27-11:10:49] [8/10] training 94.0%: Loss=0.555006, Accuracy=50.513%, MSE=0.326843
[2023-04-27-11:10:51] [8/10] training 96.4%: Loss=0.556912, Accuracy=50.300%, MSE=0.328411
[2023-04-27-11:10:53] [8/10] training 98.8%: Loss=0.556328, Accuracy=50.390%, MSE=0.32778
[2023-04-27-11:11:00] Finished Epoch 8/10: Loss=1.15624, Accuracy=49.167%, MSE=0.37039, Precision=0.64683, Recall=0.174388, F1=0.274713, AUPR=0.648887
[2023-04-27-11:11:00] Saving model to ./models/huang_both_1_dscript_partitions_epoch08.sav
[2023-04-27-11:11:02] [9/10] training 2.4%: Loss=0.443986, Accuracy=59.000%, MSE=0.237861
[2023-04-27-11:11:03] [9/10] training 4.8%: Loss=0.535205, Accuracy=52.000%, MSE=0.315511
[2023-04-27-11:11:05] [9/10] training 7.2%: Loss=0.539936, Accuracy=50.333%, MSE=0.319427
[2023-04-27-11:11:07] [9/10] training 9.6%: Loss=0.532845, Accuracy=50.250%, MSE=0.312267
[2023-04-27-11:11:09] [9/10] training 12.0%: Loss=0.524252, Accuracy=51.600%, MSE=0.304337
[2023-04-27-11:11:11] [9/10] training 14.5%: Loss=0.517924, Accuracy=52.833%, MSE=0.298484
[2023-04-27-11:11:13] [9/10] training 16.9%: Loss=0.517351, Accuracy=53.286%, MSE=0.297701
[2023-04-27-11:11:14] [9/10] training 19.3%: Loss=0.520827, Accuracy=52.500%, MSE=0.301896
[2023-04-27-11:11:16] [9/10] training 21.7%: Loss=0.520169, Accuracy=52.556%, MSE=0.300897
[2023-04-27-11:11:18] [9/10] training 24.1%: Loss=0.520381, Accuracy=52.200%, MSE=0.301971
[2023-04-27-11:11:19] [9/10] training 26.5%: Loss=0.521024, Accuracy=52.364%, MSE=0.301715
[2023-04-27-11:11:21] [9/10] training 28.9%: Loss=0.520297, Accuracy=52.333%, MSE=0.300953
[2023-04-27-11:11:23] [9/10] training 31.3%: Loss=0.519267, Accuracy=52.462%, MSE=0.300076
[2023-04-27-11:11:25] [9/10] training 33.7%: Loss=0.522238, Accuracy=52.143%, MSE=0.303208
[2023-04-27-11:11:27] [9/10] training 36.1%: Loss=0.522721, Accuracy=51.800%, MSE=0.304205
[2023-04-27-11:11:28] [9/10] training 38.6%: Loss=0.523843, Accuracy=52.062%, MSE=0.304842
[2023-04-27-11:11:30] [9/10] training 41.0%: Loss=0.521469, Accuracy=52.235%, MSE=0.302901
[2023-04-27-11:11:32] [9/10] training 43.4%: Loss=0.517945, Accuracy=52.500%, MSE=0.300042
[2023-04-27-11:11:34] [9/10] training 45.8%: Loss=0.517977, Accuracy=52.526%, MSE=0.300273
[2023-04-27-11:11:35] [9/10] training 48.2%: Loss=0.520812, Accuracy=52.300%, MSE=0.302509
[2023-04-27-11:11:37] [9/10] training 50.6%: Loss=0.518732, Accuracy=52.714%, MSE=0.300368
[2023-04-27-11:11:38] [9/10] training 53.0%: Loss=0.517011, Accuracy=52.727%, MSE=0.298979
[2023-04-27-11:11:40] [9/10] training 55.4%: Loss=0.516059, Accuracy=52.783%, MSE=0.298253
[2023-04-27-11:11:42] [9/10] training 57.8%: Loss=0.516843, Accuracy=52.958%, MSE=0.298385
[2023-04-27-11:11:44] [9/10] training 60.2%: Loss=0.516464, Accuracy=52.920%, MSE=0.298188
[2023-04-27-11:11:46] [9/10] training 62.7%: Loss=0.516395, Accuracy=52.923%, MSE=0.29804
[2023-04-27-11:11:47] [9/10] training 65.1%: Loss=0.518029, Accuracy=52.815%, MSE=0.299381
[2023-04-27-11:11:49] [9/10] training 67.5%: Loss=0.518238, Accuracy=52.929%, MSE=0.299332
[2023-04-27-11:11:51] [9/10] training 69.9%: Loss=0.517494, Accuracy=52.931%, MSE=0.298591
[2023-04-27-11:11:53] [9/10] training 72.3%: Loss=0.516748, Accuracy=53.000%, MSE=0.297926
[2023-04-27-11:11:54] [9/10] training 74.7%: Loss=0.51584, Accuracy=53.097%, MSE=0.297073
[2023-04-27-11:11:56] [9/10] training 77.1%: Loss=0.516559, Accuracy=52.906%, MSE=0.297805
[2023-04-27-11:11:58] [9/10] training 79.5%: Loss=0.51758, Accuracy=52.818%, MSE=0.298869
[2023-04-27-11:11:59] [9/10] training 81.9%: Loss=0.517894, Accuracy=52.794%, MSE=0.299346
[2023-04-27-11:12:01] [9/10] training 84.3%: Loss=0.516234, Accuracy=52.857%, MSE=0.298047
[2023-04-27-11:12:03] [9/10] training 86.7%: Loss=0.516422, Accuracy=52.889%, MSE=0.29826
[2023-04-27-11:12:05] [9/10] training 89.2%: Loss=0.515895, Accuracy=52.838%, MSE=0.297858
[2023-04-27-11:12:07] [9/10] training 91.6%: Loss=0.51724, Accuracy=52.658%, MSE=0.299084
[2023-04-27-11:12:08] [9/10] training 94.0%: Loss=0.517115, Accuracy=52.667%, MSE=0.299144
[2023-04-27-11:12:10] [9/10] training 96.4%: Loss=0.517613, Accuracy=52.500%, MSE=0.299734
[2023-04-27-11:12:12] [9/10] training 98.8%: Loss=0.517168, Accuracy=52.585%, MSE=0.299353
[2023-04-27-11:12:19] Finished Epoch 9/10: Loss=1.38205, Accuracy=49.083%, MSE=0.418463, Precision=0.598376, Recall=0.0994027, F1=0.170484, AUPR=0.618143
[2023-04-27-11:12:19] Saving model to ./models/huang_both_1_dscript_partitions_epoch09.sav
[2023-04-27-11:12:21] [10/10] training 2.4%: Loss=0.474002, Accuracy=59.000%, MSE=0.261709
[2023-04-27-11:12:23] [10/10] training 4.8%: Loss=0.484712, Accuracy=57.000%, MSE=0.270484
[2023-04-27-11:12:25] [10/10] training 7.2%: Loss=0.493321, Accuracy=55.333%, MSE=0.279622
[2023-04-27-11:12:26] [10/10] training 9.6%: Loss=0.497701, Accuracy=54.500%, MSE=0.284915
[2023-04-27-11:12:29] [10/10] training 12.0%: Loss=0.492568, Accuracy=55.200%, MSE=0.279506
[2023-04-27-11:12:30] [10/10] training 14.5%: Loss=0.483114, Accuracy=56.667%, MSE=0.270031
[2023-04-27-11:12:32] [10/10] training 16.9%: Loss=0.489099, Accuracy=55.286%, MSE=0.276077
[2023-04-27-11:12:34] [10/10] training 19.3%: Loss=0.492274, Accuracy=55.000%, MSE=0.278903
[2023-04-27-11:12:36] [10/10] training 21.7%: Loss=0.493932, Accuracy=54.333%, MSE=0.281313
[2023-04-27-11:12:37] [10/10] training 24.1%: Loss=0.491957, Accuracy=55.000%, MSE=0.278544
[2023-04-27-11:12:39] [10/10] training 26.5%: Loss=0.493486, Accuracy=54.818%, MSE=0.280235
[2023-04-27-11:12:41] [10/10] training 28.9%: Loss=0.497626, Accuracy=54.333%, MSE=0.283806
[2023-04-27-11:12:43] [10/10] training 31.3%: Loss=0.498132, Accuracy=54.538%, MSE=0.284252
[2023-04-27-11:12:45] [10/10] training 33.7%: Loss=0.494927, Accuracy=54.929%, MSE=0.28154
[2023-04-27-11:12:47] [10/10] training 36.1%: Loss=0.497389, Accuracy=54.467%, MSE=0.283879
[2023-04-27-11:12:49] [10/10] training 38.6%: Loss=0.497056, Accuracy=54.562%, MSE=0.283282
[2023-04-27-11:12:50] [10/10] training 41.0%: Loss=0.495239, Accuracy=54.824%, MSE=0.281688
[2023-04-27-11:12:52] [10/10] training 43.4%: Loss=0.496786, Accuracy=54.611%, MSE=0.283498
[2023-04-27-11:12:54] [10/10] training 45.8%: Loss=0.49662, Accuracy=54.632%, MSE=0.283481
[2023-04-27-11:12:55] [10/10] training 48.2%: Loss=0.496671, Accuracy=54.700%, MSE=0.283468
[2023-04-27-11:12:57] [10/10] training 50.6%: Loss=0.493963, Accuracy=55.143%, MSE=0.280958
[2023-04-27-11:12:59] [10/10] training 53.0%: Loss=0.494607, Accuracy=55.091%, MSE=0.28159
[2023-04-27-11:13:01] [10/10] training 55.4%: Loss=0.492427, Accuracy=55.261%, MSE=0.279419
[2023-04-27-11:13:02] [10/10] training 57.8%: Loss=0.493713, Accuracy=54.917%, MSE=0.281066
[2023-04-27-11:13:04] [10/10] training 60.2%: Loss=0.491715, Accuracy=55.120%, MSE=0.279206
[2023-04-27-11:13:06] [10/10] training 62.7%: Loss=0.493268, Accuracy=54.962%, MSE=0.28047
[2023-04-27-11:13:08] [10/10] training 65.1%: Loss=0.491925, Accuracy=55.222%, MSE=0.279088
[2023-04-27-11:13:09] [10/10] training 67.5%: Loss=0.490256, Accuracy=55.286%, MSE=0.277755
[2023-04-27-11:13:11] [10/10] training 69.9%: Loss=0.489909, Accuracy=55.483%, MSE=0.276875
[2023-04-27-11:13:13] [10/10] training 72.3%: Loss=0.491274, Accuracy=55.433%, MSE=0.278064
[2023-04-27-11:13:14] [10/10] training 74.7%: Loss=0.491924, Accuracy=55.355%, MSE=0.278643
[2023-04-27-11:13:16] [10/10] training 77.1%: Loss=0.49242, Accuracy=55.187%, MSE=0.279153
[2023-04-27-11:13:18] [10/10] training 79.5%: Loss=0.491344, Accuracy=55.394%, MSE=0.278066
[2023-04-27-11:13:19] [10/10] training 81.9%: Loss=0.489717, Accuracy=55.618%, MSE=0.276682
[2023-04-27-11:13:21] [10/10] training 84.3%: Loss=0.488437, Accuracy=55.771%, MSE=0.275472
[2023-04-27-11:13:23] [10/10] training 86.7%: Loss=0.48799, Accuracy=55.806%, MSE=0.275089
[2023-04-27-11:13:24] [10/10] training 89.2%: Loss=0.487621, Accuracy=55.919%, MSE=0.274655
[2023-04-27-11:13:26] [10/10] training 91.6%: Loss=0.487805, Accuracy=55.816%, MSE=0.274838
[2023-04-27-11:13:27] [10/10] training 94.0%: Loss=0.48769, Accuracy=55.795%, MSE=0.274858
[2023-04-27-11:13:29] [10/10] training 96.4%: Loss=0.487772, Accuracy=55.725%, MSE=0.275052
[2023-04-27-11:13:31] [10/10] training 98.8%: Loss=0.486897, Accuracy=55.732%, MSE=0.274282
[2023-04-27-11:13:38] Finished Epoch 10/10: Loss=1.44415, Accuracy=49.083%, MSE=0.421835, Precision=0.608418, Recall=0.0957488, F1=0.165459, AUPR=0.624443
[2023-04-27-11:13:38] Saving model to ./models/huang_both_1_dscript_partitions_epoch10.sav
[2023-04-27-11:13:38] Saving final model to ./models/huang_both_1_dscript_partitions_final.sav
