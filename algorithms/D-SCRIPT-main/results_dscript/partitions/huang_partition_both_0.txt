[2023-04-23-23:13:05] D-SCRIPT Version 0.2.2
[2023-04-23-23:13:05] Called as: /nfs/home/students/jbernett/.conda/envs/dscript2/bin/dscript train --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_0.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_0_dscript_partitions -o ./results_dscript/partitions/huang_partition_both_0.txt -d 2
[2023-04-23-23:13:05] Using CUDA device 2 - NVIDIA A40
[2023-04-23-23:13:06] Loaded 3440 training pairs
[2023-04-23-23:13:06] Loaded 652 test pairs
[2023-04-23-23:13:06] Loading embeddings...
[2023-04-23-23:13:23] Initializing embedding model with:
[2023-04-23-23:13:23] 	projection_dim: 100
[2023-04-23-23:13:23] 	dropout_p: 0.5
[2023-04-23-23:13:23] Initializing contact model with:
[2023-04-23-23:13:23] 	hidden_dim: 50
[2023-04-23-23:13:23] 	kernel_width: 7
[2023-04-23-23:13:23] Initializing interaction model with:
[2023-04-23-23:13:23] 	do_poool: False
[2023-04-23-23:13:23] 	pool_width: 9
[2023-04-23-23:13:23] 	do_w: True
[2023-04-23-23:13:23] 	do_sigmoid: True
[2023-04-23-23:13:23] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-04-23-23:13:24] Using save prefix "./models/huang_both_0_dscript_partitions"
[2023-04-23-23:13:24] Training with Adam: lr=0.001, weight_decay=0
[2023-04-23-23:13:24] 	num_epochs: 10
[2023-04-23-23:13:24] 	batch_size: 25
[2023-04-23-23:13:24] 	interaction weight: 0.35
[2023-04-23-23:13:24] 	contact map weight: 0.65
[2023-04-23-23:13:28] [1/10] training 2.9%: Loss=1.38827, Accuracy=53.000%, MSE=0.468488
[2023-04-23-23:13:29] [1/10] training 5.8%: Loss=1.35413, Accuracy=53.500%, MSE=0.46318
[2023-04-23-23:13:31] [1/10] training 8.7%: Loss=1.38881, Accuracy=51.000%, MSE=0.487797
[2023-04-23-23:13:33] [1/10] training 11.6%: Loss=1.40523, Accuracy=49.750%, MSE=0.500051
[2023-04-23-23:13:35] [1/10] training 14.5%: Loss=1.37358, Accuracy=50.600%, MSE=0.491376
[2023-04-23-23:13:37] [1/10] training 17.4%: Loss=1.35488, Accuracy=51.000%, MSE=0.487199
[2023-04-23-23:13:39] [1/10] training 20.3%: Loss=1.37178, Accuracy=50.000%, MSE=0.497041
[2023-04-23-23:13:41] [1/10] training 23.2%: Loss=1.36942, Accuracy=49.875%, MSE=0.498201
[2023-04-23-23:13:42] [1/10] training 26.1%: Loss=1.3577, Accuracy=50.000%, MSE=0.496764
[2023-04-23-23:13:44] [1/10] training 29.0%: Loss=1.34705, Accuracy=50.300%, MSE=0.493713
[2023-04-23-23:13:46] [1/10] training 31.9%: Loss=1.34582, Accuracy=50.091%, MSE=0.495686
[2023-04-23-23:13:48] [1/10] training 34.8%: Loss=1.33308, Accuracy=50.417%, MSE=0.49232
[2023-04-23-23:13:50] [1/10] training 37.7%: Loss=1.3342, Accuracy=49.923%, MSE=0.496927
[2023-04-23-23:13:52] [1/10] training 40.6%: Loss=1.32661, Accuracy=50.143%, MSE=0.494649
[2023-04-23-23:13:54] [1/10] training 43.5%: Loss=1.32772, Accuracy=49.733%, MSE=0.498533
[2023-04-23-23:13:56] [1/10] training 46.4%: Loss=1.32367, Accuracy=49.625%, MSE=0.499464
[2023-04-23-23:13:57] [1/10] training 49.3%: Loss=1.3148, Accuracy=49.824%, MSE=0.497359
[2023-04-23-23:13:59] [1/10] training 52.2%: Loss=1.31275, Accuracy=49.722%, MSE=0.498254
[2023-04-23-23:14:01] [1/10] training 55.1%: Loss=1.30847, Accuracy=49.632%, MSE=0.498967
[2023-04-23-23:14:03] [1/10] training 58.0%: Loss=1.30314, Accuracy=49.700%, MSE=0.498185
[2023-04-23-23:14:05] [1/10] training 60.9%: Loss=1.2987, Accuracy=49.667%, MSE=0.498381
[2023-04-23-23:14:07] [1/10] training 63.8%: Loss=1.2934, Accuracy=49.636%, MSE=0.498468
[2023-04-23-23:14:09] [1/10] training 66.7%: Loss=1.29522, Accuracy=49.391%, MSE=0.500844
[2023-04-23-23:14:10] [1/10] training 69.6%: Loss=1.28845, Accuracy=49.583%, MSE=0.498869
[2023-04-23-23:14:12] [1/10] training 72.5%: Loss=1.2842, Accuracy=49.480%, MSE=0.49964
[2023-04-23-23:14:14] [1/10] training 75.4%: Loss=1.28078, Accuracy=49.500%, MSE=0.49937
[2023-04-23-23:14:16] [1/10] training 78.3%: Loss=1.27853, Accuracy=49.407%, MSE=0.500159
[2023-04-23-23:14:18] [1/10] training 81.2%: Loss=1.28052, Accuracy=49.179%, MSE=0.502368
[2023-04-23-23:14:20] [1/10] training 84.1%: Loss=1.27544, Accuracy=49.241%, MSE=0.501595
[2023-04-23-23:14:21] [1/10] training 87.0%: Loss=1.27064, Accuracy=49.333%, MSE=0.500592
[2023-04-23-23:14:23] [1/10] training 89.9%: Loss=1.26952, Accuracy=49.194%, MSE=0.501857
[2023-04-23-23:14:25] [1/10] training 92.8%: Loss=1.26147, Accuracy=49.500%, MSE=0.498771
[2023-04-23-23:14:27] [1/10] training 95.7%: Loss=1.25379, Accuracy=49.697%, MSE=0.496674
[2023-04-23-23:14:29] [1/10] training 98.6%: Loss=1.24875, Accuracy=49.853%, MSE=0.495081
[2023-04-23-23:14:36] Finished Epoch 1/10: Loss=2.53601, Accuracy=48.296%, MSE=0.492811, Precision=0.482737, Recall=0.00726266, F1=0.01431, AUPR=0.475127
[2023-04-23-23:14:36] Saving model to ./models/huang_both_0_dscript_partitions_epoch01.sav
[2023-04-23-23:14:38] [2/10] training 2.9%: Loss=1.11498, Accuracy=50.000%, MSE=0.488714
[2023-04-23-23:14:40] [2/10] training 5.8%: Loss=1.15702, Accuracy=48.500%, MSE=0.504169
[2023-04-23-23:14:41] [2/10] training 8.7%: Loss=1.12645, Accuracy=50.000%, MSE=0.489233
[2023-04-23-23:14:43] [2/10] training 11.6%: Loss=1.08007, Accuracy=52.750%, MSE=0.462282
[2023-04-23-23:14:44] [2/10] training 14.5%: Loss=1.10051, Accuracy=51.600%, MSE=0.473707
[2023-04-23-23:14:46] [2/10] training 17.4%: Loss=1.09909, Accuracy=51.833%, MSE=0.471579
[2023-04-23-23:14:47] [2/10] training 20.3%: Loss=1.09884, Accuracy=51.429%, MSE=0.475123
[2023-04-23-23:14:49] [2/10] training 23.2%: Loss=1.10843, Accuracy=50.750%, MSE=0.481717
[2023-04-23-23:14:50] [2/10] training 26.1%: Loss=1.12724, Accuracy=49.556%, MSE=0.493398
[2023-04-23-23:14:52] [2/10] training 29.0%: Loss=1.13244, Accuracy=48.900%, MSE=0.499474
[2023-04-23-23:14:53] [2/10] training 31.9%: Loss=1.13073, Accuracy=49.091%, MSE=0.497693
[2023-04-23-23:14:55] [2/10] training 34.8%: Loss=1.12576, Accuracy=49.167%, MSE=0.496745
[2023-04-23-23:14:56] [2/10] training 37.7%: Loss=1.12666, Accuracy=49.000%, MSE=0.498306
[2023-04-23-23:14:58] [2/10] training 40.6%: Loss=1.12264, Accuracy=49.143%, MSE=0.496814
[2023-04-23-23:14:59] [2/10] training 43.5%: Loss=1.11489, Accuracy=49.533%, MSE=0.492909
[2023-04-23-23:15:01] [2/10] training 46.4%: Loss=1.10906, Accuracy=49.750%, MSE=0.49068
[2023-04-23-23:15:02] [2/10] training 49.3%: Loss=1.10703, Accuracy=49.824%, MSE=0.489904
[2023-04-23-23:15:04] [2/10] training 52.2%: Loss=1.10162, Accuracy=50.056%, MSE=0.487503
[2023-04-23-23:15:05] [2/10] training 55.1%: Loss=1.10306, Accuracy=49.947%, MSE=0.488537
[2023-04-23-23:15:07] [2/10] training 58.0%: Loss=1.09644, Accuracy=50.150%, MSE=0.486268
[2023-04-23-23:15:08] [2/10] training 60.9%: Loss=1.09272, Accuracy=50.333%, MSE=0.484443
[2023-04-23-23:15:09] [2/10] training 63.8%: Loss=1.09401, Accuracy=50.136%, MSE=0.486217
[2023-04-23-23:15:11] [2/10] training 66.7%: Loss=1.09622, Accuracy=49.870%, MSE=0.488681
[2023-04-23-23:15:12] [2/10] training 69.6%: Loss=1.09212, Accuracy=50.000%, MSE=0.487231
[2023-04-23-23:15:14] [2/10] training 72.5%: Loss=1.09163, Accuracy=49.920%, MSE=0.48781
[2023-04-23-23:15:15] [2/10] training 75.4%: Loss=1.09003, Accuracy=49.885%, MSE=0.488012
[2023-04-23-23:15:17] [2/10] training 78.3%: Loss=1.0888, Accuracy=49.926%, MSE=0.487551
[2023-04-23-23:15:18] [2/10] training 81.2%: Loss=1.0861, Accuracy=50.107%, MSE=0.485797
[2023-04-23-23:15:20] [2/10] training 84.1%: Loss=1.08396, Accuracy=50.069%, MSE=0.485958
[2023-04-23-23:15:21] [2/10] training 87.0%: Loss=1.08606, Accuracy=49.867%, MSE=0.487869
[2023-04-23-23:15:23] [2/10] training 89.9%: Loss=1.08829, Accuracy=49.581%, MSE=0.490508
[2023-04-23-23:15:24] [2/10] training 92.8%: Loss=1.08614, Accuracy=49.719%, MSE=0.489164
[2023-04-23-23:15:26] [2/10] training 95.7%: Loss=1.08029, Accuracy=49.970%, MSE=0.486536
[2023-04-23-23:15:27] [2/10] training 98.6%: Loss=1.07697, Accuracy=50.029%, MSE=0.485717
[2023-04-23-23:15:33] Finished Epoch 2/10: Loss=2.13352, Accuracy=48.296%, MSE=0.484109, Precision=0.444318, Recall=0.0163759, F1=0.0315877, AUPR=0.429449
[2023-04-23-23:15:33] Saving model to ./models/huang_both_0_dscript_partitions_epoch02.sav
[2023-04-23-23:15:35] [3/10] training 2.9%: Loss=1.03375, Accuracy=50.000%, MSE=0.483917
[2023-04-23-23:15:37] [3/10] training 5.8%: Loss=0.990832, Accuracy=51.500%, MSE=0.467406
[2023-04-23-23:15:38] [3/10] training 8.7%: Loss=0.977396, Accuracy=52.667%, MSE=0.456306
[2023-04-23-23:15:40] [3/10] training 11.6%: Loss=0.976164, Accuracy=53.000%, MSE=0.45359
[2023-04-23-23:15:41] [3/10] training 14.5%: Loss=0.966823, Accuracy=53.000%, MSE=0.452603
[2023-04-23-23:15:43] [3/10] training 17.4%: Loss=0.960785, Accuracy=53.167%, MSE=0.45057
[2023-04-23-23:15:44] [3/10] training 20.3%: Loss=0.986422, Accuracy=51.429%, MSE=0.467324
[2023-04-23-23:15:46] [3/10] training 23.2%: Loss=0.989006, Accuracy=51.125%, MSE=0.470012
[2023-04-23-23:15:47] [3/10] training 26.1%: Loss=0.990249, Accuracy=50.778%, MSE=0.472786
[2023-04-23-23:15:49] [3/10] training 29.0%: Loss=0.989823, Accuracy=50.700%, MSE=0.473521
[2023-04-23-23:15:50] [3/10] training 31.9%: Loss=0.996936, Accuracy=49.909%, MSE=0.480517
[2023-04-23-23:15:52] [3/10] training 34.8%: Loss=1.00425, Accuracy=49.417%, MSE=0.48527
[2023-04-23-23:15:53] [3/10] training 37.7%: Loss=1.0005, Accuracy=49.538%, MSE=0.483856
[2023-04-23-23:15:55] [3/10] training 40.6%: Loss=0.997847, Accuracy=49.571%, MSE=0.483327
[2023-04-23-23:15:56] [3/10] training 43.5%: Loss=0.998162, Accuracy=49.467%, MSE=0.484069
[2023-04-23-23:15:58] [3/10] training 46.4%: Loss=0.994831, Accuracy=49.687%, MSE=0.48192
[2023-04-23-23:15:59] [3/10] training 49.3%: Loss=0.986133, Accuracy=50.118%, MSE=0.477495
[2023-04-23-23:16:00] [3/10] training 52.2%: Loss=0.985724, Accuracy=50.056%, MSE=0.477884
[2023-04-23-23:16:02] [3/10] training 55.1%: Loss=0.982821, Accuracy=50.211%, MSE=0.476353
[2023-04-23-23:16:03] [3/10] training 58.0%: Loss=0.98013, Accuracy=50.300%, MSE=0.475165
[2023-04-23-23:16:05] [3/10] training 60.9%: Loss=0.978139, Accuracy=50.190%, MSE=0.475663
[2023-04-23-23:16:06] [3/10] training 63.8%: Loss=0.985465, Accuracy=49.773%, MSE=0.479794
[2023-04-23-23:16:08] [3/10] training 66.7%: Loss=0.983178, Accuracy=49.739%, MSE=0.47965
[2023-04-23-23:16:09] [3/10] training 69.6%: Loss=0.979313, Accuracy=49.792%, MSE=0.478715
[2023-04-23-23:16:11] [3/10] training 72.5%: Loss=0.97719, Accuracy=49.880%, MSE=0.477795
[2023-04-23-23:16:13] [3/10] training 75.4%: Loss=0.978934, Accuracy=49.731%, MSE=0.479261
[2023-04-23-23:16:14] [3/10] training 78.3%: Loss=0.973606, Accuracy=49.889%, MSE=0.477282
[2023-04-23-23:16:16] [3/10] training 81.2%: Loss=0.974624, Accuracy=49.786%, MSE=0.478241
[2023-04-23-23:16:17] [3/10] training 84.1%: Loss=0.972948, Accuracy=49.897%, MSE=0.477161
[2023-04-23-23:16:19] [3/10] training 87.0%: Loss=0.971179, Accuracy=49.733%, MSE=0.478087
[2023-04-23-23:16:20] [3/10] training 89.9%: Loss=0.969569, Accuracy=49.806%, MSE=0.477365
[2023-04-23-23:16:22] [3/10] training 92.8%: Loss=0.964033, Accuracy=50.062%, MSE=0.474597
[2023-04-23-23:16:23] [3/10] training 95.7%: Loss=0.961531, Accuracy=50.030%, MSE=0.474391
[2023-04-23-23:16:25] [3/10] training 98.6%: Loss=0.960235, Accuracy=49.941%, MSE=0.474863
[2023-04-23-23:16:31] Finished Epoch 3/10: Loss=1.93627, Accuracy=48.296%, MSE=0.475927, Precision=0.387847, Recall=0.02598, F1=0.0486979, AUPR=0.401451
[2023-04-23-23:16:31] Saving model to ./models/huang_both_0_dscript_partitions_epoch03.sav
[2023-04-23-23:16:33] [4/10] training 2.9%: Loss=0.84284, Accuracy=56.000%, MSE=0.41601
[2023-04-23-23:16:34] [4/10] training 5.8%: Loss=0.811167, Accuracy=56.000%, MSE=0.407983
[2023-04-23-23:16:36] [4/10] training 8.7%: Loss=0.823402, Accuracy=54.000%, MSE=0.423666
[2023-04-23-23:16:37] [4/10] training 11.6%: Loss=0.825685, Accuracy=54.500%, MSE=0.42055
[2023-04-23-23:16:39] [4/10] training 14.5%: Loss=0.828191, Accuracy=54.200%, MSE=0.423865
[2023-04-23-23:16:40] [4/10] training 17.4%: Loss=0.830467, Accuracy=54.333%, MSE=0.423596
[2023-04-23-23:16:42] [4/10] training 20.3%: Loss=0.828497, Accuracy=53.714%, MSE=0.427006
[2023-04-23-23:16:43] [4/10] training 23.2%: Loss=0.830766, Accuracy=53.875%, MSE=0.426684
[2023-04-23-23:16:45] [4/10] training 26.1%: Loss=0.840627, Accuracy=53.000%, MSE=0.434346
[2023-04-23-23:16:46] [4/10] training 29.0%: Loss=0.844355, Accuracy=53.100%, MSE=0.43433
[2023-04-23-23:16:48] [4/10] training 31.9%: Loss=0.848329, Accuracy=52.727%, MSE=0.437585
[2023-04-23-23:16:49] [4/10] training 34.8%: Loss=0.8496, Accuracy=52.000%, MSE=0.442432
[2023-04-23-23:16:51] [4/10] training 37.7%: Loss=0.86199, Accuracy=51.154%, MSE=0.450858
[2023-04-23-23:16:52] [4/10] training 40.6%: Loss=0.862797, Accuracy=50.929%, MSE=0.452765
[2023-04-23-23:16:53] [4/10] training 43.5%: Loss=0.859689, Accuracy=50.867%, MSE=0.452406
[2023-04-23-23:16:55] [4/10] training 46.4%: Loss=0.855913, Accuracy=51.062%, MSE=0.450494
[2023-04-23-23:16:56] [4/10] training 49.3%: Loss=0.856577, Accuracy=50.824%, MSE=0.452159
[2023-04-23-23:16:58] [4/10] training 52.2%: Loss=0.860597, Accuracy=50.556%, MSE=0.454768
[2023-04-23-23:16:59] [4/10] training 55.1%: Loss=0.859241, Accuracy=50.895%, MSE=0.452247
[2023-04-23-23:17:01] [4/10] training 58.0%: Loss=0.85345, Accuracy=50.950%, MSE=0.449915
[2023-04-23-23:17:02] [4/10] training 60.9%: Loss=0.847004, Accuracy=51.286%, MSE=0.445914
[2023-04-23-23:17:04] [4/10] training 63.8%: Loss=0.850381, Accuracy=50.955%, MSE=0.448899
[2023-04-23-23:17:05] [4/10] training 66.7%: Loss=0.850464, Accuracy=50.739%, MSE=0.45027
[2023-04-23-23:17:07] [4/10] training 69.6%: Loss=0.850591, Accuracy=50.667%, MSE=0.451068
[2023-04-23-23:17:08] [4/10] training 72.5%: Loss=0.854095, Accuracy=50.440%, MSE=0.453281
[2023-04-23-23:17:10] [4/10] training 75.4%: Loss=0.859225, Accuracy=50.000%, MSE=0.457246
[2023-04-23-23:17:11] [4/10] training 78.3%: Loss=0.853827, Accuracy=50.333%, MSE=0.453711
[2023-04-23-23:17:13] [4/10] training 81.2%: Loss=0.85228, Accuracy=50.107%, MSE=0.454761
[2023-04-23-23:17:14] [4/10] training 84.1%: Loss=0.851849, Accuracy=49.931%, MSE=0.455423
[2023-04-23-23:17:16] [4/10] training 87.0%: Loss=0.851866, Accuracy=49.867%, MSE=0.455669
[2023-04-23-23:17:18] [4/10] training 89.9%: Loss=0.850155, Accuracy=50.000%, MSE=0.454521
[2023-04-23-23:17:19] [4/10] training 92.8%: Loss=0.851253, Accuracy=49.844%, MSE=0.455755
[2023-04-23-23:17:21] [4/10] training 95.7%: Loss=0.846778, Accuracy=50.000%, MSE=0.453714
[2023-04-23-23:17:22] [4/10] training 98.6%: Loss=0.842798, Accuracy=49.824%, MSE=0.452742
[2023-04-23-23:17:28] Finished Epoch 4/10: Loss=1.4584, Accuracy=44.148%, MSE=0.453424, Precision=0.304392, Recall=0.091133, F1=0.14027, AUPR=0.361369
[2023-04-23-23:17:28] Saving model to ./models/huang_both_0_dscript_partitions_epoch04.sav
[2023-04-23-23:17:30] [5/10] training 2.9%: Loss=0.835086, Accuracy=53.000%, MSE=0.42983
[2023-04-23-23:17:31] [5/10] training 5.8%: Loss=0.807952, Accuracy=56.500%, MSE=0.403795
[2023-04-23-23:17:33] [5/10] training 8.7%: Loss=0.799272, Accuracy=53.000%, MSE=0.421142
[2023-04-23-23:17:34] [5/10] training 11.6%: Loss=0.781638, Accuracy=51.250%, MSE=0.42282
[2023-04-23-23:17:36] [5/10] training 14.5%: Loss=0.771658, Accuracy=49.600%, MSE=0.42638
[2023-04-23-23:17:37] [5/10] training 17.4%: Loss=0.772332, Accuracy=49.333%, MSE=0.427848
[2023-04-23-23:17:39] [5/10] training 20.3%: Loss=0.791364, Accuracy=49.143%, MSE=0.434976
[2023-04-23-23:17:40] [5/10] training 23.2%: Loss=0.795384, Accuracy=49.375%, MSE=0.435853
[2023-04-23-23:17:42] [5/10] training 26.1%: Loss=0.791531, Accuracy=49.222%, MSE=0.436323
[2023-04-23-23:17:43] [5/10] training 29.0%: Loss=0.78584, Accuracy=49.300%, MSE=0.434087
[2023-04-23-23:17:45] [5/10] training 31.9%: Loss=0.772073, Accuracy=49.455%, MSE=0.427474
[2023-04-23-23:17:47] [5/10] training 34.8%: Loss=0.756049, Accuracy=49.333%, MSE=0.418767
[2023-04-23-23:17:48] [5/10] training 37.7%: Loss=0.744061, Accuracy=48.692%, MSE=0.412025
[2023-04-23-23:17:50] [5/10] training 40.6%: Loss=0.740259, Accuracy=49.000%, MSE=0.410083
[2023-04-23-23:17:51] [5/10] training 43.5%: Loss=0.750469, Accuracy=48.467%, MSE=0.416727
[2023-04-23-23:17:53] [5/10] training 46.4%: Loss=0.748625, Accuracy=48.688%, MSE=0.41463
[2023-04-23-23:17:54] [5/10] training 49.3%: Loss=0.743291, Accuracy=48.235%, MSE=0.413162
[2023-04-23-23:17:56] [5/10] training 52.2%: Loss=0.739782, Accuracy=47.389%, MSE=0.413215
[2023-04-23-23:17:57] [5/10] training 55.1%: Loss=0.740668, Accuracy=47.053%, MSE=0.414971
[2023-04-23-23:17:59] [5/10] training 58.0%: Loss=0.74482, Accuracy=47.350%, MSE=0.415759
[2023-04-23-23:18:00] [5/10] training 60.9%: Loss=0.747816, Accuracy=47.524%, MSE=0.416421
[2023-04-23-23:18:02] [5/10] training 63.8%: Loss=0.750143, Accuracy=47.318%, MSE=0.418427
[2023-04-23-23:18:03] [5/10] training 66.7%: Loss=0.745087, Accuracy=47.435%, MSE=0.41553
[2023-04-23-23:18:05] [5/10] training 69.6%: Loss=0.739087, Accuracy=47.333%, MSE=0.412775
[2023-04-23-23:18:06] [5/10] training 72.5%: Loss=0.73358, Accuracy=47.360%, MSE=0.409912
[2023-04-23-23:18:08] [5/10] training 75.4%: Loss=0.72957, Accuracy=47.654%, MSE=0.407426
[2023-04-23-23:18:09] [5/10] training 78.3%: Loss=0.726556, Accuracy=47.296%, MSE=0.406989
[2023-04-23-23:18:11] [5/10] training 81.2%: Loss=0.722272, Accuracy=47.393%, MSE=0.404338
[2023-04-23-23:18:12] [5/10] training 84.1%: Loss=0.716068, Accuracy=47.586%, MSE=0.400192
[2023-04-23-23:18:14] [5/10] training 87.0%: Loss=0.719004, Accuracy=47.133%, MSE=0.402612
[2023-04-23-23:18:15] [5/10] training 89.9%: Loss=0.717006, Accuracy=47.129%, MSE=0.400795
[2023-04-23-23:18:17] [5/10] training 92.8%: Loss=0.711406, Accuracy=47.094%, MSE=0.3979
[2023-04-23-23:18:18] [5/10] training 95.7%: Loss=0.709641, Accuracy=47.394%, MSE=0.39511
[2023-04-23-23:18:19] [5/10] training 98.6%: Loss=0.713902, Accuracy=47.265%, MSE=0.398225
[2023-04-23-23:18:25] Finished Epoch 5/10: Loss=2.244, Accuracy=47.556%, MSE=0.477142, Precision=0.277695, Recall=0.0367893, F1=0.0649712, AUPR=0.370882
[2023-04-23-23:18:25] Saving model to ./models/huang_both_0_dscript_partitions_epoch05.sav
[2023-04-23-23:18:27] [6/10] training 2.9%: Loss=1.00732, Accuracy=49.000%, MSE=0.489346
[2023-04-23-23:18:29] [6/10] training 5.8%: Loss=1.06195, Accuracy=49.500%, MSE=0.489039
[2023-04-23-23:18:31] [6/10] training 8.7%: Loss=1.10898, Accuracy=46.333%, MSE=0.51936
[2023-04-23-23:18:32] [6/10] training 11.6%: Loss=1.06822, Accuracy=48.000%, MSE=0.501894
[2023-04-23-23:18:34] [6/10] training 14.5%: Loss=1.05159, Accuracy=47.800%, MSE=0.50135
[2023-04-23-23:18:35] [6/10] training 17.4%: Loss=1.00995, Accuracy=49.667%, MSE=0.482059
[2023-04-23-23:18:37] [6/10] training 20.3%: Loss=0.981189, Accuracy=50.429%, MSE=0.472568
[2023-04-23-23:18:38] [6/10] training 23.2%: Loss=0.985881, Accuracy=49.125%, MSE=0.483848
[2023-04-23-23:18:40] [6/10] training 26.1%: Loss=0.966219, Accuracy=49.556%, MSE=0.478165
[2023-04-23-23:18:41] [6/10] training 29.0%: Loss=0.958605, Accuracy=49.200%, MSE=0.479732
[2023-04-23-23:18:43] [6/10] training 31.9%: Loss=0.945733, Accuracy=49.818%, MSE=0.473594
[2023-04-23-23:18:44] [6/10] training 34.8%: Loss=0.930796, Accuracy=50.417%, MSE=0.46694
[2023-04-23-23:18:46] [6/10] training 37.7%: Loss=0.922476, Accuracy=50.231%, MSE=0.465949
[2023-04-23-23:18:47] [6/10] training 40.6%: Loss=0.920371, Accuracy=49.857%, MSE=0.468255
[2023-04-23-23:18:49] [6/10] training 43.5%: Loss=0.917355, Accuracy=49.533%, MSE=0.469991
[2023-04-23-23:18:50] [6/10] training 46.4%: Loss=0.916329, Accuracy=49.000%, MSE=0.473478
[2023-04-23-23:18:52] [6/10] training 49.3%: Loss=0.913648, Accuracy=49.118%, MSE=0.472447
[2023-04-23-23:18:53] [6/10] training 52.2%: Loss=0.902998, Accuracy=49.444%, MSE=0.467906
[2023-04-23-23:18:55] [6/10] training 55.1%: Loss=0.898629, Accuracy=49.368%, MSE=0.467781
[2023-04-23-23:18:56] [6/10] training 58.0%: Loss=0.892032, Accuracy=49.500%, MSE=0.465617
[2023-04-23-23:18:58] [6/10] training 60.9%: Loss=0.886789, Accuracy=49.286%, MSE=0.465494
[2023-04-23-23:18:59] [6/10] training 63.8%: Loss=0.880712, Accuracy=49.500%, MSE=0.462976
[2023-04-23-23:19:01] [6/10] training 66.7%: Loss=0.874944, Accuracy=49.652%, MSE=0.460919
[2023-04-23-23:19:02] [6/10] training 69.6%: Loss=0.868737, Accuracy=49.875%, MSE=0.457774
[2023-04-23-23:19:03] [6/10] training 72.5%: Loss=0.866106, Accuracy=49.840%, MSE=0.457798
[2023-04-23-23:19:05] [6/10] training 75.4%: Loss=0.858545, Accuracy=49.962%, MSE=0.454907
[2023-04-23-23:19:06] [6/10] training 78.3%: Loss=0.855565, Accuracy=49.815%, MSE=0.455024
[2023-04-23-23:19:08] [6/10] training 81.2%: Loss=0.850585, Accuracy=49.893%, MSE=0.453098
[2023-04-23-23:19:09] [6/10] training 84.1%: Loss=0.844987, Accuracy=49.931%, MSE=0.450745
[2023-04-23-23:19:11] [6/10] training 87.0%: Loss=0.839935, Accuracy=49.700%, MSE=0.449518
[2023-04-23-23:19:12] [6/10] training 89.9%: Loss=0.834844, Accuracy=49.871%, MSE=0.447137
[2023-04-23-23:19:14] [6/10] training 92.8%: Loss=0.827786, Accuracy=49.844%, MSE=0.444066
[2023-04-23-23:19:15] [6/10] training 95.7%: Loss=0.822552, Accuracy=49.606%, MSE=0.44273
[2023-04-23-23:19:17] [6/10] training 98.6%: Loss=0.816923, Accuracy=49.500%, MSE=0.440809
[2023-04-23-23:19:23] Finished Epoch 6/10: Loss=1.54864, Accuracy=47.704%, MSE=0.447167, Precision=0.346422, Recall=0.0755678, F1=0.124071, AUPR=0.384848
[2023-04-23-23:19:23] Saving model to ./models/huang_both_0_dscript_partitions_epoch06.sav
[2023-04-23-23:19:25] [7/10] training 2.9%: Loss=0.505703, Accuracy=54.000%, MSE=0.268931
[2023-04-23-23:19:26] [7/10] training 5.8%: Loss=0.550796, Accuracy=50.000%, MSE=0.303409
[2023-04-23-23:19:28] [7/10] training 8.7%: Loss=0.565497, Accuracy=48.667%, MSE=0.316523
[2023-04-23-23:19:29] [7/10] training 11.6%: Loss=0.581623, Accuracy=46.750%, MSE=0.324603
[2023-04-23-23:19:31] [7/10] training 14.5%: Loss=0.604005, Accuracy=44.200%, MSE=0.343794
[2023-04-23-23:19:32] [7/10] training 17.4%: Loss=0.597495, Accuracy=45.833%, MSE=0.337704
[2023-04-23-23:19:34] [7/10] training 20.3%: Loss=0.595812, Accuracy=47.000%, MSE=0.335624
[2023-04-23-23:19:35] [7/10] training 23.2%: Loss=0.592168, Accuracy=47.875%, MSE=0.331846
[2023-04-23-23:19:37] [7/10] training 26.1%: Loss=0.595169, Accuracy=47.778%, MSE=0.332173
[2023-04-23-23:19:38] [7/10] training 29.0%: Loss=0.59064, Accuracy=49.400%, MSE=0.323988
[2023-04-23-23:19:40] [7/10] training 31.9%: Loss=0.581935, Accuracy=51.091%, MSE=0.313996
[2023-04-23-23:19:42] [7/10] training 34.8%: Loss=0.589555, Accuracy=50.333%, MSE=0.319041
[2023-04-23-23:19:43] [7/10] training 37.7%: Loss=0.595765, Accuracy=50.769%, MSE=0.32004
[2023-04-23-23:19:45] [7/10] training 40.6%: Loss=0.603774, Accuracy=51.429%, MSE=0.319663
[2023-04-23-23:19:46] [7/10] training 43.5%: Loss=0.623626, Accuracy=50.800%, MSE=0.329646
[2023-04-23-23:19:51] [7/10] training 46.4%: Loss=0.633421, Accuracy=50.688%, MSE=0.335856
[2023-04-23-23:20:02] [7/10] training 49.3%: Loss=0.645804, Accuracy=50.647%, MSE=0.341848
[2023-04-23-23:20:03] [7/10] training 52.2%: Loss=0.661208, Accuracy=50.389%, MSE=0.347997
[2023-04-23-23:20:05] [7/10] training 55.1%: Loss=0.663958, Accuracy=49.947%, MSE=0.351304
[2023-04-23-23:20:06] [7/10] training 58.0%: Loss=0.659432, Accuracy=50.200%, MSE=0.348878
[2023-04-23-23:20:08] [7/10] training 60.9%: Loss=0.65327, Accuracy=50.762%, MSE=0.343951
[2023-04-23-23:20:09] [7/10] training 63.8%: Loss=0.647762, Accuracy=50.955%, MSE=0.341359
[2023-04-23-23:20:11] [7/10] training 66.7%: Loss=0.645274, Accuracy=51.043%, MSE=0.340837
[2023-04-23-23:20:12] [7/10] training 69.6%: Loss=0.644261, Accuracy=51.083%, MSE=0.341117
[2023-04-23-23:20:14] [7/10] training 72.5%: Loss=0.640729, Accuracy=50.960%, MSE=0.340218
[2023-04-23-23:20:15] [7/10] training 75.4%: Loss=0.63776, Accuracy=51.154%, MSE=0.338455
[2023-04-23-23:20:17] [7/10] training 78.3%: Loss=0.633756, Accuracy=51.667%, MSE=0.335036
[2023-04-23-23:20:18] [7/10] training 81.2%: Loss=0.633, Accuracy=51.714%, MSE=0.335056
[2023-04-23-23:20:20] [7/10] training 84.1%: Loss=0.639236, Accuracy=51.586%, MSE=0.338809
[2023-04-23-23:20:21] [7/10] training 87.0%: Loss=0.646055, Accuracy=51.333%, MSE=0.343267
[2023-04-23-23:20:23] [7/10] training 89.9%: Loss=0.651586, Accuracy=51.000%, MSE=0.348273
[2023-04-23-23:20:24] [7/10] training 92.8%: Loss=0.650837, Accuracy=51.062%, MSE=0.348132
[2023-04-23-23:20:26] [7/10] training 95.7%: Loss=0.649713, Accuracy=50.909%, MSE=0.348224
[2023-04-23-23:20:27] [7/10] training 98.6%: Loss=0.648762, Accuracy=50.765%, MSE=0.348313
[2023-04-23-23:20:33] Finished Epoch 7/10: Loss=2.89874, Accuracy=48.296%, MSE=0.489828, Precision=0.37119, Recall=0.0108778, F1=0.0211362, AUPR=0.422688
[2023-04-23-23:20:33] Saving model to ./models/huang_both_0_dscript_partitions_epoch07.sav
[2023-04-23-23:20:35] [8/10] training 2.9%: Loss=0.488455, Accuracy=58.000%, MSE=0.248853
[2023-04-23-23:20:37] [8/10] training 5.8%: Loss=0.510353, Accuracy=55.500%, MSE=0.267787
[2023-04-23-23:20:38] [8/10] training 8.7%: Loss=0.509737, Accuracy=57.333%, MSE=0.264529
[2023-04-23-23:20:50] [8/10] training 11.6%: Loss=0.514467, Accuracy=58.000%, MSE=0.266239
[2023-04-23-23:21:00] [8/10] training 14.5%: Loss=0.519571, Accuracy=57.800%, MSE=0.269966
[2023-04-23-23:21:02] [8/10] training 17.4%: Loss=0.530531, Accuracy=57.167%, MSE=0.277443
[2023-04-23-23:21:03] [8/10] training 20.3%: Loss=0.534328, Accuracy=57.429%, MSE=0.27966
[2023-04-23-23:21:05] [8/10] training 23.2%: Loss=0.532945, Accuracy=58.000%, MSE=0.276647
[2023-04-23-23:21:06] [8/10] training 26.1%: Loss=0.532566, Accuracy=58.333%, MSE=0.276
[2023-04-23-23:21:08] [8/10] training 29.0%: Loss=0.540666, Accuracy=58.800%, MSE=0.275157
[2023-04-23-23:21:09] [8/10] training 31.9%: Loss=0.540432, Accuracy=60.000%, MSE=0.270548
[2023-04-23-23:21:11] [8/10] training 34.8%: Loss=0.543272, Accuracy=59.833%, MSE=0.27314
[2023-04-23-23:21:12] [8/10] training 37.7%: Loss=0.562101, Accuracy=58.692%, MSE=0.286065
[2023-04-23-23:21:14] [8/10] training 40.6%: Loss=0.583623, Accuracy=57.429%, MSE=0.30183
[2023-04-23-23:21:15] [8/10] training 43.5%: Loss=0.601881, Accuracy=56.133%, MSE=0.315425
[2023-04-23-23:21:17] [8/10] training 46.4%: Loss=0.614776, Accuracy=54.625%, MSE=0.326217
[2023-04-23-23:21:18] [8/10] training 49.3%: Loss=0.615333, Accuracy=53.706%, MSE=0.329552
[2023-04-23-23:21:20] [8/10] training 52.2%: Loss=0.614007, Accuracy=54.111%, MSE=0.326677
[2023-04-23-23:21:21] [8/10] training 55.1%: Loss=0.610112, Accuracy=55.526%, MSE=0.317896
[2023-04-23-23:21:23] [8/10] training 58.0%: Loss=0.60843, Accuracy=56.850%, MSE=0.310824
[2023-04-23-23:21:24] [8/10] training 60.9%: Loss=0.621384, Accuracy=56.381%, MSE=0.317415
[2023-04-23-23:21:26] [8/10] training 63.8%: Loss=0.633765, Accuracy=56.000%, MSE=0.324913
[2023-04-23-23:21:28] [8/10] training 66.7%: Loss=0.636341, Accuracy=55.696%, MSE=0.328555
[2023-04-23-23:21:29] [8/10] training 69.6%: Loss=0.638918, Accuracy=55.333%, MSE=0.331965
[2023-04-23-23:21:30] [8/10] training 72.5%: Loss=0.638116, Accuracy=55.120%, MSE=0.333156
[2023-04-23-23:21:32] [8/10] training 75.4%: Loss=0.64068, Accuracy=54.577%, MSE=0.337
[2023-04-23-23:21:33] [8/10] training 78.3%: Loss=0.64125, Accuracy=54.148%, MSE=0.339152
[2023-04-23-23:21:35] [8/10] training 81.2%: Loss=0.64421, Accuracy=53.464%, MSE=0.343275
[2023-04-23-23:21:36] [8/10] training 84.1%: Loss=0.645912, Accuracy=52.931%, MSE=0.345811
[2023-04-23-23:21:38] [8/10] training 87.0%: Loss=0.647477, Accuracy=52.100%, MSE=0.349231
[2023-04-23-23:21:39] [8/10] training 89.9%: Loss=0.649656, Accuracy=51.419%, MSE=0.352709
[2023-04-23-23:21:41] [8/10] training 92.8%: Loss=0.648922, Accuracy=50.875%, MSE=0.353559
[2023-04-23-23:21:42] [8/10] training 95.7%: Loss=0.648361, Accuracy=50.424%, MSE=0.354563
[2023-04-23-23:21:44] [8/10] training 98.6%: Loss=0.648604, Accuracy=50.412%, MSE=0.354877
[2023-04-23-23:21:50] Finished Epoch 8/10: Loss=3.39121, Accuracy=48.296%, MSE=0.498047, Precision=0.649339, Recall=0.00195874, F1=0.00390571, AUPR=0.648496
[2023-04-23-23:21:50] Saving model to ./models/huang_both_0_dscript_partitions_epoch08.sav
[2023-04-23-23:21:52] [9/10] training 2.9%: Loss=0.657769, Accuracy=40.000%, MSE=0.392986
[2023-04-23-23:21:53] [9/10] training 5.8%: Loss=0.637191, Accuracy=41.000%, MSE=0.377536
[2023-04-23-23:21:55] [9/10] training 8.7%: Loss=0.634899, Accuracy=41.667%, MSE=0.377534
[2023-04-23-23:21:56] [9/10] training 11.6%: Loss=0.629138, Accuracy=43.000%, MSE=0.367652
[2023-04-23-23:21:58] [9/10] training 14.5%: Loss=0.632693, Accuracy=44.600%, MSE=0.367009
[2023-04-23-23:22:00] [9/10] training 17.4%: Loss=0.633073, Accuracy=44.500%, MSE=0.369337
[2023-04-23-23:22:01] [9/10] training 20.3%: Loss=0.62761, Accuracy=44.429%, MSE=0.366486
[2023-04-23-23:22:03] [9/10] training 23.2%: Loss=0.628899, Accuracy=44.875%, MSE=0.368
[2023-04-23-23:22:04] [9/10] training 26.1%: Loss=0.637975, Accuracy=44.667%, MSE=0.374649
[2023-04-23-23:22:06] [9/10] training 29.0%: Loss=0.633518, Accuracy=45.300%, MSE=0.369608
[2023-04-23-23:22:07] [9/10] training 31.9%: Loss=0.63243, Accuracy=45.818%, MSE=0.366869
[2023-04-23-23:22:09] [9/10] training 34.8%: Loss=0.631438, Accuracy=45.417%, MSE=0.367478
[2023-04-23-23:22:10] [9/10] training 37.7%: Loss=0.628873, Accuracy=45.769%, MSE=0.364623
[2023-04-23-23:22:12] [9/10] training 40.6%: Loss=0.6309, Accuracy=46.143%, MSE=0.365573
[2023-04-23-23:22:13] [9/10] training 43.5%: Loss=0.627681, Accuracy=46.800%, MSE=0.362583
[2023-04-23-23:22:14] [9/10] training 46.4%: Loss=0.625575, Accuracy=47.063%, MSE=0.360181
[2023-04-23-23:22:16] [9/10] training 49.3%: Loss=0.624085, Accuracy=47.235%, MSE=0.358868
[2023-04-23-23:22:17] [9/10] training 52.2%: Loss=0.625141, Accuracy=47.167%, MSE=0.360187
[2023-04-23-23:22:19] [9/10] training 55.1%: Loss=0.625022, Accuracy=47.474%, MSE=0.359562
[2023-04-23-23:22:20] [9/10] training 58.0%: Loss=0.623191, Accuracy=47.800%, MSE=0.357649
[2023-04-23-23:22:22] [9/10] training 60.9%: Loss=0.622843, Accuracy=48.190%, MSE=0.356396
[2023-04-23-23:22:23] [9/10] training 63.8%: Loss=0.622844, Accuracy=48.409%, MSE=0.35592
[2023-04-23-23:22:25] [9/10] training 66.7%: Loss=0.618864, Accuracy=48.913%, MSE=0.352213
[2023-04-23-23:22:26] [9/10] training 69.6%: Loss=0.616722, Accuracy=49.042%, MSE=0.35047
[2023-04-23-23:22:28] [9/10] training 72.5%: Loss=0.614823, Accuracy=49.200%, MSE=0.348848
[2023-04-23-23:22:29] [9/10] training 75.4%: Loss=0.614133, Accuracy=49.192%, MSE=0.34818
[2023-04-23-23:22:31] [9/10] training 78.3%: Loss=0.612918, Accuracy=49.519%, MSE=0.346821
[2023-04-23-23:22:32] [9/10] training 81.2%: Loss=0.612797, Accuracy=49.429%, MSE=0.347363
[2023-04-23-23:22:34] [9/10] training 84.1%: Loss=0.610008, Accuracy=49.690%, MSE=0.344949
[2023-04-23-23:22:35] [9/10] training 87.0%: Loss=0.609057, Accuracy=49.933%, MSE=0.34426
[2023-04-23-23:22:37] [9/10] training 89.9%: Loss=0.60906, Accuracy=50.065%, MSE=0.34399
[2023-04-23-23:22:38] [9/10] training 92.8%: Loss=0.607018, Accuracy=50.281%, MSE=0.342074
[2023-04-23-23:22:40] [9/10] training 95.7%: Loss=0.60397, Accuracy=50.545%, MSE=0.339477
[2023-04-23-23:22:41] [9/10] training 98.6%: Loss=0.602502, Accuracy=50.794%, MSE=0.337926
[2023-04-23-23:22:48] Finished Epoch 9/10: Loss=2.71229, Accuracy=48.296%, MSE=0.491319, Precision=0.649444, Recall=0.00879618, F1=0.0173573, AUPR=0.637274
[2023-04-23-23:22:48] Saving model to ./models/huang_both_0_dscript_partitions_epoch09.sav
[2023-04-23-23:22:49] [10/10] training 2.9%: Loss=0.534237, Accuracy=59.000%, MSE=0.269209
[2023-04-23-23:22:51] [10/10] training 5.8%: Loss=0.563219, Accuracy=56.500%, MSE=0.295077
[2023-04-23-23:22:52] [10/10] training 8.7%: Loss=0.563002, Accuracy=57.000%, MSE=0.296276
[2023-04-23-23:22:54] [10/10] training 11.6%: Loss=0.542908, Accuracy=59.000%, MSE=0.279012
[2023-04-23-23:22:56] [10/10] training 14.5%: Loss=0.548509, Accuracy=58.200%, MSE=0.284251
[2023-04-23-23:22:57] [10/10] training 17.4%: Loss=0.547046, Accuracy=58.500%, MSE=0.282452
[2023-04-23-23:22:59] [10/10] training 20.3%: Loss=0.549588, Accuracy=58.143%, MSE=0.285669
[2023-04-23-23:23:00] [10/10] training 23.2%: Loss=0.553208, Accuracy=57.250%, MSE=0.289509
[2023-04-23-23:23:02] [10/10] training 26.1%: Loss=0.554252, Accuracy=56.889%, MSE=0.292243
[2023-04-23-23:23:03] [10/10] training 29.0%: Loss=0.55143, Accuracy=57.300%, MSE=0.289441
[2023-04-23-23:23:05] [10/10] training 31.9%: Loss=0.554442, Accuracy=56.909%, MSE=0.292601
[2023-04-23-23:23:06] [10/10] training 34.8%: Loss=0.559066, Accuracy=55.750%, MSE=0.298735
[2023-04-23-23:23:08] [10/10] training 37.7%: Loss=0.557921, Accuracy=55.923%, MSE=0.297889
[2023-04-23-23:23:09] [10/10] training 40.6%: Loss=0.558015, Accuracy=55.857%, MSE=0.297444
[2023-04-23-23:23:11] [10/10] training 43.5%: Loss=0.558113, Accuracy=55.467%, MSE=0.298372
[2023-04-23-23:23:12] [10/10] training 46.4%: Loss=0.555353, Accuracy=56.062%, MSE=0.295193
[2023-04-23-23:23:14] [10/10] training 49.3%: Loss=0.55475, Accuracy=56.235%, MSE=0.294755
[2023-04-23-23:23:15] [10/10] training 52.2%: Loss=0.555241, Accuracy=56.056%, MSE=0.295389
[2023-04-23-23:23:17] [10/10] training 55.1%: Loss=0.553395, Accuracy=56.474%, MSE=0.29299
[2023-04-23-23:23:18] [10/10] training 58.0%: Loss=0.550598, Accuracy=56.800%, MSE=0.290715
[2023-04-23-23:23:20] [10/10] training 60.9%: Loss=0.549291, Accuracy=57.048%, MSE=0.289295
[2023-04-23-23:23:21] [10/10] training 63.8%: Loss=0.548722, Accuracy=57.136%, MSE=0.288347
[2023-04-23-23:23:23] [10/10] training 66.7%: Loss=0.547539, Accuracy=57.261%, MSE=0.287386
[2023-04-23-23:23:24] [10/10] training 69.6%: Loss=0.548751, Accuracy=56.875%, MSE=0.289278
[2023-04-23-23:23:26] [10/10] training 72.5%: Loss=0.547959, Accuracy=57.080%, MSE=0.288489
[2023-04-23-23:23:27] [10/10] training 75.4%: Loss=0.54835, Accuracy=57.038%, MSE=0.288802
[2023-04-23-23:23:29] [10/10] training 78.3%: Loss=0.54789, Accuracy=57.148%, MSE=0.288346
[2023-04-23-23:23:30] [10/10] training 81.2%: Loss=0.547867, Accuracy=57.000%, MSE=0.288748
[2023-04-23-23:23:32] [10/10] training 84.1%: Loss=0.546426, Accuracy=57.276%, MSE=0.287373
[2023-04-23-23:23:33] [10/10] training 87.0%: Loss=0.544877, Accuracy=57.400%, MSE=0.285845
[2023-04-23-23:23:35] [10/10] training 89.9%: Loss=0.544027, Accuracy=57.419%, MSE=0.285336
[2023-04-23-23:23:36] [10/10] training 92.8%: Loss=0.544516, Accuracy=57.344%, MSE=0.285861
[2023-04-23-23:23:38] [10/10] training 95.7%: Loss=0.544349, Accuracy=57.515%, MSE=0.285625
[2023-04-23-23:23:39] [10/10] training 98.6%: Loss=0.543636, Accuracy=57.529%, MSE=0.285087
[2023-04-23-23:23:45] Finished Epoch 10/10: Loss=1.71432, Accuracy=48.296%, MSE=0.442393, Precision=0.619247, Recall=0.0639476, F1=0.115924, AUPR=0.611695
[2023-04-23-23:23:45] Saving model to ./models/huang_both_0_dscript_partitions_epoch10.sav
[2023-04-23-23:23:45] Saving final model to ./models/huang_both_0_dscript_partitions_final.sav
