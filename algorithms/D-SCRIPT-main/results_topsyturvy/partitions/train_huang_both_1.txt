[2023-08-18-18:42:16] D-SCRIPT Version 0.2.2
[2023-08-18-18:42:16] Called as: /nfs/home/students/jbernett/miniconda3/envs/dscript/bin/dscript train --topsy-turvy --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_1.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_1_tt_partitions -o ./results_topsyturvy/partitions/train_huang_both_1.txt
[2023-08-18-18:42:18] Loaded 4136 training pairs
[2023-08-18-18:42:18] Loaded 1190 test pairs
[2023-08-18-18:42:18] Loading embeddings...
[2023-08-18-18:43:17] Running D-SCRIPT Topsy-Turvy:
[2023-08-18-18:43:17] 	glider_weight: 0.2
[2023-08-18-18:43:17] 	glider_thresh: 92.5th percentile
[2023-08-18-18:43:17] Computing GLIDER matrix...
[2023-08-18-18:43:19] Initializing embedding model with:
[2023-08-18-18:43:19] 	projection_dim: 100
[2023-08-18-18:43:19] 	dropout_p: 0.5
[2023-08-18-18:43:19] Initializing contact model with:
[2023-08-18-18:43:19] 	hidden_dim: 50
[2023-08-18-18:43:19] 	kernel_width: 7
[2023-08-18-18:43:19] Initializing interaction model with:
[2023-08-18-18:43:19] 	do_poool: False
[2023-08-18-18:43:19] 	pool_width: 9
[2023-08-18-18:43:19] 	do_w: True
[2023-08-18-18:43:19] 	do_sigmoid: True
[2023-08-18-18:43:19] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-08-18-18:43:21] Using save prefix "./models/huang_both_1_tt_partitions"
[2023-08-18-18:43:21] Training with Adam: lr=0.001, weight_decay=0
[2023-08-18-18:43:21] 	num_epochs: 10
[2023-08-18-18:43:21] 	batch_size: 25
[2023-08-18-18:43:21] 	interaction weight: 0.35
[2023-08-18-18:43:21] 	contact map weight: 0.65
[2023-08-18-18:43:24] [1/10] training 2.4%: Loss=1.58479, Accuracy=45.000%, MSE=0.54832
[2023-08-18-18:43:26] [1/10] training 4.8%: Loss=1.53577, Accuracy=46.000%, MSE=0.538006
[2023-08-18-18:43:28] [1/10] training 7.2%: Loss=1.51127, Accuracy=46.667%, MSE=0.531231
[2023-08-18-18:43:31] [1/10] training 9.6%: Loss=1.49213, Accuracy=47.500%, MSE=0.52291
[2023-08-18-18:43:33] [1/10] training 12.0%: Loss=1.45603, Accuracy=48.800%, MSE=0.509869
[2023-08-18-18:43:35] [1/10] training 14.5%: Loss=1.43613, Accuracy=49.500%, MSE=0.502842
[2023-08-18-18:43:37] [1/10] training 16.9%: Loss=1.41712, Accuracy=50.143%, MSE=0.496362
[2023-08-18-18:43:39] [1/10] training 19.3%: Loss=1.40645, Accuracy=50.375%, MSE=0.493994
[2023-08-18-18:43:41] [1/10] training 21.7%: Loss=1.40858, Accuracy=50.000%, MSE=0.497638
[2023-08-18-18:43:43] [1/10] training 24.1%: Loss=1.39872, Accuracy=50.100%, MSE=0.496524
[2023-08-18-18:43:45] [1/10] training 26.5%: Loss=1.39329, Accuracy=50.182%, MSE=0.495665
[2023-08-18-18:43:47] [1/10] training 28.9%: Loss=1.38427, Accuracy=50.333%, MSE=0.494067
[2023-08-18-18:43:49] [1/10] training 31.3%: Loss=1.38972, Accuracy=49.846%, MSE=0.498788
[2023-08-18-18:43:51] [1/10] training 33.7%: Loss=1.39686, Accuracy=49.357%, MSE=0.503607
[2023-08-18-18:43:53] [1/10] training 36.1%: Loss=1.38386, Accuracy=49.600%, MSE=0.501032
[2023-08-18-18:43:55] [1/10] training 38.6%: Loss=1.37233, Accuracy=49.937%, MSE=0.497592
[2023-08-18-18:43:57] [1/10] training 41.0%: Loss=1.36744, Accuracy=49.941%, MSE=0.497454
[2023-08-18-18:43:59] [1/10] training 43.4%: Loss=1.36367, Accuracy=49.833%, MSE=0.498367
[2023-08-18-18:44:01] [1/10] training 45.8%: Loss=1.35394, Accuracy=50.105%, MSE=0.495552
[2023-08-18-18:44:03] [1/10] training 48.2%: Loss=1.35069, Accuracy=50.050%, MSE=0.495982
[2023-08-18-18:44:05] [1/10] training 50.6%: Loss=1.34253, Accuracy=50.143%, MSE=0.494895
[2023-08-18-18:44:07] [1/10] training 53.0%: Loss=1.34149, Accuracy=50.000%, MSE=0.496164
[2023-08-18-18:44:09] [1/10] training 55.4%: Loss=1.33174, Accuracy=50.261%, MSE=0.493452
[2023-08-18-18:44:11] [1/10] training 57.8%: Loss=1.32396, Accuracy=50.375%, MSE=0.492163
[2023-08-18-18:44:13] [1/10] training 60.2%: Loss=1.32086, Accuracy=50.320%, MSE=0.492601
[2023-08-18-18:44:14] [1/10] training 62.7%: Loss=1.31204, Accuracy=50.423%, MSE=0.491305
[2023-08-18-18:44:17] [1/10] training 65.1%: Loss=1.3053, Accuracy=50.630%, MSE=0.489195
[2023-08-18-18:44:19] [1/10] training 67.5%: Loss=1.30114, Accuracy=50.607%, MSE=0.489288
[2023-08-18-18:44:20] [1/10] training 69.9%: Loss=1.29916, Accuracy=50.552%, MSE=0.489747
[2023-08-18-18:44:22] [1/10] training 72.3%: Loss=1.29652, Accuracy=50.433%, MSE=0.490754
[2023-08-18-18:44:25] [1/10] training 74.7%: Loss=1.28907, Accuracy=50.645%, MSE=0.488549
[2023-08-18-18:44:27] [1/10] training 77.1%: Loss=1.2844, Accuracy=50.656%, MSE=0.488245
[2023-08-18-18:44:29] [1/10] training 79.5%: Loss=1.28045, Accuracy=50.667%, MSE=0.488003
[2023-08-18-18:44:31] [1/10] training 81.9%: Loss=1.27325, Accuracy=50.882%, MSE=0.485741
[2023-08-18-18:44:33] [1/10] training 84.3%: Loss=1.27001, Accuracy=50.829%, MSE=0.486109
[2023-08-18-18:44:35] [1/10] training 86.7%: Loss=1.26883, Accuracy=50.667%, MSE=0.487554
[2023-08-18-18:44:37] [1/10] training 89.2%: Loss=1.26862, Accuracy=50.541%, MSE=0.488711
[2023-08-18-18:44:39] [1/10] training 91.6%: Loss=1.26777, Accuracy=50.368%, MSE=0.490227
[2023-08-18-18:44:40] [1/10] training 94.0%: Loss=1.26388, Accuracy=50.359%, MSE=0.49019
[2023-08-18-18:44:42] [1/10] training 96.4%: Loss=1.26302, Accuracy=50.200%, MSE=0.491575
[2023-08-18-18:44:44] [1/10] training 98.8%: Loss=1.26318, Accuracy=50.049%, MSE=0.492978
[2023-08-18-18:44:54] Finished Epoch 1/10: Loss=2.34146, Accuracy=49.583%, MSE=0.487555, Precision=0.554729, Recall=0.0126684, F1=0.0247711, AUPR=0.572947
[2023-08-18-18:44:54] Saving model to ./models/huang_both_1_tt_partitions_epoch01.sav
[2023-08-18-18:44:56] [2/10] training 2.4%: Loss=1.07667, Accuracy=53.000%, MSE=0.458135
[2023-08-18-18:44:58] [2/10] training 4.8%: Loss=1.04919, Accuracy=55.000%, MSE=0.439355
[2023-08-18-18:45:00] [2/10] training 7.2%: Loss=1.07767, Accuracy=52.667%, MSE=0.461788
[2023-08-18-18:45:02] [2/10] training 9.6%: Loss=1.06072, Accuracy=54.000%, MSE=0.44913
[2023-08-18-18:45:04] [2/10] training 12.0%: Loss=1.06249, Accuracy=53.200%, MSE=0.456481
[2023-08-18-18:45:05] [2/10] training 14.5%: Loss=1.07483, Accuracy=52.500%, MSE=0.463459
[2023-08-18-18:45:07] [2/10] training 16.9%: Loss=1.0773, Accuracy=52.143%, MSE=0.466753
[2023-08-18-18:45:09] [2/10] training 19.3%: Loss=1.07748, Accuracy=51.750%, MSE=0.470015
[2023-08-18-18:45:11] [2/10] training 21.7%: Loss=1.09469, Accuracy=50.889%, MSE=0.478562
[2023-08-18-18:45:13] [2/10] training 24.1%: Loss=1.10681, Accuracy=50.000%, MSE=0.486862
[2023-08-18-18:45:14] [2/10] training 26.5%: Loss=1.10905, Accuracy=49.909%, MSE=0.487791
[2023-08-18-18:45:16] [2/10] training 28.9%: Loss=1.11951, Accuracy=48.917%, MSE=0.497007
[2023-08-18-18:45:18] [2/10] training 31.3%: Loss=1.108, Accuracy=49.385%, MSE=0.491924
[2023-08-18-18:45:20] [2/10] training 33.7%: Loss=1.11303, Accuracy=49.143%, MSE=0.494499
[2023-08-18-18:45:22] [2/10] training 36.1%: Loss=1.10104, Accuracy=49.667%, MSE=0.489241
[2023-08-18-18:45:24] [2/10] training 38.6%: Loss=1.1027, Accuracy=49.438%, MSE=0.491241
[2023-08-18-18:45:26] [2/10] training 41.0%: Loss=1.10336, Accuracy=49.412%, MSE=0.491456
[2023-08-18-18:45:28] [2/10] training 43.4%: Loss=1.0961, Accuracy=49.722%, MSE=0.488123
[2023-08-18-18:45:29] [2/10] training 45.8%: Loss=1.09741, Accuracy=49.368%, MSE=0.491118
[2023-08-18-18:45:31] [2/10] training 48.2%: Loss=1.10647, Accuracy=49.000%, MSE=0.494808
[2023-08-18-18:45:33] [2/10] training 50.6%: Loss=1.1007, Accuracy=49.190%, MSE=0.492626
[2023-08-18-18:45:35] [2/10] training 53.0%: Loss=1.09699, Accuracy=49.364%, MSE=0.490984
[2023-08-18-18:45:37] [2/10] training 55.4%: Loss=1.10328, Accuracy=49.087%, MSE=0.493867
[2023-08-18-18:45:38] [2/10] training 57.8%: Loss=1.09786, Accuracy=49.250%, MSE=0.492027
[2023-08-18-18:45:40] [2/10] training 60.2%: Loss=1.09283, Accuracy=49.280%, MSE=0.491186
[2023-08-18-18:45:42] [2/10] training 62.7%: Loss=1.08631, Accuracy=49.615%, MSE=0.48779
[2023-08-18-18:45:43] [2/10] training 65.1%: Loss=1.08385, Accuracy=49.815%, MSE=0.485961
[2023-08-18-18:45:45] [2/10] training 67.5%: Loss=1.08588, Accuracy=49.643%, MSE=0.48764
[2023-08-18-18:45:47] [2/10] training 69.9%: Loss=1.07705, Accuracy=49.897%, MSE=0.484473
[2023-08-18-18:45:49] [2/10] training 72.3%: Loss=1.0735, Accuracy=49.800%, MSE=0.484868
[2023-08-18-18:45:50] [2/10] training 74.7%: Loss=1.07246, Accuracy=49.742%, MSE=0.485288
[2023-08-18-18:45:52] [2/10] training 77.1%: Loss=1.07179, Accuracy=49.812%, MSE=0.484667
[2023-08-18-18:45:54] [2/10] training 79.5%: Loss=1.07125, Accuracy=49.758%, MSE=0.485066
[2023-08-18-18:45:55] [2/10] training 81.9%: Loss=1.07015, Accuracy=49.588%, MSE=0.48632
[2023-08-18-18:45:57] [2/10] training 84.3%: Loss=1.06586, Accuracy=49.629%, MSE=0.485586
[2023-08-18-18:45:59] [2/10] training 86.7%: Loss=1.0647, Accuracy=49.472%, MSE=0.486723
[2023-08-18-18:46:01] [2/10] training 89.2%: Loss=1.06112, Accuracy=49.622%, MSE=0.485249
[2023-08-18-18:46:03] [2/10] training 91.6%: Loss=1.05698, Accuracy=49.789%, MSE=0.483543
[2023-08-18-18:46:05] [2/10] training 94.0%: Loss=1.05576, Accuracy=49.795%, MSE=0.483492
[2023-08-18-18:46:06] [2/10] training 96.4%: Loss=1.05236, Accuracy=49.875%, MSE=0.482436
[2023-08-18-18:46:09] [2/10] training 98.8%: Loss=1.04721, Accuracy=50.000%, MSE=0.480876
[2023-08-18-18:46:16] Finished Epoch 2/10: Loss=3.03285, Accuracy=49.583%, MSE=0.495817, Precision=0.431356, Recall=0.0042621, F1=0.0084408, AUPR=0.459255
[2023-08-18-18:46:16] Saving model to ./models/huang_both_1_tt_partitions_epoch02.sav
[2023-08-18-18:46:18] [3/10] training 2.4%: Loss=0.955975, Accuracy=48.000%, MSE=0.492001
[2023-08-18-18:46:20] [3/10] training 4.8%: Loss=0.948705, Accuracy=50.500%, MSE=0.470485
[2023-08-18-18:46:22] [3/10] training 7.2%: Loss=0.948539, Accuracy=49.667%, MSE=0.47594
[2023-08-18-18:46:24] [3/10] training 9.6%: Loss=0.933955, Accuracy=49.750%, MSE=0.472846
[2023-08-18-18:46:25] [3/10] training 12.0%: Loss=0.917793, Accuracy=48.400%, MSE=0.475417
[2023-08-18-18:46:27] [3/10] training 14.5%: Loss=0.924588, Accuracy=48.167%, MSE=0.478859
[2023-08-18-18:46:29] [3/10] training 16.9%: Loss=0.931989, Accuracy=47.857%, MSE=0.481918
[2023-08-18-18:46:31] [3/10] training 19.3%: Loss=0.936662, Accuracy=48.375%, MSE=0.479077
[2023-08-18-18:46:32] [3/10] training 21.7%: Loss=0.940661, Accuracy=48.556%, MSE=0.478339
[2023-08-18-18:46:34] [3/10] training 24.1%: Loss=0.943518, Accuracy=47.900%, MSE=0.483115
[2023-08-18-18:46:36] [3/10] training 26.5%: Loss=0.928565, Accuracy=48.545%, MSE=0.476022
[2023-08-18-18:46:38] [3/10] training 28.9%: Loss=0.921771, Accuracy=48.917%, MSE=0.471832
[2023-08-18-18:46:40] [3/10] training 31.3%: Loss=0.914031, Accuracy=49.231%, MSE=0.468137
[2023-08-18-18:46:42] [3/10] training 33.7%: Loss=0.918446, Accuracy=48.643%, MSE=0.473016
[2023-08-18-18:46:44] [3/10] training 36.1%: Loss=0.910894, Accuracy=49.000%, MSE=0.468743
[2023-08-18-18:46:45] [3/10] training 38.6%: Loss=0.907603, Accuracy=49.000%, MSE=0.467124
[2023-08-18-18:46:47] [3/10] training 41.0%: Loss=0.905931, Accuracy=49.235%, MSE=0.465204
[2023-08-18-18:46:49] [3/10] training 43.4%: Loss=0.910302, Accuracy=49.056%, MSE=0.467142
[2023-08-18-18:46:51] [3/10] training 45.8%: Loss=0.912304, Accuracy=48.947%, MSE=0.468331
[2023-08-18-18:46:53] [3/10] training 48.2%: Loss=0.907198, Accuracy=49.150%, MSE=0.465479
[2023-08-18-18:46:55] [3/10] training 50.6%: Loss=0.902651, Accuracy=49.381%, MSE=0.462715
[2023-08-18-18:46:56] [3/10] training 53.0%: Loss=0.89974, Accuracy=49.318%, MSE=0.461828
[2023-08-18-18:46:58] [3/10] training 55.4%: Loss=0.89577, Accuracy=49.304%, MSE=0.461053
[2023-08-18-18:47:00] [3/10] training 57.8%: Loss=0.89212, Accuracy=49.167%, MSE=0.46061
[2023-08-18-18:47:02] [3/10] training 60.2%: Loss=0.890961, Accuracy=49.040%, MSE=0.460956
[2023-08-18-18:47:04] [3/10] training 62.7%: Loss=0.888595, Accuracy=48.846%, MSE=0.461204
[2023-08-18-18:47:06] [3/10] training 65.1%: Loss=0.883597, Accuracy=48.704%, MSE=0.460096
[2023-08-18-18:47:07] [3/10] training 67.5%: Loss=0.877827, Accuracy=48.536%, MSE=0.458483
[2023-08-18-18:47:09] [3/10] training 69.9%: Loss=0.870176, Accuracy=48.517%, MSE=0.455401
[2023-08-18-18:47:11] [3/10] training 72.3%: Loss=0.862692, Accuracy=48.400%, MSE=0.452021
[2023-08-18-18:47:13] [3/10] training 74.7%: Loss=0.854549, Accuracy=48.032%, MSE=0.449297
[2023-08-18-18:47:15] [3/10] training 77.1%: Loss=0.847646, Accuracy=48.250%, MSE=0.445638
[2023-08-18-18:47:17] [3/10] training 79.5%: Loss=0.848668, Accuracy=48.121%, MSE=0.447286
[2023-08-18-18:47:19] [3/10] training 81.9%: Loss=0.852043, Accuracy=48.206%, MSE=0.447933
[2023-08-18-18:47:20] [3/10] training 84.3%: Loss=0.857134, Accuracy=48.229%, MSE=0.449198
[2023-08-18-18:47:22] [3/10] training 86.7%: Loss=0.866648, Accuracy=48.083%, MSE=0.452197
[2023-08-18-18:47:24] [3/10] training 89.2%: Loss=0.878847, Accuracy=47.811%, MSE=0.4564
[2023-08-18-18:47:26] [3/10] training 91.6%: Loss=0.880936, Accuracy=48.105%, MSE=0.45494
[2023-08-18-18:47:27] [3/10] training 94.0%: Loss=0.888314, Accuracy=48.000%, MSE=0.457247
[2023-08-18-18:47:29] [3/10] training 96.4%: Loss=0.891092, Accuracy=48.175%, MSE=0.456794
[2023-08-18-18:47:31] [3/10] training 98.8%: Loss=0.895282, Accuracy=48.195%, MSE=0.4577
[2023-08-18-18:47:38] Finished Epoch 3/10: Loss=2.62312, Accuracy=49.583%, MSE=0.484049, Precision=0.379155, Recall=0.0177274, F1=0.0338711, AUPR=0.411796
[2023-08-18-18:47:38] Saving model to ./models/huang_both_1_tt_partitions_epoch03.sav
[2023-08-18-18:47:40] [4/10] training 2.4%: Loss=0.865163, Accuracy=59.000%, MSE=0.391567
[2023-08-18-18:47:42] [4/10] training 4.8%: Loss=0.880769, Accuracy=57.000%, MSE=0.408491
[2023-08-18-18:47:44] [4/10] training 7.2%: Loss=0.862639, Accuracy=54.333%, MSE=0.421289
[2023-08-18-18:47:46] [4/10] training 9.6%: Loss=0.885481, Accuracy=50.750%, MSE=0.446825
[2023-08-18-18:47:47] [4/10] training 12.0%: Loss=0.878867, Accuracy=51.200%, MSE=0.442151
[2023-08-18-18:47:49] [4/10] training 14.5%: Loss=0.857003, Accuracy=52.833%, MSE=0.428441
[2023-08-18-18:47:51] [4/10] training 16.9%: Loss=0.846519, Accuracy=50.429%, MSE=0.433792
[2023-08-18-18:47:53] [4/10] training 19.3%: Loss=0.823463, Accuracy=49.500%, MSE=0.426029
[2023-08-18-18:47:55] [4/10] training 21.7%: Loss=0.801769, Accuracy=48.222%, MSE=0.421208
[2023-08-18-18:47:57] [4/10] training 24.1%: Loss=0.78072, Accuracy=48.400%, MSE=0.409441
[2023-08-18-18:47:58] [4/10] training 26.5%: Loss=0.79572, Accuracy=50.091%, MSE=0.401028
[2023-08-18-18:48:00] [4/10] training 28.9%: Loss=0.844257, Accuracy=49.250%, MSE=0.41643
[2023-08-18-18:48:02] [4/10] training 31.3%: Loss=0.859966, Accuracy=49.692%, MSE=0.418446
[2023-08-18-18:48:04] [4/10] training 33.7%: Loss=0.879802, Accuracy=49.643%, MSE=0.424395
[2023-08-18-18:48:06] [4/10] training 36.1%: Loss=0.892029, Accuracy=49.800%, MSE=0.427511
[2023-08-18-18:48:08] [4/10] training 38.6%: Loss=0.899072, Accuracy=49.625%, MSE=0.432138
[2023-08-18-18:48:10] [4/10] training 41.0%: Loss=0.895647, Accuracy=49.647%, MSE=0.432722
[2023-08-18-18:48:11] [4/10] training 43.4%: Loss=0.891615, Accuracy=49.667%, MSE=0.432301
[2023-08-18-18:48:13] [4/10] training 45.8%: Loss=0.890097, Accuracy=49.316%, MSE=0.434787
[2023-08-18-18:48:15] [4/10] training 48.2%: Loss=0.880944, Accuracy=49.550%, MSE=0.431009
[2023-08-18-18:48:17] [4/10] training 50.6%: Loss=0.874239, Accuracy=49.905%, MSE=0.427701
[2023-08-18-18:48:18] [4/10] training 53.0%: Loss=0.868002, Accuracy=50.000%, MSE=0.426014
[2023-08-18-18:48:20] [4/10] training 55.4%: Loss=0.862937, Accuracy=50.000%, MSE=0.425405
[2023-08-18-18:48:22] [4/10] training 57.8%: Loss=0.862014, Accuracy=49.750%, MSE=0.427357
[2023-08-18-18:48:23] [4/10] training 60.2%: Loss=0.854855, Accuracy=49.880%, MSE=0.425042
[2023-08-18-18:48:25] [4/10] training 62.7%: Loss=0.850264, Accuracy=50.038%, MSE=0.423252
[2023-08-18-18:48:27] [4/10] training 65.1%: Loss=0.847813, Accuracy=49.963%, MSE=0.423352
[2023-08-18-18:48:29] [4/10] training 67.5%: Loss=0.842393, Accuracy=49.929%, MSE=0.42226
[2023-08-18-18:48:31] [4/10] training 69.9%: Loss=0.83798, Accuracy=49.966%, MSE=0.421459
[2023-08-18-18:48:32] [4/10] training 72.3%: Loss=0.83398, Accuracy=49.900%, MSE=0.420495
[2023-08-18-18:48:34] [4/10] training 74.7%: Loss=0.829306, Accuracy=49.968%, MSE=0.419089
[2023-08-18-18:48:36] [4/10] training 77.1%: Loss=0.828352, Accuracy=49.906%, MSE=0.41946
[2023-08-18-18:48:38] [4/10] training 79.5%: Loss=0.827141, Accuracy=49.818%, MSE=0.420139
[2023-08-18-18:48:40] [4/10] training 81.9%: Loss=0.827301, Accuracy=49.412%, MSE=0.422137
[2023-08-18-18:48:42] [4/10] training 84.3%: Loss=0.82499, Accuracy=49.429%, MSE=0.421707
[2023-08-18-18:48:44] [4/10] training 86.7%: Loss=0.822681, Accuracy=49.417%, MSE=0.421824
[2023-08-18-18:48:46] [4/10] training 89.2%: Loss=0.823554, Accuracy=49.324%, MSE=0.423097
[2023-08-18-18:48:47] [4/10] training 91.6%: Loss=0.822289, Accuracy=49.263%, MSE=0.423329
[2023-08-18-18:48:49] [4/10] training 94.0%: Loss=0.818822, Accuracy=49.436%, MSE=0.421913
[2023-08-18-18:48:51] [4/10] training 96.4%: Loss=0.817796, Accuracy=49.300%, MSE=0.422636
[2023-08-18-18:48:52] [4/10] training 98.8%: Loss=0.815758, Accuracy=49.220%, MSE=0.422717
[2023-08-18-18:49:00] Finished Epoch 4/10: Loss=4.84382, Accuracy=49.583%, MSE=0.499938, Precision=0.498408, Recall=6.20924e-05, F1=0.000124169, AUPR=0.511966
[2023-08-18-18:49:00] Saving model to ./models/huang_both_1_tt_partitions_epoch04.sav
[2023-08-18-18:49:02] [5/10] training 2.4%: Loss=0.691047, Accuracy=49.000%, MSE=0.392103
[2023-08-18-18:49:03] [5/10] training 4.8%: Loss=0.696207, Accuracy=49.500%, MSE=0.393729
[2023-08-18-18:49:05] [5/10] training 7.2%: Loss=0.724962, Accuracy=49.667%, MSE=0.407513
[2023-08-18-18:49:07] [5/10] training 9.6%: Loss=0.753844, Accuracy=48.250%, MSE=0.423658
[2023-08-18-18:49:09] [5/10] training 12.0%: Loss=0.76899, Accuracy=48.200%, MSE=0.429025
[2023-08-18-18:49:10] [5/10] training 14.5%: Loss=0.759948, Accuracy=47.833%, MSE=0.425336
[2023-08-18-18:49:12] [5/10] training 16.9%: Loss=0.758578, Accuracy=47.286%, MSE=0.426698
[2023-08-18-18:49:14] [5/10] training 19.3%: Loss=0.749921, Accuracy=47.750%, MSE=0.42096
[2023-08-18-18:49:16] [5/10] training 21.7%: Loss=0.744262, Accuracy=47.889%, MSE=0.418382
[2023-08-18-18:49:18] [5/10] training 24.1%: Loss=0.748264, Accuracy=47.600%, MSE=0.421509
[2023-08-18-18:49:20] [5/10] training 26.5%: Loss=0.738571, Accuracy=48.273%, MSE=0.414597
[2023-08-18-18:49:22] [5/10] training 28.9%: Loss=0.733417, Accuracy=48.417%, MSE=0.410921
[2023-08-18-18:49:24] [5/10] training 31.3%: Loss=0.732521, Accuracy=48.154%, MSE=0.412163
[2023-08-18-18:49:25] [5/10] training 33.7%: Loss=0.730716, Accuracy=47.929%, MSE=0.412552
[2023-08-18-18:49:27] [5/10] training 36.1%: Loss=0.725178, Accuracy=48.267%, MSE=0.409389
[2023-08-18-18:49:28] [5/10] training 38.6%: Loss=0.720687, Accuracy=48.062%, MSE=0.407472
[2023-08-18-18:49:30] [5/10] training 41.0%: Loss=0.71768, Accuracy=47.529%, MSE=0.406975
[2023-08-18-18:49:32] [5/10] training 43.4%: Loss=0.713354, Accuracy=46.944%, MSE=0.405846
[2023-08-18-18:49:34] [5/10] training 45.8%: Loss=0.711762, Accuracy=46.895%, MSE=0.404865
[2023-08-18-18:49:36] [5/10] training 48.2%: Loss=0.708737, Accuracy=46.650%, MSE=0.403421
[2023-08-18-18:49:38] [5/10] training 50.6%: Loss=0.706618, Accuracy=46.667%, MSE=0.402412
[2023-08-18-18:49:40] [5/10] training 53.0%: Loss=0.706929, Accuracy=46.818%, MSE=0.402337
[2023-08-18-18:49:42] [5/10] training 55.4%: Loss=0.706789, Accuracy=47.217%, MSE=0.401128
[2023-08-18-18:49:44] [5/10] training 57.8%: Loss=0.706903, Accuracy=47.375%, MSE=0.401013
[2023-08-18-18:49:46] [5/10] training 60.2%: Loss=0.70562, Accuracy=47.600%, MSE=0.399597
[2023-08-18-18:49:47] [5/10] training 62.7%: Loss=0.704953, Accuracy=47.538%, MSE=0.399611
[2023-08-18-18:49:49] [5/10] training 65.1%: Loss=0.705357, Accuracy=47.296%, MSE=0.401285
[2023-08-18-18:49:51] [5/10] training 67.5%: Loss=0.7065, Accuracy=47.250%, MSE=0.402161
[2023-08-18-18:49:53] [5/10] training 69.9%: Loss=0.704779, Accuracy=47.483%, MSE=0.400672
[2023-08-18-18:49:54] [5/10] training 72.3%: Loss=0.701881, Accuracy=47.733%, MSE=0.398522
[2023-08-18-18:49:56] [5/10] training 74.7%: Loss=0.698427, Accuracy=48.032%, MSE=0.396241
[2023-08-18-18:49:58] [5/10] training 77.1%: Loss=0.696706, Accuracy=47.938%, MSE=0.395494
[2023-08-18-18:50:00] [5/10] training 79.5%: Loss=0.695593, Accuracy=47.818%, MSE=0.395096
[2023-08-18-18:50:01] [5/10] training 81.9%: Loss=0.693968, Accuracy=47.882%, MSE=0.394131
[2023-08-18-18:50:03] [5/10] training 84.3%: Loss=0.694467, Accuracy=47.829%, MSE=0.394602
[2023-08-18-18:50:05] [5/10] training 86.7%: Loss=0.693191, Accuracy=48.000%, MSE=0.39353
[2023-08-18-18:50:07] [5/10] training 89.2%: Loss=0.693959, Accuracy=48.081%, MSE=0.393917
[2023-08-18-18:50:09] [5/10] training 91.6%: Loss=0.694604, Accuracy=47.895%, MSE=0.394378
[2023-08-18-18:50:11] [5/10] training 94.0%: Loss=0.695233, Accuracy=47.821%, MSE=0.395024
[2023-08-18-18:50:13] [5/10] training 96.4%: Loss=0.693947, Accuracy=47.625%, MSE=0.394754
[2023-08-18-18:50:14] [5/10] training 98.8%: Loss=0.691503, Accuracy=47.780%, MSE=0.392825
[2023-08-18-18:50:22] Finished Epoch 5/10: Loss=4.78683, Accuracy=49.583%, MSE=0.49993, Precision=0.47495, Recall=7.00479e-05, F1=0.000140075, AUPR=0.431463
[2023-08-18-18:50:22] Saving model to ./models/huang_both_1_tt_partitions_epoch05.sav
[2023-08-18-18:50:24] [6/10] training 2.4%: Loss=0.753904, Accuracy=34.000%, MSE=0.461728
[2023-08-18-18:50:26] [6/10] training 4.8%: Loss=0.694839, Accuracy=41.000%, MSE=0.413894
[2023-08-18-18:50:27] [6/10] training 7.2%: Loss=0.691755, Accuracy=42.000%, MSE=0.40637
[2023-08-18-18:50:29] [6/10] training 9.6%: Loss=0.682572, Accuracy=41.750%, MSE=0.404635
[2023-08-18-18:50:31] [6/10] training 12.0%: Loss=0.678028, Accuracy=42.400%, MSE=0.401052
[2023-08-18-18:50:33] [6/10] training 14.5%: Loss=0.672266, Accuracy=41.833%, MSE=0.399318
[2023-08-18-18:50:35] [6/10] training 16.9%: Loss=0.664242, Accuracy=42.286%, MSE=0.392482
[2023-08-18-18:50:36] [6/10] training 19.3%: Loss=0.656035, Accuracy=43.000%, MSE=0.38622
[2023-08-18-18:50:38] [6/10] training 21.7%: Loss=0.655309, Accuracy=42.778%, MSE=0.385811
[2023-08-18-18:50:40] [6/10] training 24.1%: Loss=0.655107, Accuracy=43.400%, MSE=0.38462
[2023-08-18-18:50:42] [6/10] training 26.5%: Loss=0.660122, Accuracy=44.000%, MSE=0.385314
[2023-08-18-18:50:44] [6/10] training 28.9%: Loss=0.659374, Accuracy=44.500%, MSE=0.383814
[2023-08-18-18:50:45] [6/10] training 31.3%: Loss=0.658946, Accuracy=44.846%, MSE=0.382083
[2023-08-18-18:50:47] [6/10] training 33.7%: Loss=0.659704, Accuracy=45.000%, MSE=0.381256
[2023-08-18-18:50:49] [6/10] training 36.1%: Loss=0.66235, Accuracy=45.267%, MSE=0.381577
[2023-08-18-18:50:50] [6/10] training 38.6%: Loss=0.667419, Accuracy=44.938%, MSE=0.384897
[2023-08-18-18:50:52] [6/10] training 41.0%: Loss=0.669517, Accuracy=45.176%, MSE=0.385335
[2023-08-18-18:50:54] [6/10] training 43.4%: Loss=0.669928, Accuracy=45.389%, MSE=0.385124
[2023-08-18-18:50:56] [6/10] training 45.8%: Loss=0.666988, Accuracy=45.684%, MSE=0.382858
[2023-08-18-18:50:58] [6/10] training 48.2%: Loss=0.66223, Accuracy=45.950%, MSE=0.379242
[2023-08-18-18:51:00] [6/10] training 50.6%: Loss=0.659844, Accuracy=45.810%, MSE=0.37807
[2023-08-18-18:51:01] [6/10] training 53.0%: Loss=0.65841, Accuracy=45.864%, MSE=0.377379
[2023-08-18-18:51:03] [6/10] training 55.4%: Loss=0.654974, Accuracy=46.000%, MSE=0.375153
[2023-08-18-18:51:05] [6/10] training 57.8%: Loss=0.653613, Accuracy=46.333%, MSE=0.373973
[2023-08-18-18:51:07] [6/10] training 60.2%: Loss=0.651459, Accuracy=46.400%, MSE=0.372306
[2023-08-18-18:51:09] [6/10] training 62.7%: Loss=0.650121, Accuracy=46.500%, MSE=0.371345
[2023-08-18-18:51:11] [6/10] training 65.1%: Loss=0.64678, Accuracy=46.556%, MSE=0.368972
[2023-08-18-18:51:13] [6/10] training 67.5%: Loss=0.646233, Accuracy=46.214%, MSE=0.369624
[2023-08-18-18:51:14] [6/10] training 69.9%: Loss=0.645279, Accuracy=46.000%, MSE=0.36959
[2023-08-18-18:51:16] [6/10] training 72.3%: Loss=0.643421, Accuracy=45.800%, MSE=0.368731
[2023-08-18-18:51:18] [6/10] training 74.7%: Loss=0.640815, Accuracy=46.000%, MSE=0.366561
[2023-08-18-18:51:20] [6/10] training 77.1%: Loss=0.639277, Accuracy=46.156%, MSE=0.365437
[2023-08-18-18:51:22] [6/10] training 79.5%: Loss=0.638381, Accuracy=45.970%, MSE=0.365562
[2023-08-18-18:51:24] [6/10] training 81.9%: Loss=0.635111, Accuracy=46.353%, MSE=0.362896
[2023-08-18-18:51:26] [6/10] training 84.3%: Loss=0.631527, Accuracy=46.857%, MSE=0.359449
[2023-08-18-18:51:28] [6/10] training 86.7%: Loss=0.63293, Accuracy=47.194%, MSE=0.358888
[2023-08-18-18:51:29] [6/10] training 89.2%: Loss=0.640815, Accuracy=47.432%, MSE=0.360645
[2023-08-18-18:51:31] [6/10] training 91.6%: Loss=0.645685, Accuracy=47.500%, MSE=0.362533
[2023-08-18-18:51:33] [6/10] training 94.0%: Loss=0.648267, Accuracy=47.538%, MSE=0.363742
[2023-08-18-18:51:35] [6/10] training 96.4%: Loss=0.650214, Accuracy=47.700%, MSE=0.363962
[2023-08-18-18:51:37] [6/10] training 98.8%: Loss=0.652152, Accuracy=47.805%, MSE=0.364467
[2023-08-18-18:51:44] Finished Epoch 6/10: Loss=2.68936, Accuracy=49.500%, MSE=0.486033, Precision=0.373638, Recall=0.0165109, F1=0.0316243, AUPR=0.441466
[2023-08-18-18:51:44] Saving model to ./models/huang_both_1_tt_partitions_epoch06.sav
[2023-08-18-18:51:46] [7/10] training 2.4%: Loss=0.754452, Accuracy=44.000%, MSE=0.430709
[2023-08-18-18:51:48] [7/10] training 4.8%: Loss=0.727727, Accuracy=45.000%, MSE=0.419688
[2023-08-18-18:51:49] [7/10] training 7.2%: Loss=0.660908, Accuracy=51.333%, MSE=0.373094
[2023-08-18-18:51:51] [7/10] training 9.6%: Loss=0.642143, Accuracy=56.250%, MSE=0.333531
[2023-08-18-18:51:53] [7/10] training 12.0%: Loss=0.754371, Accuracy=54.200%, MSE=0.369717
[2023-08-18-18:51:55] [7/10] training 14.5%: Loss=0.819074, Accuracy=52.500%, MSE=0.39918
[2023-08-18-18:51:56] [7/10] training 16.9%: Loss=0.841765, Accuracy=52.286%, MSE=0.409855
[2023-08-18-18:51:58] [7/10] training 19.3%: Loss=0.850355, Accuracy=52.125%, MSE=0.416644
[2023-08-18-18:52:00] [7/10] training 21.7%: Loss=0.845609, Accuracy=51.556%, MSE=0.42169
[2023-08-18-18:52:02] [7/10] training 24.1%: Loss=0.830906, Accuracy=51.400%, MSE=0.420468
[2023-08-18-18:52:04] [7/10] training 26.5%: Loss=0.813544, Accuracy=50.636%, MSE=0.418154
[2023-08-18-18:52:06] [7/10] training 28.9%: Loss=0.794019, Accuracy=50.917%, MSE=0.41069
[2023-08-18-18:52:08] [7/10] training 31.3%: Loss=0.776669, Accuracy=51.385%, MSE=0.403578
[2023-08-18-18:52:10] [7/10] training 33.7%: Loss=0.763677, Accuracy=50.857%, MSE=0.400108
[2023-08-18-18:52:12] [7/10] training 36.1%: Loss=0.749234, Accuracy=51.000%, MSE=0.394155
[2023-08-18-18:52:13] [7/10] training 38.6%: Loss=0.736867, Accuracy=50.875%, MSE=0.389728
[2023-08-18-18:52:15] [7/10] training 41.0%: Loss=0.724813, Accuracy=50.765%, MSE=0.384502
[2023-08-18-18:52:17] [7/10] training 43.4%: Loss=0.717376, Accuracy=50.000%, MSE=0.38361
[2023-08-18-18:52:19] [7/10] training 45.8%: Loss=0.710313, Accuracy=49.421%, MSE=0.381798
[2023-08-18-18:52:21] [7/10] training 48.2%: Loss=0.705246, Accuracy=48.700%, MSE=0.381547
[2023-08-18-18:52:23] [7/10] training 50.6%: Loss=0.699938, Accuracy=48.429%, MSE=0.380402
[2023-08-18-18:52:24] [7/10] training 53.0%: Loss=0.695244, Accuracy=48.364%, MSE=0.379048
[2023-08-18-18:52:26] [7/10] training 55.4%: Loss=0.690487, Accuracy=48.174%, MSE=0.377535
[2023-08-18-18:52:28] [7/10] training 57.8%: Loss=0.68659, Accuracy=48.042%, MSE=0.376104
[2023-08-18-18:52:29] [7/10] training 60.2%: Loss=0.682863, Accuracy=47.840%, MSE=0.375317
[2023-08-18-18:52:31] [7/10] training 62.7%: Loss=0.677911, Accuracy=48.231%, MSE=0.37226
[2023-08-18-18:52:33] [7/10] training 65.1%: Loss=0.673028, Accuracy=48.333%, MSE=0.369826
[2023-08-18-18:52:35] [7/10] training 67.5%: Loss=0.669537, Accuracy=48.036%, MSE=0.368511
[2023-08-18-18:52:36] [7/10] training 69.9%: Loss=0.665783, Accuracy=48.310%, MSE=0.366038
[2023-08-18-18:52:38] [7/10] training 72.3%: Loss=0.662921, Accuracy=48.300%, MSE=0.364853
[2023-08-18-18:52:40] [7/10] training 74.7%: Loss=0.657829, Accuracy=48.387%, MSE=0.361639
[2023-08-18-18:52:42] [7/10] training 77.1%: Loss=0.653951, Accuracy=48.594%, MSE=0.359016
[2023-08-18-18:52:43] [7/10] training 79.5%: Loss=0.651809, Accuracy=48.485%, MSE=0.35836
[2023-08-18-18:52:45] [7/10] training 81.9%: Loss=0.647988, Accuracy=48.647%, MSE=0.355796
[2023-08-18-18:52:47] [7/10] training 84.3%: Loss=0.645691, Accuracy=48.771%, MSE=0.354279
[2023-08-18-18:52:49] [7/10] training 86.7%: Loss=0.642947, Accuracy=49.028%, MSE=0.352155
[2023-08-18-18:52:51] [7/10] training 89.2%: Loss=0.641829, Accuracy=49.054%, MSE=0.351974
[2023-08-18-18:52:53] [7/10] training 91.6%: Loss=0.639415, Accuracy=49.263%, MSE=0.350523
[2023-08-18-18:52:55] [7/10] training 94.0%: Loss=0.636777, Accuracy=49.462%, MSE=0.348804
[2023-08-18-18:52:57] [7/10] training 96.4%: Loss=0.633759, Accuracy=49.725%, MSE=0.346818
[2023-08-18-18:52:59] [7/10] training 98.8%: Loss=0.632217, Accuracy=49.951%, MSE=0.345954
[2023-08-18-18:53:06] Finished Epoch 7/10: Loss=3.28702, Accuracy=49.583%, MSE=0.497382, Precision=0.657683, Recall=0.00262766, F1=0.00523441, AUPR=0.64466
[2023-08-18-18:53:06] Saving model to ./models/huang_both_1_tt_partitions_epoch07.sav
[2023-08-18-18:53:08] [8/10] training 2.4%: Loss=0.497803, Accuracy=61.000%, MSE=0.24984
[2023-08-18-18:53:10] [8/10] training 4.8%: Loss=0.527223, Accuracy=59.000%, MSE=0.276855
[2023-08-18-18:53:12] [8/10] training 7.2%: Loss=0.521541, Accuracy=58.667%, MSE=0.272197
[2023-08-18-18:53:14] [8/10] training 9.6%: Loss=0.523068, Accuracy=56.750%, MSE=0.276716
[2023-08-18-18:53:16] [8/10] training 12.0%: Loss=0.528271, Accuracy=56.800%, MSE=0.280463
[2023-08-18-18:53:17] [8/10] training 14.5%: Loss=0.532329, Accuracy=56.500%, MSE=0.284883
[2023-08-18-18:53:19] [8/10] training 16.9%: Loss=0.534499, Accuracy=55.714%, MSE=0.286834
[2023-08-18-18:53:21] [8/10] training 19.3%: Loss=0.5398, Accuracy=54.625%, MSE=0.292652
[2023-08-18-18:53:23] [8/10] training 21.7%: Loss=0.535518, Accuracy=55.000%, MSE=0.289253
[2023-08-18-18:53:24] [8/10] training 24.1%: Loss=0.536481, Accuracy=55.200%, MSE=0.289015
[2023-08-18-18:53:26] [8/10] training 26.5%: Loss=0.537503, Accuracy=54.545%, MSE=0.290817
[2023-08-18-18:53:28] [8/10] training 28.9%: Loss=0.536626, Accuracy=54.917%, MSE=0.289992
[2023-08-18-18:53:30] [8/10] training 31.3%: Loss=0.536415, Accuracy=54.846%, MSE=0.28964
[2023-08-18-18:53:32] [8/10] training 33.7%: Loss=0.53262, Accuracy=55.500%, MSE=0.286065
[2023-08-18-18:53:34] [8/10] training 36.1%: Loss=0.531524, Accuracy=55.600%, MSE=0.285353
[2023-08-18-18:53:35] [8/10] training 38.6%: Loss=0.530144, Accuracy=55.937%, MSE=0.283374
[2023-08-18-18:53:37] [8/10] training 41.0%: Loss=0.52914, Accuracy=56.000%, MSE=0.282439
[2023-08-18-18:53:39] [8/10] training 43.4%: Loss=0.529591, Accuracy=56.111%, MSE=0.28275
[2023-08-18-18:53:41] [8/10] training 45.8%: Loss=0.528457, Accuracy=56.526%, MSE=0.281354
[2023-08-18-18:53:43] [8/10] training 48.2%: Loss=0.527228, Accuracy=56.750%, MSE=0.280234
[2023-08-18-18:53:44] [8/10] training 50.6%: Loss=0.525737, Accuracy=57.190%, MSE=0.278624
[2023-08-18-18:53:46] [8/10] training 53.0%: Loss=0.522157, Accuracy=57.545%, MSE=0.275349
[2023-08-18-18:53:48] [8/10] training 55.4%: Loss=0.522754, Accuracy=57.478%, MSE=0.276345
[2023-08-18-18:53:50] [8/10] training 57.8%: Loss=0.522694, Accuracy=57.542%, MSE=0.276295
[2023-08-18-18:53:52] [8/10] training 60.2%: Loss=0.52123, Accuracy=57.680%, MSE=0.275202
[2023-08-18-18:53:54] [8/10] training 62.7%: Loss=0.518471, Accuracy=57.808%, MSE=0.272894
[2023-08-18-18:53:56] [8/10] training 65.1%: Loss=0.518009, Accuracy=57.778%, MSE=0.272823
[2023-08-18-18:53:58] [8/10] training 67.5%: Loss=0.516386, Accuracy=58.107%, MSE=0.270807
[2023-08-18-18:53:59] [8/10] training 69.9%: Loss=0.516019, Accuracy=57.793%, MSE=0.271031
[2023-08-18-18:54:01] [8/10] training 72.3%: Loss=0.515084, Accuracy=57.933%, MSE=0.270007
[2023-08-18-18:54:03] [8/10] training 74.7%: Loss=0.515237, Accuracy=57.935%, MSE=0.270495
[2023-08-18-18:54:05] [8/10] training 77.1%: Loss=0.514929, Accuracy=57.781%, MSE=0.270483
[2023-08-18-18:54:06] [8/10] training 79.5%: Loss=0.514605, Accuracy=57.697%, MSE=0.270527
[2023-08-18-18:54:08] [8/10] training 81.9%: Loss=0.51437, Accuracy=57.588%, MSE=0.270573
[2023-08-18-18:54:10] [8/10] training 84.3%: Loss=0.513384, Accuracy=57.800%, MSE=0.269449
[2023-08-18-18:54:12] [8/10] training 86.7%: Loss=0.513131, Accuracy=57.750%, MSE=0.269428
[2023-08-18-18:54:14] [8/10] training 89.2%: Loss=0.51373, Accuracy=57.622%, MSE=0.27019
[2023-08-18-18:54:15] [8/10] training 91.6%: Loss=0.513614, Accuracy=57.579%, MSE=0.270018
[2023-08-18-18:54:17] [8/10] training 94.0%: Loss=0.513748, Accuracy=57.564%, MSE=0.270323
[2023-08-18-18:54:19] [8/10] training 96.4%: Loss=0.513597, Accuracy=57.650%, MSE=0.270282
[2023-08-18-18:54:21] [8/10] training 98.8%: Loss=0.513359, Accuracy=57.659%, MSE=0.270291
[2023-08-18-18:54:28] Finished Epoch 8/10: Loss=3.41855, Accuracy=49.583%, MSE=0.498275, Precision=0.691537, Recall=0.00172931, F1=0.00345, AUPR=0.69217
[2023-08-18-18:54:28] Saving model to ./models/huang_both_1_tt_partitions_epoch08.sav
[2023-08-18-18:54:30] [9/10] training 2.4%: Loss=0.45869, Accuracy=64.000%, MSE=0.222712
[2023-08-18-18:54:32] [9/10] training 4.8%: Loss=0.44656, Accuracy=68.500%, MSE=0.206427
[2023-08-18-18:54:34] [9/10] training 7.2%: Loss=0.445788, Accuracy=67.667%, MSE=0.207393
[2023-08-18-18:54:35] [9/10] training 9.6%: Loss=0.457564, Accuracy=65.250%, MSE=0.220309
[2023-08-18-18:54:37] [9/10] training 12.0%: Loss=0.456469, Accuracy=66.200%, MSE=0.217978
[2023-08-18-18:54:39] [9/10] training 14.5%: Loss=0.460828, Accuracy=65.500%, MSE=0.222299
[2023-08-18-18:54:41] [9/10] training 16.9%: Loss=0.465104, Accuracy=65.143%, MSE=0.226044
[2023-08-18-18:54:43] [9/10] training 19.3%: Loss=0.466244, Accuracy=65.375%, MSE=0.226922
[2023-08-18-18:54:44] [9/10] training 21.7%: Loss=0.470865, Accuracy=64.556%, MSE=0.232078
[2023-08-18-18:54:46] [9/10] training 24.1%: Loss=0.468035, Accuracy=64.700%, MSE=0.229426
[2023-08-18-18:54:48] [9/10] training 26.5%: Loss=0.475905, Accuracy=63.909%, MSE=0.235503
[2023-08-18-18:54:50] [9/10] training 28.9%: Loss=0.482224, Accuracy=62.500%, MSE=0.242622
[2023-08-18-18:54:52] [9/10] training 31.3%: Loss=0.483279, Accuracy=62.308%, MSE=0.243851
[2023-08-18-18:54:54] [9/10] training 33.7%: Loss=0.487745, Accuracy=61.571%, MSE=0.248527
[2023-08-18-18:54:56] [9/10] training 36.1%: Loss=0.489508, Accuracy=61.200%, MSE=0.250418
[2023-08-18-18:54:58] [9/10] training 38.6%: Loss=0.490859, Accuracy=60.812%, MSE=0.252019
[2023-08-18-18:54:59] [9/10] training 41.0%: Loss=0.494135, Accuracy=60.529%, MSE=0.254366
[2023-08-18-18:55:01] [9/10] training 43.4%: Loss=0.495367, Accuracy=60.000%, MSE=0.256598
[2023-08-18-18:55:03] [9/10] training 45.8%: Loss=0.495782, Accuracy=59.895%, MSE=0.257376
[2023-08-18-18:55:05] [9/10] training 48.2%: Loss=0.49607, Accuracy=59.800%, MSE=0.257829
[2023-08-18-18:55:06] [9/10] training 50.6%: Loss=0.494888, Accuracy=59.667%, MSE=0.257341
[2023-08-18-18:55:08] [9/10] training 53.0%: Loss=0.492864, Accuracy=60.000%, MSE=0.255371
[2023-08-18-18:55:10] [9/10] training 55.4%: Loss=0.49097, Accuracy=60.435%, MSE=0.253365
[2023-08-18-18:55:12] [9/10] training 57.8%: Loss=0.488524, Accuracy=60.583%, MSE=0.251226
[2023-08-18-18:55:13] [9/10] training 60.2%: Loss=0.488789, Accuracy=60.280%, MSE=0.251905
[2023-08-18-18:55:15] [9/10] training 62.7%: Loss=0.48809, Accuracy=60.231%, MSE=0.251467
[2023-08-18-18:55:17] [9/10] training 65.1%: Loss=0.488811, Accuracy=60.074%, MSE=0.252145
[2023-08-18-18:55:19] [9/10] training 67.5%: Loss=0.487414, Accuracy=60.286%, MSE=0.250917
[2023-08-18-18:55:21] [9/10] training 69.9%: Loss=0.487254, Accuracy=60.414%, MSE=0.250645
[2023-08-18-18:55:22] [9/10] training 72.3%: Loss=0.486931, Accuracy=60.367%, MSE=0.250537
[2023-08-18-18:55:24] [9/10] training 74.7%: Loss=0.48619, Accuracy=60.484%, MSE=0.249823
[2023-08-18-18:55:26] [9/10] training 77.1%: Loss=0.486315, Accuracy=60.594%, MSE=0.249894
[2023-08-18-18:55:28] [9/10] training 79.5%: Loss=0.485356, Accuracy=60.697%, MSE=0.249079
[2023-08-18-18:55:30] [9/10] training 81.9%: Loss=0.484283, Accuracy=60.882%, MSE=0.248098
[2023-08-18-18:55:31] [9/10] training 84.3%: Loss=0.483747, Accuracy=60.943%, MSE=0.247705
[2023-08-18-18:55:33] [9/10] training 86.7%: Loss=0.483712, Accuracy=61.000%, MSE=0.24767
[2023-08-18-18:55:35] [9/10] training 89.2%: Loss=0.483228, Accuracy=60.973%, MSE=0.247609
[2023-08-18-18:55:37] [9/10] training 91.6%: Loss=0.482612, Accuracy=61.026%, MSE=0.247172
[2023-08-18-18:55:39] [9/10] training 94.0%: Loss=0.482682, Accuracy=61.051%, MSE=0.247396
[2023-08-18-18:55:40] [9/10] training 96.4%: Loss=0.483048, Accuracy=61.025%, MSE=0.247969
[2023-08-18-18:55:42] [9/10] training 98.8%: Loss=0.483509, Accuracy=61.049%, MSE=0.24836
[2023-08-18-18:55:50] Finished Epoch 9/10: Loss=3.5844, Accuracy=49.583%, MSE=0.498938, Precision=0.640593, Recall=0.0010636, F1=0.00212367, AUPR=0.633826
[2023-08-18-18:55:50] Saving model to ./models/huang_both_1_tt_partitions_epoch09.sav
[2023-08-18-18:55:53] [10/10] training 2.4%: Loss=0.462134, Accuracy=64.000%, MSE=0.232765
[2023-08-18-18:55:54] [10/10] training 4.8%: Loss=0.467502, Accuracy=62.000%, MSE=0.238507
[2023-08-18-18:55:56] [10/10] training 7.2%: Loss=0.459047, Accuracy=64.667%, MSE=0.227644
[2023-08-18-18:55:57] [10/10] training 9.6%: Loss=0.460566, Accuracy=63.500%, MSE=0.231145
[2023-08-18-18:55:59] [10/10] training 12.0%: Loss=0.463576, Accuracy=63.000%, MSE=0.235945
[2023-08-18-18:56:01] [10/10] training 14.5%: Loss=0.469295, Accuracy=63.500%, MSE=0.238243
[2023-08-18-18:56:03] [10/10] training 16.9%: Loss=0.467883, Accuracy=62.857%, MSE=0.238258
[2023-08-18-18:56:05] [10/10] training 19.3%: Loss=0.47076, Accuracy=62.375%, MSE=0.240951
[2023-08-18-18:56:07] [10/10] training 21.7%: Loss=0.466172, Accuracy=62.778%, MSE=0.23667
[2023-08-18-18:56:09] [10/10] training 24.1%: Loss=0.466534, Accuracy=62.700%, MSE=0.237523
[2023-08-18-18:56:11] [10/10] training 26.5%: Loss=0.464766, Accuracy=63.091%, MSE=0.235259
[2023-08-18-18:56:12] [10/10] training 28.9%: Loss=0.461252, Accuracy=63.583%, MSE=0.231912
[2023-08-18-18:56:14] [10/10] training 31.3%: Loss=0.458958, Accuracy=64.154%, MSE=0.229056
[2023-08-18-18:56:16] [10/10] training 33.7%: Loss=0.456038, Accuracy=64.857%, MSE=0.226358
[2023-08-18-18:56:18] [10/10] training 36.1%: Loss=0.451872, Accuracy=65.267%, MSE=0.222637
[2023-08-18-18:56:20] [10/10] training 38.6%: Loss=0.448371, Accuracy=65.625%, MSE=0.219412
[2023-08-18-18:56:22] [10/10] training 41.0%: Loss=0.450678, Accuracy=65.294%, MSE=0.221873
[2023-08-18-18:56:24] [10/10] training 43.4%: Loss=0.451616, Accuracy=65.056%, MSE=0.222889
[2023-08-18-18:56:25] [10/10] training 45.8%: Loss=0.4537, Accuracy=64.474%, MSE=0.225478
[2023-08-18-18:56:27] [10/10] training 48.2%: Loss=0.454527, Accuracy=64.550%, MSE=0.22595
[2023-08-18-18:56:29] [10/10] training 50.6%: Loss=0.453264, Accuracy=64.762%, MSE=0.224706
[2023-08-18-18:56:30] [10/10] training 53.0%: Loss=0.452321, Accuracy=64.909%, MSE=0.224036
[2023-08-18-18:56:32] [10/10] training 55.4%: Loss=0.453201, Accuracy=64.783%, MSE=0.225015
[2023-08-18-18:56:34] [10/10] training 57.8%: Loss=0.452406, Accuracy=64.917%, MSE=0.224378
[2023-08-18-18:56:36] [10/10] training 60.2%: Loss=0.450533, Accuracy=65.000%, MSE=0.222944
[2023-08-18-18:56:38] [10/10] training 62.7%: Loss=0.450886, Accuracy=65.000%, MSE=0.223031
[2023-08-18-18:56:40] [10/10] training 65.1%: Loss=0.45114, Accuracy=65.111%, MSE=0.22314
[2023-08-18-18:56:41] [10/10] training 67.5%: Loss=0.45, Accuracy=65.321%, MSE=0.221938
[2023-08-18-18:56:43] [10/10] training 69.9%: Loss=0.449671, Accuracy=65.448%, MSE=0.22138
[2023-08-18-18:56:45] [10/10] training 72.3%: Loss=0.447911, Accuracy=65.800%, MSE=0.219559
[2023-08-18-18:56:47] [10/10] training 74.7%: Loss=0.448155, Accuracy=65.742%, MSE=0.219755
[2023-08-18-18:56:49] [10/10] training 77.1%: Loss=0.448625, Accuracy=65.688%, MSE=0.220284
[2023-08-18-18:56:51] [10/10] training 79.5%: Loss=0.448379, Accuracy=65.606%, MSE=0.220318
[2023-08-18-18:56:52] [10/10] training 81.9%: Loss=0.448529, Accuracy=65.588%, MSE=0.220581
[2023-08-18-18:56:54] [10/10] training 84.3%: Loss=0.448085, Accuracy=65.686%, MSE=0.220333
[2023-08-18-18:56:56] [10/10] training 86.7%: Loss=0.448763, Accuracy=65.694%, MSE=0.221124
[2023-08-18-18:56:57] [10/10] training 89.2%: Loss=0.448924, Accuracy=65.568%, MSE=0.221405
[2023-08-18-18:56:59] [10/10] training 91.6%: Loss=0.447819, Accuracy=65.632%, MSE=0.220472
[2023-08-18-18:57:01] [10/10] training 94.0%: Loss=0.448274, Accuracy=65.641%, MSE=0.220505
[2023-08-18-18:57:03] [10/10] training 96.4%: Loss=0.447913, Accuracy=65.575%, MSE=0.220321
[2023-08-18-18:57:05] [10/10] training 98.8%: Loss=0.446976, Accuracy=65.756%, MSE=0.219141
[2023-08-18-18:57:12] Finished Epoch 10/10: Loss=3.60443, Accuracy=49.583%, MSE=0.498986, Precision=0.707696, Recall=0.00101463, F1=0.00202636, AUPR=0.723287
[2023-08-18-18:57:12] Saving model to ./models/huang_both_1_tt_partitions_epoch10.sav
[2023-08-18-18:57:12] Saving final model to ./models/huang_both_1_tt_partitions_final.sav
