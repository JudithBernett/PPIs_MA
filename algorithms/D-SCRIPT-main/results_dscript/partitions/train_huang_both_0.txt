[2023-04-27-10:27:37] D-SCRIPT Version 0.2.2
[2023-04-27-10:27:37] Called as: /nfs/home/students/jbernett/.conda/envs/dscript2/bin/dscript train --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_0.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_0_dscript_partitions -o ./results_dscript/partitions/train_huang_both_0.txt -d 2
[2023-04-27-10:27:37] Using CUDA device 2 - NVIDIA A40
[2023-04-27-10:27:38] Loaded 4136 training pairs
[2023-04-27-10:27:38] Loaded 1496 test pairs
[2023-04-27-10:27:38] Loading embeddings...
[2023-04-27-10:28:32] Initializing embedding model with:
[2023-04-27-10:28:32] 	projection_dim: 100
[2023-04-27-10:28:32] 	dropout_p: 0.5
[2023-04-27-10:28:32] Initializing contact model with:
[2023-04-27-10:28:32] 	hidden_dim: 50
[2023-04-27-10:28:32] 	kernel_width: 7
[2023-04-27-10:28:32] Initializing interaction model with:
[2023-04-27-10:28:32] 	do_poool: False
[2023-04-27-10:28:32] 	pool_width: 9
[2023-04-27-10:28:32] 	do_w: True
[2023-04-27-10:28:32] 	do_sigmoid: True
[2023-04-27-10:28:32] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-04-27-10:28:33] Using save prefix "./models/huang_both_0_dscript_partitions"
[2023-04-27-10:28:33] Training with Adam: lr=0.001, weight_decay=0
[2023-04-27-10:28:33] 	num_epochs: 10
[2023-04-27-10:28:33] 	batch_size: 25
[2023-04-27-10:28:33] 	interaction weight: 0.35
[2023-04-27-10:28:33] 	contact map weight: 0.65
[2023-04-27-10:28:36] [1/10] training 2.4%: Loss=1.40037, Accuracy=53.000%, MSE=0.468633
[2023-04-27-10:28:39] [1/10] training 4.8%: Loss=1.39631, Accuracy=52.500%, MSE=0.473455
[2023-04-27-10:28:41] [1/10] training 7.2%: Loss=1.37352, Accuracy=52.667%, MSE=0.471578
[2023-04-27-10:28:43] [1/10] training 9.6%: Loss=1.3607, Accuracy=52.500%, MSE=0.472971
[2023-04-27-10:28:45] [1/10] training 12.0%: Loss=1.36142, Accuracy=51.800%, MSE=0.479705
[2023-04-27-10:28:47] [1/10] training 14.5%: Loss=1.33422, Accuracy=52.333%, MSE=0.474109
[2023-04-27-10:28:49] [1/10] training 16.9%: Loss=1.3322, Accuracy=52.000%, MSE=0.477265
[2023-04-27-10:28:51] [1/10] training 19.3%: Loss=1.37004, Accuracy=49.875%, MSE=0.498235
[2023-04-27-10:28:53] [1/10] training 21.7%: Loss=1.34323, Accuracy=50.778%, MSE=0.48908
[2023-04-27-10:28:56] [1/10] training 24.1%: Loss=1.34834, Accuracy=50.400%, MSE=0.492756
[2023-04-27-10:28:58] [1/10] training 26.5%: Loss=1.33445, Accuracy=50.636%, MSE=0.490155
[2023-04-27-10:28:59] [1/10] training 28.9%: Loss=1.33595, Accuracy=50.417%, MSE=0.492254
[2023-04-27-10:29:02] [1/10] training 31.3%: Loss=1.34225, Accuracy=49.615%, MSE=0.49995
[2023-04-27-10:29:04] [1/10] training 33.7%: Loss=1.34687, Accuracy=49.000%, MSE=0.505771
[2023-04-27-10:29:06] [1/10] training 36.1%: Loss=1.34856, Accuracy=48.933%, MSE=0.506451
[2023-04-27-10:29:08] [1/10] training 38.6%: Loss=1.32847, Accuracy=49.625%, MSE=0.499403
[2023-04-27-10:29:10] [1/10] training 41.0%: Loss=1.32484, Accuracy=49.529%, MSE=0.500196
[2023-04-27-10:29:12] [1/10] training 43.4%: Loss=1.32343, Accuracy=49.333%, MSE=0.501975
[2023-04-27-10:29:15] [1/10] training 45.8%: Loss=1.32041, Accuracy=49.368%, MSE=0.501587
[2023-04-27-10:29:17] [1/10] training 48.2%: Loss=1.30842, Accuracy=49.650%, MSE=0.498568
[2023-04-27-10:29:19] [1/10] training 50.6%: Loss=1.31581, Accuracy=49.000%, MSE=0.504852
[2023-04-27-10:29:21] [1/10] training 53.0%: Loss=1.31284, Accuracy=49.000%, MSE=0.504791
[2023-04-27-10:29:23] [1/10] training 55.4%: Loss=1.30607, Accuracy=49.087%, MSE=0.50374
[2023-04-27-10:29:25] [1/10] training 57.8%: Loss=1.29782, Accuracy=49.292%, MSE=0.501595
[2023-04-27-10:29:28] [1/10] training 60.2%: Loss=1.29775, Accuracy=49.080%, MSE=0.503539
[2023-04-27-10:29:30] [1/10] training 62.7%: Loss=1.29774, Accuracy=48.923%, MSE=0.505034
[2023-04-27-10:29:31] [1/10] training 65.1%: Loss=1.29008, Accuracy=49.074%, MSE=0.503376
[2023-04-27-10:29:34] [1/10] training 67.5%: Loss=1.28241, Accuracy=49.321%, MSE=0.500843
[2023-04-27-10:29:36] [1/10] training 69.9%: Loss=1.27356, Accuracy=49.655%, MSE=0.497465
[2023-04-27-10:29:38] [1/10] training 72.3%: Loss=1.27079, Accuracy=49.533%, MSE=0.498468
[2023-04-27-10:29:40] [1/10] training 74.7%: Loss=1.27043, Accuracy=49.419%, MSE=0.499536
[2023-04-27-10:29:42] [1/10] training 77.1%: Loss=1.26238, Accuracy=49.750%, MSE=0.49622
[2023-04-27-10:29:45] [1/10] training 79.5%: Loss=1.25807, Accuracy=49.788%, MSE=0.495719
[2023-04-27-10:29:47] [1/10] training 81.9%: Loss=1.25474, Accuracy=49.824%, MSE=0.495297
[2023-04-27-10:29:49] [1/10] training 84.3%: Loss=1.24972, Accuracy=49.943%, MSE=0.494036
[2023-04-27-10:29:51] [1/10] training 86.7%: Loss=1.248, Accuracy=49.861%, MSE=0.494743
[2023-04-27-10:29:53] [1/10] training 89.2%: Loss=1.2467, Accuracy=49.784%, MSE=0.495422
[2023-04-27-10:29:55] [1/10] training 91.6%: Loss=1.24274, Accuracy=49.789%, MSE=0.495195
[2023-04-27-10:29:57] [1/10] training 94.0%: Loss=1.23844, Accuracy=49.872%, MSE=0.494281
[2023-04-27-10:30:00] [1/10] training 96.4%: Loss=1.23388, Accuracy=50.025%, MSE=0.492723
[2023-04-27-10:30:02] [1/10] training 98.8%: Loss=1.22986, Accuracy=50.024%, MSE=0.492538
[2023-04-27-10:30:18] Finished Epoch 1/10: Loss=2.62308, Accuracy=49.867%, MSE=0.493233, Precision=0.481412, Recall=0.00684678, F1=0.0135015, AUPR=0.478492
[2023-04-27-10:30:18] Saving model to ./models/huang_both_0_dscript_partitions_epoch01.sav
[2023-04-27-10:30:21] [2/10] training 2.4%: Loss=1.18411, Accuracy=49.000%, MSE=0.50093
[2023-04-27-10:30:23] [2/10] training 4.8%: Loss=1.06935, Accuracy=54.500%, MSE=0.446167
[2023-04-27-10:30:24] [2/10] training 7.2%: Loss=1.06785, Accuracy=53.000%, MSE=0.45915
[2023-04-27-10:30:26] [2/10] training 9.6%: Loss=1.08323, Accuracy=52.000%, MSE=0.4688
[2023-04-27-10:30:28] [2/10] training 12.0%: Loss=1.09692, Accuracy=51.200%, MSE=0.476567
[2023-04-27-10:30:29] [2/10] training 14.5%: Loss=1.09262, Accuracy=51.000%, MSE=0.477941
[2023-04-27-10:30:31] [2/10] training 16.9%: Loss=1.09211, Accuracy=50.714%, MSE=0.48045
[2023-04-27-10:30:33] [2/10] training 19.3%: Loss=1.09862, Accuracy=50.250%, MSE=0.484889
[2023-04-27-10:30:35] [2/10] training 21.7%: Loss=1.10694, Accuracy=49.778%, MSE=0.489621
[2023-04-27-10:30:37] [2/10] training 24.1%: Loss=1.10488, Accuracy=49.600%, MSE=0.491015
[2023-04-27-10:30:39] [2/10] training 26.5%: Loss=1.10323, Accuracy=49.727%, MSE=0.489911
[2023-04-27-10:30:41] [2/10] training 28.9%: Loss=1.09798, Accuracy=49.917%, MSE=0.487948
[2023-04-27-10:30:43] [2/10] training 31.3%: Loss=1.09702, Accuracy=49.846%, MSE=0.48849
[2023-04-27-10:30:44] [2/10] training 33.7%: Loss=1.09202, Accuracy=50.071%, MSE=0.48619
[2023-04-27-10:30:46] [2/10] training 36.1%: Loss=1.09511, Accuracy=49.667%, MSE=0.489855
[2023-04-27-10:30:48] [2/10] training 38.6%: Loss=1.0937, Accuracy=49.562%, MSE=0.490522
[2023-04-27-10:30:49] [2/10] training 41.0%: Loss=1.09474, Accuracy=49.412%, MSE=0.491917
[2023-04-27-10:30:51] [2/10] training 43.4%: Loss=1.08695, Accuracy=49.722%, MSE=0.488713
[2023-04-27-10:30:53] [2/10] training 45.8%: Loss=1.08339, Accuracy=49.789%, MSE=0.487915
[2023-04-27-10:30:55] [2/10] training 48.2%: Loss=1.08147, Accuracy=49.700%, MSE=0.488425
[2023-04-27-10:30:57] [2/10] training 50.6%: Loss=1.07884, Accuracy=49.810%, MSE=0.487308
[2023-04-27-10:30:59] [2/10] training 53.0%: Loss=1.07784, Accuracy=49.727%, MSE=0.487947
[2023-04-27-10:31:01] [2/10] training 55.4%: Loss=1.0793, Accuracy=49.565%, MSE=0.489451
[2023-04-27-10:31:03] [2/10] training 57.8%: Loss=1.07855, Accuracy=49.417%, MSE=0.490575
[2023-04-27-10:31:05] [2/10] training 60.2%: Loss=1.0726, Accuracy=49.720%, MSE=0.487548
[2023-04-27-10:31:06] [2/10] training 62.7%: Loss=1.06927, Accuracy=49.808%, MSE=0.486524
[2023-04-27-10:31:08] [2/10] training 65.1%: Loss=1.06422, Accuracy=50.000%, MSE=0.484471
[2023-04-27-10:31:10] [2/10] training 67.5%: Loss=1.05882, Accuracy=50.286%, MSE=0.481631
[2023-04-27-10:31:11] [2/10] training 69.9%: Loss=1.05977, Accuracy=50.069%, MSE=0.483544
[2023-04-27-10:31:13] [2/10] training 72.3%: Loss=1.05763, Accuracy=50.133%, MSE=0.482873
[2023-04-27-10:31:15] [2/10] training 74.7%: Loss=1.05788, Accuracy=50.065%, MSE=0.48352
[2023-04-27-10:31:17] [2/10] training 77.1%: Loss=1.05737, Accuracy=49.906%, MSE=0.484771
[2023-04-27-10:31:18] [2/10] training 79.5%: Loss=1.05627, Accuracy=49.909%, MSE=0.484671
[2023-04-27-10:31:20] [2/10] training 81.9%: Loss=1.0558, Accuracy=49.882%, MSE=0.484909
[2023-04-27-10:31:22] [2/10] training 84.3%: Loss=1.05261, Accuracy=49.914%, MSE=0.484323
[2023-04-27-10:31:23] [2/10] training 86.7%: Loss=1.04838, Accuracy=50.028%, MSE=0.482946
[2023-04-27-10:31:25] [2/10] training 89.2%: Loss=1.0526, Accuracy=49.676%, MSE=0.48625
[2023-04-27-10:31:27] [2/10] training 91.6%: Loss=1.05235, Accuracy=49.658%, MSE=0.486398
[2023-04-27-10:31:28] [2/10] training 94.0%: Loss=1.04791, Accuracy=49.846%, MSE=0.484399
[2023-04-27-10:31:30] [2/10] training 96.4%: Loss=1.04684, Accuracy=49.800%, MSE=0.484626
[2023-04-27-10:31:32] [2/10] training 98.8%: Loss=1.04311, Accuracy=50.024%, MSE=0.482413
[2023-04-27-10:31:43] Finished Epoch 2/10: Loss=1.79488, Accuracy=49.867%, MSE=0.467207, Precision=0.503718, Recall=0.0346028, F1=0.0647571, AUPR=0.510019
[2023-04-27-10:31:43] Saving model to ./models/huang_both_0_dscript_partitions_epoch02.sav
[2023-04-27-10:31:45] [3/10] training 2.4%: Loss=0.995569, Accuracy=44.000%, MSE=0.524803
[2023-04-27-10:31:47] [3/10] training 4.8%: Loss=0.979704, Accuracy=47.500%, MSE=0.496365
[2023-04-27-10:31:49] [3/10] training 7.2%: Loss=1.00146, Accuracy=46.000%, MSE=0.511464
[2023-04-27-10:31:51] [3/10] training 9.6%: Loss=1.00581, Accuracy=46.500%, MSE=0.508134
[2023-04-27-10:31:52] [3/10] training 12.0%: Loss=0.991263, Accuracy=47.200%, MSE=0.50049
[2023-04-27-10:31:54] [3/10] training 14.5%: Loss=0.999435, Accuracy=46.833%, MSE=0.504241
[2023-04-27-10:31:56] [3/10] training 16.9%: Loss=0.982772, Accuracy=47.714%, MSE=0.494984
[2023-04-27-10:31:58] [3/10] training 19.3%: Loss=0.976324, Accuracy=48.125%, MSE=0.490902
[2023-04-27-10:32:00] [3/10] training 21.7%: Loss=0.978576, Accuracy=47.778%, MSE=0.493776
[2023-04-27-10:32:01] [3/10] training 24.1%: Loss=0.974162, Accuracy=48.000%, MSE=0.491616
[2023-04-27-10:32:03] [3/10] training 26.5%: Loss=0.957906, Accuracy=49.000%, MSE=0.481685
[2023-04-27-10:32:05] [3/10] training 28.9%: Loss=0.953705, Accuracy=49.250%, MSE=0.479115
[2023-04-27-10:32:06] [3/10] training 31.3%: Loss=0.954309, Accuracy=49.077%, MSE=0.480669
[2023-04-27-10:32:08] [3/10] training 33.7%: Loss=0.952167, Accuracy=49.286%, MSE=0.478694
[2023-04-27-10:32:10] [3/10] training 36.1%: Loss=0.963455, Accuracy=48.733%, MSE=0.484538
[2023-04-27-10:32:12] [3/10] training 38.6%: Loss=0.962592, Accuracy=48.875%, MSE=0.483338
[2023-04-27-10:32:14] [3/10] training 41.0%: Loss=0.960668, Accuracy=49.059%, MSE=0.481651
[2023-04-27-10:32:15] [3/10] training 43.4%: Loss=0.956143, Accuracy=49.389%, MSE=0.478501
[2023-04-27-10:32:17] [3/10] training 45.8%: Loss=0.961185, Accuracy=48.789%, MSE=0.483807
[2023-04-27-10:32:19] [3/10] training 48.2%: Loss=0.956873, Accuracy=49.050%, MSE=0.481181
[2023-04-27-10:32:21] [3/10] training 50.6%: Loss=0.956162, Accuracy=49.190%, MSE=0.480073
[2023-04-27-10:32:23] [3/10] training 53.0%: Loss=0.950295, Accuracy=49.409%, MSE=0.477502
[2023-04-27-10:32:24] [3/10] training 55.4%: Loss=0.950381, Accuracy=49.217%, MSE=0.478814
[2023-04-27-10:32:26] [3/10] training 57.8%: Loss=0.943422, Accuracy=49.542%, MSE=0.475262
[2023-04-27-10:32:27] [3/10] training 60.2%: Loss=0.942961, Accuracy=49.560%, MSE=0.47507
[2023-04-27-10:32:30] [3/10] training 62.7%: Loss=0.942545, Accuracy=49.500%, MSE=0.475513
[2023-04-27-10:32:31] [3/10] training 65.1%: Loss=0.941728, Accuracy=49.370%, MSE=0.476366
[2023-04-27-10:32:33] [3/10] training 67.5%: Loss=0.936319, Accuracy=49.714%, MSE=0.472881
[2023-04-27-10:32:35] [3/10] training 69.9%: Loss=0.933911, Accuracy=49.828%, MSE=0.47169
[2023-04-27-10:32:37] [3/10] training 72.3%: Loss=0.931906, Accuracy=50.000%, MSE=0.470117
[2023-04-27-10:32:38] [3/10] training 74.7%: Loss=0.931801, Accuracy=49.903%, MSE=0.470698
[2023-04-27-10:32:40] [3/10] training 77.1%: Loss=0.933479, Accuracy=49.687%, MSE=0.472584
[2023-04-27-10:32:42] [3/10] training 79.5%: Loss=0.93011, Accuracy=49.879%, MSE=0.470613
[2023-04-27-10:32:43] [3/10] training 81.9%: Loss=0.928626, Accuracy=49.853%, MSE=0.470545
[2023-04-27-10:32:45] [3/10] training 84.3%: Loss=0.92739, Accuracy=49.686%, MSE=0.471405
[2023-04-27-10:32:47] [3/10] training 86.7%: Loss=0.925678, Accuracy=49.667%, MSE=0.471186
[2023-04-27-10:32:49] [3/10] training 89.2%: Loss=0.922299, Accuracy=49.865%, MSE=0.469065
[2023-04-27-10:32:51] [3/10] training 91.6%: Loss=0.919669, Accuracy=50.079%, MSE=0.467092
[2023-04-27-10:32:52] [3/10] training 94.0%: Loss=0.917173, Accuracy=50.051%, MSE=0.466602
[2023-04-27-10:32:54] [3/10] training 96.4%: Loss=0.914487, Accuracy=50.025%, MSE=0.465985
[2023-04-27-10:32:56] [3/10] training 98.8%: Loss=0.914162, Accuracy=49.829%, MSE=0.467183
[2023-04-27-10:33:07] Finished Epoch 3/10: Loss=2.22361, Accuracy=49.867%, MSE=0.483262, Precision=0.418689, Recall=0.0175591, F1=0.0337047, AUPR=0.428025
[2023-04-27-10:33:07] Saving model to ./models/huang_both_0_dscript_partitions_epoch03.sav
[2023-04-27-10:33:09] [4/10] training 2.4%: Loss=0.812092, Accuracy=55.000%, MSE=0.413727
[2023-04-27-10:33:11] [4/10] training 4.8%: Loss=0.847476, Accuracy=50.000%, MSE=0.451867
[2023-04-27-10:33:13] [4/10] training 7.2%: Loss=0.800064, Accuracy=51.333%, MSE=0.431074
[2023-04-27-10:33:15] [4/10] training 9.6%: Loss=0.798848, Accuracy=50.750%, MSE=0.433406
[2023-04-27-10:33:16] [4/10] training 12.0%: Loss=0.800106, Accuracy=51.400%, MSE=0.431038
[2023-04-27-10:33:18] [4/10] training 14.5%: Loss=0.809593, Accuracy=51.167%, MSE=0.435478
[2023-04-27-10:33:20] [4/10] training 16.9%: Loss=0.820762, Accuracy=51.286%, MSE=0.43732
[2023-04-27-10:33:21] [4/10] training 19.3%: Loss=0.81539, Accuracy=51.000%, MSE=0.437733
[2023-04-27-10:33:23] [4/10] training 21.7%: Loss=0.810554, Accuracy=49.889%, MSE=0.440956
[2023-04-27-10:33:25] [4/10] training 24.1%: Loss=0.803273, Accuracy=49.700%, MSE=0.439753
[2023-04-27-10:33:27] [4/10] training 26.5%: Loss=0.797419, Accuracy=50.000%, MSE=0.436687
[2023-04-27-10:33:28] [4/10] training 28.9%: Loss=0.801883, Accuracy=49.583%, MSE=0.439562
[2023-04-27-10:33:30] [4/10] training 31.3%: Loss=0.810566, Accuracy=49.231%, MSE=0.443487
[2023-04-27-10:33:32] [4/10] training 33.7%: Loss=0.81194, Accuracy=49.571%, MSE=0.442263
[2023-04-27-10:33:33] [4/10] training 36.1%: Loss=0.806657, Accuracy=49.867%, MSE=0.438407
[2023-04-27-10:33:35] [4/10] training 38.6%: Loss=0.800392, Accuracy=49.562%, MSE=0.436953
[2023-04-27-10:33:37] [4/10] training 41.0%: Loss=0.79198, Accuracy=48.529%, MSE=0.435317
[2023-04-27-10:33:39] [4/10] training 43.4%: Loss=0.779225, Accuracy=47.889%, MSE=0.429675
[2023-04-27-10:33:41] [4/10] training 45.8%: Loss=0.765964, Accuracy=48.158%, MSE=0.422516
[2023-04-27-10:33:42] [4/10] training 48.2%: Loss=0.764063, Accuracy=48.900%, MSE=0.415824
[2023-04-27-10:33:44] [4/10] training 50.6%: Loss=0.772163, Accuracy=49.238%, MSE=0.416064
[2023-04-27-10:33:46] [4/10] training 53.0%: Loss=0.792121, Accuracy=49.091%, MSE=0.421302
[2023-04-27-10:33:48] [4/10] training 55.4%: Loss=0.798783, Accuracy=49.565%, MSE=0.420043
[2023-04-27-10:33:50] [4/10] training 57.8%: Loss=0.80657, Accuracy=49.750%, MSE=0.421195
[2023-04-27-10:33:51] [4/10] training 60.2%: Loss=0.817008, Accuracy=49.640%, MSE=0.424848
[2023-04-27-10:33:53] [4/10] training 62.7%: Loss=0.822702, Accuracy=49.731%, MSE=0.426265
[2023-04-27-10:33:55] [4/10] training 65.1%: Loss=0.826559, Accuracy=49.963%, MSE=0.426179
[2023-04-27-10:33:56] [4/10] training 67.5%: Loss=0.831716, Accuracy=49.857%, MSE=0.428823
[2023-04-27-10:33:58] [4/10] training 69.9%: Loss=0.83298, Accuracy=49.966%, MSE=0.429215
[2023-04-27-10:34:00] [4/10] training 72.3%: Loss=0.838152, Accuracy=49.867%, MSE=0.431625
[2023-04-27-10:34:02] [4/10] training 74.7%: Loss=0.841062, Accuracy=49.806%, MSE=0.433274
[2023-04-27-10:34:03] [4/10] training 77.1%: Loss=0.843614, Accuracy=49.750%, MSE=0.434846
[2023-04-27-10:34:05] [4/10] training 79.5%: Loss=0.843748, Accuracy=49.909%, MSE=0.434435
[2023-04-27-10:34:07] [4/10] training 81.9%: Loss=0.845976, Accuracy=49.912%, MSE=0.43544
[2023-04-27-10:34:09] [4/10] training 84.3%: Loss=0.847679, Accuracy=49.829%, MSE=0.436975
[2023-04-27-10:34:11] [4/10] training 86.7%: Loss=0.847463, Accuracy=49.944%, MSE=0.436669
[2023-04-27-10:34:13] [4/10] training 89.2%: Loss=0.851854, Accuracy=49.595%, MSE=0.440303
[2023-04-27-10:34:14] [4/10] training 91.6%: Loss=0.853891, Accuracy=49.500%, MSE=0.44187
[2023-04-27-10:34:16] [4/10] training 94.0%: Loss=0.851635, Accuracy=49.641%, MSE=0.440945
[2023-04-27-10:34:18] [4/10] training 96.4%: Loss=0.854587, Accuracy=49.425%, MSE=0.443391
[2023-04-27-10:34:20] [4/10] training 98.8%: Loss=0.85431, Accuracy=49.561%, MSE=0.442692
[2023-04-27-10:34:31] Finished Epoch 4/10: Loss=1.38969, Accuracy=49.867%, MSE=0.4203, Precision=0.507486, Recall=0.0951882, F1=0.160308, AUPR=0.51005
[2023-04-27-10:34:31] Saving model to ./models/huang_both_0_dscript_partitions_epoch04.sav
[2023-04-27-10:34:33] [5/10] training 2.4%: Loss=0.848812, Accuracy=46.000%, MSE=0.481742
[2023-04-27-10:34:35] [5/10] training 4.8%: Loss=0.841363, Accuracy=47.500%, MSE=0.466996
[2023-04-27-10:34:36] [5/10] training 7.2%: Loss=0.864721, Accuracy=46.333%, MSE=0.479243
[2023-04-27-10:34:38] [5/10] training 9.6%: Loss=0.842118, Accuracy=48.250%, MSE=0.462553
[2023-04-27-10:34:40] [5/10] training 12.0%: Loss=0.833636, Accuracy=48.600%, MSE=0.458229
[2023-04-27-10:34:42] [5/10] training 14.5%: Loss=0.823002, Accuracy=49.167%, MSE=0.451511
[2023-04-27-10:34:44] [5/10] training 16.9%: Loss=0.822013, Accuracy=48.857%, MSE=0.452843
[2023-04-27-10:34:46] [5/10] training 19.3%: Loss=0.809528, Accuracy=49.750%, MSE=0.443645
[2023-04-27-10:34:47] [5/10] training 21.7%: Loss=0.810766, Accuracy=49.889%, MSE=0.443012
[2023-04-27-10:34:49] [5/10] training 24.1%: Loss=0.801753, Accuracy=50.500%, MSE=0.437007
[2023-04-27-10:34:51] [5/10] training 26.5%: Loss=0.798389, Accuracy=50.636%, MSE=0.435523
[2023-04-27-10:34:53] [5/10] training 28.9%: Loss=0.80359, Accuracy=50.000%, MSE=0.441168
[2023-04-27-10:34:55] [5/10] training 31.3%: Loss=0.805513, Accuracy=50.077%, MSE=0.441408
[2023-04-27-10:34:57] [5/10] training 33.7%: Loss=0.799807, Accuracy=50.357%, MSE=0.437672
[2023-04-27-10:34:59] [5/10] training 36.1%: Loss=0.7949, Accuracy=50.800%, MSE=0.433953
[2023-04-27-10:35:00] [5/10] training 38.6%: Loss=0.795179, Accuracy=50.438%, MSE=0.43597
[2023-04-27-10:35:02] [5/10] training 41.0%: Loss=0.785931, Accuracy=51.059%, MSE=0.429413
[2023-04-27-10:35:04] [5/10] training 43.4%: Loss=0.784833, Accuracy=50.833%, MSE=0.430138
[2023-04-27-10:35:05] [5/10] training 45.8%: Loss=0.783671, Accuracy=50.947%, MSE=0.428932
[2023-04-27-10:35:08] [5/10] training 48.2%: Loss=0.784106, Accuracy=50.900%, MSE=0.429547
[2023-04-27-10:35:09] [5/10] training 50.6%: Loss=0.784621, Accuracy=50.762%, MSE=0.430469
[2023-04-27-10:35:11] [5/10] training 53.0%: Loss=0.782152, Accuracy=50.773%, MSE=0.429597
[2023-04-27-10:35:13] [5/10] training 55.4%: Loss=0.786662, Accuracy=50.043%, MSE=0.434624
[2023-04-27-10:35:15] [5/10] training 57.8%: Loss=0.786938, Accuracy=49.833%, MSE=0.4357
[2023-04-27-10:35:17] [5/10] training 60.2%: Loss=0.78673, Accuracy=49.760%, MSE=0.436198
[2023-04-27-10:35:19] [5/10] training 62.7%: Loss=0.787317, Accuracy=49.500%, MSE=0.437825
[2023-04-27-10:35:20] [5/10] training 65.1%: Loss=0.784459, Accuracy=49.556%, MSE=0.436628
[2023-04-27-10:35:22] [5/10] training 67.5%: Loss=0.780287, Accuracy=49.750%, MSE=0.43409
[2023-04-27-10:35:24] [5/10] training 69.9%: Loss=0.777687, Accuracy=49.724%, MSE=0.433105
[2023-04-27-10:35:26] [5/10] training 72.3%: Loss=0.778184, Accuracy=49.633%, MSE=0.43363
[2023-04-27-10:35:27] [5/10] training 74.7%: Loss=0.777454, Accuracy=49.677%, MSE=0.43326
[2023-04-27-10:35:29] [5/10] training 77.1%: Loss=0.777703, Accuracy=49.531%, MSE=0.434128
[2023-04-27-10:35:30] [5/10] training 79.5%: Loss=0.777148, Accuracy=49.515%, MSE=0.434092
[2023-04-27-10:35:32] [5/10] training 81.9%: Loss=0.773935, Accuracy=49.706%, MSE=0.432017
[2023-04-27-10:35:34] [5/10] training 84.3%: Loss=0.774821, Accuracy=49.514%, MSE=0.433497
[2023-04-27-10:35:35] [5/10] training 86.7%: Loss=0.775037, Accuracy=49.500%, MSE=0.4337
[2023-04-27-10:35:37] [5/10] training 89.2%: Loss=0.774635, Accuracy=49.378%, MSE=0.434112
[2023-04-27-10:35:39] [5/10] training 91.6%: Loss=0.773492, Accuracy=49.447%, MSE=0.433359
[2023-04-27-10:35:40] [5/10] training 94.0%: Loss=0.771879, Accuracy=49.513%, MSE=0.432396
[2023-04-27-10:35:42] [5/10] training 96.4%: Loss=0.769519, Accuracy=49.525%, MSE=0.431328
[2023-04-27-10:35:44] [5/10] training 98.8%: Loss=0.766765, Accuracy=49.707%, MSE=0.42948
[2023-04-27-10:35:56] Finished Epoch 5/10: Loss=1.92693, Accuracy=49.867%, MSE=0.47394, Precision=0.451079, Recall=0.0276003, F1=0.0520178, AUPR=0.445756
[2023-04-27-10:35:56] Saving model to ./models/huang_both_0_dscript_partitions_epoch05.sav
[2023-04-27-10:35:57] [6/10] training 2.4%: Loss=0.706029, Accuracy=52.000%, MSE=0.396767
[2023-04-27-10:35:59] [6/10] training 4.8%: Loss=0.710866, Accuracy=52.000%, MSE=0.40149
[2023-04-27-10:36:01] [6/10] training 7.2%: Loss=0.691767, Accuracy=52.333%, MSE=0.394061
[2023-04-27-10:36:03] [6/10] training 9.6%: Loss=0.699652, Accuracy=51.000%, MSE=0.401379
[2023-04-27-10:36:05] [6/10] training 12.0%: Loss=0.713384, Accuracy=49.200%, MSE=0.413634
[2023-04-27-10:36:07] [6/10] training 14.5%: Loss=0.729147, Accuracy=48.000%, MSE=0.424122
[2023-04-27-10:36:09] [6/10] training 16.9%: Loss=0.721966, Accuracy=49.143%, MSE=0.416367
[2023-04-27-10:36:10] [6/10] training 19.3%: Loss=0.721633, Accuracy=48.625%, MSE=0.41796
[2023-04-27-10:36:12] [6/10] training 21.7%: Loss=0.725133, Accuracy=47.778%, MSE=0.423239
[2023-04-27-10:36:14] [6/10] training 24.1%: Loss=0.725777, Accuracy=47.800%, MSE=0.422193
[2023-04-27-10:36:16] [6/10] training 26.5%: Loss=0.724549, Accuracy=47.909%, MSE=0.420408
[2023-04-27-10:36:17] [6/10] training 28.9%: Loss=0.723039, Accuracy=48.000%, MSE=0.419466
[2023-04-27-10:36:19] [6/10] training 31.3%: Loss=0.727864, Accuracy=47.538%, MSE=0.423832
[2023-04-27-10:36:21] [6/10] training 33.7%: Loss=0.725153, Accuracy=47.857%, MSE=0.421257
[2023-04-27-10:36:22] [6/10] training 36.1%: Loss=0.723249, Accuracy=47.800%, MSE=0.420739
[2023-04-27-10:36:24] [6/10] training 38.6%: Loss=0.718603, Accuracy=48.062%, MSE=0.417451
[2023-04-27-10:36:26] [6/10] training 41.0%: Loss=0.714773, Accuracy=48.118%, MSE=0.415299
[2023-04-27-10:36:28] [6/10] training 43.4%: Loss=0.716492, Accuracy=47.778%, MSE=0.417712
[2023-04-27-10:36:29] [6/10] training 45.8%: Loss=0.717384, Accuracy=47.421%, MSE=0.419379
[2023-04-27-10:36:31] [6/10] training 48.2%: Loss=0.720433, Accuracy=47.300%, MSE=0.421442
[2023-04-27-10:36:33] [6/10] training 50.6%: Loss=0.717929, Accuracy=47.524%, MSE=0.419332
[2023-04-27-10:36:35] [6/10] training 53.0%: Loss=0.714307, Accuracy=47.818%, MSE=0.416629
[2023-04-27-10:36:37] [6/10] training 55.4%: Loss=0.708906, Accuracy=48.217%, MSE=0.412238
[2023-04-27-10:36:39] [6/10] training 57.8%: Loss=0.706201, Accuracy=48.167%, MSE=0.410871
[2023-04-27-10:36:40] [6/10] training 60.2%: Loss=0.703909, Accuracy=48.240%, MSE=0.409455
[2023-04-27-10:36:42] [6/10] training 62.7%: Loss=0.703123, Accuracy=48.231%, MSE=0.408917
[2023-04-27-10:36:44] [6/10] training 65.1%: Loss=0.700011, Accuracy=48.667%, MSE=0.405908
[2023-04-27-10:36:46] [6/10] training 67.5%: Loss=0.696904, Accuracy=48.893%, MSE=0.403405
[2023-04-27-10:36:47] [6/10] training 69.9%: Loss=0.693989, Accuracy=49.138%, MSE=0.401275
[2023-04-27-10:36:49] [6/10] training 72.3%: Loss=0.69081, Accuracy=49.267%, MSE=0.398951
[2023-04-27-10:36:51] [6/10] training 74.7%: Loss=0.688207, Accuracy=49.290%, MSE=0.397515
[2023-04-27-10:36:53] [6/10] training 77.1%: Loss=0.687495, Accuracy=49.250%, MSE=0.397407
[2023-04-27-10:36:54] [6/10] training 79.5%: Loss=0.685582, Accuracy=49.303%, MSE=0.396173
[2023-04-27-10:36:56] [6/10] training 81.9%: Loss=0.685961, Accuracy=49.265%, MSE=0.396229
[2023-04-27-10:36:58] [6/10] training 84.3%: Loss=0.687251, Accuracy=49.143%, MSE=0.397379
[2023-04-27-10:36:59] [6/10] training 86.7%: Loss=0.687889, Accuracy=49.028%, MSE=0.398158
[2023-04-27-10:37:01] [6/10] training 89.2%: Loss=0.687293, Accuracy=49.108%, MSE=0.397499
[2023-04-27-10:37:03] [6/10] training 91.6%: Loss=0.686168, Accuracy=49.079%, MSE=0.397046
[2023-04-27-10:37:05] [6/10] training 94.0%: Loss=0.686313, Accuracy=48.744%, MSE=0.398088
[2023-04-27-10:37:06] [6/10] training 96.4%: Loss=0.68635, Accuracy=48.600%, MSE=0.3985
[2023-04-27-10:37:08] [6/10] training 98.8%: Loss=0.687778, Accuracy=48.415%, MSE=0.399935
[2023-04-27-10:37:20] Finished Epoch 6/10: Loss=1.39997, Accuracy=49.267%, MSE=0.426925, Precision=0.429691, Recall=0.093552, F1=0.153651, AUPR=0.432488
[2023-04-27-10:37:20] Saving model to ./models/huang_both_0_dscript_partitions_epoch06.sav
[2023-04-27-10:37:22] [7/10] training 2.4%: Loss=0.632785, Accuracy=51.000%, MSE=0.365194
[2023-04-27-10:37:23] [7/10] training 4.8%: Loss=0.65519, Accuracy=47.000%, MSE=0.389624
[2023-04-27-10:37:25] [7/10] training 7.2%: Loss=0.640216, Accuracy=49.000%, MSE=0.372028
[2023-04-27-10:37:27] [7/10] training 9.6%: Loss=0.660351, Accuracy=46.500%, MSE=0.392806
[2023-04-27-10:37:29] [7/10] training 12.0%: Loss=0.660771, Accuracy=46.800%, MSE=0.392666
[2023-04-27-10:37:30] [7/10] training 14.5%: Loss=0.655725, Accuracy=48.000%, MSE=0.385525
[2023-04-27-10:37:32] [7/10] training 16.9%: Loss=0.659454, Accuracy=47.571%, MSE=0.389082
[2023-04-27-10:37:34] [7/10] training 19.3%: Loss=0.65784, Accuracy=47.125%, MSE=0.388974
[2023-04-27-10:37:35] [7/10] training 21.7%: Loss=0.664538, Accuracy=46.000%, MSE=0.396055
[2023-04-27-10:37:37] [7/10] training 24.1%: Loss=0.661691, Accuracy=45.900%, MSE=0.394213
[2023-04-27-10:37:39] [7/10] training 26.5%: Loss=0.660945, Accuracy=45.273%, MSE=0.395142
[2023-04-27-10:37:40] [7/10] training 28.9%: Loss=0.657521, Accuracy=45.417%, MSE=0.392369
[2023-04-27-10:37:42] [7/10] training 31.3%: Loss=0.659065, Accuracy=45.077%, MSE=0.394251
[2023-04-27-10:37:44] [7/10] training 33.7%: Loss=0.661967, Accuracy=45.143%, MSE=0.395485
[2023-04-27-10:37:46] [7/10] training 36.1%: Loss=0.661261, Accuracy=45.267%, MSE=0.394856
[2023-04-27-10:37:47] [7/10] training 38.6%: Loss=0.655264, Accuracy=45.938%, MSE=0.388694
[2023-04-27-10:37:49] [7/10] training 41.0%: Loss=0.653267, Accuracy=46.118%, MSE=0.386382
[2023-04-27-10:37:51] [7/10] training 43.4%: Loss=0.652113, Accuracy=46.111%, MSE=0.385722
[2023-04-27-10:37:53] [7/10] training 45.8%: Loss=0.649695, Accuracy=46.368%, MSE=0.383666
[2023-04-27-10:37:55] [7/10] training 48.2%: Loss=0.64969, Accuracy=46.200%, MSE=0.383951
[2023-04-27-10:37:57] [7/10] training 50.6%: Loss=0.64759, Accuracy=46.810%, MSE=0.381334
[2023-04-27-10:37:59] [7/10] training 53.0%: Loss=0.64956, Accuracy=46.455%, MSE=0.383325
[2023-04-27-10:38:01] [7/10] training 55.4%: Loss=0.649743, Accuracy=46.087%, MSE=0.384302
[2023-04-27-10:38:03] [7/10] training 57.8%: Loss=0.648113, Accuracy=46.458%, MSE=0.38207
[2023-04-27-10:38:04] [7/10] training 60.2%: Loss=0.64956, Accuracy=46.240%, MSE=0.383181
[2023-04-27-10:38:06] [7/10] training 62.7%: Loss=0.647475, Accuracy=46.423%, MSE=0.381647
[2023-04-27-10:38:08] [7/10] training 65.1%: Loss=0.644635, Accuracy=46.481%, MSE=0.379672
[2023-04-27-10:38:10] [7/10] training 67.5%: Loss=0.64392, Accuracy=46.393%, MSE=0.379596
[2023-04-27-10:38:12] [7/10] training 69.9%: Loss=0.643399, Accuracy=46.241%, MSE=0.379593
[2023-04-27-10:38:13] [7/10] training 72.3%: Loss=0.642166, Accuracy=46.233%, MSE=0.378455
[2023-04-27-10:38:15] [7/10] training 74.7%: Loss=0.640056, Accuracy=46.419%, MSE=0.376659
[2023-04-27-10:38:17] [7/10] training 77.1%: Loss=0.63864, Accuracy=46.437%, MSE=0.375923
[2023-04-27-10:38:19] [7/10] training 79.5%: Loss=0.636547, Accuracy=46.515%, MSE=0.37431
[2023-04-27-10:38:20] [7/10] training 81.9%: Loss=0.635412, Accuracy=46.676%, MSE=0.37311
[2023-04-27-10:38:22] [7/10] training 84.3%: Loss=0.635698, Accuracy=46.800%, MSE=0.372862
[2023-04-27-10:38:24] [7/10] training 86.7%: Loss=0.636873, Accuracy=46.694%, MSE=0.373761
[2023-04-27-10:38:25] [7/10] training 89.2%: Loss=0.634732, Accuracy=46.946%, MSE=0.371932
[2023-04-27-10:38:27] [7/10] training 91.6%: Loss=0.634736, Accuracy=46.868%, MSE=0.372216
[2023-04-27-10:38:28] [7/10] training 94.0%: Loss=0.634105, Accuracy=46.872%, MSE=0.371837
[2023-04-27-10:38:30] [7/10] training 96.4%: Loss=0.633503, Accuracy=46.950%, MSE=0.371283
[2023-04-27-10:38:32] [7/10] training 98.8%: Loss=0.634179, Accuracy=46.780%, MSE=0.372098
[2023-04-27-10:38:44] Finished Epoch 7/10: Loss=2.35049, Accuracy=49.867%, MSE=0.488937, Precision=0.455258, Recall=0.011305, F1=0.0220621, AUPR=0.444684
[2023-04-27-10:38:44] Saving model to ./models/huang_both_0_dscript_partitions_epoch07.sav
[2023-04-27-10:38:46] [8/10] training 2.4%: Loss=0.567494, Accuracy=52.000%, MSE=0.316375
[2023-04-27-10:38:47] [8/10] training 4.8%: Loss=0.592098, Accuracy=49.500%, MSE=0.340089
[2023-04-27-10:38:49] [8/10] training 7.2%: Loss=0.599718, Accuracy=48.000%, MSE=0.343696
[2023-04-27-10:38:51] [8/10] training 9.6%: Loss=0.597256, Accuracy=49.250%, MSE=0.340158
[2023-04-27-10:38:52] [8/10] training 12.0%: Loss=0.605218, Accuracy=47.800%, MSE=0.349345
[2023-04-27-10:38:54] [8/10] training 14.5%: Loss=0.598262, Accuracy=49.167%, MSE=0.341612
[2023-04-27-10:38:55] [8/10] training 16.9%: Loss=0.606047, Accuracy=48.429%, MSE=0.348508
[2023-04-27-10:38:57] [8/10] training 19.3%: Loss=0.602659, Accuracy=48.375%, MSE=0.345733
[2023-04-27-10:38:59] [8/10] training 21.7%: Loss=0.602258, Accuracy=47.667%, MSE=0.347246
[2023-04-27-10:39:01] [8/10] training 24.1%: Loss=0.606989, Accuracy=47.400%, MSE=0.352048
[2023-04-27-10:39:02] [8/10] training 26.5%: Loss=0.61279, Accuracy=47.182%, MSE=0.355926
[2023-04-27-10:39:04] [8/10] training 28.9%: Loss=0.613199, Accuracy=47.250%, MSE=0.356086
[2023-04-27-10:39:06] [8/10] training 31.3%: Loss=0.614912, Accuracy=46.462%, MSE=0.35887
[2023-04-27-10:39:08] [8/10] training 33.7%: Loss=0.611496, Accuracy=46.500%, MSE=0.356211
[2023-04-27-10:39:10] [8/10] training 36.1%: Loss=0.607664, Accuracy=46.333%, MSE=0.35309
[2023-04-27-10:39:11] [8/10] training 38.6%: Loss=0.601108, Accuracy=46.750%, MSE=0.347128
[2023-04-27-10:39:13] [8/10] training 41.0%: Loss=0.5962, Accuracy=47.412%, MSE=0.342262
[2023-04-27-10:39:15] [8/10] training 43.4%: Loss=0.59428, Accuracy=47.556%, MSE=0.341051
[2023-04-27-10:39:17] [8/10] training 45.8%: Loss=0.59177, Accuracy=47.895%, MSE=0.338178
[2023-04-27-10:39:18] [8/10] training 48.2%: Loss=0.588896, Accuracy=47.950%, MSE=0.335699
[2023-04-27-10:39:20] [8/10] training 50.6%: Loss=0.584886, Accuracy=48.476%, MSE=0.331795
[2023-04-27-10:39:22] [8/10] training 53.0%: Loss=0.583294, Accuracy=48.727%, MSE=0.330056
[2023-04-27-10:39:24] [8/10] training 55.4%: Loss=0.580882, Accuracy=48.913%, MSE=0.328089
[2023-04-27-10:39:26] [8/10] training 57.8%: Loss=0.577898, Accuracy=49.000%, MSE=0.32589
[2023-04-27-10:39:28] [8/10] training 60.2%: Loss=0.575542, Accuracy=49.320%, MSE=0.323825
[2023-04-27-10:39:29] [8/10] training 62.7%: Loss=0.573242, Accuracy=49.731%, MSE=0.32059
[2023-04-27-10:39:31] [8/10] training 65.1%: Loss=0.571766, Accuracy=49.741%, MSE=0.319389
[2023-04-27-10:39:33] [8/10] training 67.5%: Loss=0.572296, Accuracy=49.679%, MSE=0.319521
[2023-04-27-10:39:34] [8/10] training 69.9%: Loss=0.570588, Accuracy=50.000%, MSE=0.317683
[2023-04-27-10:39:36] [8/10] training 72.3%: Loss=0.571365, Accuracy=49.967%, MSE=0.3185
[2023-04-27-10:39:38] [8/10] training 74.7%: Loss=0.570313, Accuracy=50.032%, MSE=0.31759
[2023-04-27-10:39:40] [8/10] training 77.1%: Loss=0.568228, Accuracy=50.125%, MSE=0.315985
[2023-04-27-10:39:41] [8/10] training 79.5%: Loss=0.566137, Accuracy=50.606%, MSE=0.313629
[2023-04-27-10:39:43] [8/10] training 81.9%: Loss=0.562707, Accuracy=51.059%, MSE=0.310458
[2023-04-27-10:39:45] [8/10] training 84.3%: Loss=0.561124, Accuracy=51.314%, MSE=0.308947
[2023-04-27-10:39:47] [8/10] training 86.7%: Loss=0.55971, Accuracy=51.611%, MSE=0.306836
[2023-04-27-10:39:49] [8/10] training 89.2%: Loss=0.558334, Accuracy=51.757%, MSE=0.305811
[2023-04-27-10:39:51] [8/10] training 91.6%: Loss=0.557225, Accuracy=51.763%, MSE=0.30521
[2023-04-27-10:39:52] [8/10] training 94.0%: Loss=0.555364, Accuracy=51.974%, MSE=0.303482
[2023-04-27-10:39:54] [8/10] training 96.4%: Loss=0.555507, Accuracy=51.925%, MSE=0.303792
[2023-04-27-10:39:56] [8/10] training 98.8%: Loss=0.555482, Accuracy=51.902%, MSE=0.303712
[2023-04-27-10:40:08] Finished Epoch 8/10: Loss=2.07434, Accuracy=49.867%, MSE=0.480528, Precision=0.413724, Recall=0.0205846, F1=0.0392178, AUPR=0.416498
[2023-04-27-10:40:08] Saving model to ./models/huang_both_0_dscript_partitions_epoch08.sav
[2023-04-27-10:40:10] [9/10] training 2.4%: Loss=0.583902, Accuracy=44.000%, MSE=0.336616
[2023-04-27-10:40:12] [9/10] training 4.8%: Loss=0.517876, Accuracy=55.500%, MSE=0.264576
[2023-04-27-10:40:13] [9/10] training 7.2%: Loss=0.50319, Accuracy=58.000%, MSE=0.253374
[2023-04-27-10:40:15] [9/10] training 9.6%: Loss=0.501886, Accuracy=58.750%, MSE=0.253733
[2023-04-27-10:40:17] [9/10] training 12.0%: Loss=0.495604, Accuracy=60.000%, MSE=0.245029
[2023-04-27-10:40:19] [9/10] training 14.5%: Loss=0.489145, Accuracy=61.000%, MSE=0.240071
[2023-04-27-10:40:20] [9/10] training 16.9%: Loss=0.48524, Accuracy=62.000%, MSE=0.234851
[2023-04-27-10:40:22] [9/10] training 19.3%: Loss=0.482958, Accuracy=62.125%, MSE=0.233704
[2023-04-27-10:40:24] [9/10] training 21.7%: Loss=0.484349, Accuracy=61.444%, MSE=0.23694
[2023-04-27-10:40:25] [9/10] training 24.1%: Loss=0.485037, Accuracy=61.200%, MSE=0.239174
[2023-04-27-10:40:27] [9/10] training 26.5%: Loss=0.487082, Accuracy=61.091%, MSE=0.239208
[2023-04-27-10:40:29] [9/10] training 28.9%: Loss=0.482781, Accuracy=61.917%, MSE=0.235014
[2023-04-27-10:40:31] [9/10] training 31.3%: Loss=0.481229, Accuracy=61.923%, MSE=0.234768
[2023-04-27-10:40:32] [9/10] training 33.7%: Loss=0.484187, Accuracy=61.571%, MSE=0.237463
[2023-04-27-10:40:34] [9/10] training 36.1%: Loss=0.483713, Accuracy=61.600%, MSE=0.237069
[2023-04-27-10:40:36] [9/10] training 38.6%: Loss=0.478813, Accuracy=62.562%, MSE=0.232461
[2023-04-27-10:40:37] [9/10] training 41.0%: Loss=0.478256, Accuracy=62.882%, MSE=0.231763
[2023-04-27-10:40:39] [9/10] training 43.4%: Loss=0.476413, Accuracy=63.056%, MSE=0.230091
[2023-04-27-10:40:41] [9/10] training 45.8%: Loss=0.473778, Accuracy=63.684%, MSE=0.226835
[2023-04-27-10:40:43] [9/10] training 48.2%: Loss=0.470466, Accuracy=64.400%, MSE=0.222771
[2023-04-27-10:40:44] [9/10] training 50.6%: Loss=0.469795, Accuracy=64.429%, MSE=0.22296
[2023-04-27-10:40:46] [9/10] training 53.0%: Loss=0.468552, Accuracy=64.955%, MSE=0.221311
[2023-04-27-10:40:48] [9/10] training 55.4%: Loss=0.46976, Accuracy=65.130%, MSE=0.220644
[2023-04-27-10:40:50] [9/10] training 57.8%: Loss=0.46799, Accuracy=65.333%, MSE=0.219372
[2023-04-27-10:40:51] [9/10] training 60.2%: Loss=0.468015, Accuracy=65.360%, MSE=0.219629
[2023-04-27-10:40:53] [9/10] training 62.7%: Loss=0.465898, Accuracy=65.846%, MSE=0.217261
[2023-04-27-10:40:55] [9/10] training 65.1%: Loss=0.463393, Accuracy=66.296%, MSE=0.214561
[2023-04-27-10:40:57] [9/10] training 67.5%: Loss=0.461989, Accuracy=66.607%, MSE=0.21342
[2023-04-27-10:40:59] [9/10] training 69.9%: Loss=0.461401, Accuracy=66.759%, MSE=0.212847
[2023-04-27-10:41:01] [9/10] training 72.3%: Loss=0.461001, Accuracy=66.867%, MSE=0.212488
[2023-04-27-10:41:02] [9/10] training 74.7%: Loss=0.459489, Accuracy=67.226%, MSE=0.211012
[2023-04-27-10:41:04] [9/10] training 77.1%: Loss=0.46054, Accuracy=67.312%, MSE=0.210942
[2023-04-27-10:41:06] [9/10] training 79.5%: Loss=0.462954, Accuracy=67.212%, MSE=0.212063
[2023-04-27-10:41:08] [9/10] training 81.9%: Loss=0.463537, Accuracy=67.353%, MSE=0.21172
[2023-04-27-10:41:09] [9/10] training 84.3%: Loss=0.464534, Accuracy=67.257%, MSE=0.212345
[2023-04-27-10:41:12] [9/10] training 86.7%: Loss=0.466473, Accuracy=67.111%, MSE=0.214014
[2023-04-27-10:41:13] [9/10] training 89.2%: Loss=0.466568, Accuracy=67.297%, MSE=0.213158
[2023-04-27-10:41:15] [9/10] training 91.6%: Loss=0.467425, Accuracy=67.316%, MSE=0.213644
[2023-04-27-10:41:17] [9/10] training 94.0%: Loss=0.46784, Accuracy=67.359%, MSE=0.214072
[2023-04-27-10:41:18] [9/10] training 96.4%: Loss=0.466259, Accuracy=67.625%, MSE=0.212611
[2023-04-27-10:41:20] [9/10] training 98.8%: Loss=0.466194, Accuracy=67.854%, MSE=0.211634
[2023-04-27-10:41:32] Finished Epoch 9/10: Loss=2.30976, Accuracy=49.867%, MSE=0.486219, Precision=0.491002, Recall=0.0142252, F1=0.0276493, AUPR=0.494572
[2023-04-27-10:41:32] Saving model to ./models/huang_both_0_dscript_partitions_epoch09.sav
[2023-04-27-10:41:34] [10/10] training 2.4%: Loss=0.367137, Accuracy=80.000%, MSE=0.129808
[2023-04-27-10:41:36] [10/10] training 4.8%: Loss=0.402447, Accuracy=76.500%, MSE=0.161908
[2023-04-27-10:41:38] [10/10] training 7.2%: Loss=0.405373, Accuracy=75.667%, MSE=0.163594
[2023-04-27-10:41:40] [10/10] training 9.6%: Loss=0.430184, Accuracy=74.500%, MSE=0.174412
[2023-04-27-10:41:41] [10/10] training 12.0%: Loss=0.432233, Accuracy=73.600%, MSE=0.178949
[2023-04-27-10:41:43] [10/10] training 14.5%: Loss=0.430519, Accuracy=74.500%, MSE=0.175013
[2023-04-27-10:41:45] [10/10] training 16.9%: Loss=0.423384, Accuracy=74.714%, MSE=0.171355
[2023-04-27-10:41:47] [10/10] training 19.3%: Loss=0.427927, Accuracy=74.250%, MSE=0.176062
[2023-04-27-10:41:49] [10/10] training 21.7%: Loss=0.434509, Accuracy=73.444%, MSE=0.182668
[2023-04-27-10:41:50] [10/10] training 24.1%: Loss=0.43561, Accuracy=73.500%, MSE=0.184308
[2023-04-27-10:41:52] [10/10] training 26.5%: Loss=0.437179, Accuracy=72.636%, MSE=0.187616
[2023-04-27-10:41:54] [10/10] training 28.9%: Loss=0.4407, Accuracy=72.583%, MSE=0.189181
[2023-04-27-10:41:56] [10/10] training 31.3%: Loss=0.445213, Accuracy=72.077%, MSE=0.192187
[2023-04-27-10:41:58] [10/10] training 33.7%: Loss=0.444819, Accuracy=71.714%, MSE=0.194047
[2023-04-27-10:41:59] [10/10] training 36.1%: Loss=0.441978, Accuracy=71.800%, MSE=0.193158
[2023-04-27-10:42:01] [10/10] training 38.6%: Loss=0.444006, Accuracy=71.625%, MSE=0.195121
[2023-04-27-10:42:03] [10/10] training 41.0%: Loss=0.441099, Accuracy=71.882%, MSE=0.19275
[2023-04-27-10:42:05] [10/10] training 43.4%: Loss=0.44005, Accuracy=72.111%, MSE=0.19113
[2023-04-27-10:42:06] [10/10] training 45.8%: Loss=0.442427, Accuracy=71.789%, MSE=0.193565
[2023-04-27-10:42:08] [10/10] training 48.2%: Loss=0.443534, Accuracy=71.800%, MSE=0.194721
[2023-04-27-10:42:10] [10/10] training 50.6%: Loss=0.443488, Accuracy=71.905%, MSE=0.194895
[2023-04-27-10:42:11] [10/10] training 53.0%: Loss=0.441866, Accuracy=71.909%, MSE=0.194211
[2023-04-27-10:42:13] [10/10] training 55.4%: Loss=0.439939, Accuracy=72.087%, MSE=0.192802
[2023-04-27-10:42:15] [10/10] training 57.8%: Loss=0.441408, Accuracy=71.708%, MSE=0.194278
[2023-04-27-10:42:16] [10/10] training 60.2%: Loss=0.438209, Accuracy=72.120%, MSE=0.191595
[2023-04-27-10:42:18] [10/10] training 62.7%: Loss=0.436398, Accuracy=72.577%, MSE=0.189212
[2023-04-27-10:42:20] [10/10] training 65.1%: Loss=0.438045, Accuracy=72.741%, MSE=0.189366
[2023-04-27-10:42:22] [10/10] training 67.5%: Loss=0.439192, Accuracy=72.893%, MSE=0.188509
[2023-04-27-10:42:24] [10/10] training 69.9%: Loss=0.438513, Accuracy=73.069%, MSE=0.187582
[2023-04-27-10:42:25] [10/10] training 72.3%: Loss=0.437229, Accuracy=73.200%, MSE=0.187046
[2023-04-27-10:42:27] [10/10] training 74.7%: Loss=0.436958, Accuracy=73.097%, MSE=0.187244
[2023-04-27-10:42:29] [10/10] training 77.1%: Loss=0.438313, Accuracy=73.156%, MSE=0.187203
[2023-04-27-10:42:30] [10/10] training 79.5%: Loss=0.439342, Accuracy=73.182%, MSE=0.187617
[2023-04-27-10:42:32] [10/10] training 81.9%: Loss=0.439531, Accuracy=73.206%, MSE=0.187869
[2023-04-27-10:42:34] [10/10] training 84.3%: Loss=0.438506, Accuracy=73.343%, MSE=0.187291
[2023-04-27-10:42:36] [10/10] training 86.7%: Loss=0.437631, Accuracy=73.444%, MSE=0.186756
[2023-04-27-10:42:38] [10/10] training 89.2%: Loss=0.443111, Accuracy=73.351%, MSE=0.188459
[2023-04-27-10:42:39] [10/10] training 91.6%: Loss=0.44586, Accuracy=73.289%, MSE=0.189106
[2023-04-27-10:42:41] [10/10] training 94.0%: Loss=0.446213, Accuracy=73.205%, MSE=0.189606
[2023-04-27-10:42:43] [10/10] training 96.4%: Loss=0.444716, Accuracy=73.325%, MSE=0.188713
[2023-04-27-10:42:44] [10/10] training 98.8%: Loss=0.446126, Accuracy=73.341%, MSE=0.18908
[2023-04-27-10:42:56] Finished Epoch 10/10: Loss=2.73873, Accuracy=49.867%, MSE=0.493647, Precision=0.501662, Recall=0.00644238, F1=0.0127214, AUPR=0.513571
[2023-04-27-10:42:56] Saving model to ./models/huang_both_0_dscript_partitions_epoch10.sav
[2023-04-27-10:42:56] Saving final model to ./models/huang_both_0_dscript_partitions_final.sav
