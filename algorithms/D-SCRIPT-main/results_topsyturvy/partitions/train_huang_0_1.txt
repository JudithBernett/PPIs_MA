[2023-08-18-18:57:22] D-SCRIPT Version 0.2.2
[2023-08-18-18:57:22] Called as: /nfs/home/students/jbernett/miniconda3/envs/dscript/bin/dscript train --topsy-turvy --train data/partitions/huang_partition_0.txt --test data/partitions/huang_partition_1.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_0_1_tt_partitions -o ./results_topsyturvy/partitions/train_huang_0_1.txt
[2023-08-18-18:57:24] Loaded 2992 training pairs
[2023-08-18-18:57:24] Loaded 1190 test pairs
[2023-08-18-18:57:24] Loading embeddings...
[2023-08-18-18:59:42] Running D-SCRIPT Topsy-Turvy:
[2023-08-18-18:59:42] 	glider_weight: 0.2
[2023-08-18-18:59:42] 	glider_thresh: 92.5th percentile
[2023-08-18-18:59:42] Computing GLIDER matrix...
[2023-08-18-18:59:43] Initializing embedding model with:
[2023-08-18-18:59:43] 	projection_dim: 100
[2023-08-18-18:59:43] 	dropout_p: 0.5
[2023-08-18-18:59:43] Initializing contact model with:
[2023-08-18-18:59:43] 	hidden_dim: 50
[2023-08-18-18:59:43] 	kernel_width: 7
[2023-08-18-18:59:43] Initializing interaction model with:
[2023-08-18-18:59:43] 	do_poool: False
[2023-08-18-18:59:43] 	pool_width: 9
[2023-08-18-18:59:43] 	do_w: True
[2023-08-18-18:59:43] 	do_sigmoid: True
[2023-08-18-18:59:43] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-08-18-18:59:45] Using save prefix "./models/huang_0_1_tt_partitions"
[2023-08-18-18:59:45] Training with Adam: lr=0.001, weight_decay=0
[2023-08-18-18:59:45] 	num_epochs: 10
[2023-08-18-18:59:45] 	batch_size: 25
[2023-08-18-18:59:45] 	interaction weight: 0.35
[2023-08-18-18:59:45] 	contact map weight: 0.65
[2023-08-18-18:59:49] [1/10] training 3.3%: Loss=1.57961, Accuracy=44.000%, MSE=0.558125
[2023-08-18-18:59:51] [1/10] training 6.7%: Loss=1.54087, Accuracy=45.000%, MSE=0.547914
[2023-08-18-18:59:54] [1/10] training 10.0%: Loss=1.487, Accuracy=47.000%, MSE=0.527857
[2023-08-18-18:59:56] [1/10] training 13.3%: Loss=1.45584, Accuracy=48.250%, MSE=0.515307
[2023-08-18-18:59:58] [1/10] training 16.7%: Loss=1.40287, Accuracy=50.400%, MSE=0.493794
[2023-08-18-19:00:00] [1/10] training 20.0%: Loss=1.40107, Accuracy=50.167%, MSE=0.496044
[2023-08-18-19:00:03] [1/10] training 23.3%: Loss=1.41616, Accuracy=49.143%, MSE=0.506129
[2023-08-18-19:00:05] [1/10] training 26.7%: Loss=1.39051, Accuracy=50.000%, MSE=0.497508
[2023-08-18-19:00:08] [1/10] training 30.0%: Loss=1.38388, Accuracy=50.000%, MSE=0.4974
[2023-08-18-19:00:10] [1/10] training 33.3%: Loss=1.38264, Accuracy=49.700%, MSE=0.50024
[2023-08-18-19:00:12] [1/10] training 36.7%: Loss=1.38482, Accuracy=49.182%, MSE=0.505197
[2023-08-18-19:00:15] [1/10] training 40.0%: Loss=1.38702, Accuracy=48.750%, MSE=0.509375
[2023-08-18-19:00:17] [1/10] training 43.3%: Loss=1.37836, Accuracy=49.000%, MSE=0.506841
[2023-08-18-19:00:20] [1/10] training 46.7%: Loss=1.36291, Accuracy=49.357%, MSE=0.503101
[2023-08-18-19:00:22] [1/10] training 50.0%: Loss=1.35178, Accuracy=49.867%, MSE=0.498041
[2023-08-18-19:00:24] [1/10] training 53.3%: Loss=1.33724, Accuracy=50.250%, MSE=0.494065
[2023-08-18-19:00:27] [1/10] training 56.7%: Loss=1.33209, Accuracy=50.294%, MSE=0.493549
[2023-08-18-19:00:30] [1/10] training 60.0%: Loss=1.33296, Accuracy=50.000%, MSE=0.496353
[2023-08-18-19:00:32] [1/10] training 63.3%: Loss=1.32471, Accuracy=50.158%, MSE=0.494673
[2023-08-18-19:00:34] [1/10] training 66.7%: Loss=1.31445, Accuracy=50.450%, MSE=0.491673
[2023-08-18-19:00:37] [1/10] training 70.0%: Loss=1.31261, Accuracy=50.238%, MSE=0.493642
[2023-08-18-19:00:39] [1/10] training 73.3%: Loss=1.31321, Accuracy=50.091%, MSE=0.49507
[2023-08-18-19:00:41] [1/10] training 76.7%: Loss=1.30161, Accuracy=50.391%, MSE=0.491923
[2023-08-18-19:00:44] [1/10] training 80.0%: Loss=1.29873, Accuracy=50.375%, MSE=0.49202
[2023-08-18-19:00:46] [1/10] training 83.3%: Loss=1.29725, Accuracy=50.240%, MSE=0.493254
[2023-08-18-19:00:48] [1/10] training 86.7%: Loss=1.2904, Accuracy=50.423%, MSE=0.491358
[2023-08-18-19:00:50] [1/10] training 90.0%: Loss=1.2877, Accuracy=50.370%, MSE=0.491785
[2023-08-18-19:00:53] [1/10] training 93.3%: Loss=1.28521, Accuracy=50.321%, MSE=0.492182
[2023-08-18-19:00:56] [1/10] training 96.7%: Loss=1.28486, Accuracy=50.172%, MSE=0.493576
[2023-08-18-19:01:07] Finished Epoch 1/10: Loss=2.70169, Accuracy=49.583%, MSE=0.49317, Precision=0.419821, Recall=0.00695537, F1=0.013684, AUPR=0.419618
[2023-08-18-19:01:07] Saving model to ./models/huang_0_1_tt_partitions_epoch01.sav
[2023-08-18-19:01:10] [2/10] training 3.3%: Loss=1.25499, Accuracy=46.000%, MSE=0.531824
[2023-08-18-19:01:12] [2/10] training 6.7%: Loss=1.22745, Accuracy=46.500%, MSE=0.525948
[2023-08-18-19:01:14] [2/10] training 10.0%: Loss=1.21606, Accuracy=48.000%, MSE=0.511908
[2023-08-18-19:01:17] [2/10] training 13.3%: Loss=1.22551, Accuracy=47.500%, MSE=0.516732
[2023-08-18-19:01:19] [2/10] training 16.7%: Loss=1.19081, Accuracy=48.800%, MSE=0.503496
[2023-08-18-19:01:21] [2/10] training 20.0%: Loss=1.20473, Accuracy=48.500%, MSE=0.506824
[2023-08-18-19:01:24] [2/10] training 23.3%: Loss=1.16786, Accuracy=50.286%, MSE=0.488983
[2023-08-18-19:01:26] [2/10] training 26.7%: Loss=1.16731, Accuracy=50.000%, MSE=0.491604
[2023-08-18-19:01:28] [2/10] training 30.0%: Loss=1.17914, Accuracy=49.444%, MSE=0.497181
[2023-08-18-19:01:30] [2/10] training 33.3%: Loss=1.16185, Accuracy=49.900%, MSE=0.492168
[2023-08-18-19:01:33] [2/10] training 36.7%: Loss=1.16657, Accuracy=49.818%, MSE=0.493162
[2023-08-18-19:01:35] [2/10] training 40.0%: Loss=1.17028, Accuracy=49.417%, MSE=0.496971
[2023-08-18-19:01:37] [2/10] training 43.3%: Loss=1.17729, Accuracy=48.923%, MSE=0.501818
[2023-08-18-19:01:39] [2/10] training 46.7%: Loss=1.17692, Accuracy=48.786%, MSE=0.503056
[2023-08-18-19:01:42] [2/10] training 50.0%: Loss=1.1665, Accuracy=49.200%, MSE=0.498857
[2023-08-18-19:01:43] [2/10] training 53.3%: Loss=1.1612, Accuracy=49.438%, MSE=0.496468
[2023-08-18-19:01:46] [2/10] training 56.7%: Loss=1.15922, Accuracy=49.412%, MSE=0.49661
[2023-08-18-19:01:48] [2/10] training 60.0%: Loss=1.1482, Accuracy=49.889%, MSE=0.491807
[2023-08-18-19:01:51] [2/10] training 63.3%: Loss=1.14851, Accuracy=49.684%, MSE=0.493698
[2023-08-18-19:01:53] [2/10] training 66.7%: Loss=1.13935, Accuracy=50.200%, MSE=0.488627
[2023-08-18-19:01:55] [2/10] training 70.0%: Loss=1.13915, Accuracy=49.905%, MSE=0.491267
[2023-08-18-19:01:57] [2/10] training 73.3%: Loss=1.13988, Accuracy=49.818%, MSE=0.492101
[2023-08-18-19:02:00] [2/10] training 76.7%: Loss=1.14, Accuracy=49.609%, MSE=0.493995
[2023-08-18-19:02:02] [2/10] training 80.0%: Loss=1.1379, Accuracy=49.583%, MSE=0.494141
[2023-08-18-19:02:04] [2/10] training 83.3%: Loss=1.13646, Accuracy=49.520%, MSE=0.494658
[2023-08-18-19:02:07] [2/10] training 86.7%: Loss=1.12889, Accuracy=49.846%, MSE=0.491361
[2023-08-18-19:02:09] [2/10] training 90.0%: Loss=1.12546, Accuracy=49.889%, MSE=0.49079
[2023-08-18-19:02:11] [2/10] training 93.3%: Loss=1.12254, Accuracy=50.036%, MSE=0.489344
[2023-08-18-19:02:13] [2/10] training 96.7%: Loss=1.12103, Accuracy=49.862%, MSE=0.490727
[2023-08-18-19:02:22] Finished Epoch 2/10: Loss=2.37048, Accuracy=49.583%, MSE=0.488103, Precision=0.418185, Recall=0.012254, F1=0.0238103, AUPR=0.414774
[2023-08-18-19:02:22] Saving model to ./models/huang_0_1_tt_partitions_epoch02.sav
[2023-08-18-19:02:24] [3/10] training 3.3%: Loss=1.05816, Accuracy=50.000%, MSE=0.486309
[2023-08-18-19:02:27] [3/10] training 6.7%: Loss=1.07852, Accuracy=48.500%, MSE=0.5005
[2023-08-18-19:02:29] [3/10] training 10.0%: Loss=1.1082, Accuracy=47.000%, MSE=0.516096
[2023-08-18-19:02:31] [3/10] training 13.3%: Loss=1.09351, Accuracy=47.500%, MSE=0.510772
[2023-08-18-19:02:33] [3/10] training 16.7%: Loss=1.11166, Accuracy=46.400%, MSE=0.521521
[2023-08-18-19:02:36] [3/10] training 20.0%: Loss=1.07417, Accuracy=48.500%, MSE=0.500607
[2023-08-18-19:02:38] [3/10] training 23.3%: Loss=1.06666, Accuracy=48.857%, MSE=0.496913
[2023-08-18-19:02:40] [3/10] training 26.7%: Loss=1.07525, Accuracy=48.375%, MSE=0.501721
[2023-08-18-19:02:42] [3/10] training 30.0%: Loss=1.06061, Accuracy=49.000%, MSE=0.495247
[2023-08-18-19:02:44] [3/10] training 33.3%: Loss=1.05135, Accuracy=49.400%, MSE=0.491143
[2023-08-18-19:02:47] [3/10] training 36.7%: Loss=1.05265, Accuracy=49.000%, MSE=0.494721
[2023-08-18-19:02:49] [3/10] training 40.0%: Loss=1.04909, Accuracy=49.083%, MSE=0.493641
[2023-08-18-19:02:51] [3/10] training 43.3%: Loss=1.03816, Accuracy=49.692%, MSE=0.487608
[2023-08-18-19:02:53] [3/10] training 46.7%: Loss=1.03482, Accuracy=49.786%, MSE=0.486465
[2023-08-18-19:02:56] [3/10] training 50.0%: Loss=1.03549, Accuracy=49.733%, MSE=0.486953
[2023-08-18-19:02:58] [3/10] training 53.3%: Loss=1.03224, Accuracy=49.875%, MSE=0.485403
[2023-08-18-19:03:00] [3/10] training 56.7%: Loss=1.03541, Accuracy=49.588%, MSE=0.488165
[2023-08-18-19:03:03] [3/10] training 60.0%: Loss=1.03232, Accuracy=49.500%, MSE=0.488519
[2023-08-18-19:03:05] [3/10] training 63.3%: Loss=1.02632, Accuracy=49.842%, MSE=0.485181
[2023-08-18-19:03:07] [3/10] training 66.7%: Loss=1.02205, Accuracy=49.950%, MSE=0.483922
[2023-08-18-19:03:09] [3/10] training 70.0%: Loss=1.01576, Accuracy=50.238%, MSE=0.481022
[2023-08-18-19:03:12] [3/10] training 73.3%: Loss=1.00975, Accuracy=50.455%, MSE=0.47872
[2023-08-18-19:03:14] [3/10] training 76.7%: Loss=1.01171, Accuracy=50.348%, MSE=0.479753
[2023-08-18-19:03:16] [3/10] training 80.0%: Loss=1.00866, Accuracy=50.500%, MSE=0.478175
[2023-08-18-19:03:18] [3/10] training 83.3%: Loss=1.00601, Accuracy=50.600%, MSE=0.477194
[2023-08-18-19:03:21] [3/10] training 86.7%: Loss=1.00758, Accuracy=50.308%, MSE=0.479776
[2023-08-18-19:03:23] [3/10] training 90.0%: Loss=1.00999, Accuracy=50.074%, MSE=0.481919
[2023-08-18-19:03:25] [3/10] training 93.3%: Loss=1.00797, Accuracy=50.107%, MSE=0.481486
[2023-08-18-19:03:27] [3/10] training 96.7%: Loss=1.00671, Accuracy=50.000%, MSE=0.482235
[2023-08-18-19:03:36] Finished Epoch 3/10: Loss=2.04397, Accuracy=49.583%, MSE=0.47642, Precision=0.431644, Recall=0.0249988, F1=0.0472605, AUPR=0.427959
[2023-08-18-19:03:36] Saving model to ./models/huang_0_1_tt_partitions_epoch03.sav
[2023-08-18-19:03:39] [4/10] training 3.3%: Loss=0.959772, Accuracy=48.000%, MSE=0.493581
[2023-08-18-19:03:41] [4/10] training 6.7%: Loss=0.926135, Accuracy=50.000%, MSE=0.473186
[2023-08-18-19:03:43] [4/10] training 10.0%: Loss=0.978696, Accuracy=48.000%, MSE=0.495428
[2023-08-18-19:03:45] [4/10] training 13.3%: Loss=0.977623, Accuracy=47.500%, MSE=0.499699
[2023-08-18-19:03:48] [4/10] training 16.7%: Loss=0.978898, Accuracy=47.200%, MSE=0.501928
[2023-08-18-19:03:50] [4/10] training 20.0%: Loss=0.962818, Accuracy=48.667%, MSE=0.48853
[2023-08-18-19:03:52] [4/10] training 23.3%: Loss=0.951214, Accuracy=48.857%, MSE=0.48556
[2023-08-18-19:03:54] [4/10] training 26.7%: Loss=0.949176, Accuracy=49.000%, MSE=0.484016
[2023-08-18-19:03:56] [4/10] training 30.0%: Loss=0.94402, Accuracy=49.556%, MSE=0.479139
[2023-08-18-19:03:59] [4/10] training 33.3%: Loss=0.942556, Accuracy=49.400%, MSE=0.480287
[2023-08-18-19:04:01] [4/10] training 36.7%: Loss=0.949734, Accuracy=48.818%, MSE=0.485653
[2023-08-18-19:04:04] [4/10] training 40.0%: Loss=0.952167, Accuracy=48.500%, MSE=0.488455
[2023-08-18-19:04:06] [4/10] training 43.3%: Loss=0.935982, Accuracy=49.462%, MSE=0.479025
[2023-08-18-19:04:08] [4/10] training 46.7%: Loss=0.934865, Accuracy=49.429%, MSE=0.478974
[2023-08-18-19:04:11] [4/10] training 50.0%: Loss=0.939841, Accuracy=49.333%, MSE=0.480306
[2023-08-18-19:04:13] [4/10] training 53.3%: Loss=0.935785, Accuracy=49.188%, MSE=0.480461
[2023-08-18-19:04:15] [4/10] training 56.7%: Loss=0.945952, Accuracy=48.706%, MSE=0.485495
[2023-08-18-19:04:17] [4/10] training 60.0%: Loss=0.945881, Accuracy=48.500%, MSE=0.486941
[2023-08-18-19:04:20] [4/10] training 63.3%: Loss=0.94184, Accuracy=48.526%, MSE=0.486113
[2023-08-18-19:04:22] [4/10] training 66.7%: Loss=0.943116, Accuracy=48.500%, MSE=0.486488
[2023-08-18-19:04:24] [4/10] training 70.0%: Loss=0.941484, Accuracy=48.571%, MSE=0.485642
[2023-08-18-19:04:26] [4/10] training 73.3%: Loss=0.939139, Accuracy=48.636%, MSE=0.484798
[2023-08-18-19:04:28] [4/10] training 76.7%: Loss=0.935651, Accuracy=48.957%, MSE=0.482108
[2023-08-18-19:04:31] [4/10] training 80.0%: Loss=0.927184, Accuracy=49.292%, MSE=0.477887
[2023-08-18-19:04:33] [4/10] training 83.3%: Loss=0.92359, Accuracy=49.480%, MSE=0.475905
[2023-08-18-19:04:36] [4/10] training 86.7%: Loss=0.921867, Accuracy=49.500%, MSE=0.475453
[2023-08-18-19:04:38] [4/10] training 90.0%: Loss=0.917579, Accuracy=49.741%, MSE=0.473063
[2023-08-18-19:04:40] [4/10] training 93.3%: Loss=0.916442, Accuracy=49.714%, MSE=0.473125
[2023-08-18-19:04:42] [4/10] training 96.7%: Loss=0.915647, Accuracy=49.793%, MSE=0.472364
[2023-08-18-19:04:51] Finished Epoch 4/10: Loss=1.8025, Accuracy=49.583%, MSE=0.461785, Precision=0.445425, Recall=0.0427083, F1=0.0779433, AUPR=0.454471
[2023-08-18-19:04:51] Saving model to ./models/huang_0_1_tt_partitions_epoch04.sav
[2023-08-18-19:04:53] [5/10] training 3.3%: Loss=0.881249, Accuracy=49.000%, MSE=0.472038
[2023-08-18-19:04:55] [5/10] training 6.7%: Loss=0.860474, Accuracy=50.000%, MSE=0.463395
[2023-08-18-19:04:58] [5/10] training 10.0%: Loss=0.851588, Accuracy=51.000%, MSE=0.455082
[2023-08-18-19:05:00] [5/10] training 13.3%: Loss=0.860912, Accuracy=50.000%, MSE=0.463849
[2023-08-18-19:05:03] [5/10] training 16.7%: Loss=0.865009, Accuracy=50.000%, MSE=0.464429
[2023-08-18-19:05:05] [5/10] training 20.0%: Loss=0.861284, Accuracy=50.000%, MSE=0.463971
[2023-08-18-19:05:07] [5/10] training 23.3%: Loss=0.862029, Accuracy=49.857%, MSE=0.465054
[2023-08-18-19:05:10] [5/10] training 26.7%: Loss=0.85594, Accuracy=50.000%, MSE=0.462461
[2023-08-18-19:05:12] [5/10] training 30.0%: Loss=0.862607, Accuracy=49.333%, MSE=0.468187
[2023-08-18-19:05:14] [5/10] training 33.3%: Loss=0.859649, Accuracy=49.300%, MSE=0.468097
[2023-08-18-19:05:17] [5/10] training 36.7%: Loss=0.866802, Accuracy=48.455%, MSE=0.475029
[2023-08-18-19:05:19] [5/10] training 40.0%: Loss=0.873464, Accuracy=47.833%, MSE=0.480783
[2023-08-18-19:05:21] [5/10] training 43.3%: Loss=0.873604, Accuracy=47.615%, MSE=0.482554
[2023-08-18-19:05:23] [5/10] training 46.7%: Loss=0.869242, Accuracy=47.786%, MSE=0.480487
[2023-08-18-19:05:26] [5/10] training 50.0%: Loss=0.863997, Accuracy=48.467%, MSE=0.47484
[2023-08-18-19:05:28] [5/10] training 53.3%: Loss=0.855153, Accuracy=48.937%, MSE=0.469814
[2023-08-18-19:05:30] [5/10] training 56.7%: Loss=0.8515, Accuracy=49.059%, MSE=0.468014
[2023-08-18-19:05:32] [5/10] training 60.0%: Loss=0.848181, Accuracy=49.278%, MSE=0.465729
[2023-08-18-19:05:34] [5/10] training 63.3%: Loss=0.848816, Accuracy=49.105%, MSE=0.467013
[2023-08-18-19:05:37] [5/10] training 66.7%: Loss=0.84783, Accuracy=49.200%, MSE=0.466237
[2023-08-18-19:05:39] [5/10] training 70.0%: Loss=0.841605, Accuracy=49.476%, MSE=0.462861
[2023-08-18-19:05:41] [5/10] training 73.3%: Loss=0.838363, Accuracy=49.773%, MSE=0.45998
[2023-08-18-19:05:43] [5/10] training 76.7%: Loss=0.840491, Accuracy=49.739%, MSE=0.460407
[2023-08-18-19:05:45] [5/10] training 80.0%: Loss=0.839045, Accuracy=49.792%, MSE=0.459709
[2023-08-18-19:05:48] [5/10] training 83.3%: Loss=0.841436, Accuracy=49.480%, MSE=0.462188
[2023-08-18-19:05:50] [5/10] training 86.7%: Loss=0.840455, Accuracy=49.500%, MSE=0.461949
[2023-08-18-19:05:52] [5/10] training 90.0%: Loss=0.836173, Accuracy=49.704%, MSE=0.459683
[2023-08-18-19:05:54] [5/10] training 93.3%: Loss=0.834382, Accuracy=49.679%, MSE=0.459508
[2023-08-18-19:05:56] [5/10] training 96.7%: Loss=0.828148, Accuracy=50.034%, MSE=0.45565
[2023-08-18-19:06:06] Finished Epoch 5/10: Loss=1.86443, Accuracy=49.583%, MSE=0.462165, Precision=0.48786, Recall=0.0410122, F1=0.0756637, AUPR=0.487373
[2023-08-18-19:06:06] Saving model to ./models/huang_0_1_tt_partitions_epoch05.sav
[2023-08-18-19:06:08] [6/10] training 3.3%: Loss=0.91287, Accuracy=44.000%, MSE=0.515038
[2023-08-18-19:06:11] [6/10] training 6.7%: Loss=0.869452, Accuracy=46.500%, MSE=0.487975
[2023-08-18-19:06:13] [6/10] training 10.0%: Loss=0.874411, Accuracy=46.000%, MSE=0.491858
[2023-08-18-19:06:15] [6/10] training 13.3%: Loss=0.872296, Accuracy=46.500%, MSE=0.487531
[2023-08-18-19:06:18] [6/10] training 16.7%: Loss=0.878642, Accuracy=46.000%, MSE=0.492277
[2023-08-18-19:06:20] [6/10] training 20.0%: Loss=0.860413, Accuracy=47.000%, MSE=0.48205
[2023-08-18-19:06:22] [6/10] training 23.3%: Loss=0.843462, Accuracy=48.000%, MSE=0.472619
[2023-08-18-19:06:25] [6/10] training 26.7%: Loss=0.836241, Accuracy=48.125%, MSE=0.470286
[2023-08-18-19:06:27] [6/10] training 30.0%: Loss=0.834543, Accuracy=48.222%, MSE=0.469222
[2023-08-18-19:06:29] [6/10] training 33.3%: Loss=0.826082, Accuracy=48.600%, MSE=0.464656
[2023-08-18-19:06:31] [6/10] training 36.7%: Loss=0.825789, Accuracy=48.273%, MSE=0.466734
[2023-08-18-19:06:34] [6/10] training 40.0%: Loss=0.817122, Accuracy=49.000%, MSE=0.459915
[2023-08-18-19:06:36] [6/10] training 43.3%: Loss=0.807954, Accuracy=49.231%, MSE=0.45574
[2023-08-18-19:06:38] [6/10] training 46.7%: Loss=0.804, Accuracy=49.357%, MSE=0.45348
[2023-08-18-19:06:40] [6/10] training 50.0%: Loss=0.805838, Accuracy=49.200%, MSE=0.454834
[2023-08-18-19:06:42] [6/10] training 53.3%: Loss=0.808485, Accuracy=48.813%, MSE=0.45772
[2023-08-18-19:06:45] [6/10] training 56.7%: Loss=0.800294, Accuracy=49.059%, MSE=0.453647
[2023-08-18-19:06:47] [6/10] training 60.0%: Loss=0.796665, Accuracy=48.833%, MSE=0.452632
[2023-08-18-19:06:49] [6/10] training 63.3%: Loss=0.798881, Accuracy=48.737%, MSE=0.453626
[2023-08-18-19:06:51] [6/10] training 66.7%: Loss=0.798055, Accuracy=48.900%, MSE=0.452305
[2023-08-18-19:06:54] [6/10] training 70.0%: Loss=0.792909, Accuracy=49.095%, MSE=0.449819
[2023-08-18-19:06:56] [6/10] training 73.3%: Loss=0.790662, Accuracy=49.273%, MSE=0.448194
[2023-08-18-19:06:58] [6/10] training 76.7%: Loss=0.790056, Accuracy=49.130%, MSE=0.448815
[2023-08-18-19:07:00] [6/10] training 80.0%: Loss=0.784447, Accuracy=49.458%, MSE=0.445273
[2023-08-18-19:07:02] [6/10] training 83.3%: Loss=0.782557, Accuracy=49.480%, MSE=0.444677
[2023-08-18-19:07:04] [6/10] training 86.7%: Loss=0.780066, Accuracy=49.538%, MSE=0.443594
[2023-08-18-19:07:07] [6/10] training 90.0%: Loss=0.784236, Accuracy=49.259%, MSE=0.446554
[2023-08-18-19:07:09] [6/10] training 93.3%: Loss=0.778552, Accuracy=49.571%, MSE=0.443039
[2023-08-18-19:07:11] [6/10] training 96.7%: Loss=0.777443, Accuracy=49.655%, MSE=0.442429
[2023-08-18-19:07:20] Finished Epoch 6/10: Loss=1.9381, Accuracy=49.583%, MSE=0.467764, Precision=0.493573, Recall=0.0346069, F1=0.0646788, AUPR=0.493127
[2023-08-18-19:07:20] Saving model to ./models/huang_0_1_tt_partitions_epoch06.sav
[2023-08-18-19:07:22] [7/10] training 3.3%: Loss=0.764004, Accuracy=44.000%, MSE=0.468931
[2023-08-18-19:07:24] [7/10] training 6.7%: Loss=0.729727, Accuracy=46.500%, MSE=0.444049
[2023-08-18-19:07:26] [7/10] training 10.0%: Loss=0.716453, Accuracy=48.667%, MSE=0.427847
[2023-08-18-19:07:29] [7/10] training 13.3%: Loss=0.738255, Accuracy=47.250%, MSE=0.443736
[2023-08-18-19:07:31] [7/10] training 16.7%: Loss=0.723679, Accuracy=48.800%, MSE=0.429722
[2023-08-18-19:07:33] [7/10] training 20.0%: Loss=0.715559, Accuracy=48.667%, MSE=0.425796
[2023-08-18-19:07:36] [7/10] training 23.3%: Loss=0.719796, Accuracy=48.000%, MSE=0.430362
[2023-08-18-19:07:38] [7/10] training 26.7%: Loss=0.729288, Accuracy=47.750%, MSE=0.434255
[2023-08-18-19:07:40] [7/10] training 30.0%: Loss=0.723714, Accuracy=48.000%, MSE=0.431631
[2023-08-18-19:07:42] [7/10] training 33.3%: Loss=0.716744, Accuracy=48.600%, MSE=0.425572
[2023-08-18-19:07:44] [7/10] training 36.7%: Loss=0.722211, Accuracy=48.545%, MSE=0.428381
[2023-08-18-19:07:47] [7/10] training 40.0%: Loss=0.725404, Accuracy=48.500%, MSE=0.430364
[2023-08-18-19:07:49] [7/10] training 43.3%: Loss=0.719383, Accuracy=48.846%, MSE=0.426378
[2023-08-18-19:07:51] [7/10] training 46.7%: Loss=0.719192, Accuracy=48.929%, MSE=0.426177
[2023-08-18-19:07:54] [7/10] training 50.0%: Loss=0.714955, Accuracy=49.400%, MSE=0.422405
[2023-08-18-19:07:56] [7/10] training 53.3%: Loss=0.717242, Accuracy=49.187%, MSE=0.424676
[2023-08-18-19:07:58] [7/10] training 56.7%: Loss=0.717903, Accuracy=49.118%, MSE=0.425447
[2023-08-18-19:08:00] [7/10] training 60.0%: Loss=0.714997, Accuracy=49.278%, MSE=0.423137
[2023-08-18-19:08:03] [7/10] training 63.3%: Loss=0.718406, Accuracy=48.947%, MSE=0.426366
[2023-08-18-19:08:05] [7/10] training 66.7%: Loss=0.715586, Accuracy=49.100%, MSE=0.424725
[2023-08-18-19:08:07] [7/10] training 70.0%: Loss=0.714184, Accuracy=49.000%, MSE=0.42442
[2023-08-18-19:08:09] [7/10] training 73.3%: Loss=0.71255, Accuracy=49.136%, MSE=0.423035
[2023-08-18-19:08:12] [7/10] training 76.7%: Loss=0.713859, Accuracy=49.000%, MSE=0.424097
[2023-08-18-19:08:15] [7/10] training 80.0%: Loss=0.713811, Accuracy=48.750%, MSE=0.424847
[2023-08-18-19:08:17] [7/10] training 83.3%: Loss=0.709146, Accuracy=49.080%, MSE=0.421391
[2023-08-18-19:08:19] [7/10] training 86.7%: Loss=0.705428, Accuracy=49.462%, MSE=0.418159
[2023-08-18-19:08:21] [7/10] training 90.0%: Loss=0.703685, Accuracy=49.333%, MSE=0.41779
[2023-08-18-19:08:23] [7/10] training 93.3%: Loss=0.701925, Accuracy=49.357%, MSE=0.416935
[2023-08-18-19:08:26] [7/10] training 96.7%: Loss=0.704492, Accuracy=49.138%, MSE=0.418908
[2023-08-18-19:08:35] Finished Epoch 7/10: Loss=1.83218, Accuracy=49.583%, MSE=0.45669, Precision=0.5345, Recall=0.04718, F1=0.0867065, AUPR=0.534714
[2023-08-18-19:08:35] Saving model to ./models/huang_0_1_tt_partitions_epoch07.sav
[2023-08-18-19:08:37] [8/10] training 3.3%: Loss=0.605192, Accuracy=49.000%, MSE=0.36875
[2023-08-18-19:08:39] [8/10] training 6.7%: Loss=0.615103, Accuracy=54.500%, MSE=0.355519
[2023-08-18-19:08:42] [8/10] training 10.0%: Loss=0.614305, Accuracy=54.333%, MSE=0.356444
[2023-08-18-19:08:44] [8/10] training 13.3%: Loss=0.615355, Accuracy=53.750%, MSE=0.358578
[2023-08-18-19:08:46] [8/10] training 16.7%: Loss=0.614031, Accuracy=54.000%, MSE=0.35827
[2023-08-18-19:08:48] [8/10] training 20.0%: Loss=0.623201, Accuracy=52.333%, MSE=0.369113
[2023-08-18-19:08:50] [8/10] training 23.3%: Loss=0.644871, Accuracy=50.857%, MSE=0.38499
[2023-08-18-19:08:53] [8/10] training 26.7%: Loss=0.661606, Accuracy=50.250%, MSE=0.394993
[2023-08-18-19:08:55] [8/10] training 30.0%: Loss=0.650075, Accuracy=51.111%, MSE=0.38589
[2023-08-18-19:08:57] [8/10] training 33.3%: Loss=0.639775, Accuracy=51.400%, MSE=0.378584
[2023-08-18-19:08:59] [8/10] training 36.7%: Loss=0.644179, Accuracy=51.273%, MSE=0.380732
[2023-08-18-19:09:01] [8/10] training 40.0%: Loss=0.652316, Accuracy=50.833%, MSE=0.385983
[2023-08-18-19:09:04] [8/10] training 43.3%: Loss=0.65739, Accuracy=50.154%, MSE=0.390139
[2023-08-18-19:09:07] [8/10] training 46.7%: Loss=0.658959, Accuracy=50.071%, MSE=0.391907
[2023-08-18-19:09:09] [8/10] training 50.0%: Loss=0.658991, Accuracy=49.867%, MSE=0.393039
[2023-08-18-19:09:11] [8/10] training 53.3%: Loss=0.651955, Accuracy=50.063%, MSE=0.388043
[2023-08-18-19:09:14] [8/10] training 56.7%: Loss=0.65645, Accuracy=50.000%, MSE=0.390497
[2023-08-18-19:09:16] [8/10] training 60.0%: Loss=0.662491, Accuracy=49.889%, MSE=0.393826
[2023-08-18-19:09:18] [8/10] training 63.3%: Loss=0.660487, Accuracy=50.000%, MSE=0.393014
[2023-08-18-19:09:20] [8/10] training 66.7%: Loss=0.66018, Accuracy=49.850%, MSE=0.393757
[2023-08-18-19:09:22] [8/10] training 70.0%: Loss=0.659663, Accuracy=49.857%, MSE=0.394167
[2023-08-18-19:09:24] [8/10] training 73.3%: Loss=0.657452, Accuracy=50.045%, MSE=0.392775
[2023-08-18-19:09:26] [8/10] training 76.7%: Loss=0.65585, Accuracy=49.957%, MSE=0.392434
[2023-08-18-19:09:29] [8/10] training 80.0%: Loss=0.657405, Accuracy=49.750%, MSE=0.393971
[2023-08-18-19:09:31] [8/10] training 83.3%: Loss=0.660099, Accuracy=49.600%, MSE=0.395964
[2023-08-18-19:09:33] [8/10] training 86.7%: Loss=0.65925, Accuracy=49.346%, MSE=0.396383
[2023-08-18-19:09:36] [8/10] training 90.0%: Loss=0.659286, Accuracy=49.185%, MSE=0.396971
[2023-08-18-19:09:38] [8/10] training 93.3%: Loss=0.659424, Accuracy=49.071%, MSE=0.397703
[2023-08-18-19:09:40] [8/10] training 96.7%: Loss=0.656327, Accuracy=49.138%, MSE=0.395806
[2023-08-18-19:09:49] Finished Epoch 8/10: Loss=2.38374, Accuracy=49.583%, MSE=0.486713, Precision=0.516176, Recall=0.0136672, F1=0.0266292, AUPR=0.513867
[2023-08-18-19:09:49] Saving model to ./models/huang_0_1_tt_partitions_epoch08.sav
[2023-08-18-19:09:52] [9/10] training 3.3%: Loss=0.619062, Accuracy=47.000%, MSE=0.383837
[2023-08-18-19:09:54] [9/10] training 6.7%: Loss=0.58245, Accuracy=50.000%, MSE=0.352445
[2023-08-18-19:09:56] [9/10] training 10.0%: Loss=0.576084, Accuracy=49.333%, MSE=0.349635
[2023-08-18-19:09:59] [9/10] training 13.3%: Loss=0.585363, Accuracy=47.500%, MSE=0.359346
[2023-08-18-19:10:01] [9/10] training 16.7%: Loss=0.596968, Accuracy=48.800%, MSE=0.363095
[2023-08-18-19:10:03] [9/10] training 20.0%: Loss=0.618939, Accuracy=47.333%, MSE=0.378772
[2023-08-18-19:10:05] [9/10] training 23.3%: Loss=0.604342, Accuracy=48.714%, MSE=0.366468
[2023-08-18-19:10:08] [9/10] training 26.7%: Loss=0.612871, Accuracy=48.375%, MSE=0.372472
[2023-08-18-19:10:10] [9/10] training 30.0%: Loss=0.620675, Accuracy=48.222%, MSE=0.377453
[2023-08-18-19:10:11] [9/10] training 33.3%: Loss=0.619762, Accuracy=48.200%, MSE=0.377318
[2023-08-18-19:10:13] [9/10] training 36.7%: Loss=0.620589, Accuracy=48.000%, MSE=0.378653
[2023-08-18-19:10:15] [9/10] training 40.0%: Loss=0.616802, Accuracy=47.500%, MSE=0.377246
[2023-08-18-19:10:18] [9/10] training 43.3%: Loss=0.614837, Accuracy=47.615%, MSE=0.376211
[2023-08-18-19:10:20] [9/10] training 46.7%: Loss=0.61396, Accuracy=47.857%, MSE=0.375013
[2023-08-18-19:10:23] [9/10] training 50.0%: Loss=0.612399, Accuracy=48.333%, MSE=0.372841
[2023-08-18-19:10:25] [9/10] training 53.3%: Loss=0.614286, Accuracy=47.938%, MSE=0.375303
[2023-08-18-19:10:27] [9/10] training 56.7%: Loss=0.616251, Accuracy=47.824%, MSE=0.376815
[2023-08-18-19:10:30] [9/10] training 60.0%: Loss=0.613856, Accuracy=48.056%, MSE=0.374182
[2023-08-18-19:10:32] [9/10] training 63.3%: Loss=0.611309, Accuracy=48.263%, MSE=0.372404
[2023-08-18-19:10:34] [9/10] training 66.7%: Loss=0.60609, Accuracy=48.400%, MSE=0.368297
[2023-08-18-19:10:37] [9/10] training 70.0%: Loss=0.605627, Accuracy=48.190%, MSE=0.368308
[2023-08-18-19:10:39] [9/10] training 73.3%: Loss=0.60701, Accuracy=48.227%, MSE=0.368769
[2023-08-18-19:10:41] [9/10] training 76.7%: Loss=0.605501, Accuracy=48.217%, MSE=0.367962
[2023-08-18-19:10:43] [9/10] training 80.0%: Loss=0.604103, Accuracy=48.417%, MSE=0.366932
[2023-08-18-19:10:46] [9/10] training 83.3%: Loss=0.59991, Accuracy=48.680%, MSE=0.36365
[2023-08-18-19:10:48] [9/10] training 86.7%: Loss=0.596467, Accuracy=48.808%, MSE=0.361091
[2023-08-18-19:10:50] [9/10] training 90.0%: Loss=0.598859, Accuracy=48.667%, MSE=0.362957
[2023-08-18-19:10:52] [9/10] training 93.3%: Loss=0.603038, Accuracy=48.393%, MSE=0.366135
[2023-08-18-19:10:55] [9/10] training 96.7%: Loss=0.603533, Accuracy=48.241%, MSE=0.366809
[2023-08-18-19:11:04] Finished Epoch 9/10: Loss=1.62061, Accuracy=49.750%, MSE=0.436035, Precision=0.521675, Recall=0.0761848, F1=0.132953, AUPR=0.523927
[2023-08-18-19:11:04] Saving model to ./models/huang_0_1_tt_partitions_epoch09.sav
[2023-08-18-19:11:06] [10/10] training 3.3%: Loss=0.563232, Accuracy=50.000%, MSE=0.346407
[2023-08-18-19:11:08] [10/10] training 6.7%: Loss=0.563671, Accuracy=51.000%, MSE=0.342136
[2023-08-18-19:11:10] [10/10] training 10.0%: Loss=0.575904, Accuracy=48.000%, MSE=0.354804
[2023-08-18-19:11:13] [10/10] training 13.3%: Loss=0.590792, Accuracy=47.250%, MSE=0.364629
[2023-08-18-19:11:15] [10/10] training 16.7%: Loss=0.595135, Accuracy=47.800%, MSE=0.365373
[2023-08-18-19:11:17] [10/10] training 20.0%: Loss=0.582106, Accuracy=47.833%, MSE=0.356636
[2023-08-18-19:11:19] [10/10] training 23.3%: Loss=0.565797, Accuracy=48.857%, MSE=0.342449
[2023-08-18-19:11:22] [10/10] training 26.7%: Loss=0.566967, Accuracy=48.750%, MSE=0.343288
[2023-08-18-19:11:24] [10/10] training 30.0%: Loss=0.565558, Accuracy=49.111%, MSE=0.342156
[2023-08-18-19:11:26] [10/10] training 33.3%: Loss=0.560508, Accuracy=49.700%, MSE=0.337773
[2023-08-18-19:11:29] [10/10] training 36.7%: Loss=0.552475, Accuracy=50.091%, MSE=0.330479
[2023-08-18-19:11:31] [10/10] training 40.0%: Loss=0.55654, Accuracy=50.333%, MSE=0.331576
[2023-08-18-19:11:33] [10/10] training 43.3%: Loss=0.564414, Accuracy=50.308%, MSE=0.336249
[2023-08-18-19:11:36] [10/10] training 46.7%: Loss=0.565523, Accuracy=50.286%, MSE=0.336687
[2023-08-18-19:11:38] [10/10] training 50.0%: Loss=0.565797, Accuracy=49.733%, MSE=0.337569
[2023-08-18-19:11:40] [10/10] training 53.3%: Loss=0.568047, Accuracy=49.750%, MSE=0.339749
[2023-08-18-19:11:43] [10/10] training 56.7%: Loss=0.575339, Accuracy=49.000%, MSE=0.346593
[2023-08-18-19:11:45] [10/10] training 60.0%: Loss=0.571208, Accuracy=49.000%, MSE=0.343728
[2023-08-18-19:11:47] [10/10] training 63.3%: Loss=0.569738, Accuracy=49.053%, MSE=0.342897
[2023-08-18-19:11:49] [10/10] training 66.7%: Loss=0.569686, Accuracy=49.050%, MSE=0.342723
[2023-08-18-19:11:52] [10/10] training 70.0%: Loss=0.568813, Accuracy=48.952%, MSE=0.342563
[2023-08-18-19:11:54] [10/10] training 73.3%: Loss=0.567667, Accuracy=48.955%, MSE=0.341942
[2023-08-18-19:11:56] [10/10] training 76.7%: Loss=0.568947, Accuracy=48.913%, MSE=0.342916
[2023-08-18-19:11:58] [10/10] training 80.0%: Loss=0.567875, Accuracy=48.958%, MSE=0.342015
[2023-08-18-19:12:00] [10/10] training 83.3%: Loss=0.565315, Accuracy=49.200%, MSE=0.33968
[2023-08-18-19:12:03] [10/10] training 86.7%: Loss=0.565, Accuracy=49.115%, MSE=0.339394
[2023-08-18-19:12:05] [10/10] training 90.0%: Loss=0.563625, Accuracy=49.333%, MSE=0.338252
[2023-08-18-19:12:07] [10/10] training 93.3%: Loss=0.560363, Accuracy=49.571%, MSE=0.335402
[2023-08-18-19:12:10] [10/10] training 96.7%: Loss=0.556278, Accuracy=49.966%, MSE=0.331987
[2023-08-18-19:12:18] Finished Epoch 10/10: Loss=2.05514, Accuracy=49.583%, MSE=0.472014, Precision=0.500634, Recall=0.0305067, F1=0.057509, AUPR=0.517038
[2023-08-18-19:12:18] Saving model to ./models/huang_0_1_tt_partitions_epoch10.sav
[2023-08-18-19:12:19] Saving final model to ./models/huang_0_1_tt_partitions_final.sav
