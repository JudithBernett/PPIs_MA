[2023-08-17-09:59:03] D-SCRIPT Version 0.2.2
[2023-08-17-09:59:03] Called as: /nfs/home/students/jbernett/miniconda3/envs/dscript/bin/dscript train --topsy-turvy --train data/partitions/guo_partition_0.txt --test data/partitions/guo_partition_1.txt --embedding /nfs/scratch/jbernett/yeast_embedding.h5 --save-prefix ./models/guo_0_1_tt_partitions -o ./results_topsyturvy/partitions/train_guo_0_1.txt -d 1
[2023-08-17-09:59:03] Loaded 7096 training pairs
[2023-08-17-09:59:03] Loaded 1476 test pairs
[2023-08-17-09:59:03] Loading embeddings...
[2023-08-17-10:00:44] Running D-SCRIPT Topsy-Turvy:
[2023-08-17-10:00:44] 	glider_weight: 0.2
[2023-08-17-10:00:44] 	glider_thresh: 92.5th percentile
[2023-08-17-10:00:44] Computing GLIDER matrix...
[2023-08-17-10:00:47] Initializing embedding model with:
[2023-08-17-10:00:47] 	projection_dim: 100
[2023-08-17-10:00:47] 	dropout_p: 0.5
[2023-08-17-10:00:47] Initializing contact model with:
[2023-08-17-10:00:47] 	hidden_dim: 50
[2023-08-17-10:00:47] 	kernel_width: 7
[2023-08-17-10:00:47] Initializing interaction model with:
[2023-08-17-10:00:47] 	do_poool: False
[2023-08-17-10:00:47] 	pool_width: 9
[2023-08-17-10:00:47] 	do_w: True
[2023-08-17-10:00:47] 	do_sigmoid: True
[2023-08-17-10:00:47] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-08-17-10:00:48] Using save prefix "./models/guo_0_1_tt_partitions"
[2023-08-17-10:00:48] Training with Adam: lr=0.001, weight_decay=0
[2023-08-17-10:00:48] 	num_epochs: 10
[2023-08-17-10:00:48] 	batch_size: 25
[2023-08-17-10:00:48] 	interaction weight: 0.35
[2023-08-17-10:00:48] 	contact map weight: 0.65
[2023-08-17-10:00:51] [1/10] training 1.4%: Loss=1.34775, Accuracy=55.000%, MSE=0.448727
[2023-08-17-10:00:54] [1/10] training 2.8%: Loss=1.31677, Accuracy=55.500%, MSE=0.443591
[2023-08-17-10:00:56] [1/10] training 4.2%: Loss=1.29009, Accuracy=56.000%, MSE=0.438439
[2023-08-17-10:00:58] [1/10] training 5.6%: Loss=1.30097, Accuracy=55.000%, MSE=0.448291
[2023-08-17-10:01:01] [1/10] training 7.0%: Loss=1.32429, Accuracy=53.600%, MSE=0.462068
[2023-08-17-10:01:03] [1/10] training 8.5%: Loss=1.29547, Accuracy=54.333%, MSE=0.454502
[2023-08-17-10:01:06] [1/10] training 9.9%: Loss=1.28489, Accuracy=54.143%, MSE=0.456141
[2023-08-17-10:01:08] [1/10] training 11.3%: Loss=1.27747, Accuracy=54.375%, MSE=0.45371
[2023-08-17-10:01:11] [1/10] training 12.7%: Loss=1.275, Accuracy=54.111%, MSE=0.456149
[2023-08-17-10:01:13] [1/10] training 14.1%: Loss=1.29441, Accuracy=52.800%, MSE=0.468903
[2023-08-17-10:01:16] [1/10] training 15.5%: Loss=1.29497, Accuracy=52.455%, MSE=0.472144
[2023-08-17-10:01:18] [1/10] training 16.9%: Loss=1.29758, Accuracy=51.917%, MSE=0.477287
[2023-08-17-10:01:21] [1/10] training 18.3%: Loss=1.30005, Accuracy=51.538%, MSE=0.480965
[2023-08-17-10:01:23] [1/10] training 19.7%: Loss=1.2978, Accuracy=51.143%, MSE=0.484649
[2023-08-17-10:01:25] [1/10] training 21.1%: Loss=1.30817, Accuracy=50.333%, MSE=0.492522
[2023-08-17-10:01:28] [1/10] training 22.5%: Loss=1.30393, Accuracy=50.250%, MSE=0.493239
[2023-08-17-10:01:30] [1/10] training 23.9%: Loss=1.29896, Accuracy=50.176%, MSE=0.493829
[2023-08-17-10:01:33] [1/10] training 25.4%: Loss=1.29311, Accuracy=50.222%, MSE=0.493222
[2023-08-17-10:01:35] [1/10] training 26.8%: Loss=1.27981, Accuracy=50.684%, MSE=0.48851
[2023-08-17-10:01:37] [1/10] training 28.2%: Loss=1.27371, Accuracy=50.800%, MSE=0.487283
[2023-08-17-10:01:40] [1/10] training 29.6%: Loss=1.27376, Accuracy=50.667%, MSE=0.488539
[2023-08-17-10:01:42] [1/10] training 31.0%: Loss=1.26847, Accuracy=50.636%, MSE=0.488639
[2023-08-17-10:01:44] [1/10] training 32.4%: Loss=1.26725, Accuracy=50.435%, MSE=0.49047
[2023-08-17-10:01:47] [1/10] training 33.8%: Loss=1.26708, Accuracy=50.333%, MSE=0.491414
[2023-08-17-10:01:49] [1/10] training 35.2%: Loss=1.26328, Accuracy=50.240%, MSE=0.492135
[2023-08-17-10:01:51] [1/10] training 36.6%: Loss=1.25355, Accuracy=50.577%, MSE=0.48866
[2023-08-17-10:01:54] [1/10] training 38.0%: Loss=1.25275, Accuracy=50.444%, MSE=0.489889
[2023-08-17-10:01:56] [1/10] training 39.4%: Loss=1.25255, Accuracy=50.286%, MSE=0.491367
[2023-08-17-10:01:58] [1/10] training 40.8%: Loss=1.24563, Accuracy=50.517%, MSE=0.489006
[2023-08-17-10:02:01] [1/10] training 42.3%: Loss=1.24428, Accuracy=50.433%, MSE=0.489767
[2023-08-17-10:02:04] [1/10] training 43.7%: Loss=1.23851, Accuracy=50.548%, MSE=0.488474
[2023-08-17-10:02:06] [1/10] training 45.1%: Loss=1.23864, Accuracy=50.344%, MSE=0.490364
[2023-08-17-10:02:09] [1/10] training 46.5%: Loss=1.23641, Accuracy=50.273%, MSE=0.490889
[2023-08-17-10:02:11] [1/10] training 47.9%: Loss=1.23574, Accuracy=50.206%, MSE=0.491486
[2023-08-17-10:02:14] [1/10] training 49.3%: Loss=1.23601, Accuracy=49.971%, MSE=0.493636
[2023-08-17-10:02:16] [1/10] training 50.7%: Loss=1.23353, Accuracy=49.917%, MSE=0.494027
[2023-08-17-10:02:18] [1/10] training 52.1%: Loss=1.22934, Accuracy=49.973%, MSE=0.493375
[2023-08-17-10:02:21] [1/10] training 53.5%: Loss=1.2279, Accuracy=49.895%, MSE=0.494023
[2023-08-17-10:02:23] [1/10] training 54.9%: Loss=1.22522, Accuracy=49.872%, MSE=0.494117
[2023-08-17-10:02:25] [1/10] training 56.3%: Loss=1.22526, Accuracy=49.650%, MSE=0.496146
[2023-08-17-10:02:28] [1/10] training 57.7%: Loss=1.22536, Accuracy=49.488%, MSE=0.497644
[2023-08-17-10:02:30] [1/10] training 59.2%: Loss=1.2214, Accuracy=49.548%, MSE=0.496938
[2023-08-17-10:02:33] [1/10] training 60.6%: Loss=1.21746, Accuracy=49.628%, MSE=0.496055
[2023-08-17-10:02:35] [1/10] training 62.0%: Loss=1.2156, Accuracy=49.568%, MSE=0.496545
[2023-08-17-10:02:38] [1/10] training 63.4%: Loss=1.21085, Accuracy=49.711%, MSE=0.495045
[2023-08-17-10:02:40] [1/10] training 64.8%: Loss=1.20636, Accuracy=49.826%, MSE=0.493803
[2023-08-17-10:02:42] [1/10] training 66.2%: Loss=1.20395, Accuracy=49.830%, MSE=0.493641
[2023-08-17-10:02:45] [1/10] training 67.6%: Loss=1.20121, Accuracy=49.854%, MSE=0.493305
[2023-08-17-10:02:47] [1/10] training 69.0%: Loss=1.19934, Accuracy=49.796%, MSE=0.493736
[2023-08-17-10:02:50] [1/10] training 70.4%: Loss=1.19652, Accuracy=49.800%, MSE=0.493557
[2023-08-17-10:02:52] [1/10] training 71.8%: Loss=1.1926, Accuracy=49.902%, MSE=0.492445
[2023-08-17-10:02:54] [1/10] training 73.2%: Loss=1.19253, Accuracy=49.808%, MSE=0.493234
[2023-08-17-10:02:57] [1/10] training 74.6%: Loss=1.18907, Accuracy=49.868%, MSE=0.492546
[2023-08-17-10:02:59] [1/10] training 76.1%: Loss=1.18536, Accuracy=49.963%, MSE=0.491483
[2023-08-17-10:03:02] [1/10] training 77.5%: Loss=1.18883, Accuracy=49.618%, MSE=0.494784
[2023-08-17-10:03:04] [1/10] training 78.9%: Loss=1.18617, Accuracy=49.607%, MSE=0.494716
[2023-08-17-10:03:07] [1/10] training 80.3%: Loss=1.18358, Accuracy=49.579%, MSE=0.494775
[2023-08-17-10:03:09] [1/10] training 81.7%: Loss=1.18308, Accuracy=49.534%, MSE=0.495188
[2023-08-17-10:03:12] [1/10] training 83.1%: Loss=1.1825, Accuracy=49.424%, MSE=0.496158
[2023-08-17-10:03:14] [1/10] training 84.5%: Loss=1.1785, Accuracy=49.533%, MSE=0.494904
[2023-08-17-10:03:16] [1/10] training 85.9%: Loss=1.17726, Accuracy=49.475%, MSE=0.495359
[2023-08-17-10:03:19] [1/10] training 87.3%: Loss=1.17372, Accuracy=49.548%, MSE=0.494493
[2023-08-17-10:03:21] [1/10] training 88.7%: Loss=1.17054, Accuracy=49.635%, MSE=0.493547
[2023-08-17-10:03:24] [1/10] training 90.1%: Loss=1.1662, Accuracy=49.750%, MSE=0.492277
[2023-08-17-10:03:26] [1/10] training 91.5%: Loss=1.16316, Accuracy=49.815%, MSE=0.491551
[2023-08-17-10:03:29] [1/10] training 93.0%: Loss=1.15975, Accuracy=49.894%, MSE=0.490653
[2023-08-17-10:03:31] [1/10] training 94.4%: Loss=1.15616, Accuracy=49.940%, MSE=0.489992
[2023-08-17-10:03:34] [1/10] training 95.8%: Loss=1.15499, Accuracy=49.882%, MSE=0.49042
[2023-08-17-10:03:36] [1/10] training 97.2%: Loss=1.15165, Accuracy=49.971%, MSE=0.489429
[2023-08-17-10:03:38] [1/10] training 98.6%: Loss=1.15008, Accuracy=49.971%, MSE=0.489345
[2023-08-17-10:03:54] Finished Epoch 1/10: Loss=2.80263, Accuracy=49.200%, MSE=0.493304, Precision=0.488546, Recall=0.00682052, F1=0.0134532, AUPR=0.47996
[2023-08-17-10:03:54] Saving model to ./models/guo_0_1_tt_partitions_epoch01.sav
[2023-08-17-10:03:56] [2/10] training 1.4%: Loss=1.07229, Accuracy=47.000%, MSE=0.51053
[2023-08-17-10:03:58] [2/10] training 2.8%: Loss=1.02905, Accuracy=47.500%, MSE=0.501918
[2023-08-17-10:04:01] [2/10] training 4.2%: Loss=1.0173, Accuracy=46.667%, MSE=0.506343
[2023-08-17-10:04:03] [2/10] training 5.6%: Loss=1.00298, Accuracy=49.250%, MSE=0.48422
[2023-08-17-10:04:05] [2/10] training 7.0%: Loss=1.01818, Accuracy=48.800%, MSE=0.489537
[2023-08-17-10:04:08] [2/10] training 8.5%: Loss=1.00598, Accuracy=48.833%, MSE=0.487019
[2023-08-17-10:04:10] [2/10] training 9.9%: Loss=1.01697, Accuracy=47.857%, MSE=0.495514
[2023-08-17-10:04:12] [2/10] training 11.3%: Loss=1.00008, Accuracy=49.375%, MSE=0.481701
[2023-08-17-10:04:14] [2/10] training 12.7%: Loss=1.01296, Accuracy=49.000%, MSE=0.486407
[2023-08-17-10:04:16] [2/10] training 14.1%: Loss=1.00058, Accuracy=49.400%, MSE=0.482008
[2023-08-17-10:04:19] [2/10] training 15.5%: Loss=0.989359, Accuracy=49.545%, MSE=0.479185
[2023-08-17-10:04:21] [2/10] training 16.9%: Loss=0.98574, Accuracy=49.500%, MSE=0.479219
[2023-08-17-10:04:24] [2/10] training 18.3%: Loss=0.986902, Accuracy=49.385%, MSE=0.480242
[2023-08-17-10:04:26] [2/10] training 19.7%: Loss=0.983544, Accuracy=49.786%, MSE=0.476868
[2023-08-17-10:04:28] [2/10] training 21.1%: Loss=0.98947, Accuracy=49.533%, MSE=0.479711
[2023-08-17-10:04:31] [2/10] training 22.5%: Loss=1.00045, Accuracy=48.625%, MSE=0.488409
[2023-08-17-10:04:33] [2/10] training 23.9%: Loss=0.994416, Accuracy=49.000%, MSE=0.484596
[2023-08-17-10:04:36] [2/10] training 25.4%: Loss=0.999607, Accuracy=48.556%, MSE=0.488746
[2023-08-17-10:04:38] [2/10] training 26.8%: Loss=0.99573, Accuracy=48.684%, MSE=0.487409
[2023-08-17-10:04:40] [2/10] training 28.2%: Loss=0.990827, Accuracy=48.450%, MSE=0.488207
[2023-08-17-10:04:43] [2/10] training 29.6%: Loss=0.990825, Accuracy=48.286%, MSE=0.489477
[2023-08-17-10:04:45] [2/10] training 31.0%: Loss=0.990383, Accuracy=48.227%, MSE=0.490005
[2023-08-17-10:04:47] [2/10] training 32.4%: Loss=0.986151, Accuracy=48.391%, MSE=0.488345
[2023-08-17-10:04:50] [2/10] training 33.8%: Loss=0.9796, Accuracy=48.625%, MSE=0.485374
[2023-08-17-10:04:52] [2/10] training 35.2%: Loss=0.975042, Accuracy=48.560%, MSE=0.484898
[2023-08-17-10:04:54] [2/10] training 36.6%: Loss=0.975194, Accuracy=48.385%, MSE=0.48618
[2023-08-17-10:04:56] [2/10] training 38.0%: Loss=0.974275, Accuracy=48.519%, MSE=0.485129
[2023-08-17-10:04:59] [2/10] training 39.4%: Loss=0.970946, Accuracy=48.857%, MSE=0.482029
[2023-08-17-10:05:01] [2/10] training 40.8%: Loss=0.967025, Accuracy=49.034%, MSE=0.480152
[2023-08-17-10:05:03] [2/10] training 42.3%: Loss=0.962217, Accuracy=49.333%, MSE=0.477197
[2023-08-17-10:05:05] [2/10] training 43.7%: Loss=0.964089, Accuracy=49.129%, MSE=0.47908
[2023-08-17-10:05:07] [2/10] training 45.1%: Loss=0.962036, Accuracy=49.188%, MSE=0.478469
[2023-08-17-10:05:10] [2/10] training 46.5%: Loss=0.963633, Accuracy=48.970%, MSE=0.480451
[2023-08-17-10:05:12] [2/10] training 47.9%: Loss=0.960709, Accuracy=49.147%, MSE=0.478703
[2023-08-17-10:05:15] [2/10] training 49.3%: Loss=0.958328, Accuracy=49.257%, MSE=0.477599
[2023-08-17-10:05:17] [2/10] training 50.7%: Loss=0.953031, Accuracy=49.556%, MSE=0.474582
[2023-08-17-10:05:20] [2/10] training 52.1%: Loss=0.950698, Accuracy=49.459%, MSE=0.474725
[2023-08-17-10:05:22] [2/10] training 53.5%: Loss=0.951256, Accuracy=49.395%, MSE=0.475219
[2023-08-17-10:05:25] [2/10] training 54.9%: Loss=0.949079, Accuracy=49.487%, MSE=0.47427
[2023-08-17-10:05:27] [2/10] training 56.3%: Loss=0.948335, Accuracy=49.425%, MSE=0.474713
[2023-08-17-10:05:29] [2/10] training 57.7%: Loss=0.946365, Accuracy=49.512%, MSE=0.473846
[2023-08-17-10:05:32] [2/10] training 59.2%: Loss=0.946057, Accuracy=49.381%, MSE=0.474758
[2023-08-17-10:05:34] [2/10] training 60.6%: Loss=0.943455, Accuracy=49.488%, MSE=0.473672
[2023-08-17-10:05:36] [2/10] training 62.0%: Loss=0.940544, Accuracy=49.477%, MSE=0.473256
[2023-08-17-10:05:38] [2/10] training 63.4%: Loss=0.938945, Accuracy=49.422%, MSE=0.473312
[2023-08-17-10:05:41] [2/10] training 64.8%: Loss=0.937427, Accuracy=49.413%, MSE=0.473114
[2023-08-17-10:05:43] [2/10] training 66.2%: Loss=0.935469, Accuracy=49.511%, MSE=0.472066
[2023-08-17-10:05:45] [2/10] training 67.6%: Loss=0.935551, Accuracy=49.354%, MSE=0.473066
[2023-08-17-10:05:48] [2/10] training 69.0%: Loss=0.93542, Accuracy=49.245%, MSE=0.473773
[2023-08-17-10:05:50] [2/10] training 70.4%: Loss=0.935703, Accuracy=49.200%, MSE=0.474165
[2023-08-17-10:05:52] [2/10] training 71.8%: Loss=0.936713, Accuracy=49.098%, MSE=0.475191
[2023-08-17-10:05:55] [2/10] training 73.2%: Loss=0.935135, Accuracy=49.135%, MSE=0.474586
[2023-08-17-10:05:57] [2/10] training 74.6%: Loss=0.931572, Accuracy=49.302%, MSE=0.472722
[2023-08-17-10:05:59] [2/10] training 76.1%: Loss=0.927763, Accuracy=49.444%, MSE=0.470943
[2023-08-17-10:06:01] [2/10] training 77.5%: Loss=0.92415, Accuracy=49.564%, MSE=0.469305
[2023-08-17-10:06:03] [2/10] training 78.9%: Loss=0.923444, Accuracy=49.464%, MSE=0.469756
[2023-08-17-10:06:06] [2/10] training 80.3%: Loss=0.920879, Accuracy=49.632%, MSE=0.468092
[2023-08-17-10:06:08] [2/10] training 81.7%: Loss=0.919012, Accuracy=49.672%, MSE=0.467465
[2023-08-17-10:06:10] [2/10] training 83.1%: Loss=0.916678, Accuracy=49.695%, MSE=0.466761
[2023-08-17-10:06:12] [2/10] training 84.5%: Loss=0.91364, Accuracy=49.833%, MSE=0.465375
[2023-08-17-10:06:15] [2/10] training 85.9%: Loss=0.910956, Accuracy=49.869%, MSE=0.46452
[2023-08-17-10:06:17] [2/10] training 87.3%: Loss=0.908596, Accuracy=49.903%, MSE=0.463789
[2023-08-17-10:06:19] [2/10] training 88.7%: Loss=0.905966, Accuracy=49.937%, MSE=0.462908
[2023-08-17-10:06:21] [2/10] training 90.1%: Loss=0.903024, Accuracy=50.016%, MSE=0.461579
[2023-08-17-10:06:24] [2/10] training 91.5%: Loss=0.901789, Accuracy=49.938%, MSE=0.46176
[2023-08-17-10:06:26] [2/10] training 93.0%: Loss=0.898957, Accuracy=49.985%, MSE=0.46077
[2023-08-17-10:06:29] [2/10] training 94.4%: Loss=0.898321, Accuracy=49.925%, MSE=0.461012
[2023-08-17-10:06:31] [2/10] training 95.8%: Loss=0.896948, Accuracy=50.015%, MSE=0.460259
[2023-08-17-10:06:33] [2/10] training 97.2%: Loss=0.895425, Accuracy=50.087%, MSE=0.45947
[2023-08-17-10:06:35] [2/10] training 98.6%: Loss=0.89542, Accuracy=49.957%, MSE=0.460427
[2023-08-17-10:06:48] Finished Epoch 2/10: Loss=2.31577, Accuracy=49.400%, MSE=0.476974, Precision=0.488582, Recall=0.0259399, F1=0.0492643, AUPR=0.462368
[2023-08-17-10:06:48] Saving model to ./models/guo_0_1_tt_partitions_epoch02.sav
[2023-08-17-10:06:50] [3/10] training 1.4%: Loss=0.804964, Accuracy=47.000%, MSE=0.45375
[2023-08-17-10:06:52] [3/10] training 2.8%: Loss=0.730613, Accuracy=53.500%, MSE=0.395138
[2023-08-17-10:06:55] [3/10] training 4.2%: Loss=0.745195, Accuracy=50.000%, MSE=0.419509
[2023-08-17-10:06:57] [3/10] training 5.6%: Loss=0.748293, Accuracy=49.500%, MSE=0.423733
[2023-08-17-10:06:59] [3/10] training 7.0%: Loss=0.741622, Accuracy=48.800%, MSE=0.423976
[2023-08-17-10:07:01] [3/10] training 8.5%: Loss=0.736337, Accuracy=48.167%, MSE=0.42093
[2023-08-17-10:07:04] [3/10] training 9.9%: Loss=0.734791, Accuracy=47.571%, MSE=0.422374
[2023-08-17-10:07:06] [3/10] training 11.3%: Loss=0.734973, Accuracy=46.625%, MSE=0.423439
[2023-08-17-10:07:09] [3/10] training 12.7%: Loss=0.730666, Accuracy=46.778%, MSE=0.420874
[2023-08-17-10:07:11] [3/10] training 14.1%: Loss=0.73361, Accuracy=47.100%, MSE=0.422174
[2023-08-17-10:07:13] [3/10] training 15.5%: Loss=0.739399, Accuracy=47.455%, MSE=0.422332
[2023-08-17-10:07:16] [3/10] training 16.9%: Loss=0.745936, Accuracy=47.500%, MSE=0.425282
[2023-08-17-10:07:18] [3/10] training 18.3%: Loss=0.743621, Accuracy=47.692%, MSE=0.423479
[2023-08-17-10:07:20] [3/10] training 19.7%: Loss=0.739289, Accuracy=48.143%, MSE=0.420414
[2023-08-17-10:07:23] [3/10] training 21.1%: Loss=0.741881, Accuracy=47.467%, MSE=0.424618
[2023-08-17-10:07:25] [3/10] training 22.5%: Loss=0.738504, Accuracy=46.938%, MSE=0.423662
[2023-08-17-10:07:27] [3/10] training 23.9%: Loss=0.731489, Accuracy=46.941%, MSE=0.420135
[2023-08-17-10:07:30] [3/10] training 25.4%: Loss=0.725316, Accuracy=46.889%, MSE=0.416948
[2023-08-17-10:07:32] [3/10] training 26.8%: Loss=0.721049, Accuracy=47.105%, MSE=0.415225
[2023-08-17-10:07:34] [3/10] training 28.2%: Loss=0.729833, Accuracy=47.050%, MSE=0.419288
[2023-08-17-10:07:37] [3/10] training 29.6%: Loss=0.736054, Accuracy=47.429%, MSE=0.419528
[2023-08-17-10:07:39] [3/10] training 31.0%: Loss=0.750233, Accuracy=47.409%, MSE=0.423692
[2023-08-17-10:07:41] [3/10] training 32.4%: Loss=0.754102, Accuracy=47.913%, MSE=0.422319
[2023-08-17-10:07:44] [3/10] training 33.8%: Loss=0.755588, Accuracy=48.333%, MSE=0.420887
[2023-08-17-10:07:46] [3/10] training 35.2%: Loss=0.755828, Accuracy=48.480%, MSE=0.420482
[2023-08-17-10:07:49] [3/10] training 36.6%: Loss=0.757512, Accuracy=48.154%, MSE=0.422059
[2023-08-17-10:07:51] [3/10] training 38.0%: Loss=0.757169, Accuracy=47.852%, MSE=0.423005
[2023-08-17-10:07:54] [3/10] training 39.4%: Loss=0.753864, Accuracy=47.679%, MSE=0.422447
[2023-08-17-10:07:56] [3/10] training 40.8%: Loss=0.749761, Accuracy=47.103%, MSE=0.422094
[2023-08-17-10:07:58] [3/10] training 42.3%: Loss=0.743732, Accuracy=46.933%, MSE=0.419564
[2023-08-17-10:08:01] [3/10] training 43.7%: Loss=0.747534, Accuracy=47.032%, MSE=0.418871
[2023-08-17-10:08:03] [3/10] training 45.1%: Loss=0.747486, Accuracy=47.031%, MSE=0.419577
[2023-08-17-10:08:05] [3/10] training 46.5%: Loss=0.746551, Accuracy=47.091%, MSE=0.41892
[2023-08-17-10:08:07] [3/10] training 47.9%: Loss=0.742946, Accuracy=47.147%, MSE=0.416826
[2023-08-17-10:08:10] [3/10] training 49.3%: Loss=0.741702, Accuracy=46.829%, MSE=0.416797
[2023-08-17-10:08:12] [3/10] training 50.7%: Loss=0.739711, Accuracy=46.722%, MSE=0.416112
[2023-08-17-10:08:14] [3/10] training 52.1%: Loss=0.736704, Accuracy=46.703%, MSE=0.41499
[2023-08-17-10:08:16] [3/10] training 53.5%: Loss=0.733963, Accuracy=46.658%, MSE=0.413472
[2023-08-17-10:08:19] [3/10] training 54.9%: Loss=0.73254, Accuracy=46.538%, MSE=0.412904
[2023-08-17-10:08:21] [3/10] training 56.3%: Loss=0.730275, Accuracy=46.425%, MSE=0.41143
[2023-08-17-10:08:24] [3/10] training 57.7%: Loss=0.728921, Accuracy=46.488%, MSE=0.410483
[2023-08-17-10:08:26] [3/10] training 59.2%: Loss=0.726439, Accuracy=46.595%, MSE=0.408862
[2023-08-17-10:08:28] [3/10] training 60.6%: Loss=0.723592, Accuracy=46.651%, MSE=0.407172
[2023-08-17-10:08:31] [3/10] training 62.0%: Loss=0.721249, Accuracy=46.659%, MSE=0.405818
[2023-08-17-10:08:33] [3/10] training 63.4%: Loss=0.719575, Accuracy=46.556%, MSE=0.405137
[2023-08-17-10:08:35] [3/10] training 64.8%: Loss=0.718343, Accuracy=46.457%, MSE=0.404611
[2023-08-17-10:08:37] [3/10] training 66.2%: Loss=0.718471, Accuracy=46.319%, MSE=0.404842
[2023-08-17-10:08:39] [3/10] training 67.6%: Loss=0.71688, Accuracy=46.354%, MSE=0.403974
[2023-08-17-10:08:42] [3/10] training 69.0%: Loss=0.715198, Accuracy=46.265%, MSE=0.40337
[2023-08-17-10:08:44] [3/10] training 70.4%: Loss=0.712752, Accuracy=46.420%, MSE=0.401571
[2023-08-17-10:08:46] [3/10] training 71.8%: Loss=0.711167, Accuracy=46.549%, MSE=0.400539
[2023-08-17-10:08:49] [3/10] training 73.2%: Loss=0.70867, Accuracy=46.712%, MSE=0.398783
[2023-08-17-10:08:51] [3/10] training 74.6%: Loss=0.707235, Accuracy=46.774%, MSE=0.397908
[2023-08-17-10:08:53] [3/10] training 76.1%: Loss=0.705855, Accuracy=46.704%, MSE=0.397415
[2023-08-17-10:08:55] [3/10] training 77.5%: Loss=0.703888, Accuracy=46.764%, MSE=0.396214
[2023-08-17-10:08:57] [3/10] training 78.9%: Loss=0.702711, Accuracy=46.804%, MSE=0.395392
[2023-08-17-10:09:00] [3/10] training 80.3%: Loss=0.701707, Accuracy=46.895%, MSE=0.394689
[2023-08-17-10:09:02] [3/10] training 81.7%: Loss=0.700449, Accuracy=46.966%, MSE=0.393848
[2023-08-17-10:09:04] [3/10] training 83.1%: Loss=0.697962, Accuracy=47.102%, MSE=0.392159
[2023-08-17-10:09:07] [3/10] training 84.5%: Loss=0.696202, Accuracy=47.133%, MSE=0.391208
[2023-08-17-10:09:09] [3/10] training 85.9%: Loss=0.695082, Accuracy=47.016%, MSE=0.391039
[2023-08-17-10:09:12] [3/10] training 87.3%: Loss=0.692706, Accuracy=47.194%, MSE=0.389435
[2023-08-17-10:09:14] [3/10] training 88.7%: Loss=0.690829, Accuracy=47.333%, MSE=0.388067
[2023-08-17-10:09:17] [3/10] training 90.1%: Loss=0.689448, Accuracy=47.438%, MSE=0.387141
[2023-08-17-10:09:19] [3/10] training 91.5%: Loss=0.687356, Accuracy=47.585%, MSE=0.385531
[2023-08-17-10:09:21] [3/10] training 93.0%: Loss=0.68538, Accuracy=47.682%, MSE=0.384077
[2023-08-17-10:09:23] [3/10] training 94.4%: Loss=0.684288, Accuracy=47.731%, MSE=0.383299
[2023-08-17-10:09:26] [3/10] training 95.8%: Loss=0.682972, Accuracy=47.824%, MSE=0.382427
[2023-08-17-10:09:27] [3/10] training 97.2%: Loss=0.681406, Accuracy=47.855%, MSE=0.381416
[2023-08-17-10:09:30] [3/10] training 98.6%: Loss=0.679842, Accuracy=47.971%, MSE=0.380429
[2023-08-17-10:09:42] Finished Epoch 3/10: Loss=4.68583, Accuracy=49.200%, MSE=0.499902, Precision=0.517445, Recall=9.77152e-05, F1=0.000195393, AUPR=0.488128
[2023-08-17-10:09:42] Saving model to ./models/guo_0_1_tt_partitions_epoch03.sav
[2023-08-17-10:09:45] [4/10] training 1.4%: Loss=0.631931, Accuracy=48.000%, MSE=0.36118
[2023-08-17-10:09:47] [4/10] training 2.8%: Loss=0.61938, Accuracy=50.500%, MSE=0.35146
[2023-08-17-10:09:49] [4/10] training 4.2%: Loss=0.625096, Accuracy=47.333%, MSE=0.359793
[2023-08-17-10:09:52] [4/10] training 5.6%: Loss=0.622242, Accuracy=48.250%, MSE=0.356096
[2023-08-17-10:09:54] [4/10] training 7.0%: Loss=0.617161, Accuracy=50.000%, MSE=0.347173
[2023-08-17-10:09:56] [4/10] training 8.5%: Loss=0.605764, Accuracy=52.000%, MSE=0.335274
[2023-08-17-10:09:58] [4/10] training 9.9%: Loss=0.610038, Accuracy=52.429%, MSE=0.33493
[2023-08-17-10:10:01] [4/10] training 11.3%: Loss=0.612035, Accuracy=51.000%, MSE=0.338865
[2023-08-17-10:10:03] [4/10] training 12.7%: Loss=0.613059, Accuracy=50.667%, MSE=0.340596
[2023-08-17-10:10:05] [4/10] training 14.1%: Loss=0.610608, Accuracy=50.900%, MSE=0.33806
[2023-08-17-10:10:08] [4/10] training 15.5%: Loss=0.616578, Accuracy=50.364%, MSE=0.343481
[2023-08-17-10:10:10] [4/10] training 16.9%: Loss=0.617868, Accuracy=50.000%, MSE=0.34573
[2023-08-17-10:10:12] [4/10] training 18.3%: Loss=0.618553, Accuracy=49.385%, MSE=0.347174
[2023-08-17-10:10:15] [4/10] training 19.7%: Loss=0.620345, Accuracy=49.071%, MSE=0.349749
[2023-08-17-10:10:17] [4/10] training 21.1%: Loss=0.617627, Accuracy=49.333%, MSE=0.347854
[2023-08-17-10:10:19] [4/10] training 22.5%: Loss=0.613719, Accuracy=49.750%, MSE=0.343958
[2023-08-17-10:10:22] [4/10] training 23.9%: Loss=0.609713, Accuracy=50.412%, MSE=0.340321
[2023-08-17-10:10:24] [4/10] training 25.4%: Loss=0.606682, Accuracy=50.889%, MSE=0.337544
[2023-08-17-10:10:26] [4/10] training 26.8%: Loss=0.606462, Accuracy=50.895%, MSE=0.337581
[2023-08-17-10:10:29] [4/10] training 28.2%: Loss=0.603375, Accuracy=51.400%, MSE=0.334691
[2023-08-17-10:10:31] [4/10] training 29.6%: Loss=0.603577, Accuracy=51.333%, MSE=0.335157
[2023-08-17-10:10:33] [4/10] training 31.0%: Loss=0.603895, Accuracy=51.182%, MSE=0.336099
[2023-08-17-10:10:36] [4/10] training 32.4%: Loss=0.602288, Accuracy=51.217%, MSE=0.335312
[2023-08-17-10:10:38] [4/10] training 33.8%: Loss=0.602856, Accuracy=51.042%, MSE=0.335886
[2023-08-17-10:10:40] [4/10] training 35.2%: Loss=0.600046, Accuracy=51.240%, MSE=0.33324
[2023-08-17-10:10:43] [4/10] training 36.6%: Loss=0.599611, Accuracy=51.308%, MSE=0.332964
[2023-08-17-10:10:45] [4/10] training 38.0%: Loss=0.599682, Accuracy=51.185%, MSE=0.333517
[2023-08-17-10:10:47] [4/10] training 39.4%: Loss=0.600455, Accuracy=51.179%, MSE=0.33458
[2023-08-17-10:10:50] [4/10] training 40.8%: Loss=0.599317, Accuracy=51.345%, MSE=0.333711
[2023-08-17-10:10:52] [4/10] training 42.3%: Loss=0.599138, Accuracy=51.367%, MSE=0.333951
[2023-08-17-10:10:54] [4/10] training 43.7%: Loss=0.599851, Accuracy=51.323%, MSE=0.334597
[2023-08-17-10:10:56] [4/10] training 45.1%: Loss=0.600002, Accuracy=51.531%, MSE=0.334104
[2023-08-17-10:10:59] [4/10] training 46.5%: Loss=0.599054, Accuracy=51.667%, MSE=0.333345
[2023-08-17-10:11:01] [4/10] training 47.9%: Loss=0.599484, Accuracy=51.647%, MSE=0.333733
[2023-08-17-10:11:03] [4/10] training 49.3%: Loss=0.598729, Accuracy=51.771%, MSE=0.333126
[2023-08-17-10:11:05] [4/10] training 50.7%: Loss=0.596821, Accuracy=51.944%, MSE=0.331779
[2023-08-17-10:11:07] [4/10] training 52.1%: Loss=0.596271, Accuracy=51.919%, MSE=0.331763
[2023-08-17-10:11:10] [4/10] training 53.5%: Loss=0.595631, Accuracy=52.053%, MSE=0.331145
[2023-08-17-10:11:12] [4/10] training 54.9%: Loss=0.595414, Accuracy=52.179%, MSE=0.330836
[2023-08-17-10:11:15] [4/10] training 56.3%: Loss=0.595938, Accuracy=52.025%, MSE=0.331634
[2023-08-17-10:11:18] [4/10] training 57.7%: Loss=0.595306, Accuracy=52.098%, MSE=0.331164
[2023-08-17-10:11:20] [4/10] training 59.2%: Loss=0.595698, Accuracy=51.976%, MSE=0.331542
[2023-08-17-10:11:22] [4/10] training 60.6%: Loss=0.592841, Accuracy=52.279%, MSE=0.328934
[2023-08-17-10:11:24] [4/10] training 62.0%: Loss=0.590925, Accuracy=52.500%, MSE=0.327158
[2023-08-17-10:11:27] [4/10] training 63.4%: Loss=0.590988, Accuracy=52.489%, MSE=0.327267
[2023-08-17-10:11:29] [4/10] training 64.8%: Loss=0.589623, Accuracy=52.587%, MSE=0.326211
[2023-08-17-10:11:31] [4/10] training 66.2%: Loss=0.589662, Accuracy=52.660%, MSE=0.326339
[2023-08-17-10:11:33] [4/10] training 67.6%: Loss=0.590478, Accuracy=52.542%, MSE=0.327108
[2023-08-17-10:11:36] [4/10] training 69.0%: Loss=0.590136, Accuracy=52.490%, MSE=0.327282
[2023-08-17-10:11:38] [4/10] training 70.4%: Loss=0.590154, Accuracy=52.480%, MSE=0.327614
[2023-08-17-10:11:40] [4/10] training 71.8%: Loss=0.589887, Accuracy=52.510%, MSE=0.327488
[2023-08-17-10:11:43] [4/10] training 73.2%: Loss=0.588053, Accuracy=52.788%, MSE=0.325802
[2023-08-17-10:11:45] [4/10] training 74.6%: Loss=0.587922, Accuracy=52.755%, MSE=0.325845
[2023-08-17-10:11:47] [4/10] training 76.1%: Loss=0.586655, Accuracy=52.907%, MSE=0.324779
[2023-08-17-10:11:49] [4/10] training 77.5%: Loss=0.58667, Accuracy=52.964%, MSE=0.324791
[2023-08-17-10:11:52] [4/10] training 78.9%: Loss=0.585139, Accuracy=53.089%, MSE=0.323567
[2023-08-17-10:11:54] [4/10] training 80.3%: Loss=0.585564, Accuracy=52.982%, MSE=0.324192
[2023-08-17-10:11:56] [4/10] training 81.7%: Loss=0.584376, Accuracy=53.172%, MSE=0.323228
[2023-08-17-10:11:58] [4/10] training 83.1%: Loss=0.583597, Accuracy=53.169%, MSE=0.32282
[2023-08-17-10:12:01] [4/10] training 84.5%: Loss=0.583404, Accuracy=53.100%, MSE=0.322874
[2023-08-17-10:12:03] [4/10] training 85.9%: Loss=0.582852, Accuracy=53.098%, MSE=0.322541
[2023-08-17-10:12:06] [4/10] training 87.3%: Loss=0.583407, Accuracy=52.952%, MSE=0.323394
[2023-08-17-10:12:08] [4/10] training 88.7%: Loss=0.583198, Accuracy=52.905%, MSE=0.323411
[2023-08-17-10:12:10] [4/10] training 90.1%: Loss=0.583162, Accuracy=52.844%, MSE=0.323691
[2023-08-17-10:12:13] [4/10] training 91.5%: Loss=0.583029, Accuracy=52.785%, MSE=0.323817
[2023-08-17-10:12:15] [4/10] training 93.0%: Loss=0.582614, Accuracy=52.788%, MSE=0.323635
[2023-08-17-10:12:17] [4/10] training 94.4%: Loss=0.581981, Accuracy=52.851%, MSE=0.323192
[2023-08-17-10:12:19] [4/10] training 95.8%: Loss=0.582315, Accuracy=52.794%, MSE=0.323572
[2023-08-17-10:12:22] [4/10] training 97.2%: Loss=0.581412, Accuracy=52.855%, MSE=0.322843
[2023-08-17-10:12:24] [4/10] training 98.6%: Loss=0.581235, Accuracy=52.871%, MSE=0.322557
[2023-08-17-10:12:36] Finished Epoch 4/10: Loss=4.39569, Accuracy=49.200%, MSE=0.499739, Precision=0.427514, Recall=0.000261397, F1=0.000522475, AUPR=0.454277
[2023-08-17-10:12:36] Saving model to ./models/guo_0_1_tt_partitions_epoch04.sav
[2023-08-17-10:12:39] [5/10] training 1.4%: Loss=0.553006, Accuracy=49.000%, MSE=0.323688
[2023-08-17-10:12:41] [5/10] training 2.8%: Loss=0.547127, Accuracy=49.500%, MSE=0.312001
[2023-08-17-10:12:44] [5/10] training 4.2%: Loss=0.529138, Accuracy=53.000%, MSE=0.293894
[2023-08-17-10:12:46] [5/10] training 5.6%: Loss=0.530291, Accuracy=53.750%, MSE=0.293986
[2023-08-17-10:12:49] [5/10] training 7.0%: Loss=0.534695, Accuracy=53.200%, MSE=0.301447
[2023-08-17-10:12:51] [5/10] training 8.5%: Loss=0.530759, Accuracy=53.833%, MSE=0.297248
[2023-08-17-10:12:54] [5/10] training 9.9%: Loss=0.522793, Accuracy=55.571%, MSE=0.289178
[2023-08-17-10:12:56] [5/10] training 11.3%: Loss=0.51813, Accuracy=56.000%, MSE=0.28533
[2023-08-17-10:12:58] [5/10] training 12.7%: Loss=0.511862, Accuracy=57.111%, MSE=0.279917
[2023-08-17-10:13:00] [5/10] training 14.1%: Loss=0.512148, Accuracy=57.800%, MSE=0.277226
[2023-08-17-10:13:03] [5/10] training 15.5%: Loss=0.51218, Accuracy=57.818%, MSE=0.277265
[2023-08-17-10:13:05] [5/10] training 16.9%: Loss=0.513276, Accuracy=57.583%, MSE=0.277782
[2023-08-17-10:13:08] [5/10] training 18.3%: Loss=0.512275, Accuracy=58.000%, MSE=0.276669
[2023-08-17-10:13:10] [5/10] training 19.7%: Loss=0.511419, Accuracy=57.786%, MSE=0.276462
[2023-08-17-10:13:12] [5/10] training 21.1%: Loss=0.512869, Accuracy=57.400%, MSE=0.278001
[2023-08-17-10:13:15] [5/10] training 22.5%: Loss=0.512553, Accuracy=57.625%, MSE=0.276996
[2023-08-17-10:13:17] [5/10] training 23.9%: Loss=0.513299, Accuracy=57.412%, MSE=0.277576
[2023-08-17-10:13:20] [5/10] training 25.4%: Loss=0.51273, Accuracy=57.500%, MSE=0.276832
[2023-08-17-10:13:22] [5/10] training 26.8%: Loss=0.515079, Accuracy=57.105%, MSE=0.278606
[2023-08-17-10:13:24] [5/10] training 28.2%: Loss=0.51751, Accuracy=56.850%, MSE=0.280836
[2023-08-17-10:13:26] [5/10] training 29.6%: Loss=0.521548, Accuracy=56.429%, MSE=0.284596
[2023-08-17-10:13:29] [5/10] training 31.0%: Loss=0.524268, Accuracy=56.273%, MSE=0.286483
[2023-08-17-10:13:31] [5/10] training 32.4%: Loss=0.523272, Accuracy=56.609%, MSE=0.285332
[2023-08-17-10:13:33] [5/10] training 33.8%: Loss=0.521083, Accuracy=56.958%, MSE=0.283166
[2023-08-17-10:13:35] [5/10] training 35.2%: Loss=0.51984, Accuracy=57.280%, MSE=0.28204
[2023-08-17-10:13:38] [5/10] training 36.6%: Loss=0.518382, Accuracy=57.615%, MSE=0.280453
[2023-08-17-10:13:40] [5/10] training 38.0%: Loss=0.513795, Accuracy=58.333%, MSE=0.275807
[2023-08-17-10:13:43] [5/10] training 39.4%: Loss=0.513039, Accuracy=58.500%, MSE=0.274671
[2023-08-17-10:13:45] [5/10] training 40.8%: Loss=0.512244, Accuracy=58.724%, MSE=0.273879
[2023-08-17-10:13:47] [5/10] training 42.3%: Loss=0.512369, Accuracy=58.833%, MSE=0.273592
[2023-08-17-10:13:49] [5/10] training 43.7%: Loss=0.512246, Accuracy=59.032%, MSE=0.27334
[2023-08-17-10:13:51] [5/10] training 45.1%: Loss=0.512196, Accuracy=59.156%, MSE=0.273327
[2023-08-17-10:13:54] [5/10] training 46.5%: Loss=0.511532, Accuracy=59.242%, MSE=0.272699
[2023-08-17-10:13:56] [5/10] training 47.9%: Loss=0.510964, Accuracy=59.176%, MSE=0.272265
[2023-08-17-10:13:59] [5/10] training 49.3%: Loss=0.509298, Accuracy=59.371%, MSE=0.270812
[2023-08-17-10:14:01] [5/10] training 50.7%: Loss=0.509852, Accuracy=59.417%, MSE=0.271346
[2023-08-17-10:14:03] [5/10] training 52.1%: Loss=0.509621, Accuracy=59.595%, MSE=0.270868
[2023-08-17-10:14:05] [5/10] training 53.5%: Loss=0.50815, Accuracy=59.711%, MSE=0.26954
[2023-08-17-10:14:07] [5/10] training 54.9%: Loss=0.50788, Accuracy=59.846%, MSE=0.268764
[2023-08-17-10:14:10] [5/10] training 56.3%: Loss=0.506203, Accuracy=60.075%, MSE=0.267269
[2023-08-17-10:14:12] [5/10] training 57.7%: Loss=0.504851, Accuracy=60.268%, MSE=0.266045
[2023-08-17-10:14:15] [5/10] training 59.2%: Loss=0.504801, Accuracy=60.238%, MSE=0.266062
[2023-08-17-10:14:17] [5/10] training 60.6%: Loss=0.504078, Accuracy=60.419%, MSE=0.265317
[2023-08-17-10:14:19] [5/10] training 62.0%: Loss=0.503565, Accuracy=60.545%, MSE=0.264571
[2023-08-17-10:14:21] [5/10] training 63.4%: Loss=0.502645, Accuracy=60.667%, MSE=0.263789
[2023-08-17-10:14:24] [5/10] training 64.8%: Loss=0.502254, Accuracy=60.609%, MSE=0.263635
[2023-08-17-10:14:26] [5/10] training 66.2%: Loss=0.501597, Accuracy=60.681%, MSE=0.26299
[2023-08-17-10:14:29] [5/10] training 67.6%: Loss=0.50091, Accuracy=60.687%, MSE=0.262578
[2023-08-17-10:14:31] [5/10] training 69.0%: Loss=0.500219, Accuracy=60.714%, MSE=0.261982
[2023-08-17-10:14:33] [5/10] training 70.4%: Loss=0.49965, Accuracy=60.940%, MSE=0.261147
[2023-08-17-10:14:35] [5/10] training 71.8%: Loss=0.498927, Accuracy=61.157%, MSE=0.260278
[2023-08-17-10:14:38] [5/10] training 73.2%: Loss=0.498757, Accuracy=61.231%, MSE=0.26002
[2023-08-17-10:14:40] [5/10] training 74.6%: Loss=0.497679, Accuracy=61.415%, MSE=0.258938
[2023-08-17-10:14:42] [5/10] training 76.1%: Loss=0.496884, Accuracy=61.537%, MSE=0.258138
[2023-08-17-10:14:45] [5/10] training 77.5%: Loss=0.495538, Accuracy=61.782%, MSE=0.257015
[2023-08-17-10:14:47] [5/10] training 78.9%: Loss=0.494872, Accuracy=61.911%, MSE=0.256305
[2023-08-17-10:14:49] [5/10] training 80.3%: Loss=0.493664, Accuracy=62.035%, MSE=0.255213
[2023-08-17-10:14:51] [5/10] training 81.7%: Loss=0.494039, Accuracy=62.086%, MSE=0.255548
[2023-08-17-10:14:54] [5/10] training 83.1%: Loss=0.494358, Accuracy=62.119%, MSE=0.25579
[2023-08-17-10:14:56] [5/10] training 84.5%: Loss=0.494868, Accuracy=62.100%, MSE=0.256312
[2023-08-17-10:14:58] [5/10] training 85.9%: Loss=0.495258, Accuracy=62.049%, MSE=0.25669
[2023-08-17-10:15:00] [5/10] training 87.3%: Loss=0.495763, Accuracy=61.968%, MSE=0.257363
[2023-08-17-10:15:03] [5/10] training 88.7%: Loss=0.496335, Accuracy=61.873%, MSE=0.257843
[2023-08-17-10:15:05] [5/10] training 90.1%: Loss=0.496, Accuracy=61.875%, MSE=0.257744
[2023-08-17-10:15:07] [5/10] training 91.5%: Loss=0.495543, Accuracy=61.877%, MSE=0.257428
[2023-08-17-10:15:10] [5/10] training 93.0%: Loss=0.495077, Accuracy=61.909%, MSE=0.257027
[2023-08-17-10:15:12] [5/10] training 94.4%: Loss=0.494224, Accuracy=62.045%, MSE=0.256237
[2023-08-17-10:15:14] [5/10] training 95.8%: Loss=0.493891, Accuracy=62.118%, MSE=0.255831
[2023-08-17-10:15:16] [5/10] training 97.2%: Loss=0.493861, Accuracy=62.174%, MSE=0.255736
[2023-08-17-10:15:18] [5/10] training 98.6%: Loss=0.493692, Accuracy=62.229%, MSE=0.255621
[2023-08-17-10:15:30] Finished Epoch 5/10: Loss=3.51794, Accuracy=49.200%, MSE=0.492533, Precision=0.384983, Recall=0.00870345, F1=0.0170221, AUPR=0.441298
[2023-08-17-10:15:30] Saving model to ./models/guo_0_1_tt_partitions_epoch05.sav
[2023-08-17-10:15:33] [6/10] training 1.4%: Loss=0.486909, Accuracy=57.000%, MSE=0.267716
[2023-08-17-10:15:35] [6/10] training 2.8%: Loss=0.453511, Accuracy=65.000%, MSE=0.228229
[2023-08-17-10:15:38] [6/10] training 4.2%: Loss=0.467256, Accuracy=63.667%, MSE=0.240799
[2023-08-17-10:15:40] [6/10] training 5.6%: Loss=0.464247, Accuracy=64.000%, MSE=0.239594
[2023-08-17-10:15:42] [6/10] training 7.0%: Loss=0.451397, Accuracy=65.600%, MSE=0.226457
[2023-08-17-10:15:45] [6/10] training 8.5%: Loss=0.455185, Accuracy=65.333%, MSE=0.229264
[2023-08-17-10:15:47] [6/10] training 9.9%: Loss=0.468833, Accuracy=64.000%, MSE=0.242101
[2023-08-17-10:15:49] [6/10] training 11.3%: Loss=0.468585, Accuracy=63.375%, MSE=0.243294
[2023-08-17-10:15:52] [6/10] training 12.7%: Loss=0.465352, Accuracy=64.444%, MSE=0.240073
[2023-08-17-10:15:54] [6/10] training 14.1%: Loss=0.460771, Accuracy=65.000%, MSE=0.236045
[2023-08-17-10:15:57] [6/10] training 15.5%: Loss=0.460038, Accuracy=65.000%, MSE=0.235033
[2023-08-17-10:15:59] [6/10] training 16.9%: Loss=0.459074, Accuracy=65.167%, MSE=0.235063
[2023-08-17-10:16:01] [6/10] training 18.3%: Loss=0.457334, Accuracy=65.308%, MSE=0.23374
[2023-08-17-10:16:03] [6/10] training 19.7%: Loss=0.454533, Accuracy=65.714%, MSE=0.230819
[2023-08-17-10:16:05] [6/10] training 21.1%: Loss=0.454189, Accuracy=65.600%, MSE=0.231612
[2023-08-17-10:16:08] [6/10] training 22.5%: Loss=0.455733, Accuracy=65.312%, MSE=0.233762
[2023-08-17-10:16:10] [6/10] training 23.9%: Loss=0.458438, Accuracy=65.529%, MSE=0.233968
[2023-08-17-10:16:12] [6/10] training 25.4%: Loss=0.457142, Accuracy=66.167%, MSE=0.231339
[2023-08-17-10:16:15] [6/10] training 26.8%: Loss=0.459551, Accuracy=66.053%, MSE=0.23326
[2023-08-17-10:16:17] [6/10] training 28.2%: Loss=0.464914, Accuracy=65.100%, MSE=0.23887
[2023-08-17-10:16:20] [6/10] training 29.6%: Loss=0.468782, Accuracy=64.619%, MSE=0.242935
[2023-08-17-10:16:22] [6/10] training 31.0%: Loss=0.471649, Accuracy=64.045%, MSE=0.245833
[2023-08-17-10:16:24] [6/10] training 32.4%: Loss=0.472645, Accuracy=64.043%, MSE=0.246144
[2023-08-17-10:16:26] [6/10] training 33.8%: Loss=0.472848, Accuracy=63.958%, MSE=0.246291
[2023-08-17-10:16:28] [6/10] training 35.2%: Loss=0.475759, Accuracy=63.280%, MSE=0.249706
[2023-08-17-10:16:31] [6/10] training 36.6%: Loss=0.476131, Accuracy=63.115%, MSE=0.250311
[2023-08-17-10:16:33] [6/10] training 38.0%: Loss=0.47413, Accuracy=63.481%, MSE=0.248465
[2023-08-17-10:16:36] [6/10] training 39.4%: Loss=0.472177, Accuracy=63.929%, MSE=0.24622
[2023-08-17-10:16:38] [6/10] training 40.8%: Loss=0.469323, Accuracy=64.586%, MSE=0.242627
[2023-08-17-10:16:40] [6/10] training 42.3%: Loss=0.469456, Accuracy=64.767%, MSE=0.241854
[2023-08-17-10:16:43] [6/10] training 43.7%: Loss=0.471833, Accuracy=64.645%, MSE=0.243636
[2023-08-17-10:16:45] [6/10] training 45.1%: Loss=0.473242, Accuracy=64.531%, MSE=0.245183
[2023-08-17-10:16:47] [6/10] training 46.5%: Loss=0.47407, Accuracy=64.515%, MSE=0.245557
[2023-08-17-10:16:49] [6/10] training 47.9%: Loss=0.476516, Accuracy=64.088%, MSE=0.248234
[2023-08-17-10:16:52] [6/10] training 49.3%: Loss=0.479248, Accuracy=63.857%, MSE=0.250572
[2023-08-17-10:16:54] [6/10] training 50.7%: Loss=0.481846, Accuracy=63.472%, MSE=0.253318
[2023-08-17-10:16:56] [6/10] training 52.1%: Loss=0.479713, Accuracy=63.730%, MSE=0.25144
[2023-08-17-10:16:58] [6/10] training 53.5%: Loss=0.479962, Accuracy=63.684%, MSE=0.25192
[2023-08-17-10:17:01] [6/10] training 54.9%: Loss=0.479127, Accuracy=63.795%, MSE=0.250885
[2023-08-17-10:17:03] [6/10] training 56.3%: Loss=0.480249, Accuracy=63.600%, MSE=0.251956
[2023-08-17-10:17:06] [6/10] training 57.7%: Loss=0.480145, Accuracy=63.537%, MSE=0.25196
[2023-08-17-10:17:08] [6/10] training 59.2%: Loss=0.478956, Accuracy=63.714%, MSE=0.250819
[2023-08-17-10:17:10] [6/10] training 60.6%: Loss=0.478255, Accuracy=63.814%, MSE=0.25017
[2023-08-17-10:17:12] [6/10] training 62.0%: Loss=0.477548, Accuracy=63.955%, MSE=0.249217
[2023-08-17-10:17:15] [6/10] training 63.4%: Loss=0.476651, Accuracy=64.067%, MSE=0.248445
[2023-08-17-10:17:17] [6/10] training 64.8%: Loss=0.476959, Accuracy=64.065%, MSE=0.248479
[2023-08-17-10:17:19] [6/10] training 66.2%: Loss=0.476523, Accuracy=64.106%, MSE=0.247991
[2023-08-17-10:17:22] [6/10] training 67.6%: Loss=0.475035, Accuracy=64.208%, MSE=0.246817
[2023-08-17-10:17:24] [6/10] training 69.0%: Loss=0.474926, Accuracy=64.265%, MSE=0.246683
[2023-08-17-10:17:27] [6/10] training 70.4%: Loss=0.474459, Accuracy=64.360%, MSE=0.246324
[2023-08-17-10:17:29] [6/10] training 71.8%: Loss=0.474429, Accuracy=64.235%, MSE=0.246735
[2023-08-17-10:17:31] [6/10] training 73.2%: Loss=0.474277, Accuracy=64.250%, MSE=0.246465
[2023-08-17-10:17:33] [6/10] training 74.6%: Loss=0.474176, Accuracy=64.208%, MSE=0.246498
[2023-08-17-10:17:36] [6/10] training 76.1%: Loss=0.473432, Accuracy=64.296%, MSE=0.245843
[2023-08-17-10:17:38] [6/10] training 77.5%: Loss=0.473161, Accuracy=64.327%, MSE=0.245788
[2023-08-17-10:17:40] [6/10] training 78.9%: Loss=0.47232, Accuracy=64.339%, MSE=0.245286
[2023-08-17-10:17:43] [6/10] training 80.3%: Loss=0.472163, Accuracy=64.351%, MSE=0.245171
[2023-08-17-10:17:45] [6/10] training 81.7%: Loss=0.471483, Accuracy=64.397%, MSE=0.244719
[2023-08-17-10:17:47] [6/10] training 83.1%: Loss=0.470936, Accuracy=64.441%, MSE=0.244258
[2023-08-17-10:17:49] [6/10] training 84.5%: Loss=0.470522, Accuracy=64.417%, MSE=0.244217
[2023-08-17-10:17:52] [6/10] training 85.9%: Loss=0.471493, Accuracy=64.262%, MSE=0.245181
[2023-08-17-10:17:54] [6/10] training 87.3%: Loss=0.472244, Accuracy=64.065%, MSE=0.245944
[2023-08-17-10:17:56] [6/10] training 88.7%: Loss=0.472018, Accuracy=64.111%, MSE=0.245821
[2023-08-17-10:17:59] [6/10] training 90.1%: Loss=0.471285, Accuracy=64.109%, MSE=0.245327
[2023-08-17-10:18:01] [6/10] training 91.5%: Loss=0.471181, Accuracy=64.062%, MSE=0.245448
[2023-08-17-10:18:04] [6/10] training 93.0%: Loss=0.471091, Accuracy=64.030%, MSE=0.245589
[2023-08-17-10:18:06] [6/10] training 94.4%: Loss=0.47127, Accuracy=63.985%, MSE=0.245672
[2023-08-17-10:18:08] [6/10] training 95.8%: Loss=0.470051, Accuracy=64.147%, MSE=0.244596
[2023-08-17-10:18:10] [6/10] training 97.2%: Loss=0.470111, Accuracy=64.174%, MSE=0.244542
[2023-08-17-10:18:13] [6/10] training 98.6%: Loss=0.469693, Accuracy=64.257%, MSE=0.244157
[2023-08-17-10:18:25] Finished Epoch 6/10: Loss=2.8974, Accuracy=49.200%, MSE=0.492647, Precision=0.609903, Recall=0.0075492, F1=0.0149138, AUPR=0.580376
[2023-08-17-10:18:25] Saving model to ./models/guo_0_1_tt_partitions_epoch06.sav
[2023-08-17-10:18:27] [7/10] training 1.4%: Loss=0.448436, Accuracy=71.000%, MSE=0.218352
[2023-08-17-10:18:30] [7/10] training 2.8%: Loss=0.436663, Accuracy=69.000%, MSE=0.21708
[2023-08-17-10:18:32] [7/10] training 4.2%: Loss=0.488183, Accuracy=60.667%, MSE=0.272573
[2023-08-17-10:18:34] [7/10] training 5.6%: Loss=0.503908, Accuracy=60.750%, MSE=0.28212
[2023-08-17-10:18:36] [7/10] training 7.0%: Loss=0.523821, Accuracy=58.400%, MSE=0.301851
[2023-08-17-10:18:39] [7/10] training 8.5%: Loss=0.533265, Accuracy=57.333%, MSE=0.310541
[2023-08-17-10:18:41] [7/10] training 9.9%: Loss=0.525289, Accuracy=57.571%, MSE=0.304902
[2023-08-17-10:18:43] [7/10] training 11.3%: Loss=0.523288, Accuracy=57.125%, MSE=0.303136
[2023-08-17-10:18:45] [7/10] training 12.7%: Loss=0.520405, Accuracy=57.000%, MSE=0.300569
[2023-08-17-10:18:48] [7/10] training 14.1%: Loss=0.523237, Accuracy=56.000%, MSE=0.304162
[2023-08-17-10:18:50] [7/10] training 15.5%: Loss=0.51732, Accuracy=56.091%, MSE=0.299539
[2023-08-17-10:18:52] [7/10] training 16.9%: Loss=0.511576, Accuracy=56.833%, MSE=0.293938
[2023-08-17-10:18:54] [7/10] training 18.3%: Loss=0.510965, Accuracy=56.769%, MSE=0.294187
[2023-08-17-10:18:57] [7/10] training 19.7%: Loss=0.504274, Accuracy=58.000%, MSE=0.287599
[2023-08-17-10:18:59] [7/10] training 21.1%: Loss=0.498072, Accuracy=58.533%, MSE=0.282924
[2023-08-17-10:19:01] [7/10] training 22.5%: Loss=0.493983, Accuracy=59.063%, MSE=0.279066
[2023-08-17-10:19:04] [7/10] training 23.9%: Loss=0.490879, Accuracy=59.294%, MSE=0.276572
[2023-08-17-10:19:06] [7/10] training 25.4%: Loss=0.487127, Accuracy=59.833%, MSE=0.27298
[2023-08-17-10:19:08] [7/10] training 26.8%: Loss=0.48751, Accuracy=59.684%, MSE=0.273261
[2023-08-17-10:19:11] [7/10] training 28.2%: Loss=0.495169, Accuracy=59.100%, MSE=0.279306
[2023-08-17-10:19:13] [7/10] training 29.6%: Loss=0.502051, Accuracy=58.905%, MSE=0.283325
[2023-08-17-10:19:16] [7/10] training 31.0%: Loss=0.509062, Accuracy=58.636%, MSE=0.287086
[2023-08-17-10:19:18] [7/10] training 32.4%: Loss=0.514676, Accuracy=58.348%, MSE=0.290123
[2023-08-17-10:19:20] [7/10] training 33.8%: Loss=0.517208, Accuracy=58.292%, MSE=0.291897
[2023-08-17-10:19:23] [7/10] training 35.2%: Loss=0.517552, Accuracy=58.280%, MSE=0.292142
[2023-08-17-10:19:25] [7/10] training 36.6%: Loss=0.51687, Accuracy=58.538%, MSE=0.291034
[2023-08-17-10:19:27] [7/10] training 38.0%: Loss=0.513065, Accuracy=58.889%, MSE=0.2884
[2023-08-17-10:19:30] [7/10] training 39.4%: Loss=0.510543, Accuracy=59.036%, MSE=0.286898
[2023-08-17-10:19:32] [7/10] training 40.8%: Loss=0.507441, Accuracy=59.690%, MSE=0.282644
[2023-08-17-10:19:35] [7/10] training 42.3%: Loss=0.504769, Accuracy=60.167%, MSE=0.280055
[2023-08-17-10:19:37] [7/10] training 43.7%: Loss=0.507214, Accuracy=60.323%, MSE=0.27988
[2023-08-17-10:19:39] [7/10] training 45.1%: Loss=0.511026, Accuracy=60.219%, MSE=0.281044
[2023-08-17-10:19:42] [7/10] training 46.5%: Loss=0.515631, Accuracy=59.970%, MSE=0.28323
[2023-08-17-10:19:44] [7/10] training 47.9%: Loss=0.521653, Accuracy=59.794%, MSE=0.28549
[2023-08-17-10:19:46] [7/10] training 49.3%: Loss=0.524467, Accuracy=59.714%, MSE=0.286442
[2023-08-17-10:19:49] [7/10] training 50.7%: Loss=0.524737, Accuracy=60.028%, MSE=0.28553
[2023-08-17-10:19:51] [7/10] training 52.1%: Loss=0.525225, Accuracy=59.865%, MSE=0.286132
[2023-08-17-10:19:53] [7/10] training 53.5%: Loss=0.526635, Accuracy=59.842%, MSE=0.286802
[2023-08-17-10:19:55] [7/10] training 54.9%: Loss=0.527842, Accuracy=59.974%, MSE=0.286637
[2023-08-17-10:19:58] [7/10] training 56.3%: Loss=0.529817, Accuracy=60.250%, MSE=0.285454
[2023-08-17-10:20:00] [7/10] training 57.7%: Loss=0.534756, Accuracy=60.561%, MSE=0.284545
[2023-08-17-10:20:02] [7/10] training 59.2%: Loss=0.545775, Accuracy=60.500%, MSE=0.287313
[2023-08-17-10:20:05] [7/10] training 60.6%: Loss=0.55257, Accuracy=60.372%, MSE=0.290114
[2023-08-17-10:20:07] [7/10] training 62.0%: Loss=0.556287, Accuracy=60.227%, MSE=0.292481
[2023-08-17-10:20:09] [7/10] training 63.4%: Loss=0.557565, Accuracy=60.067%, MSE=0.294033
[2023-08-17-10:20:11] [7/10] training 64.8%: Loss=0.558175, Accuracy=59.848%, MSE=0.295472
[2023-08-17-10:20:14] [7/10] training 66.2%: Loss=0.558445, Accuracy=59.574%, MSE=0.296641
[2023-08-17-10:20:16] [7/10] training 67.6%: Loss=0.558405, Accuracy=59.250%, MSE=0.297753
[2023-08-17-10:20:18] [7/10] training 69.0%: Loss=0.558356, Accuracy=59.020%, MSE=0.298755
[2023-08-17-10:20:21] [7/10] training 70.4%: Loss=0.558782, Accuracy=58.580%, MSE=0.300187
[2023-08-17-10:20:23] [7/10] training 71.8%: Loss=0.558884, Accuracy=58.157%, MSE=0.301254
[2023-08-17-10:20:25] [7/10] training 73.2%: Loss=0.557407, Accuracy=58.231%, MSE=0.30058
[2023-08-17-10:20:28] [7/10] training 74.6%: Loss=0.556843, Accuracy=58.113%, MSE=0.300921
[2023-08-17-10:20:30] [7/10] training 76.1%: Loss=0.555662, Accuracy=58.037%, MSE=0.300415
[2023-08-17-10:20:33] [7/10] training 77.5%: Loss=0.554193, Accuracy=58.055%, MSE=0.299586
[2023-08-17-10:20:35] [7/10] training 78.9%: Loss=0.553044, Accuracy=57.946%, MSE=0.299319
[2023-08-17-10:20:37] [7/10] training 80.3%: Loss=0.551317, Accuracy=58.000%, MSE=0.298283
[2023-08-17-10:20:40] [7/10] training 81.7%: Loss=0.5508, Accuracy=57.897%, MSE=0.298657
[2023-08-17-10:20:42] [7/10] training 83.1%: Loss=0.550815, Accuracy=57.576%, MSE=0.299568
[2023-08-17-10:20:44] [7/10] training 84.5%: Loss=0.549612, Accuracy=57.683%, MSE=0.298728
[2023-08-17-10:20:47] [7/10] training 85.9%: Loss=0.54831, Accuracy=57.721%, MSE=0.297884
[2023-08-17-10:20:49] [7/10] training 87.3%: Loss=0.547665, Accuracy=57.629%, MSE=0.297939
[2023-08-17-10:20:51] [7/10] training 88.7%: Loss=0.54652, Accuracy=57.635%, MSE=0.297511
[2023-08-17-10:20:53] [7/10] training 90.1%: Loss=0.545412, Accuracy=57.609%, MSE=0.296889
[2023-08-17-10:20:56] [7/10] training 91.5%: Loss=0.544796, Accuracy=57.615%, MSE=0.296712
[2023-08-17-10:20:58] [7/10] training 93.0%: Loss=0.544275, Accuracy=57.667%, MSE=0.296549
[2023-08-17-10:21:00] [7/10] training 94.4%: Loss=0.543137, Accuracy=57.701%, MSE=0.29579
[2023-08-17-10:21:02] [7/10] training 95.8%: Loss=0.541996, Accuracy=57.765%, MSE=0.295001
[2023-08-17-10:21:04] [7/10] training 97.2%: Loss=0.541108, Accuracy=57.870%, MSE=0.294338
[2023-08-17-10:21:07] [7/10] training 98.6%: Loss=0.540187, Accuracy=57.929%, MSE=0.293709
[2023-08-17-10:21:19] Finished Epoch 7/10: Loss=3.77432, Accuracy=49.200%, MSE=0.498136, Precision=0.704816, Recall=0.00188111, F1=0.0037522, AUPR=0.606138
[2023-08-17-10:21:19] Saving model to ./models/guo_0_1_tt_partitions_epoch07.sav
[2023-08-17-10:21:21] [8/10] training 1.4%: Loss=0.459082, Accuracy=62.000%, MSE=0.233312
[2023-08-17-10:21:24] [8/10] training 2.8%: Loss=0.489358, Accuracy=58.000%, MSE=0.276931
[2023-08-17-10:21:26] [8/10] training 4.2%: Loss=0.489205, Accuracy=57.667%, MSE=0.275189
[2023-08-17-10:21:28] [8/10] training 5.6%: Loss=0.474874, Accuracy=60.750%, MSE=0.259332
[2023-08-17-10:21:31] [8/10] training 7.0%: Loss=0.481216, Accuracy=60.800%, MSE=0.261271
[2023-08-17-10:21:33] [8/10] training 8.5%: Loss=0.478317, Accuracy=61.667%, MSE=0.259276
[2023-08-17-10:21:35] [8/10] training 9.9%: Loss=0.472067, Accuracy=61.571%, MSE=0.255843
[2023-08-17-10:21:37] [8/10] training 11.3%: Loss=0.469712, Accuracy=61.375%, MSE=0.255749
[2023-08-17-10:21:40] [8/10] training 12.7%: Loss=0.464157, Accuracy=62.667%, MSE=0.249157
[2023-08-17-10:21:42] [8/10] training 14.1%: Loss=0.465681, Accuracy=61.900%, MSE=0.251494
[2023-08-17-10:21:44] [8/10] training 15.5%: Loss=0.464794, Accuracy=61.727%, MSE=0.25202
[2023-08-17-10:21:47] [8/10] training 16.9%: Loss=0.463829, Accuracy=61.667%, MSE=0.251824
[2023-08-17-10:21:49] [8/10] training 18.3%: Loss=0.462715, Accuracy=61.538%, MSE=0.251306
[2023-08-17-10:21:51] [8/10] training 19.7%: Loss=0.461125, Accuracy=61.500%, MSE=0.249972
[2023-08-17-10:21:53] [8/10] training 21.1%: Loss=0.461416, Accuracy=61.600%, MSE=0.250847
[2023-08-17-10:21:55] [8/10] training 22.5%: Loss=0.464743, Accuracy=61.250%, MSE=0.252983
[2023-08-17-10:21:57] [8/10] training 23.9%: Loss=0.463224, Accuracy=61.471%, MSE=0.251486
[2023-08-17-10:22:00] [8/10] training 25.4%: Loss=0.461275, Accuracy=61.722%, MSE=0.24981
[2023-08-17-10:22:02] [8/10] training 26.8%: Loss=0.462168, Accuracy=62.000%, MSE=0.24995
[2023-08-17-10:22:05] [8/10] training 28.2%: Loss=0.459272, Accuracy=62.350%, MSE=0.247069
[2023-08-17-10:22:07] [8/10] training 29.6%: Loss=0.456705, Accuracy=62.667%, MSE=0.244939
[2023-08-17-10:22:10] [8/10] training 31.0%: Loss=0.455145, Accuracy=62.773%, MSE=0.243681
[2023-08-17-10:22:12] [8/10] training 32.4%: Loss=0.452362, Accuracy=63.174%, MSE=0.240969
[2023-08-17-10:22:15] [8/10] training 33.8%: Loss=0.453123, Accuracy=63.042%, MSE=0.242052
[2023-08-17-10:22:17] [8/10] training 35.2%: Loss=0.451777, Accuracy=63.280%, MSE=0.240419
[2023-08-17-10:22:19] [8/10] training 36.6%: Loss=0.451234, Accuracy=63.269%, MSE=0.240137
[2023-08-17-10:22:22] [8/10] training 38.0%: Loss=0.452579, Accuracy=62.852%, MSE=0.242223
[2023-08-17-10:22:24] [8/10] training 39.4%: Loss=0.454559, Accuracy=62.464%, MSE=0.245024
[2023-08-17-10:22:26] [8/10] training 40.8%: Loss=0.455161, Accuracy=61.966%, MSE=0.246506
[2023-08-17-10:22:29] [8/10] training 42.3%: Loss=0.4548, Accuracy=61.767%, MSE=0.246514
[2023-08-17-10:22:31] [8/10] training 43.7%: Loss=0.454228, Accuracy=61.710%, MSE=0.246182
[2023-08-17-10:22:33] [8/10] training 45.1%: Loss=0.453159, Accuracy=61.937%, MSE=0.24503
[2023-08-17-10:22:36] [8/10] training 46.5%: Loss=0.451483, Accuracy=62.212%, MSE=0.243482
[2023-08-17-10:22:38] [8/10] training 47.9%: Loss=0.45071, Accuracy=62.588%, MSE=0.241832
[2023-08-17-10:22:41] [8/10] training 49.3%: Loss=0.45031, Accuracy=62.800%, MSE=0.241064
[2023-08-17-10:22:43] [8/10] training 50.7%: Loss=0.449622, Accuracy=63.028%, MSE=0.240276
[2023-08-17-10:22:45] [8/10] training 52.1%: Loss=0.449048, Accuracy=63.189%, MSE=0.239546
[2023-08-17-10:22:47] [8/10] training 53.5%: Loss=0.44815, Accuracy=63.395%, MSE=0.238253
[2023-08-17-10:22:50] [8/10] training 54.9%: Loss=0.447845, Accuracy=63.538%, MSE=0.237735
[2023-08-17-10:22:52] [8/10] training 56.3%: Loss=0.446882, Accuracy=63.750%, MSE=0.236806
[2023-08-17-10:22:54] [8/10] training 57.7%: Loss=0.44669, Accuracy=63.854%, MSE=0.236493
[2023-08-17-10:22:57] [8/10] training 59.2%: Loss=0.446758, Accuracy=64.119%, MSE=0.235629
[2023-08-17-10:22:59] [8/10] training 60.6%: Loss=0.449278, Accuracy=64.140%, MSE=0.236497
[2023-08-17-10:23:01] [8/10] training 62.0%: Loss=0.452807, Accuracy=63.909%, MSE=0.239075
[2023-08-17-10:23:04] [8/10] training 63.4%: Loss=0.4556, Accuracy=63.711%, MSE=0.241312
[2023-08-17-10:23:07] [8/10] training 64.8%: Loss=0.455154, Accuracy=63.804%, MSE=0.240889
[2023-08-17-10:23:09] [8/10] training 66.2%: Loss=0.454568, Accuracy=63.894%, MSE=0.240573
[2023-08-17-10:23:12] [8/10] training 67.6%: Loss=0.454553, Accuracy=63.854%, MSE=0.240631
[2023-08-17-10:23:14] [8/10] training 69.0%: Loss=0.454073, Accuracy=63.898%, MSE=0.240361
[2023-08-17-10:23:16] [8/10] training 70.4%: Loss=0.454605, Accuracy=63.820%, MSE=0.241034
[2023-08-17-10:23:18] [8/10] training 71.8%: Loss=0.455237, Accuracy=63.667%, MSE=0.24199
[2023-08-17-10:23:20] [8/10] training 73.2%: Loss=0.455541, Accuracy=63.673%, MSE=0.241977
[2023-08-17-10:23:23] [8/10] training 74.6%: Loss=0.455699, Accuracy=63.660%, MSE=0.242098
[2023-08-17-10:23:25] [8/10] training 76.1%: Loss=0.45535, Accuracy=63.815%, MSE=0.24157
[2023-08-17-10:23:27] [8/10] training 77.5%: Loss=0.455277, Accuracy=63.891%, MSE=0.241272
[2023-08-17-10:23:30] [8/10] training 78.9%: Loss=0.455146, Accuracy=63.893%, MSE=0.241089
[2023-08-17-10:23:32] [8/10] training 80.3%: Loss=0.455868, Accuracy=63.789%, MSE=0.24192
[2023-08-17-10:23:34] [8/10] training 81.7%: Loss=0.455086, Accuracy=63.983%, MSE=0.24104
[2023-08-17-10:23:36] [8/10] training 83.1%: Loss=0.454888, Accuracy=64.068%, MSE=0.240925
[2023-08-17-10:23:38] [8/10] training 84.5%: Loss=0.454496, Accuracy=64.133%, MSE=0.240798
[2023-08-17-10:23:41] [8/10] training 85.9%: Loss=0.454157, Accuracy=64.164%, MSE=0.240728
[2023-08-17-10:23:42] [8/10] training 87.3%: Loss=0.453602, Accuracy=64.258%, MSE=0.24027
[2023-08-17-10:23:45] [8/10] training 88.7%: Loss=0.452826, Accuracy=64.429%, MSE=0.239578
[2023-08-17-10:23:47] [8/10] training 90.1%: Loss=0.452242, Accuracy=64.516%, MSE=0.238866
[2023-08-17-10:23:50] [8/10] training 91.5%: Loss=0.45113, Accuracy=64.708%, MSE=0.237866
[2023-08-17-10:23:52] [8/10] training 93.0%: Loss=0.450227, Accuracy=64.848%, MSE=0.237093
[2023-08-17-10:23:54] [8/10] training 94.4%: Loss=0.449596, Accuracy=64.955%, MSE=0.236534
[2023-08-17-10:23:56] [8/10] training 95.8%: Loss=0.449224, Accuracy=64.926%, MSE=0.236529
[2023-08-17-10:23:58] [8/10] training 97.2%: Loss=0.449303, Accuracy=64.855%, MSE=0.236685
[2023-08-17-10:24:01] [8/10] training 98.6%: Loss=0.449691, Accuracy=64.800%, MSE=0.23716
[2023-08-17-10:24:13] Finished Epoch 8/10: Loss=3.51284, Accuracy=49.200%, MSE=0.497055, Precision=0.489219, Recall=0.00300419, F1=0.0059717, AUPR=0.533594
[2023-08-17-10:24:13] Saving model to ./models/guo_0_1_tt_partitions_epoch08.sav
[2023-08-17-10:24:16] [9/10] training 1.4%: Loss=0.401099, Accuracy=72.000%, MSE=0.199022
[2023-08-17-10:24:18] [9/10] training 2.8%: Loss=0.407091, Accuracy=71.000%, MSE=0.205442
[2023-08-17-10:24:20] [9/10] training 4.2%: Loss=0.422744, Accuracy=70.333%, MSE=0.215235
[2023-08-17-10:24:22] [9/10] training 5.6%: Loss=0.417938, Accuracy=72.250%, MSE=0.205012
[2023-08-17-10:24:24] [9/10] training 7.0%: Loss=0.406194, Accuracy=72.800%, MSE=0.196382
[2023-08-17-10:24:26] [9/10] training 8.5%: Loss=0.405422, Accuracy=73.333%, MSE=0.194581
[2023-08-17-10:24:29] [9/10] training 9.9%: Loss=0.408048, Accuracy=72.714%, MSE=0.199334
[2023-08-17-10:24:31] [9/10] training 11.3%: Loss=0.408878, Accuracy=72.250%, MSE=0.200563
[2023-08-17-10:24:33] [9/10] training 12.7%: Loss=0.404434, Accuracy=72.667%, MSE=0.197087
[2023-08-17-10:24:35] [9/10] training 14.1%: Loss=0.406393, Accuracy=72.600%, MSE=0.199166
[2023-08-17-10:24:38] [9/10] training 15.5%: Loss=0.413695, Accuracy=71.273%, MSE=0.207667
[2023-08-17-10:24:40] [9/10] training 16.9%: Loss=0.416267, Accuracy=70.667%, MSE=0.210839
[2023-08-17-10:24:42] [9/10] training 18.3%: Loss=0.417389, Accuracy=70.385%, MSE=0.212774
[2023-08-17-10:24:44] [9/10] training 19.7%: Loss=0.421565, Accuracy=69.714%, MSE=0.215967
[2023-08-17-10:24:47] [9/10] training 21.1%: Loss=0.426725, Accuracy=69.200%, MSE=0.219668
[2023-08-17-10:24:49] [9/10] training 22.5%: Loss=0.43852, Accuracy=68.437%, MSE=0.228744
[2023-08-17-10:24:52] [9/10] training 23.9%: Loss=0.447329, Accuracy=67.529%, MSE=0.235948
[2023-08-17-10:24:54] [9/10] training 25.4%: Loss=0.45061, Accuracy=67.111%, MSE=0.238854
[2023-08-17-10:24:56] [9/10] training 26.8%: Loss=0.449698, Accuracy=66.947%, MSE=0.238287
[2023-08-17-10:24:58] [9/10] training 28.2%: Loss=0.451426, Accuracy=66.200%, MSE=0.240861
[2023-08-17-10:25:01] [9/10] training 29.6%: Loss=0.450669, Accuracy=66.190%, MSE=0.240533
[2023-08-17-10:25:03] [9/10] training 31.0%: Loss=0.450642, Accuracy=65.909%, MSE=0.241507
[2023-08-17-10:25:06] [9/10] training 32.4%: Loss=0.449267, Accuracy=66.000%, MSE=0.240078
[2023-08-17-10:25:08] [9/10] training 33.8%: Loss=0.449749, Accuracy=65.792%, MSE=0.240909
[2023-08-17-10:25:10] [9/10] training 35.2%: Loss=0.448247, Accuracy=66.160%, MSE=0.239376
[2023-08-17-10:25:13] [9/10] training 36.6%: Loss=0.449111, Accuracy=66.231%, MSE=0.239694
[2023-08-17-10:25:15] [9/10] training 38.0%: Loss=0.449187, Accuracy=66.407%, MSE=0.238599
[2023-08-17-10:25:17] [9/10] training 39.4%: Loss=0.45294, Accuracy=66.214%, MSE=0.241261
[2023-08-17-10:25:19] [9/10] training 40.8%: Loss=0.459127, Accuracy=65.690%, MSE=0.246451
[2023-08-17-10:25:22] [9/10] training 42.3%: Loss=0.462893, Accuracy=65.267%, MSE=0.250107
[2023-08-17-10:25:24] [9/10] training 43.7%: Loss=0.466228, Accuracy=64.645%, MSE=0.253813
[2023-08-17-10:25:26] [9/10] training 45.1%: Loss=0.465396, Accuracy=64.531%, MSE=0.253306
[2023-08-17-10:25:29] [9/10] training 46.5%: Loss=0.463642, Accuracy=64.606%, MSE=0.251828
[2023-08-17-10:25:31] [9/10] training 47.9%: Loss=0.462889, Accuracy=64.735%, MSE=0.251007
[2023-08-17-10:25:33] [9/10] training 49.3%: Loss=0.461972, Accuracy=64.714%, MSE=0.250543
[2023-08-17-10:25:36] [9/10] training 50.7%: Loss=0.462148, Accuracy=64.389%, MSE=0.25135
[2023-08-17-10:25:38] [9/10] training 52.1%: Loss=0.463275, Accuracy=64.135%, MSE=0.252849
[2023-08-17-10:25:41] [9/10] training 53.5%: Loss=0.463749, Accuracy=64.000%, MSE=0.253672
[2023-08-17-10:25:43] [9/10] training 54.9%: Loss=0.463181, Accuracy=64.026%, MSE=0.253641
[2023-08-17-10:25:45] [9/10] training 56.3%: Loss=0.462353, Accuracy=64.025%, MSE=0.253291
[2023-08-17-10:25:48] [9/10] training 57.7%: Loss=0.45997, Accuracy=64.317%, MSE=0.251129
[2023-08-17-10:25:50] [9/10] training 59.2%: Loss=0.459773, Accuracy=64.333%, MSE=0.250737
[2023-08-17-10:25:53] [9/10] training 60.6%: Loss=0.459982, Accuracy=64.488%, MSE=0.250558
[2023-08-17-10:25:55] [9/10] training 62.0%: Loss=0.460342, Accuracy=64.523%, MSE=0.250873
[2023-08-17-10:25:58] [9/10] training 63.4%: Loss=0.46084, Accuracy=64.422%, MSE=0.25127
[2023-08-17-10:26:00] [9/10] training 64.8%: Loss=0.461376, Accuracy=64.261%, MSE=0.251736
[2023-08-17-10:26:02] [9/10] training 66.2%: Loss=0.461504, Accuracy=64.128%, MSE=0.251931
[2023-08-17-10:26:04] [9/10] training 67.6%: Loss=0.460961, Accuracy=64.167%, MSE=0.251466
[2023-08-17-10:26:07] [9/10] training 69.0%: Loss=0.460547, Accuracy=64.061%, MSE=0.251415
[2023-08-17-10:26:09] [9/10] training 70.4%: Loss=0.459531, Accuracy=64.080%, MSE=0.250702
[2023-08-17-10:26:11] [9/10] training 71.8%: Loss=0.458545, Accuracy=64.137%, MSE=0.249895
[2023-08-17-10:26:13] [9/10] training 73.2%: Loss=0.457049, Accuracy=64.365%, MSE=0.248316
[2023-08-17-10:26:15] [9/10] training 74.6%: Loss=0.455983, Accuracy=64.509%, MSE=0.247292
[2023-08-17-10:26:18] [9/10] training 76.1%: Loss=0.455463, Accuracy=64.593%, MSE=0.246822
[2023-08-17-10:26:20] [9/10] training 77.5%: Loss=0.454825, Accuracy=64.655%, MSE=0.246292
[2023-08-17-10:26:22] [9/10] training 78.9%: Loss=0.454237, Accuracy=64.607%, MSE=0.246093
[2023-08-17-10:26:25] [9/10] training 80.3%: Loss=0.453023, Accuracy=64.737%, MSE=0.244987
[2023-08-17-10:26:27] [9/10] training 81.7%: Loss=0.451867, Accuracy=64.845%, MSE=0.243912
[2023-08-17-10:26:30] [9/10] training 83.1%: Loss=0.451595, Accuracy=64.814%, MSE=0.2438
[2023-08-17-10:26:32] [9/10] training 84.5%: Loss=0.450594, Accuracy=64.900%, MSE=0.242951
[2023-08-17-10:26:34] [9/10] training 85.9%: Loss=0.449572, Accuracy=64.984%, MSE=0.242149
[2023-08-17-10:26:36] [9/10] training 87.3%: Loss=0.448621, Accuracy=65.032%, MSE=0.24154
[2023-08-17-10:26:39] [9/10] training 88.7%: Loss=0.447907, Accuracy=65.111%, MSE=0.24091
[2023-08-17-10:26:41] [9/10] training 90.1%: Loss=0.448102, Accuracy=65.125%, MSE=0.241149
[2023-08-17-10:26:43] [9/10] training 91.5%: Loss=0.447285, Accuracy=65.231%, MSE=0.240488
[2023-08-17-10:26:45] [9/10] training 93.0%: Loss=0.446639, Accuracy=65.394%, MSE=0.239724
[2023-08-17-10:26:47] [9/10] training 94.4%: Loss=0.445867, Accuracy=65.507%, MSE=0.23909
[2023-08-17-10:26:50] [9/10] training 95.8%: Loss=0.445865, Accuracy=65.441%, MSE=0.239268
[2023-08-17-10:26:52] [9/10] training 97.2%: Loss=0.446169, Accuracy=65.333%, MSE=0.239899
[2023-08-17-10:26:54] [9/10] training 98.6%: Loss=0.446947, Accuracy=65.071%, MSE=0.240959
[2023-08-17-10:27:07] Finished Epoch 9/10: Loss=2.58792, Accuracy=47.933%, MSE=0.470834, Precision=0.408514, Recall=0.0433254, F1=0.0783422, AUPR=0.477714
[2023-08-17-10:27:07] Saving model to ./models/guo_0_1_tt_partitions_epoch09.sav
[2023-08-17-10:27:10] [10/10] training 1.4%: Loss=0.40167, Accuracy=69.000%, MSE=0.198814
[2023-08-17-10:27:12] [10/10] training 2.8%: Loss=0.427499, Accuracy=64.000%, MSE=0.233099
[2023-08-17-10:27:14] [10/10] training 4.2%: Loss=0.437963, Accuracy=61.000%, MSE=0.249304
[2023-08-17-10:27:16] [10/10] training 5.6%: Loss=0.435237, Accuracy=61.750%, MSE=0.24658
[2023-08-17-10:27:18] [10/10] training 7.0%: Loss=0.427893, Accuracy=63.600%, MSE=0.23736
[2023-08-17-10:27:21] [10/10] training 8.5%: Loss=0.426485, Accuracy=64.167%, MSE=0.235289
[2023-08-17-10:27:23] [10/10] training 9.9%: Loss=0.428837, Accuracy=64.714%, MSE=0.233246
[2023-08-17-10:27:26] [10/10] training 11.3%: Loss=0.433826, Accuracy=65.000%, MSE=0.235508
[2023-08-17-10:27:28] [10/10] training 12.7%: Loss=0.448191, Accuracy=63.889%, MSE=0.246692
[2023-08-17-10:27:30] [10/10] training 14.1%: Loss=0.46736, Accuracy=61.900%, MSE=0.264258
[2023-08-17-10:27:32] [10/10] training 15.5%: Loss=0.470287, Accuracy=61.455%, MSE=0.266554
[2023-08-17-10:27:35] [10/10] training 16.9%: Loss=0.469326, Accuracy=61.083%, MSE=0.266871
[2023-08-17-10:27:37] [10/10] training 18.3%: Loss=0.466666, Accuracy=60.846%, MSE=0.264466
[2023-08-17-10:27:40] [10/10] training 19.7%: Loss=0.464284, Accuracy=60.857%, MSE=0.262864
[2023-08-17-10:27:42] [10/10] training 21.1%: Loss=0.461189, Accuracy=61.267%, MSE=0.259861
[2023-08-17-10:27:44] [10/10] training 22.5%: Loss=0.461374, Accuracy=61.437%, MSE=0.260134
[2023-08-17-10:27:47] [10/10] training 23.9%: Loss=0.457864, Accuracy=62.000%, MSE=0.256915
[2023-08-17-10:27:49] [10/10] training 25.4%: Loss=0.457795, Accuracy=61.889%, MSE=0.257412
[2023-08-17-10:27:51] [10/10] training 26.8%: Loss=0.454562, Accuracy=62.263%, MSE=0.254847
[2023-08-17-10:27:54] [10/10] training 28.2%: Loss=0.45184, Accuracy=62.850%, MSE=0.252168
[2023-08-17-10:27:56] [10/10] training 29.6%: Loss=0.448722, Accuracy=63.571%, MSE=0.248765
[2023-08-17-10:27:58] [10/10] training 31.0%: Loss=0.44796, Accuracy=63.818%, MSE=0.247618
[2023-08-17-10:28:00] [10/10] training 32.4%: Loss=0.444504, Accuracy=64.435%, MSE=0.244043
[2023-08-17-10:28:03] [10/10] training 33.8%: Loss=0.443113, Accuracy=64.708%, MSE=0.242484
[2023-08-17-10:28:05] [10/10] training 35.2%: Loss=0.443641, Accuracy=64.520%, MSE=0.243735
[2023-08-17-10:28:07] [10/10] training 36.6%: Loss=0.442968, Accuracy=64.538%, MSE=0.243064
[2023-08-17-10:28:10] [10/10] training 38.0%: Loss=0.440649, Accuracy=64.815%, MSE=0.241008
[2023-08-17-10:28:12] [10/10] training 39.4%: Loss=0.440954, Accuracy=64.464%, MSE=0.241686
[2023-08-17-10:28:14] [10/10] training 40.8%: Loss=0.44033, Accuracy=64.414%, MSE=0.241339
[2023-08-17-10:28:16] [10/10] training 42.3%: Loss=0.438247, Accuracy=64.567%, MSE=0.239474
[2023-08-17-10:28:19] [10/10] training 43.7%: Loss=0.437398, Accuracy=64.581%, MSE=0.238617
[2023-08-17-10:28:21] [10/10] training 45.1%: Loss=0.43738, Accuracy=64.500%, MSE=0.239128
[2023-08-17-10:28:24] [10/10] training 46.5%: Loss=0.437625, Accuracy=64.333%, MSE=0.239847
[2023-08-17-10:28:26] [10/10] training 47.9%: Loss=0.43655, Accuracy=64.382%, MSE=0.239159
[2023-08-17-10:28:28] [10/10] training 49.3%: Loss=0.434584, Accuracy=64.686%, MSE=0.237566
[2023-08-17-10:28:31] [10/10] training 50.7%: Loss=0.432397, Accuracy=65.056%, MSE=0.235338
[2023-08-17-10:28:33] [10/10] training 52.1%: Loss=0.430215, Accuracy=65.432%, MSE=0.233327
[2023-08-17-10:28:35] [10/10] training 53.5%: Loss=0.429756, Accuracy=65.553%, MSE=0.232864
[2023-08-17-10:28:37] [10/10] training 54.9%: Loss=0.428851, Accuracy=65.641%, MSE=0.232086
[2023-08-17-10:28:40] [10/10] training 56.3%: Loss=0.430247, Accuracy=65.375%, MSE=0.233987
[2023-08-17-10:28:42] [10/10] training 57.7%: Loss=0.431648, Accuracy=65.220%, MSE=0.235261
[2023-08-17-10:28:44] [10/10] training 59.2%: Loss=0.432257, Accuracy=65.071%, MSE=0.236063
[2023-08-17-10:28:46] [10/10] training 60.6%: Loss=0.432323, Accuracy=65.000%, MSE=0.236235
[2023-08-17-10:28:49] [10/10] training 62.0%: Loss=0.432655, Accuracy=64.795%, MSE=0.236854
[2023-08-17-10:28:51] [10/10] training 63.4%: Loss=0.433792, Accuracy=64.667%, MSE=0.237902
[2023-08-17-10:28:53] [10/10] training 64.8%: Loss=0.433592, Accuracy=64.587%, MSE=0.237833
[2023-08-17-10:28:55] [10/10] training 66.2%: Loss=0.433839, Accuracy=64.468%, MSE=0.238197
[2023-08-17-10:28:58] [10/10] training 67.6%: Loss=0.433539, Accuracy=64.437%, MSE=0.238204
[2023-08-17-10:29:00] [10/10] training 69.0%: Loss=0.432815, Accuracy=64.551%, MSE=0.237572
[2023-08-17-10:29:02] [10/10] training 70.4%: Loss=0.432509, Accuracy=64.620%, MSE=0.237352
[2023-08-17-10:29:05] [10/10] training 71.8%: Loss=0.431313, Accuracy=64.784%, MSE=0.236272
[2023-08-17-10:29:07] [10/10] training 73.2%: Loss=0.429375, Accuracy=65.135%, MSE=0.234297
[2023-08-17-10:29:09] [10/10] training 74.6%: Loss=0.42903, Accuracy=65.264%, MSE=0.233964
[2023-08-17-10:29:11] [10/10] training 76.1%: Loss=0.429406, Accuracy=65.241%, MSE=0.23433
[2023-08-17-10:29:14] [10/10] training 77.5%: Loss=0.430919, Accuracy=65.018%, MSE=0.235872
[2023-08-17-10:29:16] [10/10] training 78.9%: Loss=0.431985, Accuracy=64.839%, MSE=0.237067
[2023-08-17-10:29:18] [10/10] training 80.3%: Loss=0.43237, Accuracy=64.754%, MSE=0.237573
[2023-08-17-10:29:21] [10/10] training 81.7%: Loss=0.432207, Accuracy=64.672%, MSE=0.23755
[2023-08-17-10:29:23] [10/10] training 83.1%: Loss=0.432114, Accuracy=64.678%, MSE=0.237496
[2023-08-17-10:29:25] [10/10] training 84.5%: Loss=0.432122, Accuracy=64.700%, MSE=0.237472
[2023-08-17-10:29:28] [10/10] training 85.9%: Loss=0.431332, Accuracy=64.902%, MSE=0.236477
[2023-08-17-10:29:30] [10/10] training 87.3%: Loss=0.430889, Accuracy=64.935%, MSE=0.236063
[2023-08-17-10:29:32] [10/10] training 88.7%: Loss=0.431045, Accuracy=64.937%, MSE=0.23627
[2023-08-17-10:29:35] [10/10] training 90.1%: Loss=0.430976, Accuracy=64.922%, MSE=0.236304
[2023-08-17-10:29:37] [10/10] training 91.5%: Loss=0.430511, Accuracy=65.015%, MSE=0.235937
[2023-08-17-10:29:39] [10/10] training 93.0%: Loss=0.430178, Accuracy=65.076%, MSE=0.235642
[2023-08-17-10:29:42] [10/10] training 94.4%: Loss=0.429272, Accuracy=65.209%, MSE=0.234611
[2023-08-17-10:29:44] [10/10] training 95.8%: Loss=0.428156, Accuracy=65.441%, MSE=0.233307
[2023-08-17-10:29:46] [10/10] training 97.2%: Loss=0.427175, Accuracy=65.696%, MSE=0.232054
[2023-08-17-10:29:48] [10/10] training 98.6%: Loss=0.427267, Accuracy=65.700%, MSE=0.232142
[2023-08-17-10:30:01] Finished Epoch 10/10: Loss=2.78433, Accuracy=49.200%, MSE=0.494749, Precision=0.441762, Recall=0.00541047, F1=0.01069, AUPR=0.458221
[2023-08-17-10:30:01] Saving model to ./models/guo_0_1_tt_partitions_epoch10.sav
[2023-08-17-10:30:01] Saving final model to ./models/guo_0_1_tt_partitions_final.sav
