Model:
InteractionModel(
  (conv1): Conv1d(2, 20, kernel_size=(80,), stride=(20,))
  (conv2): Conv1d(20, 10, kernel_size=(80,), stride=(20,))
  (fc0): Linear(in_features=130, out_features=60, bias=True)
  (fc1): Linear(in_features=60, out_features=2, bias=True)
)
Epochs: 150
08:57:49
Size of batches: 9
Learning rate: 0.001
Momentum: 0.8
Loss over epochs
0 0.6926884633226147
1 0.6921675104744779
2 0.6903024125165911
3 0.6702988614347525
4 0.6348491520631615
5 0.6116476086240322
6 0.5886718570489337
7 0.5659686526578628
8 0.5460569465193734
9 0.5300671214585561
10 0.5170840083090616
11 0.5072139445244579
12 0.49905307660143666
13 0.49301878229681506
14 0.4890644721316396
15 0.4853004753383555
16 0.48258634396375777
17 0.4806847311642204
18 0.4790673202978846
19 0.47740247296607924
20 0.4763240456473172
21 0.4752161290286833
22 0.4743664927944997
23 0.4740524833036325
24 0.47343114436477435
25 0.4727744391708732
26 0.47241414761539346
27 0.47155199768337563
28 0.47154774225617774
29 0.4711218344996468
30 0.47077484644770345
31 0.4704371810126234
32 0.4705197220330259
33 0.4702440298796878
34 0.470081989299831
35 0.469781721147574
36 0.46937419372068884
37 0.46894961169156973
38 0.4691790684120491
39 0.4691292743640469
40 0.4687592085839731
41 0.4686898768271982
42 0.4683238984940277
43 0.46822930518678824
44 0.4682435125828888
45 0.46805768437219913
46 0.4680030547035812
47 0.4681309742885551
48 0.4684542397016909
49 0.46793748139550034
50 0.4683658130857008
51 0.46795131376023585
52 0.4677697294414691
53 0.46787288269794103
54 0.4679168294458983
55 0.4676753265374108
56 0.4677104210388437
57 0.4675340990820801
58 0.467547442706392
59 0.4674487949094766
60 0.46749565304601354
61 0.46706576834276076
62 0.4671654549620832
63 0.4670005586485271
64 0.46737924342803905
65 0.46706414262460255
66 0.4669697512312865
67 0.4670221514761899
68 0.4671479394247864
69 0.46672207904580315
70 0.46685728605911453
71 0.4669369671212869
72 0.4662244876906163
73 0.46642602043478437
74 0.46654342719901737
75 0.46617698976582983
76 0.46606592274159636
77 0.4662940162879525
78 0.46580140990845104
79 0.46604771136864653
80 0.465700120420726
81 0.46584997949020857
82 0.4653438978635601
83 0.46588262648204853
84 0.46587419117364515
85 0.46552006907670324
86 0.4654272966844925
87 0.4652317825178587
88 0.46519120451176993
89 0.46528901147006335
90 0.46511297295919407
91 0.465414021570195
92 0.4651309988355024
93 0.46532384503189966
94 0.46509806372674234
95 0.46518646017241955
96 0.46489019151243444
97 0.46519159670130455
98 0.4650684376423556
99 0.46533034975920456
100 0.46496325846090497
101 0.4649941305806851
102 0.46519762466504927
103 0.4649519912106134
104 0.4651320464357091
105 0.4649534810274339
106 0.46497143925727885
107 0.46498682765258864
108 0.4647416184421115
109 0.46506574707750353
110 0.4647049330000741
111 0.4645386972257013
112 0.46448956958883325
113 0.4642591302552661
114 0.46397682721672934
115 0.4641123803962325
116 0.4643456366576762
117 0.4642454801635755
118 0.46444113747850624
119 0.4645066121553252
120 0.4642711362341811
121 0.4644091301571589
122 0.46439237739543676
123 0.4640200635811432
124 0.4641800261874477
125 0.46413855986705843
126 0.4641274017431173
127 0.4645552859470803
128 0.46420922344026105
129 0.4642654455754174
130 0.4643080662672246
131 0.4642472946804764
132 0.4641459237147524
133 0.46413882380455074
134 0.46443714623412763
135 0.4643670237492212
136 0.46425283464468503
137 0.46441817218864045
138 0.4646715000836049
139 0.46445989914442076
140 0.4640582804229254
141 0.4644226291617713
142 0.46410181220028407
143 0.4639433012869863
144 0.46376838352792465
145 0.4640369119566053
146 0.464133097892299
147 0.463803375674032
148 0.46356630728144294
149 0.4641178340740333
