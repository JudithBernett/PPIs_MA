[2023-08-18-09:34:47] D-SCRIPT Version 0.2.2
[2023-08-18-09:34:47] Called as: /nfs/home/students/jbernett/miniconda3/envs/dscript/bin/dscript train --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_0.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_0_dscript_partitions -o ./results_dscript/partitions/train_huang_both_0.txt
[2023-08-18-09:34:49] Loaded 4136 training pairs
[2023-08-18-09:34:49] Loaded 1496 test pairs
[2023-08-18-09:34:49] Loading embeddings...
[2023-08-18-09:36:08] Initializing embedding model with:
[2023-08-18-09:36:08] 	projection_dim: 100
[2023-08-18-09:36:08] 	dropout_p: 0.5
[2023-08-18-09:36:08] Initializing contact model with:
[2023-08-18-09:36:08] 	hidden_dim: 50
[2023-08-18-09:36:08] 	kernel_width: 7
[2023-08-18-09:36:08] Initializing interaction model with:
[2023-08-18-09:36:08] 	do_poool: False
[2023-08-18-09:36:08] 	pool_width: 9
[2023-08-18-09:36:08] 	do_w: True
[2023-08-18-09:36:08] 	do_sigmoid: True
[2023-08-18-09:36:08] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-08-18-09:36:11] Using save prefix "./models/huang_both_0_dscript_partitions"
[2023-08-18-09:36:11] Training with Adam: lr=0.001, weight_decay=0
[2023-08-18-09:36:11] 	num_epochs: 10
[2023-08-18-09:36:11] 	batch_size: 25
[2023-08-18-09:36:11] 	interaction weight: 0.35
[2023-08-18-09:36:11] 	contact map weight: 0.65
[2023-08-18-09:36:14] [1/10] training 2.4%: Loss=1.34035, Accuracy=55.000%, MSE=0.448533
[2023-08-18-09:36:16] [1/10] training 4.8%: Loss=1.51743, Accuracy=46.500%, MSE=0.533043
[2023-08-18-09:36:18] [1/10] training 7.2%: Loss=1.43363, Accuracy=49.667%, MSE=0.501334
[2023-08-18-09:36:20] [1/10] training 9.6%: Loss=1.40166, Accuracy=50.500%, MSE=0.492825
[2023-08-18-09:36:22] [1/10] training 12.0%: Loss=1.38763, Accuracy=50.600%, MSE=0.491626
[2023-08-18-09:36:23] [1/10] training 14.5%: Loss=1.41473, Accuracy=49.000%, MSE=0.507388
[2023-08-18-09:36:25] [1/10] training 16.9%: Loss=1.40665, Accuracy=49.000%, MSE=0.50725
[2023-08-18-09:36:28] [1/10] training 19.3%: Loss=1.39426, Accuracy=49.375%, MSE=0.503446
[2023-08-18-09:36:30] [1/10] training 21.7%: Loss=1.41879, Accuracy=47.778%, MSE=0.519151
[2023-08-18-09:36:32] [1/10] training 24.1%: Loss=1.40764, Accuracy=47.900%, MSE=0.517763
[2023-08-18-09:36:34] [1/10] training 26.5%: Loss=1.39476, Accuracy=48.273%, MSE=0.513902
[2023-08-18-09:36:36] [1/10] training 28.9%: Loss=1.37448, Accuracy=49.083%, MSE=0.505796
[2023-08-18-09:36:38] [1/10] training 31.3%: Loss=1.36125, Accuracy=49.385%, MSE=0.502634
[2023-08-18-09:36:40] [1/10] training 33.7%: Loss=1.35229, Accuracy=49.643%, MSE=0.499978
[2023-08-18-09:36:42] [1/10] training 36.1%: Loss=1.3529, Accuracy=49.400%, MSE=0.502295
[2023-08-18-09:36:44] [1/10] training 38.6%: Loss=1.34372, Accuracy=49.562%, MSE=0.500503
[2023-08-18-09:36:46] [1/10] training 41.0%: Loss=1.3383, Accuracy=49.706%, MSE=0.499042
[2023-08-18-09:36:48] [1/10] training 43.4%: Loss=1.32835, Accuracy=50.000%, MSE=0.496021
[2023-08-18-09:36:50] [1/10] training 45.8%: Loss=1.31636, Accuracy=50.316%, MSE=0.492726
[2023-08-18-09:36:52] [1/10] training 48.2%: Loss=1.31848, Accuracy=50.100%, MSE=0.49484
[2023-08-18-09:36:54] [1/10] training 50.6%: Loss=1.31229, Accuracy=50.143%, MSE=0.494277
[2023-08-18-09:36:56] [1/10] training 53.0%: Loss=1.31422, Accuracy=49.818%, MSE=0.497377
[2023-08-18-09:36:58] [1/10] training 55.4%: Loss=1.3149, Accuracy=49.565%, MSE=0.499754
[2023-08-18-09:37:00] [1/10] training 57.8%: Loss=1.30611, Accuracy=49.833%, MSE=0.497009
[2023-08-18-09:37:02] [1/10] training 60.2%: Loss=1.29998, Accuracy=50.000%, MSE=0.495293
[2023-08-18-09:37:04] [1/10] training 62.7%: Loss=1.29006, Accuracy=50.269%, MSE=0.492483
[2023-08-18-09:37:06] [1/10] training 65.1%: Loss=1.29399, Accuracy=49.852%, MSE=0.496487
[2023-08-18-09:37:08] [1/10] training 67.5%: Loss=1.29132, Accuracy=49.750%, MSE=0.497333
[2023-08-18-09:37:10] [1/10] training 69.9%: Loss=1.28654, Accuracy=49.862%, MSE=0.496123
[2023-08-18-09:37:12] [1/10] training 72.3%: Loss=1.28527, Accuracy=49.733%, MSE=0.4973
[2023-08-18-09:37:14] [1/10] training 74.7%: Loss=1.27567, Accuracy=50.065%, MSE=0.493919
[2023-08-18-09:37:16] [1/10] training 77.1%: Loss=1.27168, Accuracy=50.000%, MSE=0.494341
[2023-08-18-09:37:18] [1/10] training 79.5%: Loss=1.26751, Accuracy=50.152%, MSE=0.492831
[2023-08-18-09:37:20] [1/10] training 81.9%: Loss=1.26657, Accuracy=50.000%, MSE=0.494207
[2023-08-18-09:37:22] [1/10] training 84.3%: Loss=1.26044, Accuracy=50.171%, MSE=0.492406
[2023-08-18-09:37:24] [1/10] training 86.7%: Loss=1.25814, Accuracy=50.139%, MSE=0.492622
[2023-08-18-09:37:26] [1/10] training 89.2%: Loss=1.25833, Accuracy=50.000%, MSE=0.493935
[2023-08-18-09:37:28] [1/10] training 91.6%: Loss=1.25415, Accuracy=50.000%, MSE=0.493718
[2023-08-18-09:37:30] [1/10] training 94.0%: Loss=1.25028, Accuracy=50.154%, MSE=0.492161
[2023-08-18-09:37:32] [1/10] training 96.4%: Loss=1.24453, Accuracy=50.250%, MSE=0.491033
[2023-08-18-09:37:34] [1/10] training 98.8%: Loss=1.24327, Accuracy=50.146%, MSE=0.491934
[2023-08-18-09:37:48] Finished Epoch 1/10: Loss=2.32954, Accuracy=49.867%, MSE=0.487568, Precision=0.42077, Recall=0.0129209, F1=0.0250718, AUPR=0.426791
[2023-08-18-09:37:48] Saving model to ./models/huang_both_0_dscript_partitions_epoch01.sav
[2023-08-18-09:37:51] [2/10] training 2.4%: Loss=1.01823, Accuracy=55.000%, MSE=0.437872
[2023-08-18-09:37:52] [2/10] training 4.8%: Loss=0.988546, Accuracy=56.500%, MSE=0.423686
[2023-08-18-09:37:54] [2/10] training 7.2%: Loss=1.00112, Accuracy=56.333%, MSE=0.425751
[2023-08-18-09:37:56] [2/10] training 9.6%: Loss=1.05165, Accuracy=53.750%, MSE=0.451198
[2023-08-18-09:37:58] [2/10] training 12.0%: Loss=1.06015, Accuracy=52.800%, MSE=0.459848
[2023-08-18-09:38:00] [2/10] training 14.5%: Loss=1.07483, Accuracy=51.667%, MSE=0.470922
[2023-08-18-09:38:01] [2/10] training 16.9%: Loss=1.07975, Accuracy=51.429%, MSE=0.473476
[2023-08-18-09:38:03] [2/10] training 19.3%: Loss=1.07287, Accuracy=51.500%, MSE=0.472333
[2023-08-18-09:38:05] [2/10] training 21.7%: Loss=1.08217, Accuracy=51.111%, MSE=0.476314
[2023-08-18-09:38:06] [2/10] training 24.1%: Loss=1.08514, Accuracy=50.700%, MSE=0.480034
[2023-08-18-09:38:08] [2/10] training 26.5%: Loss=1.0779, Accuracy=50.909%, MSE=0.47775
[2023-08-18-09:38:10] [2/10] training 28.9%: Loss=1.0718, Accuracy=51.417%, MSE=0.47296
[2023-08-18-09:38:12] [2/10] training 31.3%: Loss=1.07212, Accuracy=51.308%, MSE=0.473973
[2023-08-18-09:38:13] [2/10] training 33.7%: Loss=1.0573, Accuracy=51.857%, MSE=0.468215
[2023-08-18-09:38:15] [2/10] training 36.1%: Loss=1.0668, Accuracy=51.267%, MSE=0.473979
[2023-08-18-09:38:17] [2/10] training 38.6%: Loss=1.07064, Accuracy=50.875%, MSE=0.477628
[2023-08-18-09:38:19] [2/10] training 41.0%: Loss=1.06463, Accuracy=51.118%, MSE=0.475088
[2023-08-18-09:38:21] [2/10] training 43.4%: Loss=1.06676, Accuracy=50.889%, MSE=0.47713
[2023-08-18-09:38:22] [2/10] training 45.8%: Loss=1.06791, Accuracy=50.632%, MSE=0.479453
[2023-08-18-09:38:24] [2/10] training 48.2%: Loss=1.05806, Accuracy=51.000%, MSE=0.4756
[2023-08-18-09:38:26] [2/10] training 50.6%: Loss=1.05533, Accuracy=51.048%, MSE=0.475143
[2023-08-18-09:38:28] [2/10] training 53.0%: Loss=1.05274, Accuracy=51.136%, MSE=0.474147
[2023-08-18-09:38:29] [2/10] training 55.4%: Loss=1.04989, Accuracy=51.043%, MSE=0.474665
[2023-08-18-09:38:31] [2/10] training 57.8%: Loss=1.04749, Accuracy=51.083%, MSE=0.47419
[2023-08-18-09:38:33] [2/10] training 60.2%: Loss=1.04259, Accuracy=51.120%, MSE=0.47341
[2023-08-18-09:38:35] [2/10] training 62.7%: Loss=1.04871, Accuracy=50.731%, MSE=0.477225
[2023-08-18-09:38:37] [2/10] training 65.1%: Loss=1.04647, Accuracy=50.667%, MSE=0.477535
[2023-08-18-09:38:39] [2/10] training 67.5%: Loss=1.04335, Accuracy=50.714%, MSE=0.476807
[2023-08-18-09:38:40] [2/10] training 69.9%: Loss=1.04011, Accuracy=50.862%, MSE=0.475339
[2023-08-18-09:38:42] [2/10] training 72.3%: Loss=1.03941, Accuracy=50.800%, MSE=0.475826
[2023-08-18-09:38:44] [2/10] training 74.7%: Loss=1.03808, Accuracy=50.742%, MSE=0.47621
[2023-08-18-09:38:46] [2/10] training 77.1%: Loss=1.03689, Accuracy=50.625%, MSE=0.476998
[2023-08-18-09:38:48] [2/10] training 79.5%: Loss=1.03439, Accuracy=50.667%, MSE=0.476483
[2023-08-18-09:38:50] [2/10] training 81.9%: Loss=1.03364, Accuracy=50.618%, MSE=0.47706
[2023-08-18-09:38:52] [2/10] training 84.3%: Loss=1.03277, Accuracy=50.457%, MSE=0.478201
[2023-08-18-09:38:53] [2/10] training 86.7%: Loss=1.03376, Accuracy=50.250%, MSE=0.479991
[2023-08-18-09:38:55] [2/10] training 89.2%: Loss=1.03486, Accuracy=50.027%, MSE=0.481849
[2023-08-18-09:38:57] [2/10] training 91.6%: Loss=1.03101, Accuracy=50.105%, MSE=0.480723
[2023-08-18-09:38:59] [2/10] training 94.0%: Loss=1.03046, Accuracy=50.000%, MSE=0.481374
[2023-08-18-09:39:01] [2/10] training 96.4%: Loss=1.02995, Accuracy=49.950%, MSE=0.481713
[2023-08-18-09:39:03] [2/10] training 98.8%: Loss=1.02646, Accuracy=50.024%, MSE=0.480804
[2023-08-18-09:39:15] Finished Epoch 2/10: Loss=1.79416, Accuracy=49.867%, MSE=0.465824, Precision=0.357327, Recall=0.0414199, F1=0.0742348, AUPR=0.389807
[2023-08-18-09:39:15] Saving model to ./models/huang_both_0_dscript_partitions_epoch02.sav
[2023-08-18-09:39:17] [3/10] training 2.4%: Loss=0.884749, Accuracy=51.000%, MSE=0.456674
[2023-08-18-09:39:19] [3/10] training 4.8%: Loss=0.870566, Accuracy=52.000%, MSE=0.448001
[2023-08-18-09:39:21] [3/10] training 7.2%: Loss=0.878922, Accuracy=50.333%, MSE=0.458949
[2023-08-18-09:39:22] [3/10] training 9.6%: Loss=0.854315, Accuracy=53.250%, MSE=0.433634
[2023-08-18-09:39:24] [3/10] training 12.0%: Loss=0.866554, Accuracy=51.600%, MSE=0.448462
[2023-08-18-09:39:26] [3/10] training 14.5%: Loss=0.878976, Accuracy=51.500%, MSE=0.45075
[2023-08-18-09:39:28] [3/10] training 16.9%: Loss=0.890693, Accuracy=51.571%, MSE=0.451943
[2023-08-18-09:39:30] [3/10] training 19.3%: Loss=0.902513, Accuracy=51.000%, MSE=0.458143
[2023-08-18-09:39:32] [3/10] training 21.7%: Loss=0.916567, Accuracy=50.000%, MSE=0.467476
[2023-08-18-09:39:33] [3/10] training 24.1%: Loss=0.921973, Accuracy=49.800%, MSE=0.469767
[2023-08-18-09:39:35] [3/10] training 26.5%: Loss=0.908074, Accuracy=50.455%, MSE=0.46208
[2023-08-18-09:39:37] [3/10] training 28.9%: Loss=0.90003, Accuracy=50.417%, MSE=0.460564
[2023-08-18-09:39:38] [3/10] training 31.3%: Loss=0.904196, Accuracy=49.923%, MSE=0.464527
[2023-08-18-09:39:40] [3/10] training 33.7%: Loss=0.916338, Accuracy=49.286%, MSE=0.47036
[2023-08-18-09:39:42] [3/10] training 36.1%: Loss=0.915493, Accuracy=49.067%, MSE=0.471437
[2023-08-18-09:39:44] [3/10] training 38.6%: Loss=0.903594, Accuracy=49.875%, MSE=0.463679
[2023-08-18-09:39:46] [3/10] training 41.0%: Loss=0.897618, Accuracy=50.059%, MSE=0.461113
[2023-08-18-09:39:48] [3/10] training 43.4%: Loss=0.903489, Accuracy=49.444%, MSE=0.465941
[2023-08-18-09:39:49] [3/10] training 45.8%: Loss=0.898621, Accuracy=49.789%, MSE=0.462809
[2023-08-18-09:39:51] [3/10] training 48.2%: Loss=0.896276, Accuracy=49.800%, MSE=0.462294
[2023-08-18-09:39:53] [3/10] training 50.6%: Loss=0.893083, Accuracy=49.905%, MSE=0.461071
[2023-08-18-09:39:55] [3/10] training 53.0%: Loss=0.891772, Accuracy=49.864%, MSE=0.461307
[2023-08-18-09:39:57] [3/10] training 55.4%: Loss=0.893637, Accuracy=49.522%, MSE=0.463919
[2023-08-18-09:39:59] [3/10] training 57.8%: Loss=0.887958, Accuracy=49.833%, MSE=0.460795
[2023-08-18-09:40:01] [3/10] training 60.2%: Loss=0.885165, Accuracy=49.760%, MSE=0.460396
[2023-08-18-09:40:02] [3/10] training 62.7%: Loss=0.886983, Accuracy=49.692%, MSE=0.461096
[2023-08-18-09:40:04] [3/10] training 65.1%: Loss=0.883565, Accuracy=49.926%, MSE=0.458822
[2023-08-18-09:40:06] [3/10] training 67.5%: Loss=0.880618, Accuracy=50.000%, MSE=0.458217
[2023-08-18-09:40:07] [3/10] training 69.9%: Loss=0.879632, Accuracy=49.966%, MSE=0.45836
[2023-08-18-09:40:09] [3/10] training 72.3%: Loss=0.876735, Accuracy=50.000%, MSE=0.457337
[2023-08-18-09:40:11] [3/10] training 74.7%: Loss=0.875864, Accuracy=49.968%, MSE=0.457304
[2023-08-18-09:40:13] [3/10] training 77.1%: Loss=0.874619, Accuracy=49.906%, MSE=0.457136
[2023-08-18-09:40:15] [3/10] training 79.5%: Loss=0.872586, Accuracy=49.879%, MSE=0.456797
[2023-08-18-09:40:17] [3/10] training 81.9%: Loss=0.873785, Accuracy=49.471%, MSE=0.459545
[2023-08-18-09:40:19] [3/10] training 84.3%: Loss=0.8738, Accuracy=49.257%, MSE=0.460774
[2023-08-18-09:40:20] [3/10] training 86.7%: Loss=0.871365, Accuracy=49.111%, MSE=0.460291
[2023-08-18-09:40:22] [3/10] training 89.2%: Loss=0.86963, Accuracy=49.081%, MSE=0.460283
[2023-08-18-09:40:24] [3/10] training 91.6%: Loss=0.866613, Accuracy=49.158%, MSE=0.458832
[2023-08-18-09:40:26] [3/10] training 94.0%: Loss=0.862932, Accuracy=49.077%, MSE=0.457397
[2023-08-18-09:40:27] [3/10] training 96.4%: Loss=0.86187, Accuracy=48.900%, MSE=0.457598
[2023-08-18-09:40:29] [3/10] training 98.8%: Loss=0.858828, Accuracy=48.927%, MSE=0.456515
[2023-08-18-09:40:42] Finished Epoch 3/10: Loss=1.02095, Accuracy=42.067%, MSE=0.358407, Precision=0.451496, Recall=0.299517, F1=0.360129, AUPR=0.428974
[2023-08-18-09:40:42] Saving model to ./models/huang_both_0_dscript_partitions_epoch03.sav
[2023-08-18-09:40:44] [4/10] training 2.4%: Loss=0.713474, Accuracy=56.000%, MSE=0.381192
[2023-08-18-09:40:46] [4/10] training 4.8%: Loss=0.675526, Accuracy=51.000%, MSE=0.370141
[2023-08-18-09:40:48] [4/10] training 7.2%: Loss=0.64737, Accuracy=50.667%, MSE=0.359375
[2023-08-18-09:40:49] [4/10] training 9.6%: Loss=0.663987, Accuracy=49.500%, MSE=0.371647
[2023-08-18-09:40:51] [4/10] training 12.0%: Loss=0.685572, Accuracy=48.400%, MSE=0.382262
[2023-08-18-09:40:53] [4/10] training 14.5%: Loss=0.703218, Accuracy=48.000%, MSE=0.39086
[2023-08-18-09:40:55] [4/10] training 16.9%: Loss=0.703209, Accuracy=48.000%, MSE=0.391746
[2023-08-18-09:40:56] [4/10] training 19.3%: Loss=0.692621, Accuracy=47.125%, MSE=0.38818
[2023-08-18-09:40:58] [4/10] training 21.7%: Loss=0.69087, Accuracy=47.000%, MSE=0.389255
[2023-08-18-09:41:00] [4/10] training 24.1%: Loss=0.712403, Accuracy=46.400%, MSE=0.400682
[2023-08-18-09:41:02] [4/10] training 26.5%: Loss=0.715731, Accuracy=46.091%, MSE=0.403669
[2023-08-18-09:41:04] [4/10] training 28.9%: Loss=0.710757, Accuracy=45.667%, MSE=0.40296
[2023-08-18-09:41:05] [4/10] training 31.3%: Loss=0.707555, Accuracy=45.077%, MSE=0.402132
[2023-08-18-09:41:07] [4/10] training 33.7%: Loss=0.705958, Accuracy=45.500%, MSE=0.401446
[2023-08-18-09:41:09] [4/10] training 36.1%: Loss=0.705577, Accuracy=45.800%, MSE=0.400266
[2023-08-18-09:41:11] [4/10] training 38.6%: Loss=0.705044, Accuracy=45.562%, MSE=0.400283
[2023-08-18-09:41:12] [4/10] training 41.0%: Loss=0.697913, Accuracy=46.059%, MSE=0.394109
[2023-08-18-09:41:14] [4/10] training 43.4%: Loss=0.719589, Accuracy=45.778%, MSE=0.403266
[2023-08-18-09:41:16] [4/10] training 45.8%: Loss=0.733741, Accuracy=45.895%, MSE=0.408223
[2023-08-18-09:41:18] [4/10] training 48.2%: Loss=0.743858, Accuracy=46.200%, MSE=0.410791
[2023-08-18-09:41:20] [4/10] training 50.6%: Loss=0.758289, Accuracy=46.048%, MSE=0.416934
[2023-08-18-09:41:22] [4/10] training 53.0%: Loss=0.76714, Accuracy=46.227%, MSE=0.419568
[2023-08-18-09:41:23] [4/10] training 55.4%: Loss=0.775106, Accuracy=46.304%, MSE=0.422566
[2023-08-18-09:41:25] [4/10] training 57.8%: Loss=0.773238, Accuracy=46.708%, MSE=0.420988
[2023-08-18-09:41:27] [4/10] training 60.2%: Loss=0.774059, Accuracy=46.680%, MSE=0.422515
[2023-08-18-09:41:28] [4/10] training 62.7%: Loss=0.772353, Accuracy=47.192%, MSE=0.420236
[2023-08-18-09:41:30] [4/10] training 65.1%: Loss=0.772903, Accuracy=47.333%, MSE=0.420866
[2023-08-18-09:41:32] [4/10] training 67.5%: Loss=0.769644, Accuracy=47.643%, MSE=0.418977
[2023-08-18-09:41:34] [4/10] training 69.9%: Loss=0.767625, Accuracy=47.414%, MSE=0.41925
[2023-08-18-09:41:36] [4/10] training 72.3%: Loss=0.764558, Accuracy=47.367%, MSE=0.418667
[2023-08-18-09:41:37] [4/10] training 74.7%: Loss=0.764171, Accuracy=47.226%, MSE=0.419712
[2023-08-18-09:41:39] [4/10] training 77.1%: Loss=0.76064, Accuracy=47.531%, MSE=0.417793
[2023-08-18-09:41:41] [4/10] training 79.5%: Loss=0.75721, Accuracy=47.576%, MSE=0.416295
[2023-08-18-09:41:43] [4/10] training 81.9%: Loss=0.752313, Accuracy=47.824%, MSE=0.413366
[2023-08-18-09:41:45] [4/10] training 84.3%: Loss=0.74934, Accuracy=47.629%, MSE=0.412466
[2023-08-18-09:41:47] [4/10] training 86.7%: Loss=0.74622, Accuracy=47.444%, MSE=0.411809
[2023-08-18-09:41:49] [4/10] training 89.2%: Loss=0.745392, Accuracy=47.405%, MSE=0.411636
[2023-08-18-09:41:51] [4/10] training 91.6%: Loss=0.750746, Accuracy=47.237%, MSE=0.414465
[2023-08-18-09:41:52] [4/10] training 94.0%: Loss=0.750913, Accuracy=47.179%, MSE=0.414895
[2023-08-18-09:41:54] [4/10] training 96.4%: Loss=0.748764, Accuracy=47.050%, MSE=0.414411
[2023-08-18-09:41:56] [4/10] training 98.8%: Loss=0.744113, Accuracy=47.122%, MSE=0.412107
[2023-08-18-09:42:09] Finished Epoch 4/10: Loss=0.732216, Accuracy=66.333%, MSE=0.221317, Precision=0.658455, Recall=0.525125, F1=0.58428, AUPR=0.676499
[2023-08-18-09:42:09] Saving model to ./models/huang_both_0_dscript_partitions_epoch04.sav
[2023-08-18-09:42:11] [5/10] training 2.4%: Loss=0.551645, Accuracy=50.000%, MSE=0.316193
[2023-08-18-09:42:12] [5/10] training 4.8%: Loss=0.571983, Accuracy=49.500%, MSE=0.325694
[2023-08-18-09:42:15] [5/10] training 7.2%: Loss=0.605626, Accuracy=48.667%, MSE=0.343593
[2023-08-18-09:42:17] [5/10] training 9.6%: Loss=0.598766, Accuracy=48.250%, MSE=0.339216
[2023-08-18-09:42:18] [5/10] training 12.0%: Loss=0.585646, Accuracy=50.000%, MSE=0.328806
[2023-08-18-09:42:20] [5/10] training 14.5%: Loss=0.577597, Accuracy=50.833%, MSE=0.323493
[2023-08-18-09:42:22] [5/10] training 16.9%: Loss=0.599112, Accuracy=49.571%, MSE=0.336271
[2023-08-18-09:42:24] [5/10] training 19.3%: Loss=0.601103, Accuracy=49.625%, MSE=0.336907
[2023-08-18-09:42:26] [5/10] training 21.7%: Loss=0.596195, Accuracy=49.889%, MSE=0.33352
[2023-08-18-09:42:28] [5/10] training 24.1%: Loss=0.583807, Accuracy=51.100%, MSE=0.324207
[2023-08-18-09:42:30] [5/10] training 26.5%: Loss=0.572755, Accuracy=52.091%, MSE=0.315477
[2023-08-18-09:42:31] [5/10] training 28.9%: Loss=0.568753, Accuracy=52.167%, MSE=0.312907
[2023-08-18-09:42:33] [5/10] training 31.3%: Loss=0.567577, Accuracy=52.231%, MSE=0.312612
[2023-08-18-09:42:35] [5/10] training 33.7%: Loss=0.570996, Accuracy=51.929%, MSE=0.315394
[2023-08-18-09:42:37] [5/10] training 36.1%: Loss=0.566907, Accuracy=52.133%, MSE=0.312855
[2023-08-18-09:42:38] [5/10] training 38.6%: Loss=0.556747, Accuracy=53.437%, MSE=0.30425
[2023-08-18-09:42:40] [5/10] training 41.0%: Loss=0.556413, Accuracy=53.824%, MSE=0.302906
[2023-08-18-09:42:42] [5/10] training 43.4%: Loss=0.558358, Accuracy=54.000%, MSE=0.303635
[2023-08-18-09:42:44] [5/10] training 45.8%: Loss=0.567016, Accuracy=53.368%, MSE=0.309397
[2023-08-18-09:42:46] [5/10] training 48.2%: Loss=0.578946, Accuracy=52.800%, MSE=0.316
[2023-08-18-09:42:48] [5/10] training 50.6%: Loss=0.586214, Accuracy=52.524%, MSE=0.320511
[2023-08-18-09:42:50] [5/10] training 53.0%: Loss=0.583994, Accuracy=52.545%, MSE=0.319681
[2023-08-18-09:42:51] [5/10] training 55.4%: Loss=0.579152, Accuracy=52.913%, MSE=0.316653
[2023-08-18-09:42:53] [5/10] training 57.8%: Loss=0.573674, Accuracy=53.250%, MSE=0.312399
[2023-08-18-09:42:55] [5/10] training 60.2%: Loss=0.569607, Accuracy=53.880%, MSE=0.308916
[2023-08-18-09:42:56] [5/10] training 62.7%: Loss=0.567206, Accuracy=54.346%, MSE=0.306773
[2023-08-18-09:42:58] [5/10] training 65.1%: Loss=0.567444, Accuracy=54.333%, MSE=0.306702
[2023-08-18-09:43:00] [5/10] training 67.5%: Loss=0.570318, Accuracy=54.143%, MSE=0.30848
[2023-08-18-09:43:01] [5/10] training 69.9%: Loss=0.569948, Accuracy=53.897%, MSE=0.309247
[2023-08-18-09:43:03] [5/10] training 72.3%: Loss=0.568606, Accuracy=53.967%, MSE=0.308463
[2023-08-18-09:43:05] [5/10] training 74.7%: Loss=0.566351, Accuracy=54.065%, MSE=0.30704
[2023-08-18-09:43:07] [5/10] training 77.1%: Loss=0.565938, Accuracy=54.094%, MSE=0.30699
[2023-08-18-09:43:09] [5/10] training 79.5%: Loss=0.564921, Accuracy=54.121%, MSE=0.306727
[2023-08-18-09:43:11] [5/10] training 81.9%: Loss=0.560855, Accuracy=54.735%, MSE=0.303263
[2023-08-18-09:43:13] [5/10] training 84.3%: Loss=0.558716, Accuracy=55.086%, MSE=0.301193
[2023-08-18-09:43:14] [5/10] training 86.7%: Loss=0.561578, Accuracy=55.000%, MSE=0.302776
[2023-08-18-09:43:16] [5/10] training 89.2%: Loss=0.564167, Accuracy=54.757%, MSE=0.304685
[2023-08-18-09:43:18] [5/10] training 91.6%: Loss=0.566676, Accuracy=54.316%, MSE=0.307223
[2023-08-18-09:43:19] [5/10] training 94.0%: Loss=0.569062, Accuracy=54.026%, MSE=0.309456
[2023-08-18-09:43:21] [5/10] training 96.4%: Loss=0.568433, Accuracy=54.075%, MSE=0.309273
[2023-08-18-09:43:23] [5/10] training 98.8%: Loss=0.566498, Accuracy=54.317%, MSE=0.307953
[2023-08-18-09:43:36] Finished Epoch 5/10: Loss=0.771417, Accuracy=65.133%, MSE=0.230316, Precision=0.735536, Recall=0.43172, F1=0.544089, AUPR=0.753249
[2023-08-18-09:43:36] Saving model to ./models/huang_both_0_dscript_partitions_epoch05.sav
[2023-08-18-09:43:38] [6/10] training 2.4%: Loss=0.593284, Accuracy=47.000%, MSE=0.348509
[2023-08-18-09:43:40] [6/10] training 4.8%: Loss=0.538528, Accuracy=54.000%, MSE=0.299399
[2023-08-18-09:43:42] [6/10] training 7.2%: Loss=0.512926, Accuracy=57.667%, MSE=0.278427
[2023-08-18-09:43:43] [6/10] training 9.6%: Loss=0.501261, Accuracy=61.250%, MSE=0.261397
[2023-08-18-09:43:45] [6/10] training 12.0%: Loss=0.472646, Accuracy=65.600%, MSE=0.233881
[2023-08-18-09:43:47] [6/10] training 14.5%: Loss=0.473097, Accuracy=65.333%, MSE=0.235419
[2023-08-18-09:43:49] [6/10] training 16.9%: Loss=0.477899, Accuracy=63.857%, MSE=0.240761
[2023-08-18-09:43:51] [6/10] training 19.3%: Loss=0.501816, Accuracy=61.375%, MSE=0.259116
[2023-08-18-09:43:53] [6/10] training 21.7%: Loss=0.512533, Accuracy=60.111%, MSE=0.268699
[2023-08-18-09:43:54] [6/10] training 24.1%: Loss=0.519632, Accuracy=59.100%, MSE=0.276296
[2023-08-18-09:43:56] [6/10] training 26.5%: Loss=0.512222, Accuracy=59.909%, MSE=0.27009
[2023-08-18-09:43:58] [6/10] training 28.9%: Loss=0.50878, Accuracy=60.417%, MSE=0.266653
[2023-08-18-09:44:00] [6/10] training 31.3%: Loss=0.510216, Accuracy=60.308%, MSE=0.268044
[2023-08-18-09:44:02] [6/10] training 33.7%: Loss=0.508732, Accuracy=60.500%, MSE=0.266646
[2023-08-18-09:44:03] [6/10] training 36.1%: Loss=0.522571, Accuracy=59.200%, MSE=0.276763
[2023-08-18-09:44:05] [6/10] training 38.6%: Loss=0.531185, Accuracy=58.625%, MSE=0.282268
[2023-08-18-09:44:07] [6/10] training 41.0%: Loss=0.53189, Accuracy=58.353%, MSE=0.283272
[2023-08-18-09:44:09] [6/10] training 43.4%: Loss=0.53264, Accuracy=58.333%, MSE=0.283936
[2023-08-18-09:44:11] [6/10] training 45.8%: Loss=0.527229, Accuracy=59.158%, MSE=0.279119
[2023-08-18-09:44:13] [6/10] training 48.2%: Loss=0.522353, Accuracy=59.900%, MSE=0.27517
[2023-08-18-09:44:15] [6/10] training 50.6%: Loss=0.519532, Accuracy=60.286%, MSE=0.273135
[2023-08-18-09:44:16] [6/10] training 53.0%: Loss=0.517637, Accuracy=60.273%, MSE=0.272521
[2023-08-18-09:44:18] [6/10] training 55.4%: Loss=0.51388, Accuracy=60.739%, MSE=0.269503
[2023-08-18-09:44:20] [6/10] training 57.8%: Loss=0.511977, Accuracy=61.083%, MSE=0.267673
[2023-08-18-09:44:21] [6/10] training 60.2%: Loss=0.508915, Accuracy=61.560%, MSE=0.264858
[2023-08-18-09:44:23] [6/10] training 62.7%: Loss=0.506689, Accuracy=61.692%, MSE=0.263301
[2023-08-18-09:44:25] [6/10] training 65.1%: Loss=0.511666, Accuracy=61.037%, MSE=0.267628
[2023-08-18-09:44:27] [6/10] training 67.5%: Loss=0.51342, Accuracy=60.679%, MSE=0.269551
[2023-08-18-09:44:29] [6/10] training 69.9%: Loss=0.513136, Accuracy=60.552%, MSE=0.269407
[2023-08-18-09:44:30] [6/10] training 72.3%: Loss=0.510937, Accuracy=60.767%, MSE=0.267879
[2023-08-18-09:44:32] [6/10] training 74.7%: Loss=0.508011, Accuracy=61.226%, MSE=0.265469
[2023-08-18-09:44:34] [6/10] training 77.1%: Loss=0.507425, Accuracy=61.437%, MSE=0.264491
[2023-08-18-09:44:36] [6/10] training 79.5%: Loss=0.509482, Accuracy=61.121%, MSE=0.266221
[2023-08-18-09:44:38] [6/10] training 81.9%: Loss=0.510861, Accuracy=60.912%, MSE=0.267451
[2023-08-18-09:44:39] [6/10] training 84.3%: Loss=0.509535, Accuracy=60.943%, MSE=0.266834
[2023-08-18-09:44:41] [6/10] training 86.7%: Loss=0.507828, Accuracy=61.194%, MSE=0.265663
[2023-08-18-09:44:43] [6/10] training 89.2%: Loss=0.505723, Accuracy=61.432%, MSE=0.263976
[2023-08-18-09:44:45] [6/10] training 91.6%: Loss=0.503654, Accuracy=61.711%, MSE=0.262291
[2023-08-18-09:44:47] [6/10] training 94.0%: Loss=0.499687, Accuracy=62.256%, MSE=0.258897
[2023-08-18-09:44:48] [6/10] training 96.4%: Loss=0.49697, Accuracy=62.700%, MSE=0.256341
[2023-08-18-09:44:50] [6/10] training 98.8%: Loss=0.495029, Accuracy=62.878%, MSE=0.254999
[2023-08-18-09:45:02] Finished Epoch 6/10: Loss=1.28843, Accuracy=60.733%, MSE=0.293117, Precision=0.850672, Recall=0.291615, F1=0.434337, AUPR=0.8255
[2023-08-18-09:45:02] Saving model to ./models/huang_both_0_dscript_partitions_epoch06.sav
[2023-08-18-09:45:05] [7/10] training 2.4%: Loss=0.467474, Accuracy=65.000%, MSE=0.245652
[2023-08-18-09:45:06] [7/10] training 4.8%: Loss=0.502846, Accuracy=59.500%, MSE=0.276177
[2023-08-18-09:45:08] [7/10] training 7.2%: Loss=0.490399, Accuracy=60.667%, MSE=0.263775
[2023-08-18-09:45:10] [7/10] training 9.6%: Loss=0.463827, Accuracy=64.500%, MSE=0.238675
[2023-08-18-09:45:12] [7/10] training 12.0%: Loss=0.468227, Accuracy=65.800%, MSE=0.234691
[2023-08-18-09:45:14] [7/10] training 14.5%: Loss=0.509862, Accuracy=63.167%, MSE=0.266116
[2023-08-18-09:45:15] [7/10] training 16.9%: Loss=0.55444, Accuracy=60.571%, MSE=0.298428
[2023-08-18-09:45:17] [7/10] training 19.3%: Loss=0.578728, Accuracy=59.000%, MSE=0.317169
[2023-08-18-09:45:19] [7/10] training 21.7%: Loss=0.59794, Accuracy=58.222%, MSE=0.328938
[2023-08-18-09:45:21] [7/10] training 24.1%: Loss=0.616331, Accuracy=57.500%, MSE=0.338558
[2023-08-18-09:45:23] [7/10] training 26.5%: Loss=0.632994, Accuracy=57.000%, MSE=0.345185
[2023-08-18-09:45:24] [7/10] training 28.9%: Loss=0.647161, Accuracy=55.750%, MSE=0.353819
[2023-08-18-09:45:26] [7/10] training 31.3%: Loss=0.651015, Accuracy=54.615%, MSE=0.358265
[2023-08-18-09:45:28] [7/10] training 33.7%: Loss=0.648127, Accuracy=53.929%, MSE=0.359157
[2023-08-18-09:45:30] [7/10] training 36.1%: Loss=0.637517, Accuracy=54.000%, MSE=0.353858
[2023-08-18-09:45:32] [7/10] training 38.6%: Loss=0.617987, Accuracy=56.125%, MSE=0.338773
[2023-08-18-09:45:34] [7/10] training 41.0%: Loss=0.606658, Accuracy=57.235%, MSE=0.329686
[2023-08-18-09:45:36] [7/10] training 43.4%: Loss=0.599835, Accuracy=57.222%, MSE=0.326486
[2023-08-18-09:45:37] [7/10] training 45.8%: Loss=0.599596, Accuracy=56.789%, MSE=0.328799
[2023-08-18-09:45:39] [7/10] training 48.2%: Loss=0.600533, Accuracy=56.700%, MSE=0.329193
[2023-08-18-09:45:41] [7/10] training 50.6%: Loss=0.604923, Accuracy=55.952%, MSE=0.333578
[2023-08-18-09:45:43] [7/10] training 53.0%: Loss=0.616296, Accuracy=55.136%, MSE=0.340473
[2023-08-18-09:45:45] [7/10] training 55.4%: Loss=0.620112, Accuracy=54.304%, MSE=0.345363
[2023-08-18-09:45:47] [7/10] training 57.8%: Loss=0.619615, Accuracy=54.083%, MSE=0.345735
[2023-08-18-09:45:48] [7/10] training 60.2%: Loss=0.612255, Accuracy=54.520%, MSE=0.340837
[2023-08-18-09:45:50] [7/10] training 62.7%: Loss=0.603502, Accuracy=55.346%, MSE=0.334414
[2023-08-18-09:45:52] [7/10] training 65.1%: Loss=0.593677, Accuracy=56.444%, MSE=0.326631
[2023-08-18-09:45:53] [7/10] training 67.5%: Loss=0.584606, Accuracy=57.393%, MSE=0.319649
[2023-08-18-09:45:55] [7/10] training 69.9%: Loss=0.578919, Accuracy=57.862%, MSE=0.315804
[2023-08-18-09:45:57] [7/10] training 72.3%: Loss=0.572706, Accuracy=58.400%, MSE=0.311179
[2023-08-18-09:45:59] [7/10] training 74.7%: Loss=0.56826, Accuracy=58.774%, MSE=0.308006
[2023-08-18-09:46:01] [7/10] training 77.1%: Loss=0.565457, Accuracy=58.719%, MSE=0.306901
[2023-08-18-09:46:03] [7/10] training 79.5%: Loss=0.568077, Accuracy=58.242%, MSE=0.309717
[2023-08-18-09:46:04] [7/10] training 81.9%: Loss=0.565069, Accuracy=58.588%, MSE=0.30764
[2023-08-18-09:46:06] [7/10] training 84.3%: Loss=0.558132, Accuracy=59.371%, MSE=0.30197
[2023-08-18-09:46:08] [7/10] training 86.7%: Loss=0.553267, Accuracy=59.778%, MSE=0.298429
[2023-08-18-09:46:10] [7/10] training 89.2%: Loss=0.551542, Accuracy=59.838%, MSE=0.297272
[2023-08-18-09:46:11] [7/10] training 91.6%: Loss=0.551243, Accuracy=59.737%, MSE=0.297819
[2023-08-18-09:46:13] [7/10] training 94.0%: Loss=0.551379, Accuracy=59.641%, MSE=0.298627
[2023-08-18-09:46:15] [7/10] training 96.4%: Loss=0.553025, Accuracy=59.425%, MSE=0.300252
[2023-08-18-09:46:17] [7/10] training 98.8%: Loss=0.558418, Accuracy=58.951%, MSE=0.30376
[2023-08-18-09:46:29] Finished Epoch 7/10: Loss=0.613428, Accuracy=68.467%, MSE=0.206884, Precision=0.660826, Recall=0.602816, F1=0.630489, AUPR=0.682663
[2023-08-18-09:46:29] Saving model to ./models/huang_both_0_dscript_partitions_epoch07.sav
[2023-08-18-09:46:31] [8/10] training 2.4%: Loss=0.629786, Accuracy=47.000%, MSE=0.37825
[2023-08-18-09:46:33] [8/10] training 4.8%: Loss=0.54022, Accuracy=56.500%, MSE=0.308484
[2023-08-18-09:46:35] [8/10] training 7.2%: Loss=0.498658, Accuracy=60.333%, MSE=0.277343
[2023-08-18-09:46:37] [8/10] training 9.6%: Loss=0.461771, Accuracy=65.250%, MSE=0.243262
[2023-08-18-09:46:38] [8/10] training 12.0%: Loss=0.442128, Accuracy=68.000%, MSE=0.223582
[2023-08-18-09:46:40] [8/10] training 14.5%: Loss=0.44233, Accuracy=69.167%, MSE=0.22081
[2023-08-18-09:46:42] [8/10] training 16.9%: Loss=0.437692, Accuracy=69.571%, MSE=0.216667
[2023-08-18-09:46:44] [8/10] training 19.3%: Loss=0.446674, Accuracy=68.125%, MSE=0.225195
[2023-08-18-09:46:46] [8/10] training 21.7%: Loss=0.456634, Accuracy=66.889%, MSE=0.234263
[2023-08-18-09:46:48] [8/10] training 24.1%: Loss=0.460209, Accuracy=66.100%, MSE=0.23853
[2023-08-18-09:46:50] [8/10] training 26.5%: Loss=0.454612, Accuracy=66.727%, MSE=0.234169
[2023-08-18-09:46:52] [8/10] training 28.9%: Loss=0.445322, Accuracy=67.917%, MSE=0.226173
[2023-08-18-09:46:53] [8/10] training 31.3%: Loss=0.436655, Accuracy=69.077%, MSE=0.218892
[2023-08-18-09:46:55] [8/10] training 33.7%: Loss=0.430942, Accuracy=69.786%, MSE=0.214081
[2023-08-18-09:46:57] [8/10] training 36.1%: Loss=0.42767, Accuracy=70.333%, MSE=0.210624
[2023-08-18-09:46:59] [8/10] training 38.6%: Loss=0.424564, Accuracy=70.688%, MSE=0.208176
[2023-08-18-09:47:01] [8/10] training 41.0%: Loss=0.425862, Accuracy=70.353%, MSE=0.209767
[2023-08-18-09:47:03] [8/10] training 43.4%: Loss=0.43271, Accuracy=69.278%, MSE=0.215757
[2023-08-18-09:47:04] [8/10] training 45.8%: Loss=0.437604, Accuracy=68.737%, MSE=0.220363
[2023-08-18-09:47:06] [8/10] training 48.2%: Loss=0.436232, Accuracy=69.050%, MSE=0.219034
[2023-08-18-09:47:08] [8/10] training 50.6%: Loss=0.432716, Accuracy=69.476%, MSE=0.215925
[2023-08-18-09:47:10] [8/10] training 53.0%: Loss=0.435801, Accuracy=69.273%, MSE=0.218501
[2023-08-18-09:47:12] [8/10] training 55.4%: Loss=0.440867, Accuracy=68.739%, MSE=0.223015
[2023-08-18-09:47:14] [8/10] training 57.8%: Loss=0.453296, Accuracy=67.958%, MSE=0.232215
[2023-08-18-09:47:16] [8/10] training 60.2%: Loss=0.463148, Accuracy=67.400%, MSE=0.239226
[2023-08-18-09:47:17] [8/10] training 62.7%: Loss=0.47311, Accuracy=66.731%, MSE=0.246795
[2023-08-18-09:47:19] [8/10] training 65.1%: Loss=0.479888, Accuracy=66.333%, MSE=0.25168
[2023-08-18-09:47:21] [8/10] training 67.5%: Loss=0.488037, Accuracy=65.857%, MSE=0.257387
[2023-08-18-09:47:22] [8/10] training 69.9%: Loss=0.495425, Accuracy=65.310%, MSE=0.262615
[2023-08-18-09:47:24] [8/10] training 72.3%: Loss=0.500779, Accuracy=64.833%, MSE=0.266332
[2023-08-18-09:47:26] [8/10] training 74.7%: Loss=0.505727, Accuracy=64.484%, MSE=0.269027
[2023-08-18-09:47:28] [8/10] training 77.1%: Loss=0.509753, Accuracy=63.938%, MSE=0.272311
[2023-08-18-09:47:30] [8/10] training 79.5%: Loss=0.511396, Accuracy=63.424%, MSE=0.274516
[2023-08-18-09:47:31] [8/10] training 81.9%: Loss=0.512673, Accuracy=63.176%, MSE=0.276137
[2023-08-18-09:47:33] [8/10] training 84.3%: Loss=0.509961, Accuracy=63.171%, MSE=0.274644
[2023-08-18-09:47:35] [8/10] training 86.7%: Loss=0.505682, Accuracy=63.611%, MSE=0.271196
[2023-08-18-09:47:37] [8/10] training 89.2%: Loss=0.501242, Accuracy=64.108%, MSE=0.267476
[2023-08-18-09:47:38] [8/10] training 91.6%: Loss=0.497711, Accuracy=64.395%, MSE=0.264794
[2023-08-18-09:47:40] [8/10] training 94.0%: Loss=0.495609, Accuracy=64.462%, MSE=0.263385
[2023-08-18-09:47:42] [8/10] training 96.4%: Loss=0.494956, Accuracy=64.575%, MSE=0.2627
[2023-08-18-09:47:43] [8/10] training 98.8%: Loss=0.494353, Accuracy=64.463%, MSE=0.262521
[2023-08-18-09:47:56] Finished Epoch 8/10: Loss=0.706946, Accuracy=80.667%, MSE=0.15909, Precision=0.85348, Recall=0.659098, F1=0.743799, AUPR=0.856126
[2023-08-18-09:47:56] Saving model to ./models/huang_both_0_dscript_partitions_epoch08.sav
[2023-08-18-09:47:58] [9/10] training 2.4%: Loss=0.405805, Accuracy=75.000%, MSE=0.201107
[2023-08-18-09:48:00] [9/10] training 4.8%: Loss=0.373272, Accuracy=77.000%, MSE=0.170755
[2023-08-18-09:48:02] [9/10] training 7.2%: Loss=0.356036, Accuracy=80.667%, MSE=0.150287
[2023-08-18-09:48:04] [9/10] training 9.6%: Loss=0.369233, Accuracy=80.250%, MSE=0.156959
[2023-08-18-09:48:06] [9/10] training 12.0%: Loss=0.389472, Accuracy=77.600%, MSE=0.173094
[2023-08-18-09:48:08] [9/10] training 14.5%: Loss=0.403762, Accuracy=74.667%, MSE=0.189665
[2023-08-18-09:48:10] [9/10] training 16.9%: Loss=0.41699, Accuracy=71.571%, MSE=0.203397
[2023-08-18-09:48:11] [9/10] training 19.3%: Loss=0.426187, Accuracy=70.750%, MSE=0.210924
[2023-08-18-09:48:13] [9/10] training 21.7%: Loss=0.438397, Accuracy=69.000%, MSE=0.222589
[2023-08-18-09:48:15] [9/10] training 24.1%: Loss=0.444673, Accuracy=67.900%, MSE=0.229559
[2023-08-18-09:48:17] [9/10] training 26.5%: Loss=0.449081, Accuracy=67.182%, MSE=0.233755
[2023-08-18-09:48:19] [9/10] training 28.9%: Loss=0.440562, Accuracy=68.167%, MSE=0.226265
[2023-08-18-09:48:21] [9/10] training 31.3%: Loss=0.433925, Accuracy=68.923%, MSE=0.220365
[2023-08-18-09:48:22] [9/10] training 33.7%: Loss=0.430788, Accuracy=69.429%, MSE=0.217551
[2023-08-18-09:48:24] [9/10] training 36.1%: Loss=0.433788, Accuracy=69.267%, MSE=0.219664
[2023-08-18-09:48:26] [9/10] training 38.6%: Loss=0.438191, Accuracy=68.062%, MSE=0.225243
[2023-08-18-09:48:28] [9/10] training 41.0%: Loss=0.440462, Accuracy=67.471%, MSE=0.227833
[2023-08-18-09:48:29] [9/10] training 43.4%: Loss=0.449955, Accuracy=67.111%, MSE=0.233277
[2023-08-18-09:48:31] [9/10] training 45.8%: Loss=0.463202, Accuracy=66.211%, MSE=0.241293
[2023-08-18-09:48:33] [9/10] training 48.2%: Loss=0.475373, Accuracy=65.250%, MSE=0.249901
[2023-08-18-09:48:35] [9/10] training 50.6%: Loss=0.480023, Accuracy=64.381%, MSE=0.254941
[2023-08-18-09:48:37] [9/10] training 53.0%: Loss=0.479542, Accuracy=64.318%, MSE=0.255055
[2023-08-18-09:48:39] [9/10] training 55.4%: Loss=0.475847, Accuracy=64.478%, MSE=0.252536
[2023-08-18-09:48:40] [9/10] training 57.8%: Loss=0.470114, Accuracy=65.250%, MSE=0.247358
[2023-08-18-09:48:42] [9/10] training 60.2%: Loss=0.464393, Accuracy=65.880%, MSE=0.242582
[2023-08-18-09:48:44] [9/10] training 62.7%: Loss=0.459438, Accuracy=66.462%, MSE=0.238674
[2023-08-18-09:48:46] [9/10] training 65.1%: Loss=0.456994, Accuracy=66.889%, MSE=0.23565
[2023-08-18-09:48:48] [9/10] training 67.5%: Loss=0.454687, Accuracy=67.143%, MSE=0.233768
[2023-08-18-09:48:49] [9/10] training 69.9%: Loss=0.450683, Accuracy=67.483%, MSE=0.230539
[2023-08-18-09:48:51] [9/10] training 72.3%: Loss=0.448572, Accuracy=67.733%, MSE=0.22884
[2023-08-18-09:48:53] [9/10] training 74.7%: Loss=0.446835, Accuracy=67.774%, MSE=0.227742
[2023-08-18-09:48:55] [9/10] training 77.1%: Loss=0.445633, Accuracy=68.000%, MSE=0.226562
[2023-08-18-09:48:56] [9/10] training 79.5%: Loss=0.444424, Accuracy=68.121%, MSE=0.225467
[2023-08-18-09:48:58] [9/10] training 81.9%: Loss=0.443758, Accuracy=68.088%, MSE=0.225248
[2023-08-18-09:49:00] [9/10] training 84.3%: Loss=0.440583, Accuracy=68.457%, MSE=0.222745
[2023-08-18-09:49:02] [9/10] training 86.7%: Loss=0.436835, Accuracy=68.972%, MSE=0.219443
[2023-08-18-09:49:03] [9/10] training 89.2%: Loss=0.434908, Accuracy=69.216%, MSE=0.217855
[2023-08-18-09:49:05] [9/10] training 91.6%: Loss=0.433194, Accuracy=69.342%, MSE=0.216572
[2023-08-18-09:49:07] [9/10] training 94.0%: Loss=0.431053, Accuracy=69.615%, MSE=0.214812
[2023-08-18-09:49:09] [9/10] training 96.4%: Loss=0.429315, Accuracy=69.750%, MSE=0.213329
[2023-08-18-09:49:10] [9/10] training 98.8%: Loss=0.42869, Accuracy=69.829%, MSE=0.212954
[2023-08-18-09:49:23] Finished Epoch 9/10: Loss=0.943203, Accuracy=78.600%, MSE=0.180623, Precision=0.876587, Recall=0.628949, F1=0.732402, AUPR=0.880792
[2023-08-18-09:49:23] Saving model to ./models/huang_both_0_dscript_partitions_epoch09.sav
[2023-08-18-09:49:25] [10/10] training 2.4%: Loss=0.359772, Accuracy=75.000%, MSE=0.159673
[2023-08-18-09:49:27] [10/10] training 4.8%: Loss=0.340784, Accuracy=81.000%, MSE=0.139806
[2023-08-18-09:49:29] [10/10] training 7.2%: Loss=0.34391, Accuracy=79.000%, MSE=0.145023
[2023-08-18-09:49:30] [10/10] training 9.6%: Loss=0.348282, Accuracy=78.250%, MSE=0.149675
[2023-08-18-09:49:32] [10/10] training 12.0%: Loss=0.334417, Accuracy=80.800%, MSE=0.136416
[2023-08-18-09:49:34] [10/10] training 14.5%: Loss=0.333998, Accuracy=80.667%, MSE=0.134153
[2023-08-18-09:49:36] [10/10] training 16.9%: Loss=0.338584, Accuracy=80.429%, MSE=0.138137
[2023-08-18-09:49:37] [10/10] training 19.3%: Loss=0.331363, Accuracy=80.750%, MSE=0.132485
[2023-08-18-09:49:39] [10/10] training 21.7%: Loss=0.329388, Accuracy=81.222%, MSE=0.129874
[2023-08-18-09:49:41] [10/10] training 24.1%: Loss=0.3264, Accuracy=81.900%, MSE=0.127229
[2023-08-18-09:49:43] [10/10] training 26.5%: Loss=0.324051, Accuracy=82.273%, MSE=0.124896
[2023-08-18-09:49:44] [10/10] training 28.9%: Loss=0.31939, Accuracy=82.917%, MSE=0.120596
[2023-08-18-09:49:46] [10/10] training 31.3%: Loss=0.318802, Accuracy=82.923%, MSE=0.120627
[2023-08-18-09:49:48] [10/10] training 33.7%: Loss=0.316064, Accuracy=83.357%, MSE=0.118102
[2023-08-18-09:49:50] [10/10] training 36.1%: Loss=0.3171, Accuracy=83.200%, MSE=0.119128
[2023-08-18-09:49:52] [10/10] training 38.6%: Loss=0.317354, Accuracy=83.000%, MSE=0.120173
[2023-08-18-09:49:53] [10/10] training 41.0%: Loss=0.316648, Accuracy=83.118%, MSE=0.119797
[2023-08-18-09:49:55] [10/10] training 43.4%: Loss=0.323297, Accuracy=82.444%, MSE=0.124573
[2023-08-18-09:49:57] [10/10] training 45.8%: Loss=0.330232, Accuracy=82.053%, MSE=0.128625
[2023-08-18-09:49:59] [10/10] training 48.2%: Loss=0.33881, Accuracy=80.800%, MSE=0.136461
[2023-08-18-09:50:01] [10/10] training 50.6%: Loss=0.350281, Accuracy=79.286%, MSE=0.1472
[2023-08-18-09:50:02] [10/10] training 53.0%: Loss=0.358327, Accuracy=78.409%, MSE=0.154068
[2023-08-18-09:50:04] [10/10] training 55.4%: Loss=0.368362, Accuracy=77.391%, MSE=0.1622
[2023-08-18-09:50:06] [10/10] training 57.8%: Loss=0.377554, Accuracy=76.167%, MSE=0.169907
[2023-08-18-09:50:08] [10/10] training 60.2%: Loss=0.383717, Accuracy=75.400%, MSE=0.175499
[2023-08-18-09:50:10] [10/10] training 62.7%: Loss=0.384661, Accuracy=75.346%, MSE=0.176373
[2023-08-18-09:50:12] [10/10] training 65.1%: Loss=0.382695, Accuracy=75.667%, MSE=0.174787
[2023-08-18-09:50:13] [10/10] training 67.5%: Loss=0.378878, Accuracy=76.143%, MSE=0.171524
[2023-08-18-09:50:15] [10/10] training 69.9%: Loss=0.375731, Accuracy=76.483%, MSE=0.168997
[2023-08-18-09:50:17] [10/10] training 72.3%: Loss=0.372821, Accuracy=76.867%, MSE=0.166592
[2023-08-18-09:50:19] [10/10] training 74.7%: Loss=0.370561, Accuracy=77.097%, MSE=0.164769
[2023-08-18-09:50:20] [10/10] training 77.1%: Loss=0.368371, Accuracy=77.344%, MSE=0.163097
[2023-08-18-09:50:22] [10/10] training 79.5%: Loss=0.368449, Accuracy=77.182%, MSE=0.163717
[2023-08-18-09:50:24] [10/10] training 81.9%: Loss=0.367789, Accuracy=77.235%, MSE=0.163539
[2023-08-18-09:50:26] [10/10] training 84.3%: Loss=0.366339, Accuracy=77.371%, MSE=0.162571
[2023-08-18-09:50:28] [10/10] training 86.7%: Loss=0.36443, Accuracy=77.583%, MSE=0.161057
[2023-08-18-09:50:30] [10/10] training 89.2%: Loss=0.362662, Accuracy=77.811%, MSE=0.159669
[2023-08-18-09:50:31] [10/10] training 91.6%: Loss=0.361272, Accuracy=77.868%, MSE=0.15875
[2023-08-18-09:50:33] [10/10] training 94.0%: Loss=0.361618, Accuracy=77.821%, MSE=0.159314
[2023-08-18-09:50:35] [10/10] training 96.4%: Loss=0.362991, Accuracy=77.700%, MSE=0.160416
[2023-08-18-09:50:37] [10/10] training 98.8%: Loss=0.362203, Accuracy=77.756%, MSE=0.160009
[2023-08-18-09:50:50] Finished Epoch 10/10: Loss=1.46242, Accuracy=70.600%, MSE=0.261563, Precision=0.919726, Recall=0.437377, F1=0.592832, AUPR=0.887247
[2023-08-18-09:50:50] Saving model to ./models/huang_both_0_dscript_partitions_epoch10.sav
[2023-08-18-09:50:50] Saving final model to ./models/huang_both_0_dscript_partitions_final.sav
