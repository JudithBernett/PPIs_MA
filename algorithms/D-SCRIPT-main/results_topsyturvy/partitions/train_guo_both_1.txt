[2023-08-17-09:00:10] D-SCRIPT Version 0.2.2
[2023-08-17-09:00:10] Called as: /nfs/home/students/jbernett/miniconda3/envs/dscript/bin/dscript train --topsy-turvy --train data/partitions/guo_partition_both.txt --test data/partitions/guo_partition_1.txt --embedding /nfs/scratch/jbernett/yeast_embedding.h5 --save-prefix ./models/guo_both_1_tt_partitions -o ./results_topsyturvy/partitions/train_guo_both_1.txt -d 1
[2023-08-17-09:00:10] Loaded 7044 training pairs
[2023-08-17-09:00:10] Loaded 1476 test pairs
[2023-08-17-09:00:10] Loading embeddings...
[2023-08-17-09:01:45] Running D-SCRIPT Topsy-Turvy:
[2023-08-17-09:01:45] 	glider_weight: 0.2
[2023-08-17-09:01:45] 	glider_thresh: 92.5th percentile
[2023-08-17-09:01:45] Computing GLIDER matrix...
[2023-08-17-09:01:50] Initializing embedding model with:
[2023-08-17-09:01:50] 	projection_dim: 100
[2023-08-17-09:01:50] 	dropout_p: 0.5
[2023-08-17-09:01:50] Initializing contact model with:
[2023-08-17-09:01:50] 	hidden_dim: 50
[2023-08-17-09:01:50] 	kernel_width: 7
[2023-08-17-09:01:50] Initializing interaction model with:
[2023-08-17-09:01:50] 	do_poool: False
[2023-08-17-09:01:50] 	pool_width: 9
[2023-08-17-09:01:50] 	do_w: True
[2023-08-17-09:01:50] 	do_sigmoid: True
[2023-08-17-09:01:50] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-08-17-09:01:50] Using save prefix "./models/guo_both_1_tt_partitions"
[2023-08-17-09:01:50] Training with Adam: lr=0.001, weight_decay=0
[2023-08-17-09:01:50] 	num_epochs: 10
[2023-08-17-09:01:50] 	batch_size: 25
[2023-08-17-09:01:50] 	interaction weight: 0.35
[2023-08-17-09:01:50] 	contact map weight: 0.65
[2023-08-17-09:01:54] [1/10] training 1.4%: Loss=1.4221, Accuracy=52.000%, MSE=0.478561
[2023-08-17-09:01:56] [1/10] training 2.8%: Loss=1.27527, Accuracy=57.500%, MSE=0.423496
[2023-08-17-09:01:58] [1/10] training 4.3%: Loss=1.35415, Accuracy=53.667%, MSE=0.461544
[2023-08-17-09:02:00] [1/10] training 5.7%: Loss=1.39859, Accuracy=51.000%, MSE=0.487903
[2023-08-17-09:02:02] [1/10] training 7.1%: Loss=1.40325, Accuracy=50.400%, MSE=0.493771
[2023-08-17-09:02:05] [1/10] training 8.5%: Loss=1.38873, Accuracy=50.833%, MSE=0.489357
[2023-08-17-09:02:07] [1/10] training 9.9%: Loss=1.36814, Accuracy=51.286%, MSE=0.48468
[2023-08-17-09:02:09] [1/10] training 11.3%: Loss=1.38183, Accuracy=50.250%, MSE=0.494821
[2023-08-17-09:02:11] [1/10] training 12.8%: Loss=1.38095, Accuracy=50.111%, MSE=0.496131
[2023-08-17-09:02:13] [1/10] training 14.2%: Loss=1.37593, Accuracy=49.900%, MSE=0.498067
[2023-08-17-09:02:16] [1/10] training 15.6%: Loss=1.35958, Accuracy=50.545%, MSE=0.491579
[2023-08-17-09:02:18] [1/10] training 17.0%: Loss=1.35808, Accuracy=50.250%, MSE=0.494358
[2023-08-17-09:02:20] [1/10] training 18.4%: Loss=1.3505, Accuracy=50.231%, MSE=0.494384
[2023-08-17-09:02:22] [1/10] training 19.9%: Loss=1.34497, Accuracy=50.286%, MSE=0.493732
[2023-08-17-09:02:24] [1/10] training 21.3%: Loss=1.3395, Accuracy=50.200%, MSE=0.4944
[2023-08-17-09:02:26] [1/10] training 22.7%: Loss=1.33288, Accuracy=50.187%, MSE=0.494379
[2023-08-17-09:02:28] [1/10] training 24.1%: Loss=1.3319, Accuracy=50.000%, MSE=0.496127
[2023-08-17-09:02:31] [1/10] training 25.5%: Loss=1.31931, Accuracy=50.333%, MSE=0.492654
[2023-08-17-09:02:33] [1/10] training 27.0%: Loss=1.3142, Accuracy=50.316%, MSE=0.492685
[2023-08-17-09:02:35] [1/10] training 28.4%: Loss=1.30772, Accuracy=50.500%, MSE=0.490791
[2023-08-17-09:02:37] [1/10] training 29.8%: Loss=1.30045, Accuracy=50.619%, MSE=0.489467
[2023-08-17-09:02:40] [1/10] training 31.2%: Loss=1.30018, Accuracy=50.500%, MSE=0.490593
[2023-08-17-09:02:42] [1/10] training 32.6%: Loss=1.29168, Accuracy=50.696%, MSE=0.488522
[2023-08-17-09:02:44] [1/10] training 34.0%: Loss=1.29104, Accuracy=50.500%, MSE=0.490313
[2023-08-17-09:02:46] [1/10] training 35.5%: Loss=1.2927, Accuracy=50.240%, MSE=0.492828
[2023-08-17-09:02:48] [1/10] training 36.9%: Loss=1.28432, Accuracy=50.423%, MSE=0.490857
[2023-08-17-09:02:50] [1/10] training 38.3%: Loss=1.27858, Accuracy=50.593%, MSE=0.48912
[2023-08-17-09:02:52] [1/10] training 39.7%: Loss=1.28011, Accuracy=50.250%, MSE=0.492361
[2023-08-17-09:02:55] [1/10] training 41.1%: Loss=1.27954, Accuracy=50.103%, MSE=0.493723
[2023-08-17-09:02:57] [1/10] training 42.6%: Loss=1.27324, Accuracy=50.233%, MSE=0.49231
[2023-08-17-09:02:59] [1/10] training 44.0%: Loss=1.27272, Accuracy=50.065%, MSE=0.493883
[2023-08-17-09:03:01] [1/10] training 45.4%: Loss=1.26767, Accuracy=50.156%, MSE=0.492871
[2023-08-17-09:03:03] [1/10] training 46.8%: Loss=1.25979, Accuracy=50.424%, MSE=0.490112
[2023-08-17-09:03:05] [1/10] training 48.2%: Loss=1.25785, Accuracy=50.382%, MSE=0.490441
[2023-08-17-09:03:07] [1/10] training 49.6%: Loss=1.25311, Accuracy=50.429%, MSE=0.489838
[2023-08-17-09:03:10] [1/10] training 51.1%: Loss=1.24881, Accuracy=50.528%, MSE=0.488792
[2023-08-17-09:03:12] [1/10] training 52.5%: Loss=1.24907, Accuracy=50.297%, MSE=0.490929
[2023-08-17-09:03:14] [1/10] training 53.9%: Loss=1.24819, Accuracy=50.211%, MSE=0.491702
[2023-08-17-09:03:16] [1/10] training 55.3%: Loss=1.24524, Accuracy=50.205%, MSE=0.491646
[2023-08-17-09:03:19] [1/10] training 56.7%: Loss=1.24407, Accuracy=50.125%, MSE=0.492349
[2023-08-17-09:03:21] [1/10] training 58.2%: Loss=1.23992, Accuracy=50.146%, MSE=0.49196
[2023-08-17-09:03:23] [1/10] training 59.6%: Loss=1.24273, Accuracy=49.810%, MSE=0.495154
[2023-08-17-09:03:25] [1/10] training 61.0%: Loss=1.23794, Accuracy=49.953%, MSE=0.493658
[2023-08-17-09:03:27] [1/10] training 62.4%: Loss=1.23617, Accuracy=49.886%, MSE=0.49419
[2023-08-17-09:03:29] [1/10] training 63.8%: Loss=1.23116, Accuracy=50.022%, MSE=0.492754
[2023-08-17-09:03:31] [1/10] training 65.2%: Loss=1.22816, Accuracy=50.065%, MSE=0.49225
[2023-08-17-09:03:33] [1/10] training 66.7%: Loss=1.22408, Accuracy=50.128%, MSE=0.491504
[2023-08-17-09:03:35] [1/10] training 68.1%: Loss=1.22208, Accuracy=50.104%, MSE=0.491622
[2023-08-17-09:03:37] [1/10] training 69.5%: Loss=1.2194, Accuracy=50.082%, MSE=0.491709
[2023-08-17-09:03:40] [1/10] training 70.9%: Loss=1.21768, Accuracy=50.040%, MSE=0.492021
[2023-08-17-09:03:42] [1/10] training 72.3%: Loss=1.21502, Accuracy=50.039%, MSE=0.4919
[2023-08-17-09:03:44] [1/10] training 73.8%: Loss=1.21029, Accuracy=50.096%, MSE=0.491136
[2023-08-17-09:03:46] [1/10] training 75.2%: Loss=1.20558, Accuracy=50.283%, MSE=0.489254
[2023-08-17-09:03:48] [1/10] training 76.6%: Loss=1.20463, Accuracy=50.204%, MSE=0.489939
[2023-08-17-09:03:50] [1/10] training 78.0%: Loss=1.20288, Accuracy=50.127%, MSE=0.49054
[2023-08-17-09:03:52] [1/10] training 79.4%: Loss=1.19903, Accuracy=50.214%, MSE=0.489586
[2023-08-17-09:03:54] [1/10] training 80.9%: Loss=1.19709, Accuracy=50.193%, MSE=0.489699
[2023-08-17-09:03:56] [1/10] training 82.3%: Loss=1.19326, Accuracy=50.241%, MSE=0.489054
[2023-08-17-09:03:59] [1/10] training 83.7%: Loss=1.19255, Accuracy=50.186%, MSE=0.489529
[2023-08-17-09:04:01] [1/10] training 85.1%: Loss=1.18965, Accuracy=50.217%, MSE=0.489084
[2023-08-17-09:04:03] [1/10] training 86.5%: Loss=1.18906, Accuracy=50.115%, MSE=0.489951
[2023-08-17-09:04:05] [1/10] training 87.9%: Loss=1.1869, Accuracy=50.081%, MSE=0.490127
[2023-08-17-09:04:07] [1/10] training 89.4%: Loss=1.18467, Accuracy=50.063%, MSE=0.490133
[2023-08-17-09:04:09] [1/10] training 90.8%: Loss=1.18468, Accuracy=49.969%, MSE=0.491002
[2023-08-17-09:04:11] [1/10] training 92.2%: Loss=1.18364, Accuracy=49.892%, MSE=0.49163
[2023-08-17-09:04:14] [1/10] training 93.6%: Loss=1.18212, Accuracy=49.833%, MSE=0.492028
[2023-08-17-09:04:16] [1/10] training 95.0%: Loss=1.17909, Accuracy=49.896%, MSE=0.491311
[2023-08-17-09:04:18] [1/10] training 96.5%: Loss=1.17584, Accuracy=49.941%, MSE=0.4907
[2023-08-17-09:04:20] [1/10] training 97.9%: Loss=1.17401, Accuracy=49.928%, MSE=0.490734
[2023-08-17-09:04:22] [1/10] training 99.3%: Loss=1.17076, Accuracy=49.957%, MSE=0.490238
[2023-08-17-09:04:35] Finished Epoch 1/10: Loss=2.22138, Accuracy=49.200%, MSE=0.48506, Precision=0.470807, Recall=0.0154021, F1=0.0298284, AUPR=0.469894
[2023-08-17-09:04:35] Saving model to ./models/guo_both_1_tt_partitions_epoch01.sav
[2023-08-17-09:04:37] [2/10] training 1.4%: Loss=1.01881, Accuracy=53.000%, MSE=0.455502
[2023-08-17-09:04:39] [2/10] training 2.8%: Loss=0.972409, Accuracy=54.000%, MSE=0.443433
[2023-08-17-09:04:41] [2/10] training 4.3%: Loss=0.958429, Accuracy=54.333%, MSE=0.438459
[2023-08-17-09:04:43] [2/10] training 5.7%: Loss=0.955796, Accuracy=54.250%, MSE=0.43934
[2023-08-17-09:04:45] [2/10] training 7.1%: Loss=0.976718, Accuracy=52.600%, MSE=0.455254
[2023-08-17-09:04:47] [2/10] training 8.5%: Loss=1.01163, Accuracy=49.833%, MSE=0.481001
[2023-08-17-09:04:49] [2/10] training 9.9%: Loss=1.02771, Accuracy=48.714%, MSE=0.491791
[2023-08-17-09:04:51] [2/10] training 11.3%: Loss=1.03536, Accuracy=48.000%, MSE=0.498578
[2023-08-17-09:04:53] [2/10] training 12.8%: Loss=1.02848, Accuracy=48.222%, MSE=0.496228
[2023-08-17-09:04:55] [2/10] training 14.2%: Loss=1.03234, Accuracy=48.000%, MSE=0.498704
[2023-08-17-09:04:57] [2/10] training 15.6%: Loss=1.02109, Accuracy=48.455%, MSE=0.493902
[2023-08-17-09:04:59] [2/10] training 17.0%: Loss=1.02438, Accuracy=48.250%, MSE=0.496002
[2023-08-17-09:05:01] [2/10] training 18.4%: Loss=1.03011, Accuracy=47.692%, MSE=0.501132
[2023-08-17-09:05:03] [2/10] training 19.9%: Loss=1.03071, Accuracy=47.500%, MSE=0.502791
[2023-08-17-09:05:05] [2/10] training 21.3%: Loss=1.02107, Accuracy=48.000%, MSE=0.497679
[2023-08-17-09:05:07] [2/10] training 22.7%: Loss=1.01934, Accuracy=48.062%, MSE=0.496905
[2023-08-17-09:05:08] [2/10] training 24.1%: Loss=1.01273, Accuracy=48.353%, MSE=0.493756
[2023-08-17-09:05:10] [2/10] training 25.5%: Loss=1.0115, Accuracy=48.333%, MSE=0.49386
[2023-08-17-09:05:12] [2/10] training 27.0%: Loss=1.01027, Accuracy=48.316%, MSE=0.493977
[2023-08-17-09:05:14] [2/10] training 28.4%: Loss=1.01056, Accuracy=48.150%, MSE=0.495261
[2023-08-17-09:05:16] [2/10] training 29.8%: Loss=1.00725, Accuracy=48.333%, MSE=0.49342
[2023-08-17-09:05:18] [2/10] training 31.2%: Loss=1.00755, Accuracy=48.273%, MSE=0.493977
[2023-08-17-09:05:20] [2/10] training 32.6%: Loss=1.00427, Accuracy=48.435%, MSE=0.492329
[2023-08-17-09:05:23] [2/10] training 34.0%: Loss=1.0029, Accuracy=48.375%, MSE=0.492625
[2023-08-17-09:05:24] [2/10] training 35.5%: Loss=1.00101, Accuracy=48.360%, MSE=0.492438
[2023-08-17-09:05:26] [2/10] training 36.9%: Loss=0.996669, Accuracy=48.654%, MSE=0.489615
[2023-08-17-09:05:28] [2/10] training 38.3%: Loss=0.994835, Accuracy=48.593%, MSE=0.489774
[2023-08-17-09:05:30] [2/10] training 39.7%: Loss=0.995549, Accuracy=48.393%, MSE=0.491334
[2023-08-17-09:05:32] [2/10] training 41.1%: Loss=0.991556, Accuracy=48.552%, MSE=0.489493
[2023-08-17-09:05:34] [2/10] training 42.6%: Loss=0.986598, Accuracy=48.800%, MSE=0.486836
[2023-08-17-09:05:36] [2/10] training 44.0%: Loss=0.983501, Accuracy=48.839%, MSE=0.486074
[2023-08-17-09:05:38] [2/10] training 45.4%: Loss=0.978232, Accuracy=49.094%, MSE=0.48345
[2023-08-17-09:05:40] [2/10] training 46.8%: Loss=0.979068, Accuracy=48.939%, MSE=0.484769
[2023-08-17-09:05:42] [2/10] training 48.2%: Loss=0.975249, Accuracy=49.029%, MSE=0.483476
[2023-08-17-09:05:44] [2/10] training 49.6%: Loss=0.972638, Accuracy=49.114%, MSE=0.482537
[2023-08-17-09:05:46] [2/10] training 51.1%: Loss=0.973298, Accuracy=48.944%, MSE=0.483923
[2023-08-17-09:05:48] [2/10] training 52.5%: Loss=0.974232, Accuracy=48.784%, MSE=0.485297
[2023-08-17-09:05:50] [2/10] training 53.9%: Loss=0.970362, Accuracy=49.053%, MSE=0.482734
[2023-08-17-09:05:52] [2/10] training 55.3%: Loss=0.969853, Accuracy=48.872%, MSE=0.483984
[2023-08-17-09:05:54] [2/10] training 56.7%: Loss=0.969098, Accuracy=48.800%, MSE=0.484365
[2023-08-17-09:05:56] [2/10] training 58.2%: Loss=0.965515, Accuracy=49.098%, MSE=0.481645
[2023-08-17-09:05:58] [2/10] training 59.6%: Loss=0.960996, Accuracy=49.262%, MSE=0.479695
[2023-08-17-09:06:01] [2/10] training 61.0%: Loss=0.959902, Accuracy=49.256%, MSE=0.479508
[2023-08-17-09:06:03] [2/10] training 62.4%: Loss=0.958198, Accuracy=49.318%, MSE=0.478786
[2023-08-17-09:06:05] [2/10] training 63.8%: Loss=0.955319, Accuracy=49.356%, MSE=0.477994
[2023-08-17-09:06:07] [2/10] training 65.2%: Loss=0.951167, Accuracy=49.630%, MSE=0.475317
[2023-08-17-09:06:09] [2/10] training 66.7%: Loss=0.950795, Accuracy=49.596%, MSE=0.475563
[2023-08-17-09:06:11] [2/10] training 68.1%: Loss=0.948926, Accuracy=49.646%, MSE=0.47495
[2023-08-17-09:06:13] [2/10] training 69.5%: Loss=0.947619, Accuracy=49.653%, MSE=0.47469
[2023-08-17-09:06:15] [2/10] training 70.9%: Loss=0.946851, Accuracy=49.620%, MSE=0.474783
[2023-08-17-09:06:16] [2/10] training 72.3%: Loss=0.944706, Accuracy=49.667%, MSE=0.474012
[2023-08-17-09:06:19] [2/10] training 73.8%: Loss=0.94149, Accuracy=49.788%, MSE=0.472555
[2023-08-17-09:06:21] [2/10] training 75.2%: Loss=0.940946, Accuracy=49.736%, MSE=0.472881
[2023-08-17-09:06:23] [2/10] training 76.6%: Loss=0.937329, Accuracy=49.926%, MSE=0.470881
[2023-08-17-09:06:25] [2/10] training 78.0%: Loss=0.936752, Accuracy=49.891%, MSE=0.471069
[2023-08-17-09:06:27] [2/10] training 79.4%: Loss=0.935835, Accuracy=49.875%, MSE=0.470955
[2023-08-17-09:06:29] [2/10] training 80.9%: Loss=0.934495, Accuracy=49.807%, MSE=0.471204
[2023-08-17-09:06:31] [2/10] training 82.3%: Loss=0.931615, Accuracy=49.897%, MSE=0.47005
[2023-08-17-09:06:33] [2/10] training 83.7%: Loss=0.932269, Accuracy=49.780%, MSE=0.470999
[2023-08-17-09:06:35] [2/10] training 85.1%: Loss=0.928212, Accuracy=50.017%, MSE=0.468629
[2023-08-17-09:06:37] [2/10] training 86.5%: Loss=0.927586, Accuracy=49.902%, MSE=0.469298
[2023-08-17-09:06:39] [2/10] training 87.9%: Loss=0.926829, Accuracy=49.871%, MSE=0.469317
[2023-08-17-09:06:41] [2/10] training 89.4%: Loss=0.926933, Accuracy=49.810%, MSE=0.469824
[2023-08-17-09:06:43] [2/10] training 90.8%: Loss=0.92317, Accuracy=50.000%, MSE=0.467778
[2023-08-17-09:06:45] [2/10] training 92.2%: Loss=0.921301, Accuracy=49.969%, MSE=0.467532
[2023-08-17-09:06:47] [2/10] training 93.6%: Loss=0.919856, Accuracy=50.015%, MSE=0.466946
[2023-08-17-09:06:49] [2/10] training 95.0%: Loss=0.918739, Accuracy=50.015%, MSE=0.466751
[2023-08-17-09:06:51] [2/10] training 96.5%: Loss=0.917799, Accuracy=49.985%, MSE=0.466768
[2023-08-17-09:06:53] [2/10] training 97.9%: Loss=0.916754, Accuracy=49.957%, MSE=0.466733
[2023-08-17-09:06:55] [2/10] training 99.3%: Loss=0.916012, Accuracy=49.929%, MSE=0.466788
[2023-08-17-09:07:06] Finished Epoch 2/10: Loss=1.62053, Accuracy=49.000%, MSE=0.45477, Precision=0.395758, Recall=0.0542866, F1=0.0954766, AUPR=0.405395
[2023-08-17-09:07:06] Saving model to ./models/guo_both_1_tt_partitions_epoch02.sav
[2023-08-17-09:07:09] [3/10] training 1.4%: Loss=0.793846, Accuracy=51.000%, MSE=0.433662
[2023-08-17-09:07:11] [3/10] training 2.8%: Loss=0.771661, Accuracy=53.000%, MSE=0.417482
[2023-08-17-09:07:13] [3/10] training 4.3%: Loss=0.77667, Accuracy=52.333%, MSE=0.42397
[2023-08-17-09:07:15] [3/10] training 5.7%: Loss=0.775141, Accuracy=53.000%, MSE=0.419803
[2023-08-17-09:07:17] [3/10] training 7.1%: Loss=0.780756, Accuracy=52.600%, MSE=0.422892
[2023-08-17-09:07:19] [3/10] training 8.5%: Loss=0.785361, Accuracy=52.000%, MSE=0.427304
[2023-08-17-09:07:21] [3/10] training 9.9%: Loss=0.792908, Accuracy=52.000%, MSE=0.429106
[2023-08-17-09:07:23] [3/10] training 11.3%: Loss=0.795606, Accuracy=51.750%, MSE=0.431613
[2023-08-17-09:07:25] [3/10] training 12.8%: Loss=0.800464, Accuracy=51.000%, MSE=0.437257
[2023-08-17-09:07:27] [3/10] training 14.2%: Loss=0.794796, Accuracy=51.400%, MSE=0.43336
[2023-08-17-09:07:29] [3/10] training 15.6%: Loss=0.800302, Accuracy=50.636%, MSE=0.439368
[2023-08-17-09:07:31] [3/10] training 17.0%: Loss=0.801915, Accuracy=50.500%, MSE=0.44017
[2023-08-17-09:07:33] [3/10] training 18.4%: Loss=0.801918, Accuracy=50.308%, MSE=0.441165
[2023-08-17-09:07:35] [3/10] training 19.9%: Loss=0.80042, Accuracy=50.286%, MSE=0.440934
[2023-08-17-09:07:37] [3/10] training 21.3%: Loss=0.797909, Accuracy=50.533%, MSE=0.438689
[2023-08-17-09:07:39] [3/10] training 22.7%: Loss=0.797376, Accuracy=50.562%, MSE=0.438213
[2023-08-17-09:07:41] [3/10] training 24.1%: Loss=0.803006, Accuracy=50.059%, MSE=0.442417
[2023-08-17-09:07:43] [3/10] training 25.5%: Loss=0.801324, Accuracy=50.111%, MSE=0.441909
[2023-08-17-09:07:45] [3/10] training 27.0%: Loss=0.79937, Accuracy=49.947%, MSE=0.442106
[2023-08-17-09:07:46] [3/10] training 28.4%: Loss=0.801005, Accuracy=49.750%, MSE=0.443669
[2023-08-17-09:07:48] [3/10] training 29.8%: Loss=0.803026, Accuracy=49.524%, MSE=0.445674
[2023-08-17-09:07:50] [3/10] training 31.2%: Loss=0.809836, Accuracy=48.909%, MSE=0.451431
[2023-08-17-09:07:52] [3/10] training 32.6%: Loss=0.807789, Accuracy=48.783%, MSE=0.451376
[2023-08-17-09:07:54] [3/10] training 34.0%: Loss=0.805223, Accuracy=48.833%, MSE=0.450132
[2023-08-17-09:07:56] [3/10] training 35.5%: Loss=0.80426, Accuracy=48.800%, MSE=0.449889
[2023-08-17-09:07:58] [3/10] training 36.9%: Loss=0.804638, Accuracy=48.615%, MSE=0.45084
[2023-08-17-09:08:00] [3/10] training 38.3%: Loss=0.8006, Accuracy=48.889%, MSE=0.448109
[2023-08-17-09:08:02] [3/10] training 39.7%: Loss=0.802615, Accuracy=48.750%, MSE=0.449684
[2023-08-17-09:08:04] [3/10] training 41.1%: Loss=0.802072, Accuracy=48.690%, MSE=0.449828
[2023-08-17-09:08:06] [3/10] training 42.6%: Loss=0.800049, Accuracy=48.767%, MSE=0.448653
[2023-08-17-09:08:08] [3/10] training 44.0%: Loss=0.801463, Accuracy=48.742%, MSE=0.449344
[2023-08-17-09:08:10] [3/10] training 45.4%: Loss=0.800197, Accuracy=48.813%, MSE=0.448799
[2023-08-17-09:08:12] [3/10] training 46.8%: Loss=0.799295, Accuracy=48.667%, MSE=0.449233
[2023-08-17-09:08:14] [3/10] training 48.2%: Loss=0.797807, Accuracy=48.735%, MSE=0.448188
[2023-08-17-09:08:16] [3/10] training 49.6%: Loss=0.797153, Accuracy=48.914%, MSE=0.447041
[2023-08-17-09:08:18] [3/10] training 51.1%: Loss=0.79332, Accuracy=49.111%, MSE=0.444643
[2023-08-17-09:08:20] [3/10] training 52.5%: Loss=0.793762, Accuracy=48.730%, MSE=0.446422
[2023-08-17-09:08:22] [3/10] training 53.9%: Loss=0.794258, Accuracy=48.711%, MSE=0.446572
[2023-08-17-09:08:24] [3/10] training 55.3%: Loss=0.794344, Accuracy=48.692%, MSE=0.446691
[2023-08-17-09:08:26] [3/10] training 56.7%: Loss=0.791525, Accuracy=48.800%, MSE=0.44484
[2023-08-17-09:08:28] [3/10] training 58.2%: Loss=0.790223, Accuracy=48.829%, MSE=0.444413
[2023-08-17-09:08:30] [3/10] training 59.6%: Loss=0.789337, Accuracy=48.762%, MSE=0.444545
[2023-08-17-09:08:32] [3/10] training 61.0%: Loss=0.788392, Accuracy=48.721%, MSE=0.444419
[2023-08-17-09:08:34] [3/10] training 62.4%: Loss=0.787521, Accuracy=48.795%, MSE=0.443849
[2023-08-17-09:08:36] [3/10] training 63.8%: Loss=0.787044, Accuracy=48.800%, MSE=0.44389
[2023-08-17-09:08:38] [3/10] training 65.2%: Loss=0.785591, Accuracy=48.804%, MSE=0.443227
[2023-08-17-09:08:40] [3/10] training 66.7%: Loss=0.784966, Accuracy=48.809%, MSE=0.443023
[2023-08-17-09:08:42] [3/10] training 68.1%: Loss=0.784551, Accuracy=48.833%, MSE=0.442844
[2023-08-17-09:08:44] [3/10] training 69.5%: Loss=0.78412, Accuracy=48.816%, MSE=0.442624
[2023-08-17-09:08:46] [3/10] training 70.9%: Loss=0.784074, Accuracy=48.720%, MSE=0.442984
[2023-08-17-09:08:48] [3/10] training 72.3%: Loss=0.78316, Accuracy=48.882%, MSE=0.441832
[2023-08-17-09:08:50] [3/10] training 73.8%: Loss=0.781695, Accuracy=48.942%, MSE=0.441002
[2023-08-17-09:08:52] [3/10] training 75.2%: Loss=0.780736, Accuracy=48.925%, MSE=0.440727
[2023-08-17-09:08:54] [3/10] training 76.6%: Loss=0.778196, Accuracy=49.093%, MSE=0.438926
[2023-08-17-09:08:56] [3/10] training 78.0%: Loss=0.777191, Accuracy=49.145%, MSE=0.438263
[2023-08-17-09:08:58] [3/10] training 79.4%: Loss=0.776635, Accuracy=49.125%, MSE=0.438169
[2023-08-17-09:09:00] [3/10] training 80.9%: Loss=0.774186, Accuracy=49.298%, MSE=0.436527
[2023-08-17-09:09:02] [3/10] training 82.3%: Loss=0.77235, Accuracy=49.345%, MSE=0.435681
[2023-08-17-09:09:04] [3/10] training 83.7%: Loss=0.772061, Accuracy=49.271%, MSE=0.435954
[2023-08-17-09:09:06] [3/10] training 85.1%: Loss=0.770361, Accuracy=49.350%, MSE=0.434943
[2023-08-17-09:09:08] [3/10] training 86.5%: Loss=0.768838, Accuracy=49.410%, MSE=0.434131
[2023-08-17-09:09:11] [3/10] training 87.9%: Loss=0.767968, Accuracy=49.484%, MSE=0.433502
[2023-08-17-09:09:13] [3/10] training 89.4%: Loss=0.769186, Accuracy=49.254%, MSE=0.43508
[2023-08-17-09:09:15] [3/10] training 90.8%: Loss=0.768734, Accuracy=49.250%, MSE=0.434862
[2023-08-17-09:09:17] [3/10] training 92.2%: Loss=0.766622, Accuracy=49.369%, MSE=0.433486
[2023-08-17-09:09:19] [3/10] training 93.6%: Loss=0.765617, Accuracy=49.379%, MSE=0.433079
[2023-08-17-09:09:21] [3/10] training 95.0%: Loss=0.764088, Accuracy=49.448%, MSE=0.432237
[2023-08-17-09:09:23] [3/10] training 96.5%: Loss=0.762113, Accuracy=49.559%, MSE=0.430967
[2023-08-17-09:09:24] [3/10] training 97.9%: Loss=0.761002, Accuracy=49.565%, MSE=0.430434
[2023-08-17-09:09:26] [3/10] training 99.3%: Loss=0.759586, Accuracy=49.643%, MSE=0.429572
[2023-08-17-09:09:37] Finished Epoch 3/10: Loss=1.49836, Accuracy=46.067%, MSE=0.447438, Precision=0.370634, Recall=0.0831614, F1=0.135843, AUPR=0.418453
[2023-08-17-09:09:37] Saving model to ./models/guo_both_1_tt_partitions_epoch03.sav
[2023-08-17-09:09:40] [4/10] training 1.4%: Loss=0.70224, Accuracy=51.000%, MSE=0.404914
[2023-08-17-09:09:42] [4/10] training 2.8%: Loss=0.688084, Accuracy=51.000%, MSE=0.397974
[2023-08-17-09:09:44] [4/10] training 4.3%: Loss=0.697621, Accuracy=49.667%, MSE=0.408412
[2023-08-17-09:09:47] [4/10] training 5.7%: Loss=0.694845, Accuracy=49.500%, MSE=0.408774
[2023-08-17-09:09:49] [4/10] training 7.1%: Loss=0.706749, Accuracy=49.200%, MSE=0.414753
[2023-08-17-09:09:51] [4/10] training 8.5%: Loss=0.703529, Accuracy=49.667%, MSE=0.410352
[2023-08-17-09:09:53] [4/10] training 9.9%: Loss=0.700364, Accuracy=49.571%, MSE=0.409754
[2023-08-17-09:09:55] [4/10] training 11.3%: Loss=0.711513, Accuracy=48.375%, MSE=0.418801
[2023-08-17-09:09:57] [4/10] training 12.8%: Loss=0.713404, Accuracy=48.444%, MSE=0.41873
[2023-08-17-09:09:59] [4/10] training 14.2%: Loss=0.712812, Accuracy=48.400%, MSE=0.418545
[2023-08-17-09:10:01] [4/10] training 15.6%: Loss=0.705917, Accuracy=48.545%, MSE=0.414255
[2023-08-17-09:10:03] [4/10] training 17.0%: Loss=0.70316, Accuracy=48.500%, MSE=0.413134
[2023-08-17-09:10:05] [4/10] training 18.4%: Loss=0.708471, Accuracy=47.846%, MSE=0.418367
[2023-08-17-09:10:07] [4/10] training 19.9%: Loss=0.708433, Accuracy=48.000%, MSE=0.417528
[2023-08-17-09:10:09] [4/10] training 21.3%: Loss=0.705013, Accuracy=48.333%, MSE=0.414321
[2023-08-17-09:10:11] [4/10] training 22.7%: Loss=0.702142, Accuracy=48.438%, MSE=0.412917
[2023-08-17-09:10:13] [4/10] training 24.1%: Loss=0.704156, Accuracy=48.059%, MSE=0.415136
[2023-08-17-09:10:15] [4/10] training 25.5%: Loss=0.700198, Accuracy=48.556%, MSE=0.411372
[2023-08-17-09:10:18] [4/10] training 27.0%: Loss=0.701642, Accuracy=48.263%, MSE=0.413217
[2023-08-17-09:10:19] [4/10] training 28.4%: Loss=0.702514, Accuracy=48.000%, MSE=0.41445
[2023-08-17-09:10:21] [4/10] training 29.8%: Loss=0.699999, Accuracy=48.048%, MSE=0.412954
[2023-08-17-09:10:23] [4/10] training 31.2%: Loss=0.699997, Accuracy=48.045%, MSE=0.412866
[2023-08-17-09:10:25] [4/10] training 32.6%: Loss=0.70005, Accuracy=48.087%, MSE=0.412588
[2023-08-17-09:10:27] [4/10] training 34.0%: Loss=0.701303, Accuracy=48.042%, MSE=0.412968
[2023-08-17-09:10:29] [4/10] training 35.5%: Loss=0.70108, Accuracy=47.880%, MSE=0.413512
[2023-08-17-09:10:31] [4/10] training 36.9%: Loss=0.69956, Accuracy=47.885%, MSE=0.412678
[2023-08-17-09:10:32] [4/10] training 38.3%: Loss=0.698786, Accuracy=47.778%, MSE=0.412658
[2023-08-17-09:10:35] [4/10] training 39.7%: Loss=0.696411, Accuracy=47.893%, MSE=0.410981
[2023-08-17-09:10:37] [4/10] training 41.1%: Loss=0.696608, Accuracy=47.690%, MSE=0.41215
[2023-08-17-09:10:39] [4/10] training 42.6%: Loss=0.697446, Accuracy=47.500%, MSE=0.413389
[2023-08-17-09:10:41] [4/10] training 44.0%: Loss=0.697412, Accuracy=47.677%, MSE=0.412665
[2023-08-17-09:10:42] [4/10] training 45.4%: Loss=0.697711, Accuracy=47.469%, MSE=0.413414
[2023-08-17-09:10:44] [4/10] training 46.8%: Loss=0.695088, Accuracy=47.485%, MSE=0.411693
[2023-08-17-09:10:46] [4/10] training 48.2%: Loss=0.692243, Accuracy=47.618%, MSE=0.40959
[2023-08-17-09:10:48] [4/10] training 49.6%: Loss=0.69148, Accuracy=47.771%, MSE=0.408885
[2023-08-17-09:10:50] [4/10] training 51.1%: Loss=0.690302, Accuracy=47.833%, MSE=0.408172
[2023-08-17-09:10:52] [4/10] training 52.5%: Loss=0.690327, Accuracy=47.811%, MSE=0.408352
[2023-08-17-09:10:54] [4/10] training 53.9%: Loss=0.689738, Accuracy=47.789%, MSE=0.408261
[2023-08-17-09:10:56] [4/10] training 55.3%: Loss=0.688251, Accuracy=47.846%, MSE=0.407519
[2023-08-17-09:10:58] [4/10] training 56.7%: Loss=0.688452, Accuracy=47.850%, MSE=0.407822
[2023-08-17-09:11:00] [4/10] training 58.2%: Loss=0.685341, Accuracy=48.122%, MSE=0.405183
[2023-08-17-09:11:02] [4/10] training 59.6%: Loss=0.683211, Accuracy=48.143%, MSE=0.403763
[2023-08-17-09:11:04] [4/10] training 61.0%: Loss=0.682855, Accuracy=48.140%, MSE=0.403587
[2023-08-17-09:11:06] [4/10] training 62.4%: Loss=0.6823, Accuracy=48.136%, MSE=0.403283
[2023-08-17-09:11:08] [4/10] training 63.8%: Loss=0.681892, Accuracy=48.111%, MSE=0.403117
[2023-08-17-09:11:10] [4/10] training 65.2%: Loss=0.681816, Accuracy=47.978%, MSE=0.403511
[2023-08-17-09:11:12] [4/10] training 66.7%: Loss=0.681053, Accuracy=47.957%, MSE=0.40303
[2023-08-17-09:11:14] [4/10] training 68.1%: Loss=0.68045, Accuracy=47.917%, MSE=0.402785
[2023-08-17-09:11:16] [4/10] training 69.5%: Loss=0.680331, Accuracy=48.061%, MSE=0.402066
[2023-08-17-09:11:18] [4/10] training 70.9%: Loss=0.679559, Accuracy=48.120%, MSE=0.401456
[2023-08-17-09:11:20] [4/10] training 72.3%: Loss=0.679164, Accuracy=48.176%, MSE=0.401133
[2023-08-17-09:11:22] [4/10] training 73.8%: Loss=0.678026, Accuracy=48.250%, MSE=0.400367
[2023-08-17-09:11:24] [4/10] training 75.2%: Loss=0.677521, Accuracy=48.264%, MSE=0.400042
[2023-08-17-09:11:26] [4/10] training 76.6%: Loss=0.677312, Accuracy=48.222%, MSE=0.400085
[2023-08-17-09:11:28] [4/10] training 78.0%: Loss=0.676062, Accuracy=48.309%, MSE=0.399186
[2023-08-17-09:11:30] [4/10] training 79.4%: Loss=0.674929, Accuracy=48.321%, MSE=0.398455
[2023-08-17-09:11:32] [4/10] training 80.9%: Loss=0.675007, Accuracy=48.228%, MSE=0.398829
[2023-08-17-09:11:34] [4/10] training 82.3%: Loss=0.674036, Accuracy=48.224%, MSE=0.398274
[2023-08-17-09:11:36] [4/10] training 83.7%: Loss=0.672838, Accuracy=48.373%, MSE=0.397198
[2023-08-17-09:11:38] [4/10] training 85.1%: Loss=0.673342, Accuracy=48.283%, MSE=0.397766
[2023-08-17-09:11:40] [4/10] training 86.5%: Loss=0.671165, Accuracy=48.410%, MSE=0.396081
[2023-08-17-09:11:42] [4/10] training 87.9%: Loss=0.670003, Accuracy=48.435%, MSE=0.395384
[2023-08-17-09:11:44] [4/10] training 89.4%: Loss=0.668347, Accuracy=48.556%, MSE=0.39413
[2023-08-17-09:11:46] [4/10] training 90.8%: Loss=0.666733, Accuracy=48.750%, MSE=0.392626
[2023-08-17-09:11:48] [4/10] training 92.2%: Loss=0.66453, Accuracy=48.985%, MSE=0.390625
[2023-08-17-09:11:50] [4/10] training 93.6%: Loss=0.663957, Accuracy=49.015%, MSE=0.390263
[2023-08-17-09:11:52] [4/10] training 95.0%: Loss=0.662809, Accuracy=48.955%, MSE=0.389666
[2023-08-17-09:11:54] [4/10] training 96.5%: Loss=0.660721, Accuracy=49.044%, MSE=0.388194
[2023-08-17-09:11:56] [4/10] training 97.9%: Loss=0.659082, Accuracy=49.130%, MSE=0.387076
[2023-08-17-09:11:57] [4/10] training 99.3%: Loss=0.658448, Accuracy=49.157%, MSE=0.38666
[2023-08-17-09:12:08] Finished Epoch 4/10: Loss=1.13001, Accuracy=50.533%, MSE=0.37089, Precision=0.514159, Recall=0.18154, F1=0.268335, AUPR=0.520672
[2023-08-17-09:12:08] Saving model to ./models/guo_both_1_tt_partitions_epoch04.sav
[2023-08-17-09:12:11] [5/10] training 1.4%: Loss=0.626877, Accuracy=50.000%, MSE=0.364596
[2023-08-17-09:12:13] [5/10] training 2.8%: Loss=0.629792, Accuracy=50.000%, MSE=0.37105
[2023-08-17-09:12:14] [5/10] training 4.3%: Loss=0.598552, Accuracy=52.333%, MSE=0.345784
[2023-08-17-09:12:16] [5/10] training 5.7%: Loss=0.598633, Accuracy=50.000%, MSE=0.351262
[2023-08-17-09:12:18] [5/10] training 7.1%: Loss=0.594122, Accuracy=50.800%, MSE=0.346606
[2023-08-17-09:12:20] [5/10] training 8.5%: Loss=0.580323, Accuracy=52.667%, MSE=0.33391
[2023-08-17-09:12:22] [5/10] training 9.9%: Loss=0.572569, Accuracy=54.000%, MSE=0.32546
[2023-08-17-09:12:24] [5/10] training 11.3%: Loss=0.578858, Accuracy=53.000%, MSE=0.331718
[2023-08-17-09:12:26] [5/10] training 12.8%: Loss=0.588391, Accuracy=51.333%, MSE=0.341641
[2023-08-17-09:12:28] [5/10] training 14.2%: Loss=0.597024, Accuracy=50.500%, MSE=0.348714
[2023-08-17-09:12:30] [5/10] training 15.6%: Loss=0.596496, Accuracy=50.273%, MSE=0.348707
[2023-08-17-09:12:32] [5/10] training 17.0%: Loss=0.591311, Accuracy=50.583%, MSE=0.34439
[2023-08-17-09:12:34] [5/10] training 18.4%: Loss=0.591447, Accuracy=49.769%, MSE=0.345641
[2023-08-17-09:12:36] [5/10] training 19.9%: Loss=0.586662, Accuracy=50.214%, MSE=0.341275
[2023-08-17-09:12:38] [5/10] training 21.3%: Loss=0.588453, Accuracy=50.400%, MSE=0.342353
[2023-08-17-09:12:40] [5/10] training 22.7%: Loss=0.593183, Accuracy=49.812%, MSE=0.346902
[2023-08-17-09:12:42] [5/10] training 24.1%: Loss=0.594213, Accuracy=49.882%, MSE=0.347363
[2023-08-17-09:12:44] [5/10] training 25.5%: Loss=0.59663, Accuracy=49.611%, MSE=0.349676
[2023-08-17-09:12:46] [5/10] training 27.0%: Loss=0.595847, Accuracy=49.579%, MSE=0.349271
[2023-08-17-09:12:48] [5/10] training 28.4%: Loss=0.594537, Accuracy=49.650%, MSE=0.348158
[2023-08-17-09:12:50] [5/10] training 29.8%: Loss=0.597015, Accuracy=49.381%, MSE=0.350481
[2023-08-17-09:12:53] [5/10] training 31.2%: Loss=0.598845, Accuracy=49.273%, MSE=0.352056
[2023-08-17-09:12:54] [5/10] training 32.6%: Loss=0.596757, Accuracy=49.565%, MSE=0.35025
[2023-08-17-09:12:57] [5/10] training 34.0%: Loss=0.595492, Accuracy=49.500%, MSE=0.349644
[2023-08-17-09:12:58] [5/10] training 35.5%: Loss=0.594909, Accuracy=49.600%, MSE=0.348821
[2023-08-17-09:13:01] [5/10] training 36.9%: Loss=0.594931, Accuracy=49.500%, MSE=0.349154
[2023-08-17-09:13:03] [5/10] training 38.3%: Loss=0.595255, Accuracy=49.333%, MSE=0.349706
[2023-08-17-09:13:05] [5/10] training 39.7%: Loss=0.597337, Accuracy=49.107%, MSE=0.351465
[2023-08-17-09:13:07] [5/10] training 41.1%: Loss=0.597455, Accuracy=48.966%, MSE=0.351948
[2023-08-17-09:13:09] [5/10] training 42.6%: Loss=0.595797, Accuracy=49.000%, MSE=0.350945
[2023-08-17-09:13:11] [5/10] training 44.0%: Loss=0.595235, Accuracy=48.806%, MSE=0.350776
[2023-08-17-09:13:13] [5/10] training 45.4%: Loss=0.593901, Accuracy=48.781%, MSE=0.350035
[2023-08-17-09:13:16] [5/10] training 46.8%: Loss=0.593246, Accuracy=49.000%, MSE=0.349272
[2023-08-17-09:13:18] [5/10] training 48.2%: Loss=0.594007, Accuracy=48.971%, MSE=0.34984
[2023-08-17-09:13:20] [5/10] training 49.6%: Loss=0.594739, Accuracy=48.943%, MSE=0.350281
[2023-08-17-09:13:22] [5/10] training 51.1%: Loss=0.596741, Accuracy=48.639%, MSE=0.35231
[2023-08-17-09:13:24] [5/10] training 52.5%: Loss=0.595356, Accuracy=48.784%, MSE=0.351157
[2023-08-17-09:13:26] [5/10] training 53.9%: Loss=0.59423, Accuracy=48.737%, MSE=0.35036
[2023-08-17-09:13:28] [5/10] training 55.3%: Loss=0.59439, Accuracy=48.667%, MSE=0.350611
[2023-08-17-09:13:30] [5/10] training 56.7%: Loss=0.593293, Accuracy=48.625%, MSE=0.349939
[2023-08-17-09:13:32] [5/10] training 58.2%: Loss=0.593069, Accuracy=48.463%, MSE=0.349995
[2023-08-17-09:13:34] [5/10] training 59.6%: Loss=0.591279, Accuracy=48.548%, MSE=0.348701
[2023-08-17-09:13:36] [5/10] training 61.0%: Loss=0.590852, Accuracy=48.581%, MSE=0.348307
[2023-08-17-09:13:38] [5/10] training 62.4%: Loss=0.591929, Accuracy=48.409%, MSE=0.349417
[2023-08-17-09:13:39] [5/10] training 63.8%: Loss=0.590591, Accuracy=48.422%, MSE=0.348512
[2023-08-17-09:13:41] [5/10] training 65.2%: Loss=0.589971, Accuracy=48.326%, MSE=0.348273
[2023-08-17-09:13:43] [5/10] training 66.7%: Loss=0.588607, Accuracy=48.383%, MSE=0.347241
[2023-08-17-09:13:45] [5/10] training 68.1%: Loss=0.58788, Accuracy=48.500%, MSE=0.346582
[2023-08-17-09:13:48] [5/10] training 69.5%: Loss=0.587249, Accuracy=48.571%, MSE=0.346057
[2023-08-17-09:13:50] [5/10] training 70.9%: Loss=0.587448, Accuracy=48.400%, MSE=0.346583
[2023-08-17-09:13:51] [5/10] training 72.3%: Loss=0.58636, Accuracy=48.569%, MSE=0.345605
[2023-08-17-09:13:54] [5/10] training 73.8%: Loss=0.583921, Accuracy=48.865%, MSE=0.343461
[2023-08-17-09:13:56] [5/10] training 75.2%: Loss=0.58346, Accuracy=48.830%, MSE=0.343267
[2023-08-17-09:13:57] [5/10] training 76.6%: Loss=0.581988, Accuracy=48.926%, MSE=0.342103
[2023-08-17-09:13:59] [5/10] training 78.0%: Loss=0.580312, Accuracy=49.036%, MSE=0.340801
[2023-08-17-09:14:01] [5/10] training 79.4%: Loss=0.579366, Accuracy=49.196%, MSE=0.339972
[2023-08-17-09:14:03] [5/10] training 80.9%: Loss=0.576972, Accuracy=49.544%, MSE=0.337746
[2023-08-17-09:14:05] [5/10] training 82.3%: Loss=0.576175, Accuracy=49.638%, MSE=0.337061
[2023-08-17-09:14:07] [5/10] training 83.7%: Loss=0.576019, Accuracy=49.627%, MSE=0.33713
[2023-08-17-09:14:10] [5/10] training 85.1%: Loss=0.575178, Accuracy=49.667%, MSE=0.33657
[2023-08-17-09:14:11] [5/10] training 86.5%: Loss=0.573709, Accuracy=49.770%, MSE=0.335381
[2023-08-17-09:14:13] [5/10] training 87.9%: Loss=0.573466, Accuracy=49.806%, MSE=0.334918
[2023-08-17-09:14:15] [5/10] training 89.4%: Loss=0.573454, Accuracy=49.762%, MSE=0.335
[2023-08-17-09:14:17] [5/10] training 90.8%: Loss=0.573288, Accuracy=49.859%, MSE=0.33458
[2023-08-17-09:14:19] [5/10] training 92.2%: Loss=0.573865, Accuracy=49.815%, MSE=0.334944
[2023-08-17-09:14:21] [5/10] training 93.6%: Loss=0.574209, Accuracy=49.773%, MSE=0.335319
[2023-08-17-09:14:23] [5/10] training 95.0%: Loss=0.574085, Accuracy=49.687%, MSE=0.33545
[2023-08-17-09:14:25] [5/10] training 96.5%: Loss=0.573486, Accuracy=49.691%, MSE=0.335051
[2023-08-17-09:14:27] [5/10] training 97.9%: Loss=0.572838, Accuracy=49.710%, MSE=0.334655
[2023-08-17-09:14:29] [5/10] training 99.3%: Loss=0.572225, Accuracy=49.757%, MSE=0.334119
[2023-08-17-09:14:40] Finished Epoch 5/10: Loss=1.27231, Accuracy=48.000%, MSE=0.407762, Precision=0.45396, Recall=0.125161, F1=0.196222, AUPR=0.451413
[2023-08-17-09:14:40] Saving model to ./models/guo_both_1_tt_partitions_epoch05.sav
[2023-08-17-09:14:42] [6/10] training 1.4%: Loss=0.500054, Accuracy=54.000%, MSE=0.282664
[2023-08-17-09:14:44] [6/10] training 2.8%: Loss=0.49408, Accuracy=54.000%, MSE=0.276035
[2023-08-17-09:14:46] [6/10] training 4.3%: Loss=0.504499, Accuracy=52.667%, MSE=0.283929
[2023-08-17-09:14:48] [6/10] training 5.7%: Loss=0.501874, Accuracy=54.250%, MSE=0.280558
[2023-08-17-09:14:50] [6/10] training 7.1%: Loss=0.506141, Accuracy=54.000%, MSE=0.284049
[2023-08-17-09:14:52] [6/10] training 8.5%: Loss=0.518339, Accuracy=53.500%, MSE=0.2932
[2023-08-17-09:14:54] [6/10] training 9.9%: Loss=0.522099, Accuracy=52.714%, MSE=0.296636
[2023-08-17-09:14:55] [6/10] training 11.3%: Loss=0.519585, Accuracy=52.625%, MSE=0.294621
[2023-08-17-09:14:57] [6/10] training 12.8%: Loss=0.5159, Accuracy=53.000%, MSE=0.291133
[2023-08-17-09:14:59] [6/10] training 14.2%: Loss=0.516291, Accuracy=52.200%, MSE=0.292477
[2023-08-17-09:15:01] [6/10] training 15.6%: Loss=0.522793, Accuracy=51.273%, MSE=0.298491
[2023-08-17-09:15:03] [6/10] training 17.0%: Loss=0.528758, Accuracy=51.000%, MSE=0.303363
[2023-08-17-09:15:05] [6/10] training 18.4%: Loss=0.527538, Accuracy=51.077%, MSE=0.3023
[2023-08-17-09:15:07] [6/10] training 19.9%: Loss=0.526654, Accuracy=51.286%, MSE=0.301736
[2023-08-17-09:15:09] [6/10] training 21.3%: Loss=0.525261, Accuracy=51.333%, MSE=0.301191
[2023-08-17-09:15:11] [6/10] training 22.7%: Loss=0.524196, Accuracy=51.250%, MSE=0.300509
[2023-08-17-09:15:13] [6/10] training 24.1%: Loss=0.525096, Accuracy=51.412%, MSE=0.300882
[2023-08-17-09:15:16] [6/10] training 25.5%: Loss=0.524082, Accuracy=51.167%, MSE=0.300536
[2023-08-17-09:15:18] [6/10] training 27.0%: Loss=0.5252, Accuracy=51.105%, MSE=0.301686
[2023-08-17-09:15:20] [6/10] training 28.4%: Loss=0.524715, Accuracy=50.900%, MSE=0.301454
[2023-08-17-09:15:22] [6/10] training 29.8%: Loss=0.527363, Accuracy=50.619%, MSE=0.303712
[2023-08-17-09:15:23] [6/10] training 31.2%: Loss=0.525953, Accuracy=50.773%, MSE=0.302337
[2023-08-17-09:15:25] [6/10] training 32.6%: Loss=0.528844, Accuracy=50.348%, MSE=0.305265
[2023-08-17-09:15:27] [6/10] training 34.0%: Loss=0.527471, Accuracy=50.667%, MSE=0.303913
[2023-08-17-09:15:29] [6/10] training 35.5%: Loss=0.525005, Accuracy=50.880%, MSE=0.301823
[2023-08-17-09:15:31] [6/10] training 36.9%: Loss=0.5243, Accuracy=51.000%, MSE=0.300595
[2023-08-17-09:15:33] [6/10] training 38.3%: Loss=0.523626, Accuracy=50.741%, MSE=0.300515
[2023-08-17-09:15:35] [6/10] training 39.7%: Loss=0.522263, Accuracy=50.750%, MSE=0.299288
[2023-08-17-09:15:37] [6/10] training 41.1%: Loss=0.520322, Accuracy=51.000%, MSE=0.297348
[2023-08-17-09:15:39] [6/10] training 42.6%: Loss=0.520842, Accuracy=50.967%, MSE=0.297662
[2023-08-17-09:15:41] [6/10] training 44.0%: Loss=0.522812, Accuracy=50.774%, MSE=0.299537
[2023-08-17-09:15:43] [6/10] training 45.4%: Loss=0.523902, Accuracy=50.656%, MSE=0.300811
[2023-08-17-09:15:45] [6/10] training 46.8%: Loss=0.52353, Accuracy=50.848%, MSE=0.300442
[2023-08-17-09:15:47] [6/10] training 48.2%: Loss=0.521852, Accuracy=50.941%, MSE=0.299046
[2023-08-17-09:15:49] [6/10] training 49.6%: Loss=0.52246, Accuracy=50.829%, MSE=0.299584
[2023-08-17-09:15:52] [6/10] training 51.1%: Loss=0.521252, Accuracy=50.944%, MSE=0.298561
[2023-08-17-09:15:54] [6/10] training 52.5%: Loss=0.520473, Accuracy=51.027%, MSE=0.297951
[2023-08-17-09:15:56] [6/10] training 53.9%: Loss=0.51954, Accuracy=51.184%, MSE=0.296925
[2023-08-17-09:15:58] [6/10] training 55.3%: Loss=0.519273, Accuracy=51.103%, MSE=0.29691
[2023-08-17-09:16:00] [6/10] training 56.7%: Loss=0.518824, Accuracy=51.325%, MSE=0.296379
[2023-08-17-09:16:02] [6/10] training 58.2%: Loss=0.517322, Accuracy=51.537%, MSE=0.295015
[2023-08-17-09:16:04] [6/10] training 59.6%: Loss=0.516338, Accuracy=51.619%, MSE=0.294257
[2023-08-17-09:16:06] [6/10] training 61.0%: Loss=0.515346, Accuracy=51.814%, MSE=0.293153
[2023-08-17-09:16:08] [6/10] training 62.4%: Loss=0.514444, Accuracy=51.841%, MSE=0.292496
[2023-08-17-09:16:10] [6/10] training 63.8%: Loss=0.514431, Accuracy=51.889%, MSE=0.292314
[2023-08-17-09:16:12] [6/10] training 65.2%: Loss=0.513926, Accuracy=52.000%, MSE=0.291827
[2023-08-17-09:16:14] [6/10] training 66.7%: Loss=0.513347, Accuracy=52.213%, MSE=0.291333
[2023-08-17-09:16:16] [6/10] training 68.1%: Loss=0.512068, Accuracy=52.375%, MSE=0.29021
[2023-08-17-09:16:19] [6/10] training 69.5%: Loss=0.511431, Accuracy=52.531%, MSE=0.289614
[2023-08-17-09:16:20] [6/10] training 70.9%: Loss=0.512196, Accuracy=52.520%, MSE=0.290223
[2023-08-17-09:16:22] [6/10] training 72.3%: Loss=0.51236, Accuracy=52.490%, MSE=0.290366
[2023-08-17-09:16:24] [6/10] training 73.8%: Loss=0.51084, Accuracy=52.731%, MSE=0.289016
[2023-08-17-09:16:26] [6/10] training 75.2%: Loss=0.511129, Accuracy=52.717%, MSE=0.289171
[2023-08-17-09:16:29] [6/10] training 76.6%: Loss=0.510881, Accuracy=52.685%, MSE=0.289052
[2023-08-17-09:16:30] [6/10] training 78.0%: Loss=0.509556, Accuracy=52.836%, MSE=0.287741
[2023-08-17-09:16:32] [6/10] training 79.4%: Loss=0.510768, Accuracy=52.571%, MSE=0.289133
[2023-08-17-09:16:34] [6/10] training 80.9%: Loss=0.509886, Accuracy=52.719%, MSE=0.288306
[2023-08-17-09:16:37] [6/10] training 82.3%: Loss=0.509749, Accuracy=52.707%, MSE=0.288282
[2023-08-17-09:16:38] [6/10] training 83.7%: Loss=0.509592, Accuracy=52.763%, MSE=0.288158
[2023-08-17-09:16:40] [6/10] training 85.1%: Loss=0.50893, Accuracy=52.933%, MSE=0.287489
[2023-08-17-09:16:42] [6/10] training 86.5%: Loss=0.509078, Accuracy=52.820%, MSE=0.287842
[2023-08-17-09:16:44] [6/10] training 87.9%: Loss=0.509261, Accuracy=52.710%, MSE=0.288146
[2023-08-17-09:16:46] [6/10] training 89.4%: Loss=0.509784, Accuracy=52.635%, MSE=0.28866
[2023-08-17-09:16:48] [6/10] training 90.8%: Loss=0.509865, Accuracy=52.578%, MSE=0.288882
[2023-08-17-09:16:50] [6/10] training 92.2%: Loss=0.50992, Accuracy=52.446%, MSE=0.28905
[2023-08-17-09:16:52] [6/10] training 93.6%: Loss=0.509124, Accuracy=52.500%, MSE=0.288456
[2023-08-17-09:16:54] [6/10] training 95.0%: Loss=0.507226, Accuracy=52.776%, MSE=0.286586
[2023-08-17-09:16:56] [6/10] training 96.5%: Loss=0.50667, Accuracy=52.882%, MSE=0.286233
[2023-08-17-09:16:58] [6/10] training 97.9%: Loss=0.506409, Accuracy=52.928%, MSE=0.285993
[2023-08-17-09:17:00] [6/10] training 99.3%: Loss=0.505929, Accuracy=53.014%, MSE=0.285566
[2023-08-17-09:17:11] Finished Epoch 6/10: Loss=0.972122, Accuracy=42.467%, MSE=0.349067, Precision=0.452782, Recall=0.309351, F1=0.36757, AUPR=0.429733
[2023-08-17-09:17:11] Saving model to ./models/guo_both_1_tt_partitions_epoch06.sav
[2023-08-17-09:17:13] [7/10] training 1.4%: Loss=0.439061, Accuracy=59.000%, MSE=0.23338
[2023-08-17-09:17:15] [7/10] training 2.8%: Loss=0.450999, Accuracy=57.000%, MSE=0.246022
[2023-08-17-09:17:17] [7/10] training 4.3%: Loss=0.449495, Accuracy=57.667%, MSE=0.243757
[2023-08-17-09:17:19] [7/10] training 5.7%: Loss=0.443327, Accuracy=60.250%, MSE=0.234759
[2023-08-17-09:17:21] [7/10] training 7.1%: Loss=0.44171, Accuracy=60.600%, MSE=0.232578
[2023-08-17-09:17:23] [7/10] training 8.5%: Loss=0.451802, Accuracy=59.333%, MSE=0.242417
[2023-08-17-09:17:25] [7/10] training 9.9%: Loss=0.457746, Accuracy=58.857%, MSE=0.247622
[2023-08-17-09:17:27] [7/10] training 11.3%: Loss=0.462965, Accuracy=58.250%, MSE=0.251927
[2023-08-17-09:17:29] [7/10] training 12.8%: Loss=0.468929, Accuracy=57.111%, MSE=0.257949
[2023-08-17-09:17:32] [7/10] training 14.2%: Loss=0.466511, Accuracy=57.500%, MSE=0.254695
[2023-08-17-09:17:34] [7/10] training 15.6%: Loss=0.467727, Accuracy=57.364%, MSE=0.256009
[2023-08-17-09:17:36] [7/10] training 17.0%: Loss=0.467153, Accuracy=57.167%, MSE=0.255398
[2023-08-17-09:17:38] [7/10] training 18.4%: Loss=0.464393, Accuracy=57.538%, MSE=0.252992
[2023-08-17-09:17:39] [7/10] training 19.9%: Loss=0.465837, Accuracy=57.286%, MSE=0.254187
[2023-08-17-09:17:41] [7/10] training 21.3%: Loss=0.468704, Accuracy=56.800%, MSE=0.257238
[2023-08-17-09:17:43] [7/10] training 22.7%: Loss=0.47017, Accuracy=56.438%, MSE=0.258777
[2023-08-17-09:17:45] [7/10] training 24.1%: Loss=0.470318, Accuracy=56.353%, MSE=0.259074
[2023-08-17-09:17:47] [7/10] training 25.5%: Loss=0.470839, Accuracy=56.333%, MSE=0.259582
[2023-08-17-09:17:50] [7/10] training 27.0%: Loss=0.471049, Accuracy=56.368%, MSE=0.259778
[2023-08-17-09:17:52] [7/10] training 28.4%: Loss=0.470898, Accuracy=56.500%, MSE=0.259519
[2023-08-17-09:17:53] [7/10] training 29.8%: Loss=0.469816, Accuracy=56.524%, MSE=0.258611
[2023-08-17-09:17:55] [7/10] training 31.2%: Loss=0.468214, Accuracy=56.636%, MSE=0.257263
[2023-08-17-09:17:57] [7/10] training 32.6%: Loss=0.467304, Accuracy=56.783%, MSE=0.256373
[2023-08-17-09:18:00] [7/10] training 34.0%: Loss=0.466107, Accuracy=56.875%, MSE=0.25535
[2023-08-17-09:18:02] [7/10] training 35.5%: Loss=0.46621, Accuracy=56.920%, MSE=0.255143
[2023-08-17-09:18:04] [7/10] training 36.9%: Loss=0.46569, Accuracy=57.115%, MSE=0.254647
[2023-08-17-09:18:06] [7/10] training 38.3%: Loss=0.465208, Accuracy=57.148%, MSE=0.254385
[2023-08-17-09:18:07] [7/10] training 39.7%: Loss=0.464923, Accuracy=57.250%, MSE=0.254007
[2023-08-17-09:18:09] [7/10] training 41.1%: Loss=0.464669, Accuracy=57.207%, MSE=0.253867
[2023-08-17-09:18:11] [7/10] training 42.6%: Loss=0.465074, Accuracy=57.100%, MSE=0.254394
[2023-08-17-09:18:14] [7/10] training 44.0%: Loss=0.464532, Accuracy=57.065%, MSE=0.253903
[2023-08-17-09:18:16] [7/10] training 45.4%: Loss=0.46516, Accuracy=56.938%, MSE=0.254301
[2023-08-17-09:18:17] [7/10] training 46.8%: Loss=0.465571, Accuracy=56.939%, MSE=0.254622
[2023-08-17-09:18:19] [7/10] training 48.2%: Loss=0.465032, Accuracy=57.000%, MSE=0.254232
[2023-08-17-09:18:21] [7/10] training 49.6%: Loss=0.464523, Accuracy=57.114%, MSE=0.253558
[2023-08-17-09:18:23] [7/10] training 51.1%: Loss=0.462667, Accuracy=57.222%, MSE=0.252105
[2023-08-17-09:18:25] [7/10] training 52.5%: Loss=0.461963, Accuracy=57.378%, MSE=0.25129
[2023-08-17-09:18:27] [7/10] training 53.9%: Loss=0.460836, Accuracy=57.711%, MSE=0.24998
[2023-08-17-09:18:29] [7/10] training 55.3%: Loss=0.461844, Accuracy=57.615%, MSE=0.25082
[2023-08-17-09:18:31] [7/10] training 56.7%: Loss=0.461425, Accuracy=57.600%, MSE=0.250543
[2023-08-17-09:18:33] [7/10] training 58.2%: Loss=0.460766, Accuracy=57.732%, MSE=0.249865
[2023-08-17-09:18:35] [7/10] training 59.6%: Loss=0.461476, Accuracy=57.571%, MSE=0.250637
[2023-08-17-09:18:37] [7/10] training 61.0%: Loss=0.462162, Accuracy=57.512%, MSE=0.251295
[2023-08-17-09:18:38] [7/10] training 62.4%: Loss=0.461719, Accuracy=57.545%, MSE=0.250877
[2023-08-17-09:18:41] [7/10] training 63.8%: Loss=0.461264, Accuracy=57.556%, MSE=0.250666
[2023-08-17-09:18:43] [7/10] training 65.2%: Loss=0.460778, Accuracy=57.696%, MSE=0.250283
[2023-08-17-09:18:45] [7/10] training 66.7%: Loss=0.459671, Accuracy=57.872%, MSE=0.249267
[2023-08-17-09:18:47] [7/10] training 68.1%: Loss=0.458737, Accuracy=58.063%, MSE=0.248341
[2023-08-17-09:18:49] [7/10] training 69.5%: Loss=0.458868, Accuracy=58.061%, MSE=0.248504
[2023-08-17-09:18:51] [7/10] training 70.9%: Loss=0.459274, Accuracy=58.060%, MSE=0.248923
[2023-08-17-09:18:53] [7/10] training 72.3%: Loss=0.458901, Accuracy=58.137%, MSE=0.248471
[2023-08-17-09:18:55] [7/10] training 73.8%: Loss=0.459, Accuracy=58.115%, MSE=0.248409
[2023-08-17-09:18:57] [7/10] training 75.2%: Loss=0.458742, Accuracy=58.094%, MSE=0.248203
[2023-08-17-09:18:59] [7/10] training 76.6%: Loss=0.458446, Accuracy=58.148%, MSE=0.247928
[2023-08-17-09:19:01] [7/10] training 78.0%: Loss=0.459273, Accuracy=58.127%, MSE=0.248622
[2023-08-17-09:19:03] [7/10] training 79.4%: Loss=0.45881, Accuracy=58.250%, MSE=0.248126
[2023-08-17-09:19:05] [7/10] training 80.9%: Loss=0.458674, Accuracy=58.263%, MSE=0.248132
[2023-08-17-09:19:07] [7/10] training 82.3%: Loss=0.458785, Accuracy=58.224%, MSE=0.248299
[2023-08-17-09:19:09] [7/10] training 83.7%: Loss=0.459111, Accuracy=58.169%, MSE=0.248706
[2023-08-17-09:19:11] [7/10] training 85.1%: Loss=0.459576, Accuracy=58.200%, MSE=0.248674
[2023-08-17-09:19:13] [7/10] training 86.5%: Loss=0.459538, Accuracy=58.279%, MSE=0.248498
[2023-08-17-09:19:15] [7/10] training 87.9%: Loss=0.460101, Accuracy=58.210%, MSE=0.248996
[2023-08-17-09:19:17] [7/10] training 89.4%: Loss=0.459728, Accuracy=58.254%, MSE=0.248731
[2023-08-17-09:19:19] [7/10] training 90.8%: Loss=0.459178, Accuracy=58.328%, MSE=0.248357
[2023-08-17-09:19:21] [7/10] training 92.2%: Loss=0.458707, Accuracy=58.462%, MSE=0.247821
[2023-08-17-09:19:22] [7/10] training 93.6%: Loss=0.457713, Accuracy=58.652%, MSE=0.246945
[2023-08-17-09:19:25] [7/10] training 95.0%: Loss=0.457347, Accuracy=58.687%, MSE=0.246655
[2023-08-17-09:19:27] [7/10] training 96.5%: Loss=0.456749, Accuracy=58.735%, MSE=0.246142
[2023-08-17-09:19:29] [7/10] training 97.9%: Loss=0.45617, Accuracy=58.783%, MSE=0.245737
[2023-08-17-09:19:31] [7/10] training 99.3%: Loss=0.455163, Accuracy=58.957%, MSE=0.244715
[2023-08-17-09:19:42] Finished Epoch 7/10: Loss=1.0347, Accuracy=46.600%, MSE=0.354776, Precision=0.475257, Recall=0.239804, F1=0.318766, AUPR=0.459728
[2023-08-17-09:19:42] Saving model to ./models/guo_both_1_tt_partitions_epoch07.sav
[2023-08-17-09:19:44] [8/10] training 1.4%: Loss=0.391424, Accuracy=71.000%, MSE=0.17901
[2023-08-17-09:19:46] [8/10] training 2.8%: Loss=0.404374, Accuracy=69.000%, MSE=0.195539
[2023-08-17-09:19:49] [8/10] training 4.3%: Loss=0.398367, Accuracy=69.333%, MSE=0.189561
[2023-08-17-09:19:51] [8/10] training 5.7%: Loss=0.389584, Accuracy=71.250%, MSE=0.179855
[2023-08-17-09:19:52] [8/10] training 7.1%: Loss=0.39792, Accuracy=69.200%, MSE=0.189739
[2023-08-17-09:19:54] [8/10] training 8.5%: Loss=0.404953, Accuracy=67.833%, MSE=0.197731
[2023-08-17-09:19:57] [8/10] training 9.9%: Loss=0.415794, Accuracy=66.143%, MSE=0.208409
[2023-08-17-09:19:59] [8/10] training 11.3%: Loss=0.412878, Accuracy=66.375%, MSE=0.206648
[2023-08-17-09:20:00] [8/10] training 12.8%: Loss=0.414336, Accuracy=65.778%, MSE=0.208766
[2023-08-17-09:20:02] [8/10] training 14.2%: Loss=0.420729, Accuracy=64.400%, MSE=0.215088
[2023-08-17-09:20:04] [8/10] training 15.6%: Loss=0.422804, Accuracy=63.545%, MSE=0.217625
[2023-08-17-09:20:06] [8/10] training 17.0%: Loss=0.420376, Accuracy=63.833%, MSE=0.215656
[2023-08-17-09:20:08] [8/10] training 18.4%: Loss=0.417731, Accuracy=64.538%, MSE=0.212214
[2023-08-17-09:20:10] [8/10] training 19.9%: Loss=0.416503, Accuracy=65.143%, MSE=0.210649
[2023-08-17-09:20:12] [8/10] training 21.3%: Loss=0.418727, Accuracy=64.733%, MSE=0.212814
[2023-08-17-09:20:14] [8/10] training 22.7%: Loss=0.419511, Accuracy=64.562%, MSE=0.213823
[2023-08-17-09:20:16] [8/10] training 24.1%: Loss=0.418587, Accuracy=64.765%, MSE=0.21269
[2023-08-17-09:20:18] [8/10] training 25.5%: Loss=0.418974, Accuracy=64.778%, MSE=0.213073
[2023-08-17-09:20:20] [8/10] training 27.0%: Loss=0.417138, Accuracy=64.842%, MSE=0.211157
[2023-08-17-09:20:22] [8/10] training 28.4%: Loss=0.414253, Accuracy=65.050%, MSE=0.208659
[2023-08-17-09:20:24] [8/10] training 29.8%: Loss=0.413631, Accuracy=65.095%, MSE=0.208241
[2023-08-17-09:20:26] [8/10] training 31.2%: Loss=0.411393, Accuracy=65.455%, MSE=0.205749
[2023-08-17-09:20:28] [8/10] training 32.6%: Loss=0.415307, Accuracy=64.739%, MSE=0.21
[2023-08-17-09:20:31] [8/10] training 34.0%: Loss=0.414989, Accuracy=64.708%, MSE=0.210059
[2023-08-17-09:20:32] [8/10] training 35.5%: Loss=0.41492, Accuracy=64.680%, MSE=0.209741
[2023-08-17-09:20:34] [8/10] training 36.9%: Loss=0.413895, Accuracy=64.885%, MSE=0.209027
[2023-08-17-09:20:36] [8/10] training 38.3%: Loss=0.413687, Accuracy=65.074%, MSE=0.208367
[2023-08-17-09:20:38] [8/10] training 39.7%: Loss=0.412326, Accuracy=65.143%, MSE=0.20721
[2023-08-17-09:20:40] [8/10] training 41.1%: Loss=0.412368, Accuracy=65.069%, MSE=0.207423
[2023-08-17-09:20:42] [8/10] training 42.6%: Loss=0.413252, Accuracy=65.133%, MSE=0.208304
[2023-08-17-09:20:44] [8/10] training 44.0%: Loss=0.414076, Accuracy=65.097%, MSE=0.208995
[2023-08-17-09:20:46] [8/10] training 45.4%: Loss=0.413671, Accuracy=65.281%, MSE=0.208291
[2023-08-17-09:20:48] [8/10] training 46.8%: Loss=0.41341, Accuracy=65.182%, MSE=0.20795
[2023-08-17-09:20:50] [8/10] training 48.2%: Loss=0.413031, Accuracy=65.176%, MSE=0.207949
[2023-08-17-09:20:52] [8/10] training 49.6%: Loss=0.413328, Accuracy=65.057%, MSE=0.208491
[2023-08-17-09:20:54] [8/10] training 51.1%: Loss=0.413573, Accuracy=65.028%, MSE=0.208836
[2023-08-17-09:20:56] [8/10] training 52.5%: Loss=0.413322, Accuracy=65.081%, MSE=0.208482
[2023-08-17-09:20:58] [8/10] training 53.9%: Loss=0.415188, Accuracy=64.737%, MSE=0.210324
[2023-08-17-09:21:00] [8/10] training 55.3%: Loss=0.416488, Accuracy=64.410%, MSE=0.211667
[2023-08-17-09:21:03] [8/10] training 56.7%: Loss=0.416556, Accuracy=64.275%, MSE=0.211839
[2023-08-17-09:21:05] [8/10] training 58.2%: Loss=0.417312, Accuracy=64.098%, MSE=0.212668
[2023-08-17-09:21:07] [8/10] training 59.6%: Loss=0.418107, Accuracy=63.929%, MSE=0.213074
[2023-08-17-09:21:09] [8/10] training 61.0%: Loss=0.418221, Accuracy=63.977%, MSE=0.213224
[2023-08-17-09:21:10] [8/10] training 62.4%: Loss=0.418323, Accuracy=63.886%, MSE=0.213437
[2023-08-17-09:21:12] [8/10] training 63.8%: Loss=0.419752, Accuracy=63.667%, MSE=0.214667
[2023-08-17-09:21:14] [8/10] training 65.2%: Loss=0.418827, Accuracy=63.739%, MSE=0.213886
[2023-08-17-09:21:16] [8/10] training 66.7%: Loss=0.41851, Accuracy=63.872%, MSE=0.213601
[2023-08-17-09:21:18] [8/10] training 68.1%: Loss=0.41775, Accuracy=63.979%, MSE=0.212915
[2023-08-17-09:21:21] [8/10] training 69.5%: Loss=0.417763, Accuracy=63.959%, MSE=0.213004
[2023-08-17-09:21:23] [8/10] training 70.9%: Loss=0.418535, Accuracy=63.780%, MSE=0.213835
[2023-08-17-09:21:24] [8/10] training 72.3%: Loss=0.418762, Accuracy=63.745%, MSE=0.214211
[2023-08-17-09:21:26] [8/10] training 73.8%: Loss=0.418465, Accuracy=63.827%, MSE=0.213948
[2023-08-17-09:21:28] [8/10] training 75.2%: Loss=0.418048, Accuracy=63.906%, MSE=0.213505
[2023-08-17-09:21:30] [8/10] training 76.6%: Loss=0.417814, Accuracy=63.870%, MSE=0.213403
[2023-08-17-09:21:32] [8/10] training 78.0%: Loss=0.417083, Accuracy=64.000%, MSE=0.212608
[2023-08-17-09:21:34] [8/10] training 79.4%: Loss=0.416943, Accuracy=64.018%, MSE=0.212421
[2023-08-17-09:21:36] [8/10] training 80.9%: Loss=0.416626, Accuracy=64.088%, MSE=0.21212
[2023-08-17-09:21:38] [8/10] training 82.3%: Loss=0.416078, Accuracy=64.241%, MSE=0.211589
[2023-08-17-09:21:40] [8/10] training 83.7%: Loss=0.415442, Accuracy=64.356%, MSE=0.210954
[2023-08-17-09:21:42] [8/10] training 85.1%: Loss=0.415683, Accuracy=64.333%, MSE=0.211087
[2023-08-17-09:21:44] [8/10] training 86.5%: Loss=0.415047, Accuracy=64.426%, MSE=0.210502
[2023-08-17-09:21:46] [8/10] training 87.9%: Loss=0.415784, Accuracy=64.258%, MSE=0.211267
[2023-08-17-09:21:48] [8/10] training 89.4%: Loss=0.415655, Accuracy=64.270%, MSE=0.210977
[2023-08-17-09:21:50] [8/10] training 90.8%: Loss=0.414923, Accuracy=64.453%, MSE=0.21028
[2023-08-17-09:21:52] [8/10] training 92.2%: Loss=0.414415, Accuracy=64.462%, MSE=0.209905
[2023-08-17-09:21:54] [8/10] training 93.6%: Loss=0.414119, Accuracy=64.500%, MSE=0.209667
[2023-08-17-09:21:56] [8/10] training 95.0%: Loss=0.413428, Accuracy=64.597%, MSE=0.209035
[2023-08-17-09:21:58] [8/10] training 96.5%: Loss=0.412334, Accuracy=64.750%, MSE=0.208023
[2023-08-17-09:22:00] [8/10] training 97.9%: Loss=0.412365, Accuracy=64.739%, MSE=0.208136
[2023-08-17-09:22:02] [8/10] training 99.3%: Loss=0.411753, Accuracy=64.814%, MSE=0.207588
[2023-08-17-09:22:13] Finished Epoch 8/10: Loss=0.895594, Accuracy=48.467%, MSE=0.314977, Precision=0.514189, Recall=0.314882, F1=0.390579, AUPR=0.512943
[2023-08-17-09:22:13] Saving model to ./models/guo_both_1_tt_partitions_epoch08.sav
[2023-08-17-09:22:15] [9/10] training 1.4%: Loss=0.325675, Accuracy=82.000%, MSE=0.126271
[2023-08-17-09:22:17] [9/10] training 2.8%: Loss=0.34823, Accuracy=78.000%, MSE=0.145816
[2023-08-17-09:22:19] [9/10] training 4.3%: Loss=0.356233, Accuracy=76.000%, MSE=0.154017
[2023-08-17-09:22:21] [9/10] training 5.7%: Loss=0.360627, Accuracy=74.500%, MSE=0.159376
[2023-08-17-09:22:23] [9/10] training 7.1%: Loss=0.365188, Accuracy=74.000%, MSE=0.163736
[2023-08-17-09:22:25] [9/10] training 8.5%: Loss=0.368128, Accuracy=74.333%, MSE=0.166037
[2023-08-17-09:22:27] [9/10] training 9.9%: Loss=0.372548, Accuracy=73.000%, MSE=0.171462
[2023-08-17-09:22:29] [9/10] training 11.3%: Loss=0.372731, Accuracy=72.875%, MSE=0.171703
[2023-08-17-09:22:31] [9/10] training 12.8%: Loss=0.372997, Accuracy=73.000%, MSE=0.171123
[2023-08-17-09:22:32] [9/10] training 14.2%: Loss=0.375455, Accuracy=72.500%, MSE=0.17428
[2023-08-17-09:22:35] [9/10] training 15.6%: Loss=0.373422, Accuracy=73.000%, MSE=0.171879
[2023-08-17-09:22:37] [9/10] training 17.0%: Loss=0.375098, Accuracy=72.667%, MSE=0.174036
[2023-08-17-09:22:39] [9/10] training 18.4%: Loss=0.374404, Accuracy=72.692%, MSE=0.17404
[2023-08-17-09:22:41] [9/10] training 19.9%: Loss=0.377964, Accuracy=71.857%, MSE=0.177499
[2023-08-17-09:22:43] [9/10] training 21.3%: Loss=0.378416, Accuracy=71.533%, MSE=0.177904
[2023-08-17-09:22:45] [9/10] training 22.7%: Loss=0.380214, Accuracy=71.000%, MSE=0.179996
[2023-08-17-09:22:47] [9/10] training 24.1%: Loss=0.382758, Accuracy=70.353%, MSE=0.182861
[2023-08-17-09:22:48] [9/10] training 25.5%: Loss=0.383343, Accuracy=70.278%, MSE=0.183204
[2023-08-17-09:22:50] [9/10] training 27.0%: Loss=0.381856, Accuracy=70.368%, MSE=0.181886
[2023-08-17-09:22:52] [9/10] training 28.4%: Loss=0.382375, Accuracy=70.050%, MSE=0.183086
[2023-08-17-09:22:55] [9/10] training 29.8%: Loss=0.385585, Accuracy=69.571%, MSE=0.186344
[2023-08-17-09:22:57] [9/10] training 31.2%: Loss=0.384507, Accuracy=69.955%, MSE=0.185103
[2023-08-17-09:22:59] [9/10] training 32.6%: Loss=0.38385, Accuracy=69.870%, MSE=0.184821
[2023-08-17-09:23:01] [9/10] training 34.0%: Loss=0.381512, Accuracy=70.292%, MSE=0.182802
[2023-08-17-09:23:03] [9/10] training 35.5%: Loss=0.382149, Accuracy=70.480%, MSE=0.182775
[2023-08-17-09:23:04] [9/10] training 36.9%: Loss=0.379874, Accuracy=70.885%, MSE=0.180784
[2023-08-17-09:23:06] [9/10] training 38.3%: Loss=0.379662, Accuracy=70.889%, MSE=0.180608
[2023-08-17-09:23:08] [9/10] training 39.7%: Loss=0.378845, Accuracy=70.893%, MSE=0.180357
[2023-08-17-09:23:10] [9/10] training 41.1%: Loss=0.377114, Accuracy=71.103%, MSE=0.178764
[2023-08-17-09:23:12] [9/10] training 42.6%: Loss=0.375514, Accuracy=71.400%, MSE=0.177044
[2023-08-17-09:23:14] [9/10] training 44.0%: Loss=0.375072, Accuracy=71.516%, MSE=0.176684
[2023-08-17-09:23:16] [9/10] training 45.4%: Loss=0.375227, Accuracy=71.469%, MSE=0.177045
[2023-08-17-09:23:18] [9/10] training 46.8%: Loss=0.37604, Accuracy=71.333%, MSE=0.177704
[2023-08-17-09:23:20] [9/10] training 48.2%: Loss=0.37614, Accuracy=71.294%, MSE=0.177761
[2023-08-17-09:23:22] [9/10] training 49.6%: Loss=0.376228, Accuracy=71.314%, MSE=0.177849
[2023-08-17-09:23:24] [9/10] training 51.1%: Loss=0.375996, Accuracy=71.361%, MSE=0.177589
[2023-08-17-09:23:26] [9/10] training 52.5%: Loss=0.374745, Accuracy=71.514%, MSE=0.176461
[2023-08-17-09:23:28] [9/10] training 53.9%: Loss=0.375656, Accuracy=71.421%, MSE=0.177375
[2023-08-17-09:23:30] [9/10] training 55.3%: Loss=0.376143, Accuracy=71.308%, MSE=0.177993
[2023-08-17-09:23:32] [9/10] training 56.7%: Loss=0.376259, Accuracy=71.375%, MSE=0.177677
[2023-08-17-09:23:34] [9/10] training 58.2%: Loss=0.376798, Accuracy=71.195%, MSE=0.178413
[2023-08-17-09:23:36] [9/10] training 59.6%: Loss=0.377553, Accuracy=71.095%, MSE=0.17937
[2023-08-17-09:23:39] [9/10] training 61.0%: Loss=0.376885, Accuracy=71.233%, MSE=0.178877
[2023-08-17-09:23:40] [9/10] training 62.4%: Loss=0.377799, Accuracy=71.182%, MSE=0.179854
[2023-08-17-09:23:42] [9/10] training 63.8%: Loss=0.378888, Accuracy=70.978%, MSE=0.181007
[2023-08-17-09:23:44] [9/10] training 65.2%: Loss=0.379631, Accuracy=70.761%, MSE=0.181694
[2023-08-17-09:23:47] [9/10] training 66.7%: Loss=0.380507, Accuracy=70.638%, MSE=0.182428
[2023-08-17-09:23:49] [9/10] training 68.1%: Loss=0.380714, Accuracy=70.479%, MSE=0.182914
[2023-08-17-09:23:51] [9/10] training 69.5%: Loss=0.381653, Accuracy=70.224%, MSE=0.18373
[2023-08-17-09:23:53] [9/10] training 70.9%: Loss=0.380762, Accuracy=70.380%, MSE=0.182887
[2023-08-17-09:23:55] [9/10] training 72.3%: Loss=0.379859, Accuracy=70.549%, MSE=0.182021
[2023-08-17-09:23:57] [9/10] training 73.8%: Loss=0.380146, Accuracy=70.538%, MSE=0.18226
[2023-08-17-09:23:59] [9/10] training 75.2%: Loss=0.380083, Accuracy=70.491%, MSE=0.18225
[2023-08-17-09:24:01] [9/10] training 76.6%: Loss=0.379431, Accuracy=70.667%, MSE=0.181579
[2023-08-17-09:24:03] [9/10] training 78.0%: Loss=0.378456, Accuracy=70.800%, MSE=0.180687
[2023-08-17-09:24:05] [9/10] training 79.4%: Loss=0.37898, Accuracy=70.661%, MSE=0.181239
[2023-08-17-09:24:07] [9/10] training 80.9%: Loss=0.377646, Accuracy=70.842%, MSE=0.180009
[2023-08-17-09:24:09] [9/10] training 82.3%: Loss=0.376143, Accuracy=71.086%, MSE=0.17862
[2023-08-17-09:24:11] [9/10] training 83.7%: Loss=0.375957, Accuracy=71.153%, MSE=0.178268
[2023-08-17-09:24:13] [9/10] training 85.1%: Loss=0.375624, Accuracy=71.150%, MSE=0.178044
[2023-08-17-09:24:15] [9/10] training 86.5%: Loss=0.375217, Accuracy=71.246%, MSE=0.177319
[2023-08-17-09:24:17] [9/10] training 87.9%: Loss=0.375717, Accuracy=71.161%, MSE=0.177804
[2023-08-17-09:24:19] [9/10] training 89.4%: Loss=0.37639, Accuracy=70.921%, MSE=0.178697
[2023-08-17-09:24:21] [9/10] training 90.8%: Loss=0.375895, Accuracy=71.000%, MSE=0.178257
[2023-08-17-09:24:23] [9/10] training 92.2%: Loss=0.3763, Accuracy=70.969%, MSE=0.178585
[2023-08-17-09:24:25] [9/10] training 93.6%: Loss=0.376935, Accuracy=70.909%, MSE=0.179142
[2023-08-17-09:24:27] [9/10] training 95.0%: Loss=0.376258, Accuracy=71.015%, MSE=0.178531
[2023-08-17-09:24:29] [9/10] training 96.5%: Loss=0.375794, Accuracy=71.088%, MSE=0.178025
[2023-08-17-09:24:31] [9/10] training 97.9%: Loss=0.375384, Accuracy=71.145%, MSE=0.177706
[2023-08-17-09:24:33] [9/10] training 99.3%: Loss=0.374966, Accuracy=71.214%, MSE=0.177323
[2023-08-17-09:24:44] Finished Epoch 9/10: Loss=1.24239, Accuracy=49.200%, MSE=0.394363, Precision=0.497188, Recall=0.146397, F1=0.226192, AUPR=0.498038
[2023-08-17-09:24:44] Saving model to ./models/guo_both_1_tt_partitions_epoch09.sav
[2023-08-17-09:24:46] [10/10] training 1.4%: Loss=0.369668, Accuracy=72.000%, MSE=0.178655
[2023-08-17-09:24:48] [10/10] training 2.8%: Loss=0.360143, Accuracy=74.000%, MSE=0.169148
[2023-08-17-09:24:50] [10/10] training 4.3%: Loss=0.363633, Accuracy=73.333%, MSE=0.170449
[2023-08-17-09:24:52] [10/10] training 5.7%: Loss=0.36083, Accuracy=74.250%, MSE=0.167914
[2023-08-17-09:24:54] [10/10] training 7.1%: Loss=0.356098, Accuracy=75.400%, MSE=0.162508
[2023-08-17-09:24:56] [10/10] training 8.5%: Loss=0.362612, Accuracy=73.833%, MSE=0.169352
[2023-08-17-09:24:58] [10/10] training 9.9%: Loss=0.36365, Accuracy=73.286%, MSE=0.170888
[2023-08-17-09:25:00] [10/10] training 11.3%: Loss=0.367208, Accuracy=72.375%, MSE=0.174584
[2023-08-17-09:25:02] [10/10] training 12.8%: Loss=0.365732, Accuracy=72.222%, MSE=0.173936
[2023-08-17-09:25:04] [10/10] training 14.2%: Loss=0.363853, Accuracy=72.700%, MSE=0.171475
[2023-08-17-09:25:06] [10/10] training 15.6%: Loss=0.363704, Accuracy=72.636%, MSE=0.170658
[2023-08-17-09:25:08] [10/10] training 17.0%: Loss=0.360605, Accuracy=73.167%, MSE=0.166748
[2023-08-17-09:25:10] [10/10] training 18.4%: Loss=0.359942, Accuracy=73.077%, MSE=0.166591
[2023-08-17-09:25:12] [10/10] training 19.9%: Loss=0.358161, Accuracy=73.429%, MSE=0.164524
[2023-08-17-09:25:14] [10/10] training 21.3%: Loss=0.357881, Accuracy=73.200%, MSE=0.164762
[2023-08-17-09:25:16] [10/10] training 22.7%: Loss=0.359269, Accuracy=73.062%, MSE=0.16595
[2023-08-17-09:25:18] [10/10] training 24.1%: Loss=0.358517, Accuracy=73.000%, MSE=0.165303
[2023-08-17-09:25:20] [10/10] training 25.5%: Loss=0.358801, Accuracy=72.889%, MSE=0.165332
[2023-08-17-09:25:22] [10/10] training 27.0%: Loss=0.361656, Accuracy=72.947%, MSE=0.166494
[2023-08-17-09:25:24] [10/10] training 28.4%: Loss=0.362743, Accuracy=73.050%, MSE=0.167172
[2023-08-17-09:25:26] [10/10] training 29.8%: Loss=0.36326, Accuracy=72.857%, MSE=0.168037
[2023-08-17-09:25:28] [10/10] training 31.2%: Loss=0.361771, Accuracy=73.091%, MSE=0.166676
[2023-08-17-09:25:30] [10/10] training 32.6%: Loss=0.36286, Accuracy=72.696%, MSE=0.167908
[2023-08-17-09:25:32] [10/10] training 34.0%: Loss=0.363359, Accuracy=72.375%, MSE=0.168689
[2023-08-17-09:25:34] [10/10] training 35.5%: Loss=0.362437, Accuracy=72.480%, MSE=0.167779
[2023-08-17-09:25:36] [10/10] training 36.9%: Loss=0.363869, Accuracy=72.346%, MSE=0.169028
[2023-08-17-09:25:38] [10/10] training 38.3%: Loss=0.363211, Accuracy=72.222%, MSE=0.168943
[2023-08-17-09:25:40] [10/10] training 39.7%: Loss=0.361909, Accuracy=72.429%, MSE=0.167753
[2023-08-17-09:25:42] [10/10] training 41.1%: Loss=0.360451, Accuracy=72.655%, MSE=0.166377
[2023-08-17-09:25:44] [10/10] training 42.6%: Loss=0.359925, Accuracy=72.767%, MSE=0.165557
[2023-08-17-09:25:46] [10/10] training 44.0%: Loss=0.359781, Accuracy=72.839%, MSE=0.165452
[2023-08-17-09:25:48] [10/10] training 45.4%: Loss=0.36059, Accuracy=72.656%, MSE=0.166232
[2023-08-17-09:25:50] [10/10] training 46.8%: Loss=0.359474, Accuracy=72.909%, MSE=0.165139
[2023-08-17-09:25:52] [10/10] training 48.2%: Loss=0.358728, Accuracy=73.000%, MSE=0.164705
[2023-08-17-09:25:55] [10/10] training 49.6%: Loss=0.359173, Accuracy=72.743%, MSE=0.165515
[2023-08-17-09:25:57] [10/10] training 51.1%: Loss=0.358475, Accuracy=73.056%, MSE=0.16448
[2023-08-17-09:25:59] [10/10] training 52.5%: Loss=0.359158, Accuracy=73.081%, MSE=0.164919
[2023-08-17-09:26:01] [10/10] training 53.9%: Loss=0.360312, Accuracy=72.789%, MSE=0.166365
[2023-08-17-09:26:03] [10/10] training 55.3%: Loss=0.361943, Accuracy=72.333%, MSE=0.168202
[2023-08-17-09:26:05] [10/10] training 56.7%: Loss=0.363952, Accuracy=71.975%, MSE=0.17014
[2023-08-17-09:26:07] [10/10] training 58.2%: Loss=0.365027, Accuracy=71.756%, MSE=0.171208
[2023-08-17-09:26:08] [10/10] training 59.6%: Loss=0.365456, Accuracy=71.571%, MSE=0.171717
[2023-08-17-09:26:10] [10/10] training 61.0%: Loss=0.365551, Accuracy=71.581%, MSE=0.17192
[2023-08-17-09:26:12] [10/10] training 62.4%: Loss=0.364746, Accuracy=71.659%, MSE=0.171327
[2023-08-17-09:26:14] [10/10] training 63.8%: Loss=0.363698, Accuracy=71.911%, MSE=0.170239
[2023-08-17-09:26:17] [10/10] training 65.2%: Loss=0.364447, Accuracy=71.848%, MSE=0.170905
[2023-08-17-09:26:18] [10/10] training 66.7%: Loss=0.363622, Accuracy=71.957%, MSE=0.170099
[2023-08-17-09:26:20] [10/10] training 68.1%: Loss=0.363127, Accuracy=71.938%, MSE=0.169772
[2023-08-17-09:26:22] [10/10] training 69.5%: Loss=0.362353, Accuracy=72.143%, MSE=0.168969
[2023-08-17-09:26:24] [10/10] training 70.9%: Loss=0.360996, Accuracy=72.380%, MSE=0.167664
[2023-08-17-09:26:26] [10/10] training 72.3%: Loss=0.360399, Accuracy=72.588%, MSE=0.167016
[2023-08-17-09:26:28] [10/10] training 73.8%: Loss=0.360236, Accuracy=72.558%, MSE=0.167003
[2023-08-17-09:26:30] [10/10] training 75.2%: Loss=0.359166, Accuracy=72.792%, MSE=0.16599
[2023-08-17-09:26:32] [10/10] training 76.6%: Loss=0.358017, Accuracy=72.981%, MSE=0.164947
[2023-08-17-09:26:34] [10/10] training 78.0%: Loss=0.358475, Accuracy=72.927%, MSE=0.165299
[2023-08-17-09:26:36] [10/10] training 79.4%: Loss=0.358801, Accuracy=72.893%, MSE=0.165404
[2023-08-17-09:26:39] [10/10] training 80.9%: Loss=0.358468, Accuracy=72.982%, MSE=0.165084
[2023-08-17-09:26:40] [10/10] training 82.3%: Loss=0.358349, Accuracy=73.034%, MSE=0.164909
[2023-08-17-09:26:42] [10/10] training 83.7%: Loss=0.358274, Accuracy=72.966%, MSE=0.164874
[2023-08-17-09:26:45] [10/10] training 85.1%: Loss=0.357742, Accuracy=73.000%, MSE=0.164553
[2023-08-17-09:26:47] [10/10] training 86.5%: Loss=0.356974, Accuracy=73.082%, MSE=0.163881
[2023-08-17-09:26:48] [10/10] training 87.9%: Loss=0.356868, Accuracy=73.097%, MSE=0.163818
[2023-08-17-09:26:50] [10/10] training 89.4%: Loss=0.357006, Accuracy=73.143%, MSE=0.164004
[2023-08-17-09:26:52] [10/10] training 90.8%: Loss=0.355512, Accuracy=73.406%, MSE=0.16255
[2023-08-17-09:26:54] [10/10] training 92.2%: Loss=0.354494, Accuracy=73.615%, MSE=0.161491
[2023-08-17-09:26:56] [10/10] training 93.6%: Loss=0.35395, Accuracy=73.697%, MSE=0.161077
[2023-08-17-09:26:58] [10/10] training 95.0%: Loss=0.354695, Accuracy=73.582%, MSE=0.161631
[2023-08-17-09:27:00] [10/10] training 96.5%: Loss=0.354292, Accuracy=73.691%, MSE=0.161117
[2023-08-17-09:27:02] [10/10] training 97.9%: Loss=0.353906, Accuracy=73.725%, MSE=0.160913
[2023-08-17-09:27:04] [10/10] training 99.3%: Loss=0.353405, Accuracy=73.786%, MSE=0.160435
[2023-08-17-09:27:15] Finished Epoch 10/10: Loss=0.81507, Accuracy=49.067%, MSE=0.292291, Precision=0.513075, Recall=0.477826, F1=0.494823, AUPR=0.494647
[2023-08-17-09:27:15] Saving model to ./models/guo_both_1_tt_partitions_epoch10.sav
[2023-08-17-09:27:15] Saving final model to ./models/guo_both_1_tt_partitions_final.sav
