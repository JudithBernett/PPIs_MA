[2023-08-18-09:50:58] D-SCRIPT Version 0.2.2
[2023-08-18-09:50:58] Called as: /nfs/home/students/jbernett/miniconda3/envs/dscript/bin/dscript train --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_1.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_1_dscript_partitions -o ./results_dscript/partitions/train_huang_both_1.txt
[2023-08-18-09:51:01] Loaded 4136 training pairs
[2023-08-18-09:51:01] Loaded 1190 test pairs
[2023-08-18-09:51:01] Loading embeddings...
[2023-08-18-09:51:47] Initializing embedding model with:
[2023-08-18-09:51:47] 	projection_dim: 100
[2023-08-18-09:51:47] 	dropout_p: 0.5
[2023-08-18-09:51:47] Initializing contact model with:
[2023-08-18-09:51:47] 	hidden_dim: 50
[2023-08-18-09:51:47] 	kernel_width: 7
[2023-08-18-09:51:47] Initializing interaction model with:
[2023-08-18-09:51:47] 	do_poool: False
[2023-08-18-09:51:47] 	pool_width: 9
[2023-08-18-09:51:47] 	do_w: True
[2023-08-18-09:51:47] 	do_sigmoid: True
[2023-08-18-09:51:47] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-08-18-09:51:50] Using save prefix "./models/huang_both_1_dscript_partitions"
[2023-08-18-09:51:50] Training with Adam: lr=0.001, weight_decay=0
[2023-08-18-09:51:50] 	num_epochs: 10
[2023-08-18-09:51:50] 	batch_size: 25
[2023-08-18-09:51:50] 	interaction weight: 0.35
[2023-08-18-09:51:50] 	contact map weight: 0.65
[2023-08-18-09:51:53] [1/10] training 2.4%: Loss=1.51016, Accuracy=47.000%, MSE=0.528145
[2023-08-18-09:51:55] [1/10] training 4.8%: Loss=1.39072, Accuracy=51.500%, MSE=0.483054
[2023-08-18-09:51:57] [1/10] training 7.2%: Loss=1.37454, Accuracy=52.000%, MSE=0.477997
[2023-08-18-09:51:59] [1/10] training 9.6%: Loss=1.36502, Accuracy=52.000%, MSE=0.477825
[2023-08-18-09:52:01] [1/10] training 12.0%: Loss=1.39388, Accuracy=50.200%, MSE=0.495603
[2023-08-18-09:52:03] [1/10] training 14.5%: Loss=1.3723, Accuracy=51.000%, MSE=0.487571
[2023-08-18-09:52:05] [1/10] training 16.9%: Loss=1.37509, Accuracy=50.571%, MSE=0.49168
[2023-08-18-09:52:07] [1/10] training 19.3%: Loss=1.37843, Accuracy=50.000%, MSE=0.497194
[2023-08-18-09:52:09] [1/10] training 21.7%: Loss=1.37745, Accuracy=49.778%, MSE=0.499313
[2023-08-18-09:52:11] [1/10] training 24.1%: Loss=1.3703, Accuracy=49.800%, MSE=0.498989
[2023-08-18-09:52:13] [1/10] training 26.5%: Loss=1.34811, Accuracy=50.545%, MSE=0.491423
[2023-08-18-09:52:15] [1/10] training 28.9%: Loss=1.34144, Accuracy=50.750%, MSE=0.48934
[2023-08-18-09:52:17] [1/10] training 31.3%: Loss=1.33543, Accuracy=50.692%, MSE=0.489727
[2023-08-18-09:52:19] [1/10] training 33.7%: Loss=1.32652, Accuracy=50.929%, MSE=0.487321
[2023-08-18-09:52:21] [1/10] training 36.1%: Loss=1.3173, Accuracy=51.133%, MSE=0.48516
[2023-08-18-09:52:23] [1/10] training 38.6%: Loss=1.31431, Accuracy=50.937%, MSE=0.48692
[2023-08-18-09:52:25] [1/10] training 41.0%: Loss=1.31124, Accuracy=51.000%, MSE=0.486278
[2023-08-18-09:52:27] [1/10] training 43.4%: Loss=1.31193, Accuracy=50.667%, MSE=0.489459
[2023-08-18-09:52:29] [1/10] training 45.8%: Loss=1.30394, Accuracy=50.895%, MSE=0.487133
[2023-08-18-09:52:31] [1/10] training 48.2%: Loss=1.293, Accuracy=51.250%, MSE=0.483522
[2023-08-18-09:52:33] [1/10] training 50.6%: Loss=1.29574, Accuracy=50.905%, MSE=0.486861
[2023-08-18-09:52:35] [1/10] training 53.0%: Loss=1.29897, Accuracy=50.545%, MSE=0.490305
[2023-08-18-09:52:37] [1/10] training 55.4%: Loss=1.29777, Accuracy=50.304%, MSE=0.492516
[2023-08-18-09:52:39] [1/10] training 57.8%: Loss=1.30067, Accuracy=50.042%, MSE=0.495034
[2023-08-18-09:52:41] [1/10] training 60.2%: Loss=1.29906, Accuracy=49.960%, MSE=0.495706
[2023-08-18-09:52:43] [1/10] training 62.7%: Loss=1.29875, Accuracy=49.692%, MSE=0.49814
[2023-08-18-09:52:45] [1/10] training 65.1%: Loss=1.29933, Accuracy=49.704%, MSE=0.498048
[2023-08-18-09:52:47] [1/10] training 67.5%: Loss=1.28983, Accuracy=50.036%, MSE=0.494671
[2023-08-18-09:52:49] [1/10] training 69.9%: Loss=1.28662, Accuracy=49.931%, MSE=0.495544
[2023-08-18-09:52:51] [1/10] training 72.3%: Loss=1.2857, Accuracy=49.900%, MSE=0.495823
[2023-08-18-09:52:53] [1/10] training 74.7%: Loss=1.2851, Accuracy=49.774%, MSE=0.496979
[2023-08-18-09:52:55] [1/10] training 77.1%: Loss=1.28567, Accuracy=49.500%, MSE=0.499542
[2023-08-18-09:52:57] [1/10] training 79.5%: Loss=1.2796, Accuracy=49.697%, MSE=0.49752
[2023-08-18-09:52:59] [1/10] training 81.9%: Loss=1.27271, Accuracy=49.912%, MSE=0.495311
[2023-08-18-09:53:01] [1/10] training 84.3%: Loss=1.27052, Accuracy=49.829%, MSE=0.496021
[2023-08-18-09:53:03] [1/10] training 86.7%: Loss=1.26674, Accuracy=49.861%, MSE=0.495601
[2023-08-18-09:53:05] [1/10] training 89.2%: Loss=1.26658, Accuracy=49.703%, MSE=0.497055
[2023-08-18-09:53:07] [1/10] training 91.6%: Loss=1.26346, Accuracy=49.684%, MSE=0.497111
[2023-08-18-09:53:09] [1/10] training 94.0%: Loss=1.25974, Accuracy=49.795%, MSE=0.495962
[2023-08-18-09:53:11] [1/10] training 96.4%: Loss=1.25455, Accuracy=49.875%, MSE=0.495041
[2023-08-18-09:53:13] [1/10] training 98.8%: Loss=1.25076, Accuracy=49.927%, MSE=0.494425
[2023-08-18-09:53:22] Finished Epoch 1/10: Loss=2.36325, Accuracy=49.583%, MSE=0.487897, Precision=0.434966, Recall=0.012483, F1=0.0242695, AUPR=0.435474
[2023-08-18-09:53:22] Saving model to ./models/huang_both_1_dscript_partitions_epoch01.sav
[2023-08-18-09:53:25] [2/10] training 2.4%: Loss=1.21872, Accuracy=43.000%, MSE=0.555971
[2023-08-18-09:53:26] [2/10] training 4.8%: Loss=1.09492, Accuracy=49.500%, MSE=0.491384
[2023-08-18-09:53:28] [2/10] training 7.2%: Loss=1.09909, Accuracy=49.667%, MSE=0.490313
[2023-08-18-09:53:30] [2/10] training 9.6%: Loss=1.09703, Accuracy=50.500%, MSE=0.482952
[2023-08-18-09:53:32] [2/10] training 12.0%: Loss=1.09374, Accuracy=50.400%, MSE=0.483783
[2023-08-18-09:53:34] [2/10] training 14.5%: Loss=1.10077, Accuracy=50.000%, MSE=0.48767
[2023-08-18-09:53:36] [2/10] training 16.9%: Loss=1.1106, Accuracy=49.571%, MSE=0.492117
[2023-08-18-09:53:38] [2/10] training 19.3%: Loss=1.09258, Accuracy=50.500%, MSE=0.482776
[2023-08-18-09:53:39] [2/10] training 21.7%: Loss=1.0825, Accuracy=50.889%, MSE=0.478655
[2023-08-18-09:53:41] [2/10] training 24.1%: Loss=1.0852, Accuracy=51.000%, MSE=0.477901
[2023-08-18-09:53:43] [2/10] training 26.5%: Loss=1.06947, Accuracy=51.636%, MSE=0.471268
[2023-08-18-09:53:45] [2/10] training 28.9%: Loss=1.07837, Accuracy=51.000%, MSE=0.477409
[2023-08-18-09:53:46] [2/10] training 31.3%: Loss=1.08316, Accuracy=50.615%, MSE=0.481162
[2023-08-18-09:53:49] [2/10] training 33.7%: Loss=1.07676, Accuracy=50.857%, MSE=0.478678
[2023-08-18-09:53:51] [2/10] training 36.1%: Loss=1.07759, Accuracy=50.800%, MSE=0.479271
[2023-08-18-09:53:53] [2/10] training 38.6%: Loss=1.0785, Accuracy=50.625%, MSE=0.480834
[2023-08-18-09:53:54] [2/10] training 41.0%: Loss=1.07976, Accuracy=50.412%, MSE=0.482732
[2023-08-18-09:53:56] [2/10] training 43.4%: Loss=1.08313, Accuracy=50.167%, MSE=0.485093
[2023-08-18-09:53:58] [2/10] training 45.8%: Loss=1.08713, Accuracy=49.737%, MSE=0.489146
[2023-08-18-09:54:00] [2/10] training 48.2%: Loss=1.08349, Accuracy=49.900%, MSE=0.487531
[2023-08-18-09:54:02] [2/10] training 50.6%: Loss=1.0801, Accuracy=50.048%, MSE=0.486083
[2023-08-18-09:54:03] [2/10] training 53.0%: Loss=1.07737, Accuracy=50.045%, MSE=0.48587
[2023-08-18-09:54:05] [2/10] training 55.4%: Loss=1.07843, Accuracy=49.913%, MSE=0.487113
[2023-08-18-09:54:07] [2/10] training 57.8%: Loss=1.0753, Accuracy=49.917%, MSE=0.486826
[2023-08-18-09:54:09] [2/10] training 60.2%: Loss=1.06737, Accuracy=50.240%, MSE=0.483459
[2023-08-18-09:54:10] [2/10] training 62.7%: Loss=1.06731, Accuracy=50.192%, MSE=0.483831
[2023-08-18-09:54:12] [2/10] training 65.1%: Loss=1.06233, Accuracy=50.370%, MSE=0.481945
[2023-08-18-09:54:14] [2/10] training 67.5%: Loss=1.06254, Accuracy=50.179%, MSE=0.483583
[2023-08-18-09:54:15] [2/10] training 69.9%: Loss=1.06722, Accuracy=49.862%, MSE=0.486587
[2023-08-18-09:54:17] [2/10] training 72.3%: Loss=1.06324, Accuracy=50.067%, MSE=0.484566
[2023-08-18-09:54:19] [2/10] training 74.7%: Loss=1.06023, Accuracy=50.032%, MSE=0.484615
[2023-08-18-09:54:21] [2/10] training 77.1%: Loss=1.06225, Accuracy=49.813%, MSE=0.486599
[2023-08-18-09:54:22] [2/10] training 79.5%: Loss=1.06143, Accuracy=49.758%, MSE=0.487037
[2023-08-18-09:54:24] [2/10] training 81.9%: Loss=1.05919, Accuracy=49.676%, MSE=0.487382
[2023-08-18-09:54:26] [2/10] training 84.3%: Loss=1.05533, Accuracy=49.857%, MSE=0.485606
[2023-08-18-09:54:28] [2/10] training 86.7%: Loss=1.05199, Accuracy=49.972%, MSE=0.484396
[2023-08-18-09:54:30] [2/10] training 89.2%: Loss=1.04992, Accuracy=49.946%, MSE=0.484483
[2023-08-18-09:54:32] [2/10] training 91.6%: Loss=1.04569, Accuracy=50.105%, MSE=0.482874
[2023-08-18-09:54:33] [2/10] training 94.0%: Loss=1.04324, Accuracy=50.154%, MSE=0.482201
[2023-08-18-09:54:35] [2/10] training 96.4%: Loss=1.04149, Accuracy=50.200%, MSE=0.481731
[2023-08-18-09:54:37] [2/10] training 98.8%: Loss=1.03847, Accuracy=50.195%, MSE=0.481426
[2023-08-18-09:54:44] Finished Epoch 2/10: Loss=2.09997, Accuracy=49.583%, MSE=0.479963, Precision=0.374976, Recall=0.021902, F1=0.0413867, AUPR=0.395665
[2023-08-18-09:54:44] Saving model to ./models/huang_both_1_dscript_partitions_epoch02.sav
[2023-08-18-09:54:46] [3/10] training 2.4%: Loss=1.01627, Accuracy=49.000%, MSE=0.490145
[2023-08-18-09:54:48] [3/10] training 4.8%: Loss=0.95841, Accuracy=50.000%, MSE=0.476358
[2023-08-18-09:54:49] [3/10] training 7.2%: Loss=0.949657, Accuracy=50.000%, MSE=0.475098
[2023-08-18-09:54:51] [3/10] training 9.6%: Loss=0.973584, Accuracy=48.750%, MSE=0.488561
[2023-08-18-09:54:53] [3/10] training 12.0%: Loss=0.963482, Accuracy=49.600%, MSE=0.480118
[2023-08-18-09:54:55] [3/10] training 14.5%: Loss=0.957653, Accuracy=49.833%, MSE=0.477077
[2023-08-18-09:54:57] [3/10] training 16.9%: Loss=0.954167, Accuracy=50.000%, MSE=0.475414
[2023-08-18-09:54:59] [3/10] training 19.3%: Loss=0.964873, Accuracy=49.250%, MSE=0.482586
[2023-08-18-09:55:00] [3/10] training 21.7%: Loss=0.943735, Accuracy=50.333%, MSE=0.471481
[2023-08-18-09:55:02] [3/10] training 24.1%: Loss=0.946242, Accuracy=50.000%, MSE=0.474398
[2023-08-18-09:55:04] [3/10] training 26.5%: Loss=0.957018, Accuracy=49.273%, MSE=0.48094
[2023-08-18-09:55:06] [3/10] training 28.9%: Loss=0.951449, Accuracy=49.667%, MSE=0.476991
[2023-08-18-09:55:08] [3/10] training 31.3%: Loss=0.948275, Accuracy=49.385%, MSE=0.478474
[2023-08-18-09:55:10] [3/10] training 33.7%: Loss=0.947863, Accuracy=49.714%, MSE=0.475311
[2023-08-18-09:55:11] [3/10] training 36.1%: Loss=0.954844, Accuracy=49.400%, MSE=0.478651
[2023-08-18-09:55:13] [3/10] training 38.6%: Loss=0.947644, Accuracy=49.625%, MSE=0.475759
[2023-08-18-09:55:14] [3/10] training 41.0%: Loss=0.944467, Accuracy=49.765%, MSE=0.474033
[2023-08-18-09:55:16] [3/10] training 43.4%: Loss=0.944593, Accuracy=49.722%, MSE=0.474573
[2023-08-18-09:55:18] [3/10] training 45.8%: Loss=0.938652, Accuracy=49.947%, MSE=0.471933
[2023-08-18-09:55:20] [3/10] training 48.2%: Loss=0.934537, Accuracy=50.200%, MSE=0.469544
[2023-08-18-09:55:22] [3/10] training 50.6%: Loss=0.935995, Accuracy=50.048%, MSE=0.471193
[2023-08-18-09:55:23] [3/10] training 53.0%: Loss=0.933697, Accuracy=49.909%, MSE=0.471656
[2023-08-18-09:55:25] [3/10] training 55.4%: Loss=0.937693, Accuracy=49.478%, MSE=0.47527
[2023-08-18-09:55:27] [3/10] training 57.8%: Loss=0.935174, Accuracy=49.583%, MSE=0.474279
[2023-08-18-09:55:29] [3/10] training 60.2%: Loss=0.937113, Accuracy=49.280%, MSE=0.476986
[2023-08-18-09:55:31] [3/10] training 62.7%: Loss=0.934929, Accuracy=49.385%, MSE=0.475701
[2023-08-18-09:55:33] [3/10] training 65.1%: Loss=0.93271, Accuracy=49.444%, MSE=0.475121
[2023-08-18-09:55:35] [3/10] training 67.5%: Loss=0.932495, Accuracy=49.179%, MSE=0.476966
[2023-08-18-09:55:36] [3/10] training 69.9%: Loss=0.933992, Accuracy=48.966%, MSE=0.478785
[2023-08-18-09:55:38] [3/10] training 72.3%: Loss=0.928156, Accuracy=49.333%, MSE=0.475298
[2023-08-18-09:55:40] [3/10] training 74.7%: Loss=0.924248, Accuracy=49.452%, MSE=0.473824
[2023-08-18-09:55:42] [3/10] training 77.1%: Loss=0.922792, Accuracy=49.563%, MSE=0.472606
[2023-08-18-09:55:43] [3/10] training 79.5%: Loss=0.917922, Accuracy=49.697%, MSE=0.470601
[2023-08-18-09:55:46] [3/10] training 81.9%: Loss=0.919118, Accuracy=49.559%, MSE=0.471685
[2023-08-18-09:55:47] [3/10] training 84.3%: Loss=0.918904, Accuracy=49.514%, MSE=0.471874
[2023-08-18-09:55:49] [3/10] training 86.7%: Loss=0.914211, Accuracy=49.639%, MSE=0.470107
[2023-08-18-09:55:51] [3/10] training 89.2%: Loss=0.914384, Accuracy=49.486%, MSE=0.471143
[2023-08-18-09:55:53] [3/10] training 91.6%: Loss=0.913291, Accuracy=49.447%, MSE=0.471056
[2023-08-18-09:55:55] [3/10] training 94.0%: Loss=0.910703, Accuracy=49.538%, MSE=0.469924
[2023-08-18-09:55:56] [3/10] training 96.4%: Loss=0.910541, Accuracy=49.500%, MSE=0.470018
[2023-08-18-09:55:58] [3/10] training 98.8%: Loss=0.907433, Accuracy=49.610%, MSE=0.468762
[2023-08-18-09:56:06] Finished Epoch 3/10: Loss=1.51195, Accuracy=49.250%, MSE=0.436259, Precision=0.429782, Recall=0.0815746, F1=0.137123, AUPR=0.436466
[2023-08-18-09:56:06] Saving model to ./models/huang_both_1_dscript_partitions_epoch03.sav
[2023-08-18-09:56:08] [4/10] training 2.4%: Loss=0.812206, Accuracy=52.000%, MSE=0.441671
[2023-08-18-09:56:09] [4/10] training 4.8%: Loss=0.831444, Accuracy=50.000%, MSE=0.456841
[2023-08-18-09:56:12] [4/10] training 7.2%: Loss=0.819649, Accuracy=50.667%, MSE=0.448163
[2023-08-18-09:56:13] [4/10] training 9.6%: Loss=0.817035, Accuracy=51.500%, MSE=0.442684
[2023-08-18-09:56:15] [4/10] training 12.0%: Loss=0.819521, Accuracy=51.000%, MSE=0.44718
[2023-08-18-09:56:17] [4/10] training 14.5%: Loss=0.823324, Accuracy=49.333%, MSE=0.456628
[2023-08-18-09:56:19] [4/10] training 16.9%: Loss=0.828153, Accuracy=49.286%, MSE=0.457518
[2023-08-18-09:56:21] [4/10] training 19.3%: Loss=0.836323, Accuracy=49.625%, MSE=0.456999
[2023-08-18-09:56:23] [4/10] training 21.7%: Loss=0.83115, Accuracy=49.778%, MSE=0.455218
[2023-08-18-09:56:25] [4/10] training 24.1%: Loss=0.827151, Accuracy=50.300%, MSE=0.450639
[2023-08-18-09:56:26] [4/10] training 26.5%: Loss=0.831439, Accuracy=49.727%, MSE=0.455057
[2023-08-18-09:56:28] [4/10] training 28.9%: Loss=0.821595, Accuracy=50.000%, MSE=0.449655
[2023-08-18-09:56:29] [4/10] training 31.3%: Loss=0.818925, Accuracy=50.231%, MSE=0.447508
[2023-08-18-09:56:31] [4/10] training 33.7%: Loss=0.821256, Accuracy=50.000%, MSE=0.449624
[2023-08-18-09:56:33] [4/10] training 36.1%: Loss=0.83035, Accuracy=49.600%, MSE=0.454168
[2023-08-18-09:56:35] [4/10] training 38.6%: Loss=0.827196, Accuracy=49.813%, MSE=0.452235
[2023-08-18-09:56:37] [4/10] training 41.0%: Loss=0.820014, Accuracy=50.294%, MSE=0.447483
[2023-08-18-09:56:38] [4/10] training 43.4%: Loss=0.814346, Accuracy=50.389%, MSE=0.445569
[2023-08-18-09:56:40] [4/10] training 45.8%: Loss=0.811607, Accuracy=50.526%, MSE=0.444113
[2023-08-18-09:56:42] [4/10] training 48.2%: Loss=0.817248, Accuracy=50.300%, MSE=0.446494
[2023-08-18-09:56:44] [4/10] training 50.6%: Loss=0.822831, Accuracy=49.762%, MSE=0.451126
[2023-08-18-09:56:46] [4/10] training 53.0%: Loss=0.820636, Accuracy=49.773%, MSE=0.450505
[2023-08-18-09:56:48] [4/10] training 55.4%: Loss=0.819299, Accuracy=49.913%, MSE=0.44906
[2023-08-18-09:56:50] [4/10] training 57.8%: Loss=0.819642, Accuracy=49.792%, MSE=0.4496
[2023-08-18-09:56:52] [4/10] training 60.2%: Loss=0.818296, Accuracy=49.760%, MSE=0.449549
[2023-08-18-09:56:54] [4/10] training 62.7%: Loss=0.817596, Accuracy=49.654%, MSE=0.450168
[2023-08-18-09:56:55] [4/10] training 65.1%: Loss=0.816622, Accuracy=49.630%, MSE=0.450108
[2023-08-18-09:56:57] [4/10] training 67.5%: Loss=0.816798, Accuracy=49.500%, MSE=0.451093
[2023-08-18-09:56:59] [4/10] training 69.9%: Loss=0.815183, Accuracy=49.517%, MSE=0.450597
[2023-08-18-09:57:00] [4/10] training 72.3%: Loss=0.811895, Accuracy=49.633%, MSE=0.449083
[2023-08-18-09:57:02] [4/10] training 74.7%: Loss=0.8142, Accuracy=49.452%, MSE=0.450948
[2023-08-18-09:57:04] [4/10] training 77.1%: Loss=0.809794, Accuracy=49.781%, MSE=0.447913
[2023-08-18-09:57:06] [4/10] training 79.5%: Loss=0.813063, Accuracy=49.424%, MSE=0.450713
[2023-08-18-09:57:08] [4/10] training 81.9%: Loss=0.811531, Accuracy=49.324%, MSE=0.450886
[2023-08-18-09:57:09] [4/10] training 84.3%: Loss=0.813233, Accuracy=49.114%, MSE=0.452525
[2023-08-18-09:57:11] [4/10] training 86.7%: Loss=0.808628, Accuracy=49.500%, MSE=0.44917
[2023-08-18-09:57:13] [4/10] training 89.2%: Loss=0.804992, Accuracy=49.378%, MSE=0.448012
[2023-08-18-09:57:15] [4/10] training 91.6%: Loss=0.802093, Accuracy=49.526%, MSE=0.446487
[2023-08-18-09:57:16] [4/10] training 94.0%: Loss=0.801402, Accuracy=49.538%, MSE=0.446388
[2023-08-18-09:57:18] [4/10] training 96.4%: Loss=0.802856, Accuracy=49.400%, MSE=0.447479
[2023-08-18-09:57:20] [4/10] training 98.8%: Loss=0.801974, Accuracy=49.317%, MSE=0.447581
[2023-08-18-09:57:27] Finished Epoch 4/10: Loss=1.50637, Accuracy=49.500%, MSE=0.437392, Precision=0.479293, Recall=0.0743028, F1=0.12866, AUPR=0.483911
[2023-08-18-09:57:27] Saving model to ./models/huang_both_1_dscript_partitions_epoch04.sav
[2023-08-18-09:57:30] [5/10] training 2.4%: Loss=0.718414, Accuracy=58.000%, MSE=0.378826
[2023-08-18-09:57:31] [5/10] training 4.8%: Loss=0.720539, Accuracy=55.500%, MSE=0.396652
[2023-08-18-09:57:33] [5/10] training 7.2%: Loss=0.729643, Accuracy=53.000%, MSE=0.407443
[2023-08-18-09:57:35] [5/10] training 9.6%: Loss=0.744313, Accuracy=52.000%, MSE=0.418793
[2023-08-18-09:57:37] [5/10] training 12.0%: Loss=0.743701, Accuracy=51.600%, MSE=0.420946
[2023-08-18-09:57:39] [5/10] training 14.5%: Loss=0.742888, Accuracy=50.833%, MSE=0.42396
[2023-08-18-09:57:40] [5/10] training 16.9%: Loss=0.744591, Accuracy=50.571%, MSE=0.42678
[2023-08-18-09:57:42] [5/10] training 19.3%: Loss=0.743618, Accuracy=50.875%, MSE=0.423619
[2023-08-18-09:57:44] [5/10] training 21.7%: Loss=0.739423, Accuracy=50.222%, MSE=0.425029
[2023-08-18-09:57:46] [5/10] training 24.1%: Loss=0.744083, Accuracy=49.600%, MSE=0.429397
[2023-08-18-09:57:48] [5/10] training 26.5%: Loss=0.760424, Accuracy=48.545%, MSE=0.440272
[2023-08-18-09:57:50] [5/10] training 28.9%: Loss=0.765496, Accuracy=48.417%, MSE=0.442704
[2023-08-18-09:57:52] [5/10] training 31.3%: Loss=0.756809, Accuracy=48.462%, MSE=0.438321
[2023-08-18-09:57:54] [5/10] training 33.7%: Loss=0.753288, Accuracy=48.429%, MSE=0.436901
[2023-08-18-09:57:55] [5/10] training 36.1%: Loss=0.74579, Accuracy=49.000%, MSE=0.431239
[2023-08-18-09:57:57] [5/10] training 38.6%: Loss=0.752452, Accuracy=48.375%, MSE=0.43695
[2023-08-18-09:57:59] [5/10] training 41.0%: Loss=0.749764, Accuracy=48.706%, MSE=0.434732
[2023-08-18-09:58:00] [5/10] training 43.4%: Loss=0.744317, Accuracy=49.056%, MSE=0.431061
[2023-08-18-09:58:02] [5/10] training 45.8%: Loss=0.741401, Accuracy=49.053%, MSE=0.429878
[2023-08-18-09:58:04] [5/10] training 48.2%: Loss=0.739444, Accuracy=49.150%, MSE=0.42861
[2023-08-18-09:58:06] [5/10] training 50.6%: Loss=0.745939, Accuracy=48.714%, MSE=0.432638
[2023-08-18-09:58:08] [5/10] training 53.0%: Loss=0.741207, Accuracy=49.227%, MSE=0.428815
[2023-08-18-09:58:10] [5/10] training 55.4%: Loss=0.736017, Accuracy=49.304%, MSE=0.425976
[2023-08-18-09:58:12] [5/10] training 57.8%: Loss=0.73547, Accuracy=49.292%, MSE=0.425806
[2023-08-18-09:58:14] [5/10] training 60.2%: Loss=0.735723, Accuracy=49.240%, MSE=0.426197
[2023-08-18-09:58:15] [5/10] training 62.7%: Loss=0.735357, Accuracy=49.231%, MSE=0.426187
[2023-08-18-09:58:17] [5/10] training 65.1%: Loss=0.736675, Accuracy=49.296%, MSE=0.426549
[2023-08-18-09:58:19] [5/10] training 67.5%: Loss=0.735306, Accuracy=49.036%, MSE=0.426716
[2023-08-18-09:58:20] [5/10] training 69.9%: Loss=0.736374, Accuracy=49.000%, MSE=0.427493
[2023-08-18-09:58:22] [5/10] training 72.3%: Loss=0.738631, Accuracy=49.067%, MSE=0.427625
[2023-08-18-09:58:24] [5/10] training 74.7%: Loss=0.736175, Accuracy=49.258%, MSE=0.426017
[2023-08-18-09:58:26] [5/10] training 77.1%: Loss=0.735444, Accuracy=49.094%, MSE=0.42644
[2023-08-18-09:58:28] [5/10] training 79.5%: Loss=0.735175, Accuracy=49.061%, MSE=0.42632
[2023-08-18-09:58:29] [5/10] training 81.9%: Loss=0.733664, Accuracy=49.176%, MSE=0.425418
[2023-08-18-09:58:31] [5/10] training 84.3%: Loss=0.731769, Accuracy=49.114%, MSE=0.424859
[2023-08-18-09:58:33] [5/10] training 86.7%: Loss=0.72827, Accuracy=49.222%, MSE=0.422842
[2023-08-18-09:58:35] [5/10] training 89.2%: Loss=0.730766, Accuracy=48.946%, MSE=0.42504
[2023-08-18-09:58:37] [5/10] training 91.6%: Loss=0.729537, Accuracy=49.105%, MSE=0.423929
[2023-08-18-09:58:38] [5/10] training 94.0%: Loss=0.726752, Accuracy=49.154%, MSE=0.422485
[2023-08-18-09:58:40] [5/10] training 96.4%: Loss=0.725247, Accuracy=49.200%, MSE=0.421755
[2023-08-18-09:58:42] [5/10] training 98.8%: Loss=0.72602, Accuracy=49.171%, MSE=0.42208
[2023-08-18-09:58:49] Finished Epoch 5/10: Loss=1.32735, Accuracy=49.667%, MSE=0.406574, Precision=0.646603, Recall=0.108605, F1=0.185974, AUPR=0.653957
[2023-08-18-09:58:49] Saving model to ./models/huang_both_1_dscript_partitions_epoch05.sav
[2023-08-18-09:58:51] [6/10] training 2.4%: Loss=0.712477, Accuracy=38.000%, MSE=0.450806
[2023-08-18-09:58:53] [6/10] training 4.8%: Loss=0.669902, Accuracy=46.000%, MSE=0.407078
[2023-08-18-09:58:55] [6/10] training 7.2%: Loss=0.642507, Accuracy=50.333%, MSE=0.378488
[2023-08-18-09:58:56] [6/10] training 9.6%: Loss=0.647443, Accuracy=49.750%, MSE=0.384044
[2023-08-18-09:58:58] [6/10] training 12.0%: Loss=0.655833, Accuracy=49.000%, MSE=0.393196
[2023-08-18-09:59:00] [6/10] training 14.5%: Loss=0.65216, Accuracy=49.667%, MSE=0.388598
[2023-08-18-09:59:02] [6/10] training 16.9%: Loss=0.64614, Accuracy=50.429%, MSE=0.381838
[2023-08-18-09:59:04] [6/10] training 19.3%: Loss=0.657635, Accuracy=49.500%, MSE=0.389373
[2023-08-18-09:59:06] [6/10] training 21.7%: Loss=0.664453, Accuracy=49.444%, MSE=0.392602
[2023-08-18-09:59:07] [6/10] training 24.1%: Loss=0.661743, Accuracy=49.600%, MSE=0.391479
[2023-08-18-09:59:09] [6/10] training 26.5%: Loss=0.652947, Accuracy=50.091%, MSE=0.385633
[2023-08-18-09:59:11] [6/10] training 28.9%: Loss=0.651472, Accuracy=50.083%, MSE=0.384777
[2023-08-18-09:59:13] [6/10] training 31.3%: Loss=0.660279, Accuracy=50.154%, MSE=0.387865
[2023-08-18-09:59:15] [6/10] training 33.7%: Loss=0.659754, Accuracy=50.500%, MSE=0.386641
[2023-08-18-09:59:17] [6/10] training 36.1%: Loss=0.661386, Accuracy=50.200%, MSE=0.388925
[2023-08-18-09:59:18] [6/10] training 38.6%: Loss=0.662545, Accuracy=50.187%, MSE=0.389984
[2023-08-18-09:59:20] [6/10] training 41.0%: Loss=0.663661, Accuracy=50.176%, MSE=0.390988
[2023-08-18-09:59:22] [6/10] training 43.4%: Loss=0.66084, Accuracy=50.222%, MSE=0.389524
[2023-08-18-09:59:24] [6/10] training 45.8%: Loss=0.663209, Accuracy=49.895%, MSE=0.391827
[2023-08-18-09:59:26] [6/10] training 48.2%: Loss=0.665093, Accuracy=49.900%, MSE=0.392738
[2023-08-18-09:59:27] [6/10] training 50.6%: Loss=0.667955, Accuracy=49.381%, MSE=0.395905
[2023-08-18-09:59:29] [6/10] training 53.0%: Loss=0.669956, Accuracy=49.364%, MSE=0.39723
[2023-08-18-09:59:31] [6/10] training 55.4%: Loss=0.667093, Accuracy=49.478%, MSE=0.395117
[2023-08-18-09:59:33] [6/10] training 57.8%: Loss=0.66497, Accuracy=49.583%, MSE=0.393805
[2023-08-18-09:59:34] [6/10] training 60.2%: Loss=0.668679, Accuracy=49.280%, MSE=0.396876
[2023-08-18-09:59:36] [6/10] training 62.7%: Loss=0.670206, Accuracy=49.000%, MSE=0.398556
[2023-08-18-09:59:38] [6/10] training 65.1%: Loss=0.671411, Accuracy=48.963%, MSE=0.399217
[2023-08-18-09:59:40] [6/10] training 67.5%: Loss=0.67146, Accuracy=48.750%, MSE=0.400111
[2023-08-18-09:59:42] [6/10] training 69.9%: Loss=0.670469, Accuracy=48.690%, MSE=0.399739
[2023-08-18-09:59:43] [6/10] training 72.3%: Loss=0.66914, Accuracy=48.800%, MSE=0.398975
[2023-08-18-09:59:45] [6/10] training 74.7%: Loss=0.666934, Accuracy=48.935%, MSE=0.397395
[2023-08-18-09:59:47] [6/10] training 77.1%: Loss=0.669225, Accuracy=48.844%, MSE=0.398556
[2023-08-18-09:59:49] [6/10] training 79.5%: Loss=0.664834, Accuracy=49.273%, MSE=0.394862
[2023-08-18-09:59:51] [6/10] training 81.9%: Loss=0.661879, Accuracy=49.294%, MSE=0.393077
[2023-08-18-09:59:52] [6/10] training 84.3%: Loss=0.661553, Accuracy=49.314%, MSE=0.392909
[2023-08-18-09:59:54] [6/10] training 86.7%: Loss=0.662709, Accuracy=49.306%, MSE=0.393457
[2023-08-18-09:59:56] [6/10] training 89.2%: Loss=0.660635, Accuracy=49.486%, MSE=0.391805
[2023-08-18-09:59:58] [6/10] training 91.6%: Loss=0.659865, Accuracy=49.474%, MSE=0.391319
[2023-08-18-10:00:00] [6/10] training 94.0%: Loss=0.657641, Accuracy=49.641%, MSE=0.389635
[2023-08-18-10:00:02] [6/10] training 96.4%: Loss=0.656704, Accuracy=49.625%, MSE=0.389272
[2023-08-18-10:00:03] [6/10] training 98.8%: Loss=0.659137, Accuracy=49.488%, MSE=0.390976
[2023-08-18-10:00:11] Finished Epoch 6/10: Loss=1.03458, Accuracy=51.083%, MSE=0.348221, Precision=0.675664, Recall=0.193813, F1=0.301221, AUPR=0.688692
[2023-08-18-10:00:11] Saving model to ./models/huang_both_1_dscript_partitions_epoch06.sav
[2023-08-18-10:00:13] [7/10] training 2.4%: Loss=0.626479, Accuracy=46.000%, MSE=0.380296
[2023-08-18-10:00:15] [7/10] training 4.8%: Loss=0.626213, Accuracy=45.000%, MSE=0.386103
[2023-08-18-10:00:17] [7/10] training 7.2%: Loss=0.619088, Accuracy=45.667%, MSE=0.382032
[2023-08-18-10:00:18] [7/10] training 9.6%: Loss=0.627926, Accuracy=45.250%, MSE=0.387437
[2023-08-18-10:00:20] [7/10] training 12.0%: Loss=0.643309, Accuracy=44.600%, MSE=0.397529
[2023-08-18-10:00:22] [7/10] training 14.5%: Loss=0.649362, Accuracy=45.000%, MSE=0.401142
[2023-08-18-10:00:24] [7/10] training 16.9%: Loss=0.646038, Accuracy=45.286%, MSE=0.397798
[2023-08-18-10:00:26] [7/10] training 19.3%: Loss=0.632088, Accuracy=46.625%, MSE=0.386129
[2023-08-18-10:00:28] [7/10] training 21.7%: Loss=0.622084, Accuracy=47.778%, MSE=0.37716
[2023-08-18-10:00:30] [7/10] training 24.1%: Loss=0.619322, Accuracy=47.900%, MSE=0.375113
[2023-08-18-10:00:32] [7/10] training 26.5%: Loss=0.617991, Accuracy=48.545%, MSE=0.37268
[2023-08-18-10:00:33] [7/10] training 28.9%: Loss=0.619408, Accuracy=48.417%, MSE=0.374083
[2023-08-18-10:00:35] [7/10] training 31.3%: Loss=0.62122, Accuracy=48.000%, MSE=0.376461
[2023-08-18-10:00:37] [7/10] training 33.7%: Loss=0.620729, Accuracy=48.357%, MSE=0.375267
[2023-08-18-10:00:39] [7/10] training 36.1%: Loss=0.619069, Accuracy=48.800%, MSE=0.372766
[2023-08-18-10:00:41] [7/10] training 38.6%: Loss=0.62284, Accuracy=48.313%, MSE=0.375958
[2023-08-18-10:00:42] [7/10] training 41.0%: Loss=0.619538, Accuracy=49.059%, MSE=0.372347
[2023-08-18-10:00:44] [7/10] training 43.4%: Loss=0.615719, Accuracy=49.500%, MSE=0.369364
[2023-08-18-10:00:47] [7/10] training 45.8%: Loss=0.611696, Accuracy=49.684%, MSE=0.366501
[2023-08-18-10:00:48] [7/10] training 48.2%: Loss=0.604629, Accuracy=50.400%, MSE=0.360205
[2023-08-18-10:00:50] [7/10] training 50.6%: Loss=0.6041, Accuracy=50.524%, MSE=0.359426
[2023-08-18-10:00:52] [7/10] training 53.0%: Loss=0.60404, Accuracy=50.409%, MSE=0.360055
[2023-08-18-10:00:54] [7/10] training 55.4%: Loss=0.603659, Accuracy=50.435%, MSE=0.359633
[2023-08-18-10:00:55] [7/10] training 57.8%: Loss=0.601733, Accuracy=50.875%, MSE=0.357391
[2023-08-18-10:00:57] [7/10] training 60.2%: Loss=0.600285, Accuracy=51.040%, MSE=0.3563
[2023-08-18-10:00:59] [7/10] training 62.7%: Loss=0.600234, Accuracy=50.769%, MSE=0.356739
[2023-08-18-10:01:00] [7/10] training 65.1%: Loss=0.598634, Accuracy=50.889%, MSE=0.355242
[2023-08-18-10:01:02] [7/10] training 67.5%: Loss=0.601837, Accuracy=50.571%, MSE=0.358152
[2023-08-18-10:01:04] [7/10] training 69.9%: Loss=0.600714, Accuracy=50.621%, MSE=0.357421
[2023-08-18-10:01:06] [7/10] training 72.3%: Loss=0.603119, Accuracy=50.267%, MSE=0.359908
[2023-08-18-10:01:07] [7/10] training 74.7%: Loss=0.602601, Accuracy=50.258%, MSE=0.35956
[2023-08-18-10:01:09] [7/10] training 77.1%: Loss=0.599519, Accuracy=50.500%, MSE=0.357064
[2023-08-18-10:01:11] [7/10] training 79.5%: Loss=0.598724, Accuracy=50.606%, MSE=0.356267
[2023-08-18-10:01:13] [7/10] training 81.9%: Loss=0.598155, Accuracy=50.559%, MSE=0.356071
[2023-08-18-10:01:15] [7/10] training 84.3%: Loss=0.597902, Accuracy=50.600%, MSE=0.355802
[2023-08-18-10:01:16] [7/10] training 86.7%: Loss=0.597989, Accuracy=50.639%, MSE=0.355752
[2023-08-18-10:01:18] [7/10] training 89.2%: Loss=0.59768, Accuracy=50.622%, MSE=0.355596
[2023-08-18-10:01:20] [7/10] training 91.6%: Loss=0.598279, Accuracy=50.447%, MSE=0.356373
[2023-08-18-10:01:21] [7/10] training 94.0%: Loss=0.597054, Accuracy=50.462%, MSE=0.355573
[2023-08-18-10:01:23] [7/10] training 96.4%: Loss=0.596052, Accuracy=50.575%, MSE=0.354603
[2023-08-18-10:01:25] [7/10] training 98.8%: Loss=0.596566, Accuracy=50.561%, MSE=0.354958
[2023-08-18-10:01:33] Finished Epoch 7/10: Loss=1.26543, Accuracy=49.833%, MSE=0.401344, Precision=0.624749, Recall=0.118401, F1=0.199074, AUPR=0.643226
[2023-08-18-10:01:33] Saving model to ./models/huang_both_1_dscript_partitions_epoch07.sav
[2023-08-18-10:01:35] [8/10] training 2.4%: Loss=0.546291, Accuracy=57.000%, MSE=0.307757
[2023-08-18-10:01:36] [8/10] training 4.8%: Loss=0.564001, Accuracy=52.500%, MSE=0.333084
[2023-08-18-10:01:38] [8/10] training 7.2%: Loss=0.556604, Accuracy=51.667%, MSE=0.328951
[2023-08-18-10:01:40] [8/10] training 9.6%: Loss=0.541043, Accuracy=53.000%, MSE=0.314275
[2023-08-18-10:01:41] [8/10] training 12.0%: Loss=0.538071, Accuracy=53.000%, MSE=0.312829
[2023-08-18-10:01:43] [8/10] training 14.5%: Loss=0.544365, Accuracy=53.333%, MSE=0.315879
[2023-08-18-10:01:45] [8/10] training 16.9%: Loss=0.553396, Accuracy=52.000%, MSE=0.324667
[2023-08-18-10:01:47] [8/10] training 19.3%: Loss=0.553114, Accuracy=51.750%, MSE=0.325017
[2023-08-18-10:01:49] [8/10] training 21.7%: Loss=0.554901, Accuracy=51.111%, MSE=0.327683
[2023-08-18-10:01:50] [8/10] training 24.1%: Loss=0.551382, Accuracy=51.500%, MSE=0.324325
[2023-08-18-10:01:52] [8/10] training 26.5%: Loss=0.552994, Accuracy=51.091%, MSE=0.326025
[2023-08-18-10:01:54] [8/10] training 28.9%: Loss=0.554888, Accuracy=51.167%, MSE=0.327472
[2023-08-18-10:01:56] [8/10] training 31.3%: Loss=0.559837, Accuracy=50.846%, MSE=0.331696
[2023-08-18-10:01:57] [8/10] training 33.7%: Loss=0.557567, Accuracy=50.929%, MSE=0.330103
[2023-08-18-10:01:59] [8/10] training 36.1%: Loss=0.553741, Accuracy=51.200%, MSE=0.327269
[2023-08-18-10:02:01] [8/10] training 38.6%: Loss=0.555716, Accuracy=50.875%, MSE=0.329477
[2023-08-18-10:02:02] [8/10] training 41.0%: Loss=0.558864, Accuracy=50.765%, MSE=0.331896
[2023-08-18-10:02:04] [8/10] training 43.4%: Loss=0.560503, Accuracy=50.778%, MSE=0.332985
[2023-08-18-10:02:06] [8/10] training 45.8%: Loss=0.563076, Accuracy=50.053%, MSE=0.336044
[2023-08-18-10:02:08] [8/10] training 48.2%: Loss=0.563343, Accuracy=49.950%, MSE=0.336214
[2023-08-18-10:02:10] [8/10] training 50.6%: Loss=0.564636, Accuracy=49.619%, MSE=0.338026
[2023-08-18-10:02:12] [8/10] training 53.0%: Loss=0.563052, Accuracy=49.727%, MSE=0.336537
[2023-08-18-10:02:14] [8/10] training 55.4%: Loss=0.559739, Accuracy=50.130%, MSE=0.333598
[2023-08-18-10:02:15] [8/10] training 57.8%: Loss=0.558469, Accuracy=50.417%, MSE=0.332183
[2023-08-18-10:02:17] [8/10] training 60.2%: Loss=0.557171, Accuracy=50.360%, MSE=0.331414
[2023-08-18-10:02:19] [8/10] training 62.7%: Loss=0.55719, Accuracy=50.385%, MSE=0.331517
[2023-08-18-10:02:21] [8/10] training 65.1%: Loss=0.559068, Accuracy=50.333%, MSE=0.332633
[2023-08-18-10:02:23] [8/10] training 67.5%: Loss=0.558614, Accuracy=50.321%, MSE=0.332266
[2023-08-18-10:02:25] [8/10] training 69.9%: Loss=0.557164, Accuracy=50.517%, MSE=0.330857
[2023-08-18-10:02:27] [8/10] training 72.3%: Loss=0.555703, Accuracy=50.667%, MSE=0.329591
[2023-08-18-10:02:28] [8/10] training 74.7%: Loss=0.555039, Accuracy=50.645%, MSE=0.329024
[2023-08-18-10:02:30] [8/10] training 77.1%: Loss=0.5548, Accuracy=50.656%, MSE=0.32894
[2023-08-18-10:02:32] [8/10] training 79.5%: Loss=0.552443, Accuracy=50.818%, MSE=0.327083
[2023-08-18-10:02:34] [8/10] training 81.9%: Loss=0.551023, Accuracy=50.941%, MSE=0.325737
[2023-08-18-10:02:36] [8/10] training 84.3%: Loss=0.550171, Accuracy=51.057%, MSE=0.324784
[2023-08-18-10:02:38] [8/10] training 86.7%: Loss=0.551197, Accuracy=50.861%, MSE=0.325843
[2023-08-18-10:02:39] [8/10] training 89.2%: Loss=0.551663, Accuracy=50.838%, MSE=0.326129
[2023-08-18-10:02:41] [8/10] training 91.6%: Loss=0.550741, Accuracy=50.868%, MSE=0.32547
[2023-08-18-10:02:43] [8/10] training 94.0%: Loss=0.549678, Accuracy=50.897%, MSE=0.324708
[2023-08-18-10:02:45] [8/10] training 96.4%: Loss=0.548449, Accuracy=50.950%, MSE=0.323739
[2023-08-18-10:02:47] [8/10] training 98.8%: Loss=0.548521, Accuracy=50.902%, MSE=0.32388
[2023-08-18-10:02:54] Finished Epoch 8/10: Loss=1.09165, Accuracy=52.250%, MSE=0.346235, Precision=0.759131, Recall=0.200279, F1=0.316941, AUPR=0.770485
[2023-08-18-10:02:54] Saving model to ./models/huang_both_1_dscript_partitions_epoch08.sav
[2023-08-18-10:02:56] [9/10] training 2.4%: Loss=0.537509, Accuracy=50.000%, MSE=0.322841
[2023-08-18-10:02:58] [9/10] training 4.8%: Loss=0.533866, Accuracy=49.500%, MSE=0.318023
[2023-08-18-10:03:00] [9/10] training 7.2%: Loss=0.525986, Accuracy=51.667%, MSE=0.309512
[2023-08-18-10:03:02] [9/10] training 9.6%: Loss=0.535919, Accuracy=49.500%, MSE=0.320488
[2023-08-18-10:03:04] [9/10] training 12.0%: Loss=0.519344, Accuracy=52.000%, MSE=0.304091
[2023-08-18-10:03:06] [9/10] training 14.5%: Loss=0.52957, Accuracy=50.500%, MSE=0.313757
[2023-08-18-10:03:08] [9/10] training 16.9%: Loss=0.528749, Accuracy=50.286%, MSE=0.313363
[2023-08-18-10:03:10] [9/10] training 19.3%: Loss=0.52937, Accuracy=49.875%, MSE=0.313839
[2023-08-18-10:03:12] [9/10] training 21.7%: Loss=0.52273, Accuracy=50.889%, MSE=0.306908
[2023-08-18-10:03:13] [9/10] training 24.1%: Loss=0.526187, Accuracy=50.300%, MSE=0.310308
[2023-08-18-10:03:15] [9/10] training 26.5%: Loss=0.522918, Accuracy=50.545%, MSE=0.306994
[2023-08-18-10:03:17] [9/10] training 28.9%: Loss=0.528124, Accuracy=49.667%, MSE=0.312264
[2023-08-18-10:03:19] [9/10] training 31.3%: Loss=0.525955, Accuracy=49.846%, MSE=0.310099
[2023-08-18-10:03:21] [9/10] training 33.7%: Loss=0.522062, Accuracy=50.429%, MSE=0.306197
[2023-08-18-10:03:22] [9/10] training 36.1%: Loss=0.515614, Accuracy=51.267%, MSE=0.30012
[2023-08-18-10:03:24] [9/10] training 38.6%: Loss=0.513288, Accuracy=51.687%, MSE=0.297914
[2023-08-18-10:03:26] [9/10] training 41.0%: Loss=0.512853, Accuracy=51.647%, MSE=0.297493
[2023-08-18-10:03:28] [9/10] training 43.4%: Loss=0.512056, Accuracy=51.722%, MSE=0.296781
[2023-08-18-10:03:30] [9/10] training 45.8%: Loss=0.514121, Accuracy=51.421%, MSE=0.298818
[2023-08-18-10:03:32] [9/10] training 48.2%: Loss=0.512106, Accuracy=51.750%, MSE=0.296869
[2023-08-18-10:03:33] [9/10] training 50.6%: Loss=0.514843, Accuracy=51.381%, MSE=0.29962
[2023-08-18-10:03:35] [9/10] training 53.0%: Loss=0.516123, Accuracy=51.318%, MSE=0.300694
[2023-08-18-10:03:37] [9/10] training 55.4%: Loss=0.514271, Accuracy=51.565%, MSE=0.299115
[2023-08-18-10:03:39] [9/10] training 57.8%: Loss=0.515794, Accuracy=51.292%, MSE=0.300631
[2023-08-18-10:03:41] [9/10] training 60.2%: Loss=0.512445, Accuracy=51.880%, MSE=0.297412
[2023-08-18-10:03:43] [9/10] training 62.7%: Loss=0.511363, Accuracy=52.077%, MSE=0.296372
[2023-08-18-10:03:44] [9/10] training 65.1%: Loss=0.511602, Accuracy=52.000%, MSE=0.296593
[2023-08-18-10:03:46] [9/10] training 67.5%: Loss=0.511393, Accuracy=51.929%, MSE=0.296491
[2023-08-18-10:03:48] [9/10] training 69.9%: Loss=0.50975, Accuracy=52.241%, MSE=0.294702
[2023-08-18-10:03:49] [9/10] training 72.3%: Loss=0.508171, Accuracy=52.467%, MSE=0.293285
[2023-08-18-10:03:51] [9/10] training 74.7%: Loss=0.510145, Accuracy=52.226%, MSE=0.29511
[2023-08-18-10:03:53] [9/10] training 77.1%: Loss=0.510417, Accuracy=52.188%, MSE=0.295382
[2023-08-18-10:03:55] [9/10] training 79.5%: Loss=0.510267, Accuracy=52.333%, MSE=0.294889
[2023-08-18-10:03:56] [9/10] training 81.9%: Loss=0.509965, Accuracy=52.353%, MSE=0.294569
[2023-08-18-10:03:58] [9/10] training 84.3%: Loss=0.509647, Accuracy=52.429%, MSE=0.294172
[2023-08-18-10:04:00] [9/10] training 86.7%: Loss=0.510375, Accuracy=52.444%, MSE=0.294421
[2023-08-18-10:04:02] [9/10] training 89.2%: Loss=0.51092, Accuracy=52.378%, MSE=0.295044
[2023-08-18-10:04:03] [9/10] training 91.6%: Loss=0.508654, Accuracy=52.711%, MSE=0.292933
[2023-08-18-10:04:05] [9/10] training 94.0%: Loss=0.507769, Accuracy=52.769%, MSE=0.292218
[2023-08-18-10:04:07] [9/10] training 96.4%: Loss=0.507475, Accuracy=52.675%, MSE=0.292052
[2023-08-18-10:04:09] [9/10] training 98.8%: Loss=0.508337, Accuracy=52.512%, MSE=0.293033
[2023-08-18-10:04:16] Finished Epoch 9/10: Loss=0.94913, Accuracy=52.917%, MSE=0.323329, Precision=0.733799, Recall=0.229023, F1=0.349092, AUPR=0.773657
[2023-08-18-10:04:16] Saving model to ./models/huang_both_1_dscript_partitions_epoch09.sav
[2023-08-18-10:04:18] [10/10] training 2.4%: Loss=0.491626, Accuracy=54.000%, MSE=0.275721
[2023-08-18-10:04:20] [10/10] training 4.8%: Loss=0.438815, Accuracy=60.500%, MSE=0.228411
[2023-08-18-10:04:22] [10/10] training 7.2%: Loss=0.456759, Accuracy=56.000%, MSE=0.247354
[2023-08-18-10:04:24] [10/10] training 9.6%: Loss=0.464714, Accuracy=56.250%, MSE=0.249071
[2023-08-18-10:04:25] [10/10] training 12.0%: Loss=0.472836, Accuracy=54.800%, MSE=0.258094
[2023-08-18-10:04:27] [10/10] training 14.5%: Loss=0.478921, Accuracy=54.000%, MSE=0.264586
[2023-08-18-10:04:29] [10/10] training 16.9%: Loss=0.485586, Accuracy=53.714%, MSE=0.271466
[2023-08-18-10:04:31] [10/10] training 19.3%: Loss=0.4843, Accuracy=53.250%, MSE=0.271714
[2023-08-18-10:04:32] [10/10] training 21.7%: Loss=0.483903, Accuracy=53.333%, MSE=0.271565
[2023-08-18-10:04:34] [10/10] training 24.1%: Loss=0.489322, Accuracy=52.500%, MSE=0.277161
[2023-08-18-10:04:36] [10/10] training 26.5%: Loss=0.485691, Accuracy=52.909%, MSE=0.274159
[2023-08-18-10:04:38] [10/10] training 28.9%: Loss=0.480699, Accuracy=53.583%, MSE=0.269818
[2023-08-18-10:04:39] [10/10] training 31.3%: Loss=0.478145, Accuracy=54.077%, MSE=0.267423
[2023-08-18-10:04:41] [10/10] training 33.7%: Loss=0.476179, Accuracy=54.357%, MSE=0.265435
[2023-08-18-10:04:43] [10/10] training 36.1%: Loss=0.477209, Accuracy=54.067%, MSE=0.266413
[2023-08-18-10:04:45] [10/10] training 38.6%: Loss=0.475081, Accuracy=54.188%, MSE=0.264553
[2023-08-18-10:04:47] [10/10] training 41.0%: Loss=0.474275, Accuracy=54.588%, MSE=0.263538
[2023-08-18-10:04:49] [10/10] training 43.4%: Loss=0.474279, Accuracy=54.500%, MSE=0.263583
[2023-08-18-10:04:50] [10/10] training 45.8%: Loss=0.474843, Accuracy=54.526%, MSE=0.263951
[2023-08-18-10:04:52] [10/10] training 48.2%: Loss=0.476255, Accuracy=54.450%, MSE=0.265119
[2023-08-18-10:04:54] [10/10] training 50.6%: Loss=0.4772, Accuracy=54.095%, MSE=0.266474
[2023-08-18-10:04:56] [10/10] training 53.0%: Loss=0.47619, Accuracy=54.000%, MSE=0.265768
[2023-08-18-10:04:58] [10/10] training 55.4%: Loss=0.47833, Accuracy=53.609%, MSE=0.26735
[2023-08-18-10:05:00] [10/10] training 57.8%: Loss=0.479705, Accuracy=53.417%, MSE=0.268691
[2023-08-18-10:05:02] [10/10] training 60.2%: Loss=0.477547, Accuracy=53.800%, MSE=0.266576
[2023-08-18-10:05:03] [10/10] training 62.7%: Loss=0.477165, Accuracy=53.846%, MSE=0.26627
[2023-08-18-10:05:05] [10/10] training 65.1%: Loss=0.477094, Accuracy=53.852%, MSE=0.26634
[2023-08-18-10:05:07] [10/10] training 67.5%: Loss=0.476454, Accuracy=54.071%, MSE=0.265429
[2023-08-18-10:05:09] [10/10] training 69.9%: Loss=0.474915, Accuracy=54.138%, MSE=0.264141
[2023-08-18-10:05:11] [10/10] training 72.3%: Loss=0.476989, Accuracy=53.800%, MSE=0.26636
[2023-08-18-10:05:13] [10/10] training 74.7%: Loss=0.477851, Accuracy=53.613%, MSE=0.2673
[2023-08-18-10:05:14] [10/10] training 77.1%: Loss=0.47754, Accuracy=53.625%, MSE=0.267006
[2023-08-18-10:05:16] [10/10] training 79.5%: Loss=0.476399, Accuracy=53.818%, MSE=0.265961
[2023-08-18-10:05:18] [10/10] training 81.9%: Loss=0.476669, Accuracy=53.794%, MSE=0.266254
[2023-08-18-10:05:20] [10/10] training 84.3%: Loss=0.477067, Accuracy=53.771%, MSE=0.266779
[2023-08-18-10:05:21] [10/10] training 86.7%: Loss=0.476886, Accuracy=53.722%, MSE=0.266728
[2023-08-18-10:05:23] [10/10] training 89.2%: Loss=0.475396, Accuracy=53.919%, MSE=0.265447
[2023-08-18-10:05:25] [10/10] training 91.6%: Loss=0.474939, Accuracy=53.947%, MSE=0.265084
[2023-08-18-10:05:27] [10/10] training 94.0%: Loss=0.473947, Accuracy=54.103%, MSE=0.264044
[2023-08-18-10:05:29] [10/10] training 96.4%: Loss=0.473737, Accuracy=54.200%, MSE=0.263859
[2023-08-18-10:05:30] [10/10] training 98.8%: Loss=0.473277, Accuracy=54.171%, MSE=0.263611
[2023-08-18-10:05:38] Finished Epoch 10/10: Loss=0.800145, Accuracy=54.250%, MSE=0.282382, Precision=0.628706, Recall=0.321652, F1=0.425575, AUPR=0.672997
[2023-08-18-10:05:38] Saving model to ./models/huang_both_1_dscript_partitions_epoch10.sav
[2023-08-18-10:05:38] Saving final model to ./models/huang_both_1_dscript_partitions_final.sav
