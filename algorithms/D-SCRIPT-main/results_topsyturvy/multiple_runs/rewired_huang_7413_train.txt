[2023-12-24-01:38:33] D-SCRIPT Version 0.2.2
[2023-12-24-01:38:33] Called as: /nfs/home/students/jbernett/miniconda3/envs/dscript/bin/dscript train --topsy-turvy --train data/multiple_runs/rewired_huang_train_7413.txt --test data/multiple_runs/rewired_huang_test_7413.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_7413_tt_rewired -o results_topsyturvy/multiple_runs/rewired_huang_7413_train.txt
[2023-12-24-01:38:33] Loaded 7568 training pairs
[2023-12-24-01:38:33] Loaded 1008 test pairs
[2023-12-24-01:38:33] Loading embeddings...
[2023-12-24-01:38:58] Running D-SCRIPT Topsy-Turvy:
[2023-12-24-01:38:58] 	glider_weight: 0.2
[2023-12-24-01:38:58] 	glider_thresh: 92.5th percentile
[2023-12-24-01:38:58] Computing GLIDER matrix...
[2023-12-24-01:39:02] Initializing embedding model with:
[2023-12-24-01:39:02] 	projection_dim: 100
[2023-12-24-01:39:02] 	dropout_p: 0.5
[2023-12-24-01:39:02] Initializing contact model with:
[2023-12-24-01:39:02] 	hidden_dim: 50
[2023-12-24-01:39:02] 	kernel_width: 7
[2023-12-24-01:39:02] Initializing interaction model with:
[2023-12-24-01:39:02] 	do_poool: False
[2023-12-24-01:39:02] 	pool_width: 9
[2023-12-24-01:39:02] 	do_w: True
[2023-12-24-01:39:02] 	do_sigmoid: True
[2023-12-24-01:39:02] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-12-24-01:39:02] Using save prefix "./models/huang_7413_tt_rewired"
[2023-12-24-01:39:02] Training with Adam: lr=0.001, weight_decay=0
[2023-12-24-01:39:02] 	num_epochs: 10
[2023-12-24-01:39:02] 	batch_size: 25
[2023-12-24-01:39:02] 	interaction weight: 0.35
[2023-12-24-01:39:02] 	contact map weight: 0.65
[2023-12-24-01:39:05] [1/10] training 1.3%: Loss=1.33125, Accuracy=55.000%, MSE=0.448571
[2023-12-24-01:39:07] [1/10] training 2.6%: Loss=1.4556, Accuracy=48.500%, MSE=0.513034
[2023-12-24-01:39:09] [1/10] training 4.0%: Loss=1.45698, Accuracy=47.667%, MSE=0.521019
[2023-12-24-01:39:11] [1/10] training 5.3%: Loss=1.4664, Accuracy=46.750%, MSE=0.529958
[2023-12-24-01:39:13] [1/10] training 6.6%: Loss=1.44504, Accuracy=47.400%, MSE=0.523388
[2023-12-24-01:39:15] [1/10] training 7.9%: Loss=1.41734, Accuracy=48.500%, MSE=0.512371
[2023-12-24-01:39:17] [1/10] training 9.2%: Loss=1.39947, Accuracy=49.000%, MSE=0.507267
[2023-12-24-01:39:19] [1/10] training 10.6%: Loss=1.36984, Accuracy=50.125%, MSE=0.495989
[2023-12-24-01:39:21] [1/10] training 11.9%: Loss=1.36903, Accuracy=50.111%, MSE=0.49612
[2023-12-24-01:39:23] [1/10] training 13.2%: Loss=1.37517, Accuracy=49.500%, MSE=0.502067
[2023-12-24-01:39:26] [1/10] training 14.5%: Loss=1.38305, Accuracy=49.000%, MSE=0.506966
[2023-12-24-01:39:28] [1/10] training 15.8%: Loss=1.3602, Accuracy=49.750%, MSE=0.499374
[2023-12-24-01:39:30] [1/10] training 17.2%: Loss=1.35734, Accuracy=49.769%, MSE=0.49914
[2023-12-24-01:39:32] [1/10] training 18.5%: Loss=1.35626, Accuracy=49.857%, MSE=0.498264
[2023-12-24-01:39:34] [1/10] training 19.8%: Loss=1.33841, Accuracy=50.333%, MSE=0.493324
[2023-12-24-01:39:36] [1/10] training 21.1%: Loss=1.32863, Accuracy=50.687%, MSE=0.489769
[2023-12-24-01:39:38] [1/10] training 22.4%: Loss=1.32539, Accuracy=50.706%, MSE=0.489518
[2023-12-24-01:39:40] [1/10] training 23.8%: Loss=1.31355, Accuracy=51.000%, MSE=0.486448
[2023-12-24-01:39:42] [1/10] training 25.1%: Loss=1.31146, Accuracy=50.842%, MSE=0.48789
[2023-12-24-01:39:44] [1/10] training 26.4%: Loss=1.31299, Accuracy=50.550%, MSE=0.490641
[2023-12-24-01:39:46] [1/10] training 27.7%: Loss=1.30705, Accuracy=50.667%, MSE=0.489409
[2023-12-24-01:39:48] [1/10] training 29.0%: Loss=1.31248, Accuracy=50.136%, MSE=0.494536
[2023-12-24-01:39:51] [1/10] training 30.4%: Loss=1.30627, Accuracy=50.304%, MSE=0.492828
[2023-12-24-01:39:53] [1/10] training 31.7%: Loss=1.30118, Accuracy=50.333%, MSE=0.492401
[2023-12-24-01:39:55] [1/10] training 33.0%: Loss=1.29598, Accuracy=50.360%, MSE=0.492013
[2023-12-24-01:39:57] [1/10] training 34.3%: Loss=1.28847, Accuracy=50.615%, MSE=0.489414
[2023-12-24-01:39:59] [1/10] training 35.6%: Loss=1.28395, Accuracy=50.556%, MSE=0.489799
[2023-12-24-01:40:01] [1/10] training 37.0%: Loss=1.2833, Accuracy=50.500%, MSE=0.490312
[2023-12-24-01:40:04] [1/10] training 38.3%: Loss=1.28019, Accuracy=50.448%, MSE=0.490674
[2023-12-24-01:40:06] [1/10] training 39.6%: Loss=1.27115, Accuracy=50.767%, MSE=0.487441
[2023-12-24-01:40:08] [1/10] training 40.9%: Loss=1.26472, Accuracy=50.968%, MSE=0.485383
[2023-12-24-01:40:10] [1/10] training 42.2%: Loss=1.26232, Accuracy=50.906%, MSE=0.485895
[2023-12-24-01:40:12] [1/10] training 43.6%: Loss=1.25921, Accuracy=50.879%, MSE=0.486056
[2023-12-24-01:40:13] [1/10] training 44.9%: Loss=1.25824, Accuracy=50.735%, MSE=0.48737
[2023-12-24-01:40:16] [1/10] training 46.2%: Loss=1.25202, Accuracy=50.857%, MSE=0.486029
[2023-12-24-01:40:18] [1/10] training 47.5%: Loss=1.25513, Accuracy=50.472%, MSE=0.489703
[2023-12-24-01:40:20] [1/10] training 48.8%: Loss=1.25502, Accuracy=50.324%, MSE=0.491084
[2023-12-24-01:40:22] [1/10] training 50.2%: Loss=1.25138, Accuracy=50.342%, MSE=0.490797
[2023-12-24-01:40:24] [1/10] training 51.5%: Loss=1.24695, Accuracy=50.436%, MSE=0.489791
[2023-12-24-01:40:26] [1/10] training 52.8%: Loss=1.24453, Accuracy=50.400%, MSE=0.49002
[2023-12-24-01:40:28] [1/10] training 54.1%: Loss=1.24431, Accuracy=50.244%, MSE=0.491444
[2023-12-24-01:40:30] [1/10] training 55.4%: Loss=1.23974, Accuracy=50.310%, MSE=0.490662
[2023-12-24-01:40:32] [1/10] training 56.8%: Loss=1.2361, Accuracy=50.349%, MSE=0.490179
[2023-12-24-01:40:34] [1/10] training 58.1%: Loss=1.23486, Accuracy=50.250%, MSE=0.491042
[2023-12-24-01:40:36] [1/10] training 59.4%: Loss=1.23154, Accuracy=50.267%, MSE=0.490777
[2023-12-24-01:40:38] [1/10] training 60.7%: Loss=1.22907, Accuracy=50.261%, MSE=0.490727
[2023-12-24-01:40:40] [1/10] training 62.0%: Loss=1.22465, Accuracy=50.362%, MSE=0.489638
[2023-12-24-01:40:42] [1/10] training 63.4%: Loss=1.21973, Accuracy=50.479%, MSE=0.488351
[2023-12-24-01:40:44] [1/10] training 64.7%: Loss=1.21746, Accuracy=50.449%, MSE=0.488526
[2023-12-24-01:40:46] [1/10] training 66.0%: Loss=1.21653, Accuracy=50.380%, MSE=0.48913
[2023-12-24-01:40:49] [1/10] training 67.3%: Loss=1.21126, Accuracy=50.490%, MSE=0.48788
[2023-12-24-01:40:51] [1/10] training 68.6%: Loss=1.20989, Accuracy=50.423%, MSE=0.488427
[2023-12-24-01:40:53] [1/10] training 70.0%: Loss=1.21085, Accuracy=50.189%, MSE=0.490603
[2023-12-24-01:40:55] [1/10] training 71.3%: Loss=1.21003, Accuracy=50.074%, MSE=0.49161
[2023-12-24-01:40:57] [1/10] training 72.6%: Loss=1.2081, Accuracy=50.018%, MSE=0.492013
[2023-12-24-01:40:59] [1/10] training 73.9%: Loss=1.20585, Accuracy=50.000%, MSE=0.492071
[2023-12-24-01:41:01] [1/10] training 75.2%: Loss=1.20362, Accuracy=49.965%, MSE=0.492281
[2023-12-24-01:41:04] [1/10] training 76.6%: Loss=1.19986, Accuracy=50.052%, MSE=0.491337
[2023-12-24-01:41:06] [1/10] training 77.9%: Loss=1.19584, Accuracy=50.153%, MSE=0.490226
[2023-12-24-01:41:07] [1/10] training 79.2%: Loss=1.19161, Accuracy=50.267%, MSE=0.489005
[2023-12-24-01:41:09] [1/10] training 80.5%: Loss=1.19064, Accuracy=50.164%, MSE=0.489861
[2023-12-24-01:41:11] [1/10] training 81.8%: Loss=1.18854, Accuracy=50.161%, MSE=0.489785
[2023-12-24-01:41:13] [1/10] training 83.2%: Loss=1.18503, Accuracy=50.206%, MSE=0.489158
[2023-12-24-01:41:16] [1/10] training 84.5%: Loss=1.1839, Accuracy=50.078%, MSE=0.490226
[2023-12-24-01:41:18] [1/10] training 85.8%: Loss=1.18345, Accuracy=49.985%, MSE=0.491046
[2023-12-24-01:41:20] [1/10] training 87.1%: Loss=1.18069, Accuracy=49.985%, MSE=0.490887
[2023-12-24-01:41:22] [1/10] training 88.4%: Loss=1.17884, Accuracy=49.940%, MSE=0.491167
[2023-12-24-01:41:24] [1/10] training 89.8%: Loss=1.1753, Accuracy=50.044%, MSE=0.490066
[2023-12-24-01:41:26] [1/10] training 91.1%: Loss=1.17084, Accuracy=50.188%, MSE=0.488526
[2023-12-24-01:41:28] [1/10] training 92.4%: Loss=1.16679, Accuracy=50.271%, MSE=0.487502
[2023-12-24-01:41:30] [1/10] training 93.7%: Loss=1.16678, Accuracy=50.141%, MSE=0.488665
[2023-12-24-01:41:32] [1/10] training 95.0%: Loss=1.16446, Accuracy=50.111%, MSE=0.488736
[2023-12-24-01:41:34] [1/10] training 96.4%: Loss=1.16359, Accuracy=50.055%, MSE=0.489201
[2023-12-24-01:41:36] [1/10] training 97.7%: Loss=1.16309, Accuracy=49.919%, MSE=0.490343
[2023-12-24-01:41:38] [1/10] training 99.0%: Loss=1.15953, Accuracy=50.000%, MSE=0.489394
[2023-12-24-01:41:49] Finished Epoch 1/10: Loss=2.07303, Accuracy=49.171%, MSE=0.481749, Precision=0.419082, Recall=0.0190209, F1=0.0363902, AUPR=0.407387
[2023-12-24-01:41:49] Saving model to ./models/huang_7413_tt_rewired_epoch01.sav
[2023-12-24-01:41:51] [2/10] training 1.3%: Loss=0.968935, Accuracy=52.000%, MSE=0.459619
[2023-12-24-01:41:53] [2/10] training 2.6%: Loss=1.02806, Accuracy=47.000%, MSE=0.506835
[2023-12-24-01:41:55] [2/10] training 4.0%: Loss=0.993296, Accuracy=49.667%, MSE=0.48191
[2023-12-24-01:41:57] [2/10] training 5.3%: Loss=0.957711, Accuracy=52.000%, MSE=0.460115
[2023-12-24-01:41:59] [2/10] training 6.6%: Loss=0.969244, Accuracy=50.800%, MSE=0.471178
[2023-12-24-01:42:00] [2/10] training 7.9%: Loss=0.936902, Accuracy=52.833%, MSE=0.450946
[2023-12-24-01:42:02] [2/10] training 9.2%: Loss=0.941324, Accuracy=52.429%, MSE=0.454623
[2023-12-24-01:42:04] [2/10] training 10.6%: Loss=0.954583, Accuracy=51.625%, MSE=0.46254
[2023-12-24-01:42:06] [2/10] training 11.9%: Loss=0.95799, Accuracy=51.333%, MSE=0.46506
[2023-12-24-01:42:08] [2/10] training 13.2%: Loss=0.95048, Accuracy=51.700%, MSE=0.461195
[2023-12-24-01:42:10] [2/10] training 14.5%: Loss=0.961686, Accuracy=51.000%, MSE=0.468129
[2023-12-24-01:42:12] [2/10] training 15.8%: Loss=0.964357, Accuracy=50.667%, MSE=0.471268
[2023-12-24-01:42:14] [2/10] training 17.2%: Loss=0.967494, Accuracy=50.154%, MSE=0.475943
[2023-12-24-01:42:16] [2/10] training 18.5%: Loss=0.960826, Accuracy=50.500%, MSE=0.472369
[2023-12-24-01:42:18] [2/10] training 19.8%: Loss=0.965406, Accuracy=49.933%, MSE=0.477467
[2023-12-24-01:42:19] [2/10] training 21.1%: Loss=0.970665, Accuracy=49.625%, MSE=0.480469
[2023-12-24-01:42:22] [2/10] training 22.4%: Loss=0.964228, Accuracy=50.118%, MSE=0.475957
[2023-12-24-01:42:24] [2/10] training 23.8%: Loss=0.960203, Accuracy=49.833%, MSE=0.477041
[2023-12-24-01:42:25] [2/10] training 25.1%: Loss=0.961809, Accuracy=49.842%, MSE=0.477251
[2023-12-24-01:42:27] [2/10] training 26.4%: Loss=0.965562, Accuracy=49.550%, MSE=0.479946
[2023-12-24-01:42:30] [2/10] training 27.7%: Loss=0.963084, Accuracy=49.619%, MSE=0.478881
[2023-12-24-01:42:31] [2/10] training 29.0%: Loss=0.955214, Accuracy=50.000%, MSE=0.474969
[2023-12-24-01:42:33] [2/10] training 30.4%: Loss=0.949853, Accuracy=49.957%, MSE=0.474232
[2023-12-24-01:42:35] [2/10] training 31.7%: Loss=0.946776, Accuracy=49.958%, MSE=0.47393
[2023-12-24-01:42:37] [2/10] training 33.0%: Loss=0.943996, Accuracy=50.240%, MSE=0.471557
[2023-12-24-01:42:39] [2/10] training 34.3%: Loss=0.940204, Accuracy=50.231%, MSE=0.470856
[2023-12-24-01:42:41] [2/10] training 35.6%: Loss=0.937281, Accuracy=50.222%, MSE=0.470577
[2023-12-24-01:42:43] [2/10] training 37.0%: Loss=0.931611, Accuracy=50.357%, MSE=0.468633
[2023-12-24-01:42:45] [2/10] training 38.3%: Loss=0.930459, Accuracy=50.414%, MSE=0.46778
[2023-12-24-01:42:46] [2/10] training 39.6%: Loss=0.928207, Accuracy=50.533%, MSE=0.466547
[2023-12-24-01:42:48] [2/10] training 40.9%: Loss=0.92699, Accuracy=50.323%, MSE=0.467496
[2023-12-24-01:42:50] [2/10] training 42.2%: Loss=0.926838, Accuracy=50.250%, MSE=0.467893
[2023-12-24-01:42:52] [2/10] training 43.6%: Loss=0.929451, Accuracy=50.152%, MSE=0.469049
[2023-12-24-01:42:54] [2/10] training 44.9%: Loss=0.928344, Accuracy=50.029%, MSE=0.46951
[2023-12-24-01:42:56] [2/10] training 46.2%: Loss=0.922803, Accuracy=50.200%, MSE=0.467232
[2023-12-24-01:42:58] [2/10] training 47.5%: Loss=0.91688, Accuracy=50.444%, MSE=0.464311
[2023-12-24-01:43:00] [2/10] training 48.8%: Loss=0.918242, Accuracy=50.216%, MSE=0.465977
[2023-12-24-01:43:02] [2/10] training 50.2%: Loss=0.917729, Accuracy=50.237%, MSE=0.465867
[2023-12-24-01:43:04] [2/10] training 51.5%: Loss=0.918139, Accuracy=50.026%, MSE=0.467447
[2023-12-24-01:43:06] [2/10] training 52.8%: Loss=0.915004, Accuracy=50.025%, MSE=0.466673
[2023-12-24-01:43:07] [2/10] training 54.1%: Loss=0.91194, Accuracy=50.220%, MSE=0.464833
[2023-12-24-01:43:09] [2/10] training 55.4%: Loss=0.911431, Accuracy=50.143%, MSE=0.46524
[2023-12-24-01:43:11] [2/10] training 56.8%: Loss=0.908162, Accuracy=50.093%, MSE=0.464644
[2023-12-24-01:43:13] [2/10] training 58.1%: Loss=0.903602, Accuracy=50.295%, MSE=0.462299
[2023-12-24-01:43:15] [2/10] training 59.4%: Loss=0.901753, Accuracy=50.289%, MSE=0.461972
[2023-12-24-01:43:17] [2/10] training 60.7%: Loss=0.89998, Accuracy=50.022%, MSE=0.462761
[2023-12-24-01:43:19] [2/10] training 62.0%: Loss=0.898384, Accuracy=49.979%, MSE=0.462468
[2023-12-24-01:43:21] [2/10] training 63.4%: Loss=0.898548, Accuracy=49.917%, MSE=0.462523
[2023-12-24-01:43:23] [2/10] training 64.7%: Loss=0.899106, Accuracy=49.837%, MSE=0.462959
[2023-12-24-01:43:25] [2/10] training 66.0%: Loss=0.896228, Accuracy=49.700%, MSE=0.462574
[2023-12-24-01:43:26] [2/10] training 67.3%: Loss=0.893271, Accuracy=49.588%, MSE=0.461721
[2023-12-24-01:43:28] [2/10] training 68.6%: Loss=0.89092, Accuracy=49.423%, MSE=0.461507
[2023-12-24-01:43:30] [2/10] training 70.0%: Loss=0.888299, Accuracy=49.377%, MSE=0.460489
[2023-12-24-01:43:32] [2/10] training 71.3%: Loss=0.884064, Accuracy=49.185%, MSE=0.459358
[2023-12-24-01:43:34] [2/10] training 72.6%: Loss=0.882953, Accuracy=49.036%, MSE=0.459091
[2023-12-24-01:43:36] [2/10] training 73.9%: Loss=0.88439, Accuracy=48.893%, MSE=0.459796
[2023-12-24-01:43:38] [2/10] training 75.2%: Loss=0.882484, Accuracy=48.842%, MSE=0.459218
[2023-12-24-01:43:40] [2/10] training 76.6%: Loss=0.880005, Accuracy=48.810%, MSE=0.458433
[2023-12-24-01:43:42] [2/10] training 77.9%: Loss=0.879887, Accuracy=48.797%, MSE=0.458248
[2023-12-24-01:43:43] [2/10] training 79.2%: Loss=0.878745, Accuracy=48.833%, MSE=0.457633
[2023-12-24-01:43:45] [2/10] training 80.5%: Loss=0.878228, Accuracy=48.803%, MSE=0.457663
[2023-12-24-01:43:47] [2/10] training 81.8%: Loss=0.877269, Accuracy=48.710%, MSE=0.457784
[2023-12-24-01:43:49] [2/10] training 83.2%: Loss=0.872709, Accuracy=48.683%, MSE=0.455838
[2023-12-24-01:43:51] [2/10] training 84.5%: Loss=0.868624, Accuracy=48.516%, MSE=0.454389
[2023-12-24-01:43:53] [2/10] training 85.8%: Loss=0.865143, Accuracy=48.585%, MSE=0.452828
[2023-12-24-01:43:55] [2/10] training 87.1%: Loss=0.867671, Accuracy=48.515%, MSE=0.453995
[2023-12-24-01:43:56] [2/10] training 88.4%: Loss=0.872908, Accuracy=48.493%, MSE=0.455006
[2023-12-24-01:43:58] [2/10] training 89.8%: Loss=0.876144, Accuracy=48.559%, MSE=0.455093
[2023-12-24-01:44:00] [2/10] training 91.1%: Loss=0.87937, Accuracy=48.609%, MSE=0.455303
[2023-12-24-01:44:02] [2/10] training 92.4%: Loss=0.881789, Accuracy=48.657%, MSE=0.455476
[2023-12-24-01:44:04] [2/10] training 93.7%: Loss=0.884735, Accuracy=48.648%, MSE=0.456151
[2023-12-24-01:44:06] [2/10] training 95.0%: Loss=0.88603, Accuracy=48.708%, MSE=0.456088
[2023-12-24-01:44:08] [2/10] training 96.4%: Loss=0.886822, Accuracy=48.781%, MSE=0.455795
[2023-12-24-01:44:10] [2/10] training 97.7%: Loss=0.886728, Accuracy=48.851%, MSE=0.455501
[2023-12-24-01:44:12] [2/10] training 99.0%: Loss=0.886861, Accuracy=48.893%, MSE=0.455488
[2023-12-24-01:44:20] Finished Epoch 2/10: Loss=2.01994, Accuracy=49.171%, MSE=0.467132, Precision=0.374787, Recall=0.0382616, F1=0.0694347, AUPR=0.397269
[2023-12-24-01:44:20] Saving model to ./models/huang_7413_tt_rewired_epoch02.sav
[2023-12-24-01:44:23] [3/10] training 1.3%: Loss=0.911439, Accuracy=51.000%, MSE=0.460544
[2023-12-24-01:44:25] [3/10] training 2.6%: Loss=0.899306, Accuracy=53.500%, MSE=0.438518
[2023-12-24-01:44:27] [3/10] training 4.0%: Loss=0.924873, Accuracy=51.667%, MSE=0.456554
[2023-12-24-01:44:28] [3/10] training 5.3%: Loss=0.911612, Accuracy=51.500%, MSE=0.45675
[2023-12-24-01:44:30] [3/10] training 6.6%: Loss=0.89762, Accuracy=51.200%, MSE=0.456798
[2023-12-24-01:44:32] [3/10] training 7.9%: Loss=0.885562, Accuracy=51.000%, MSE=0.456104
[2023-12-24-01:44:34] [3/10] training 9.2%: Loss=0.879269, Accuracy=51.286%, MSE=0.453049
[2023-12-24-01:44:36] [3/10] training 10.6%: Loss=0.890956, Accuracy=50.125%, MSE=0.463492
[2023-12-24-01:44:38] [3/10] training 11.9%: Loss=0.893033, Accuracy=49.111%, MSE=0.470646
[2023-12-24-01:44:40] [3/10] training 13.2%: Loss=0.883027, Accuracy=49.400%, MSE=0.466804
[2023-12-24-01:44:42] [3/10] training 14.5%: Loss=0.872398, Accuracy=49.364%, MSE=0.464379
[2023-12-24-01:44:43] [3/10] training 15.8%: Loss=0.865715, Accuracy=49.417%, MSE=0.463098
[2023-12-24-01:44:45] [3/10] training 17.2%: Loss=0.858685, Accuracy=48.846%, MSE=0.462323
[2023-12-24-01:44:47] [3/10] training 18.5%: Loss=0.846435, Accuracy=48.214%, MSE=0.459125
[2023-12-24-01:44:49] [3/10] training 19.8%: Loss=0.829724, Accuracy=48.000%, MSE=0.451074
[2023-12-24-01:44:51] [3/10] training 21.1%: Loss=0.820456, Accuracy=48.187%, MSE=0.447393
[2023-12-24-01:44:53] [3/10] training 22.4%: Loss=0.833691, Accuracy=48.353%, MSE=0.44893
[2023-12-24-01:44:55] [3/10] training 23.8%: Loss=0.834453, Accuracy=49.000%, MSE=0.44507
[2023-12-24-01:44:57] [3/10] training 25.1%: Loss=0.830085, Accuracy=49.368%, MSE=0.442039
[2023-12-24-01:44:59] [3/10] training 26.4%: Loss=0.827942, Accuracy=48.900%, MSE=0.442441
[2023-12-24-01:45:00] [3/10] training 27.7%: Loss=0.826069, Accuracy=48.571%, MSE=0.443329
[2023-12-24-01:45:02] [3/10] training 29.0%: Loss=0.81879, Accuracy=47.864%, MSE=0.442006
[2023-12-24-01:45:04] [3/10] training 30.4%: Loss=0.808748, Accuracy=47.391%, MSE=0.438653
[2023-12-24-01:45:06] [3/10] training 31.7%: Loss=0.802628, Accuracy=46.750%, MSE=0.437622
[2023-12-24-01:45:08] [3/10] training 33.0%: Loss=0.792943, Accuracy=46.800%, MSE=0.433007
[2023-12-24-01:45:09] [3/10] training 34.3%: Loss=0.784131, Accuracy=46.769%, MSE=0.428373
[2023-12-24-01:45:11] [3/10] training 35.6%: Loss=0.777389, Accuracy=46.926%, MSE=0.424811
[2023-12-24-01:45:13] [3/10] training 37.0%: Loss=0.780106, Accuracy=47.071%, MSE=0.425149
[2023-12-24-01:45:15] [3/10] training 38.3%: Loss=0.788687, Accuracy=47.000%, MSE=0.428313
[2023-12-24-01:45:16] [3/10] training 39.6%: Loss=0.784963, Accuracy=47.367%, MSE=0.425847
[2023-12-24-01:45:18] [3/10] training 40.9%: Loss=0.781743, Accuracy=46.935%, MSE=0.425566
[2023-12-24-01:45:20] [3/10] training 42.2%: Loss=0.773267, Accuracy=47.219%, MSE=0.420925
[2023-12-24-01:45:22] [3/10] training 43.6%: Loss=0.767759, Accuracy=47.364%, MSE=0.418326
[2023-12-24-01:45:24] [3/10] training 44.9%: Loss=0.763417, Accuracy=47.618%, MSE=0.415161
[2023-12-24-01:45:26] [3/10] training 46.2%: Loss=0.759775, Accuracy=47.629%, MSE=0.412973
[2023-12-24-01:45:28] [3/10] training 47.5%: Loss=0.757107, Accuracy=47.722%, MSE=0.410971
[2023-12-24-01:45:30] [3/10] training 48.8%: Loss=0.757661, Accuracy=47.676%, MSE=0.410565
[2023-12-24-01:45:31] [3/10] training 50.2%: Loss=0.756775, Accuracy=47.500%, MSE=0.41055
[2023-12-24-01:45:33] [3/10] training 51.5%: Loss=0.754403, Accuracy=47.385%, MSE=0.409921
[2023-12-24-01:45:35] [3/10] training 52.8%: Loss=0.750792, Accuracy=47.525%, MSE=0.407592
[2023-12-24-01:45:37] [3/10] training 54.1%: Loss=0.74531, Accuracy=47.927%, MSE=0.403937
[2023-12-24-01:45:39] [3/10] training 55.4%: Loss=0.744364, Accuracy=48.048%, MSE=0.403528
[2023-12-24-01:45:41] [3/10] training 56.8%: Loss=0.750753, Accuracy=48.163%, MSE=0.404741
[2023-12-24-01:45:43] [3/10] training 58.1%: Loss=0.762548, Accuracy=48.068%, MSE=0.408073
[2023-12-24-01:45:45] [3/10] training 59.4%: Loss=0.767613, Accuracy=48.289%, MSE=0.408156
[2023-12-24-01:45:47] [3/10] training 60.7%: Loss=0.775428, Accuracy=48.174%, MSE=0.411211
[2023-12-24-01:45:49] [3/10] training 62.0%: Loss=0.779256, Accuracy=48.298%, MSE=0.41188
[2023-12-24-01:45:51] [3/10] training 63.4%: Loss=0.78289, Accuracy=48.375%, MSE=0.412779
[2023-12-24-01:45:53] [3/10] training 64.7%: Loss=0.786979, Accuracy=48.245%, MSE=0.415098
[2023-12-24-01:45:54] [3/10] training 66.0%: Loss=0.787422, Accuracy=48.380%, MSE=0.415007
[2023-12-24-01:45:56] [3/10] training 67.3%: Loss=0.78744, Accuracy=48.431%, MSE=0.415281
[2023-12-24-01:45:58] [3/10] training 68.6%: Loss=0.787159, Accuracy=48.462%, MSE=0.415575
[2023-12-24-01:46:00] [3/10] training 70.0%: Loss=0.789726, Accuracy=48.358%, MSE=0.417081
[2023-12-24-01:46:02] [3/10] training 71.3%: Loss=0.790755, Accuracy=48.222%, MSE=0.417622
[2023-12-24-01:46:04] [3/10] training 72.6%: Loss=0.79124, Accuracy=47.836%, MSE=0.419063
[2023-12-24-01:46:06] [3/10] training 73.9%: Loss=0.788351, Accuracy=47.821%, MSE=0.418033
[2023-12-24-01:46:08] [3/10] training 75.2%: Loss=0.784321, Accuracy=48.035%, MSE=0.415377
[2023-12-24-01:46:10] [3/10] training 76.6%: Loss=0.77894, Accuracy=48.431%, MSE=0.411593
[2023-12-24-01:46:12] [3/10] training 77.9%: Loss=0.778378, Accuracy=48.678%, MSE=0.409333
[2023-12-24-01:46:14] [3/10] training 79.2%: Loss=0.779178, Accuracy=48.850%, MSE=0.408405
[2023-12-24-01:46:15] [3/10] training 80.5%: Loss=0.779263, Accuracy=48.934%, MSE=0.408616
[2023-12-24-01:46:17] [3/10] training 81.8%: Loss=0.779018, Accuracy=48.903%, MSE=0.409018
[2023-12-24-01:46:19] [3/10] training 83.2%: Loss=0.776806, Accuracy=48.857%, MSE=0.408202
[2023-12-24-01:46:21] [3/10] training 84.5%: Loss=0.774319, Accuracy=48.687%, MSE=0.40744
[2023-12-24-01:46:23] [3/10] training 85.8%: Loss=0.77361, Accuracy=48.462%, MSE=0.407897
[2023-12-24-01:46:25] [3/10] training 87.1%: Loss=0.772059, Accuracy=48.303%, MSE=0.407679
[2023-12-24-01:46:27] [3/10] training 88.4%: Loss=0.771564, Accuracy=48.045%, MSE=0.408199
[2023-12-24-01:46:28] [3/10] training 89.8%: Loss=0.768865, Accuracy=48.059%, MSE=0.407051
[2023-12-24-01:46:31] [3/10] training 91.1%: Loss=0.766973, Accuracy=48.072%, MSE=0.406483
[2023-12-24-01:46:32] [3/10] training 92.4%: Loss=0.764752, Accuracy=48.043%, MSE=0.405655
[2023-12-24-01:46:34] [3/10] training 93.7%: Loss=0.762315, Accuracy=48.042%, MSE=0.404605
[2023-12-24-01:46:36] [3/10] training 95.0%: Loss=0.76148, Accuracy=47.931%, MSE=0.404726
[2023-12-24-01:46:38] [3/10] training 96.4%: Loss=0.761334, Accuracy=47.740%, MSE=0.405401
[2023-12-24-01:46:40] [3/10] training 97.7%: Loss=0.760051, Accuracy=47.703%, MSE=0.405034
[2023-12-24-01:46:42] [3/10] training 99.0%: Loss=0.758572, Accuracy=47.653%, MSE=0.404657
[2023-12-24-01:46:51] Finished Epoch 3/10: Loss=4.74548, Accuracy=49.171%, MSE=0.499909, Precision=0.351507, Recall=9.14554e-05, F1=0.000182863, AUPR=0.398072
[2023-12-24-01:46:51] Saving model to ./models/huang_7413_tt_rewired_epoch03.sav
[2023-12-24-01:46:53] [4/10] training 1.3%: Loss=0.604785, Accuracy=48.000%, MSE=0.345669
[2023-12-24-01:46:55] [4/10] training 2.6%: Loss=0.639584, Accuracy=44.000%, MSE=0.376562
[2023-12-24-01:46:57] [4/10] training 4.0%: Loss=0.650981, Accuracy=41.667%, MSE=0.385351
[2023-12-24-01:46:59] [4/10] training 5.3%: Loss=0.66718, Accuracy=39.500%, MSE=0.400469
[2023-12-24-01:47:01] [4/10] training 6.6%: Loss=0.656446, Accuracy=41.800%, MSE=0.386125
[2023-12-24-01:47:04] [4/10] training 7.9%: Loss=0.652356, Accuracy=41.500%, MSE=0.385063
[2023-12-24-01:47:05] [4/10] training 9.2%: Loss=0.645407, Accuracy=43.714%, MSE=0.377828
[2023-12-24-01:47:07] [4/10] training 10.6%: Loss=0.643587, Accuracy=44.375%, MSE=0.375053
[2023-12-24-01:47:09] [4/10] training 11.9%: Loss=0.638721, Accuracy=45.111%, MSE=0.369778
[2023-12-24-01:47:11] [4/10] training 13.2%: Loss=0.640376, Accuracy=44.900%, MSE=0.369031
[2023-12-24-01:47:13] [4/10] training 14.5%: Loss=0.640363, Accuracy=44.909%, MSE=0.367923
[2023-12-24-01:47:15] [4/10] training 15.8%: Loss=0.643596, Accuracy=45.583%, MSE=0.367612
[2023-12-24-01:47:17] [4/10] training 17.2%: Loss=0.648297, Accuracy=45.000%, MSE=0.370006
[2023-12-24-01:47:18] [4/10] training 18.5%: Loss=0.645091, Accuracy=45.000%, MSE=0.368206
[2023-12-24-01:47:20] [4/10] training 19.8%: Loss=0.648031, Accuracy=44.467%, MSE=0.370581
[2023-12-24-01:47:22] [4/10] training 21.1%: Loss=0.647917, Accuracy=44.188%, MSE=0.371855
[2023-12-24-01:47:24] [4/10] training 22.4%: Loss=0.644295, Accuracy=44.706%, MSE=0.368062
[2023-12-24-01:47:26] [4/10] training 23.8%: Loss=0.645222, Accuracy=44.778%, MSE=0.367901
[2023-12-24-01:47:28] [4/10] training 25.1%: Loss=0.646172, Accuracy=44.789%, MSE=0.369095
[2023-12-24-01:47:30] [4/10] training 26.4%: Loss=0.643282, Accuracy=45.050%, MSE=0.36703
[2023-12-24-01:47:32] [4/10] training 27.7%: Loss=0.64292, Accuracy=44.857%, MSE=0.367058
[2023-12-24-01:47:34] [4/10] training 29.0%: Loss=0.641569, Accuracy=44.682%, MSE=0.366642
[2023-12-24-01:47:35] [4/10] training 30.4%: Loss=0.640897, Accuracy=44.696%, MSE=0.366402
[2023-12-24-01:47:37] [4/10] training 31.7%: Loss=0.642035, Accuracy=44.750%, MSE=0.367462
[2023-12-24-01:47:39] [4/10] training 33.0%: Loss=0.640716, Accuracy=44.960%, MSE=0.366281
[2023-12-24-01:47:41] [4/10] training 34.3%: Loss=0.637521, Accuracy=45.423%, MSE=0.363779
[2023-12-24-01:47:42] [4/10] training 35.6%: Loss=0.636442, Accuracy=45.630%, MSE=0.362579
[2023-12-24-01:47:44] [4/10] training 37.0%: Loss=0.635458, Accuracy=46.036%, MSE=0.360963
[2023-12-24-01:47:46] [4/10] training 38.3%: Loss=0.632434, Accuracy=46.207%, MSE=0.35914
[2023-12-24-01:47:48] [4/10] training 39.6%: Loss=0.628281, Accuracy=46.733%, MSE=0.355988
[2023-12-24-01:47:50] [4/10] training 40.9%: Loss=0.627531, Accuracy=46.710%, MSE=0.355691
[2023-12-24-01:47:52] [4/10] training 42.2%: Loss=0.626868, Accuracy=46.750%, MSE=0.35552
[2023-12-24-01:47:54] [4/10] training 43.6%: Loss=0.627462, Accuracy=46.788%, MSE=0.355846
[2023-12-24-01:47:55] [4/10] training 44.9%: Loss=0.626025, Accuracy=47.059%, MSE=0.354618
[2023-12-24-01:47:57] [4/10] training 46.2%: Loss=0.626442, Accuracy=47.057%, MSE=0.354776
[2023-12-24-01:47:59] [4/10] training 47.5%: Loss=0.626567, Accuracy=47.111%, MSE=0.354506
[2023-12-24-01:48:00] [4/10] training 48.8%: Loss=0.624339, Accuracy=47.297%, MSE=0.352402
[2023-12-24-01:48:02] [4/10] training 50.2%: Loss=0.623433, Accuracy=47.447%, MSE=0.35173
[2023-12-24-01:48:04] [4/10] training 51.5%: Loss=0.621506, Accuracy=47.795%, MSE=0.349917
[2023-12-24-01:48:06] [4/10] training 52.8%: Loss=0.622524, Accuracy=47.700%, MSE=0.35083
[2023-12-24-01:48:07] [4/10] training 54.1%: Loss=0.622096, Accuracy=47.732%, MSE=0.350252
[2023-12-24-01:48:09] [4/10] training 55.4%: Loss=0.621134, Accuracy=47.690%, MSE=0.350054
[2023-12-24-01:48:11] [4/10] training 56.8%: Loss=0.619473, Accuracy=47.977%, MSE=0.348498
[2023-12-24-01:48:13] [4/10] training 58.1%: Loss=0.619319, Accuracy=48.136%, MSE=0.348279
[2023-12-24-01:48:15] [4/10] training 59.4%: Loss=0.617593, Accuracy=48.311%, MSE=0.3468
[2023-12-24-01:48:17] [4/10] training 60.7%: Loss=0.615875, Accuracy=48.457%, MSE=0.34545
[2023-12-24-01:48:19] [4/10] training 62.0%: Loss=0.615309, Accuracy=48.660%, MSE=0.344516
[2023-12-24-01:48:21] [4/10] training 63.4%: Loss=0.615547, Accuracy=48.562%, MSE=0.345026
[2023-12-24-01:48:22] [4/10] training 64.7%: Loss=0.614974, Accuracy=48.531%, MSE=0.345078
[2023-12-24-01:48:24] [4/10] training 66.0%: Loss=0.612033, Accuracy=48.860%, MSE=0.342549
[2023-12-24-01:48:26] [4/10] training 67.3%: Loss=0.610036, Accuracy=49.098%, MSE=0.341004
[2023-12-24-01:48:28] [4/10] training 68.6%: Loss=0.609807, Accuracy=49.269%, MSE=0.340564
[2023-12-24-01:48:30] [4/10] training 70.0%: Loss=0.610144, Accuracy=49.396%, MSE=0.340115
[2023-12-24-01:48:31] [4/10] training 71.3%: Loss=0.61044, Accuracy=49.481%, MSE=0.340096
[2023-12-24-01:48:33] [4/10] training 72.6%: Loss=0.61225, Accuracy=49.364%, MSE=0.341694
[2023-12-24-01:48:35] [4/10] training 73.9%: Loss=0.612059, Accuracy=49.589%, MSE=0.341038
[2023-12-24-01:48:36] [4/10] training 75.2%: Loss=0.613268, Accuracy=49.596%, MSE=0.341945
[2023-12-24-01:48:38] [4/10] training 76.6%: Loss=0.614667, Accuracy=49.638%, MSE=0.342599
[2023-12-24-01:48:40] [4/10] training 77.9%: Loss=0.615619, Accuracy=49.644%, MSE=0.343197
[2023-12-24-01:48:42] [4/10] training 79.2%: Loss=0.616596, Accuracy=49.567%, MSE=0.344052
[2023-12-24-01:48:44] [4/10] training 80.5%: Loss=0.617305, Accuracy=49.459%, MSE=0.344831
[2023-12-24-01:48:46] [4/10] training 81.8%: Loss=0.617382, Accuracy=49.387%, MSE=0.345263
[2023-12-24-01:48:48] [4/10] training 83.2%: Loss=0.616847, Accuracy=49.444%, MSE=0.344958
[2023-12-24-01:48:50] [4/10] training 84.5%: Loss=0.615183, Accuracy=49.625%, MSE=0.343679
[2023-12-24-01:48:52] [4/10] training 85.8%: Loss=0.614323, Accuracy=49.754%, MSE=0.342775
[2023-12-24-01:48:54] [4/10] training 87.1%: Loss=0.612851, Accuracy=49.985%, MSE=0.341364
[2023-12-24-01:48:56] [4/10] training 88.4%: Loss=0.612294, Accuracy=50.030%, MSE=0.341051
[2023-12-24-01:48:58] [4/10] training 89.8%: Loss=0.612623, Accuracy=49.897%, MSE=0.341631
[2023-12-24-01:48:59] [4/10] training 91.1%: Loss=0.613006, Accuracy=49.797%, MSE=0.34208
[2023-12-24-01:49:01] [4/10] training 92.4%: Loss=0.613859, Accuracy=49.757%, MSE=0.342448
[2023-12-24-01:49:03] [4/10] training 93.7%: Loss=0.614942, Accuracy=49.676%, MSE=0.343048
[2023-12-24-01:49:05] [4/10] training 95.0%: Loss=0.616856, Accuracy=49.569%, MSE=0.344305
[2023-12-24-01:49:07] [4/10] training 96.4%: Loss=0.61671, Accuracy=49.493%, MSE=0.344474
[2023-12-24-01:49:09] [4/10] training 97.7%: Loss=0.617241, Accuracy=49.378%, MSE=0.345284
[2023-12-24-01:49:10] [4/10] training 99.0%: Loss=0.616703, Accuracy=49.347%, MSE=0.345185
[2023-12-24-01:49:19] Finished Epoch 4/10: Loss=3.74493, Accuracy=49.171%, MSE=0.49783, Precision=0.116953, Recall=0.00646349, F1=0.01225, AUPR=0.351164
[2023-12-24-01:49:19] Saving model to ./models/huang_7413_tt_rewired_epoch04.sav
[2023-12-24-01:49:21] [5/10] training 1.3%: Loss=0.53193, Accuracy=63.000%, MSE=0.268385
[2023-12-24-01:49:23] [5/10] training 2.6%: Loss=0.525586, Accuracy=62.000%, MSE=0.266294
[2023-12-24-01:49:25] [5/10] training 4.0%: Loss=0.525383, Accuracy=61.333%, MSE=0.265264
[2023-12-24-01:49:27] [5/10] training 5.3%: Loss=0.526542, Accuracy=60.500%, MSE=0.268393
[2023-12-24-01:49:28] [5/10] training 6.6%: Loss=0.527064, Accuracy=60.200%, MSE=0.269804
[2023-12-24-01:49:31] [5/10] training 7.9%: Loss=0.527876, Accuracy=59.833%, MSE=0.272505
[2023-12-24-01:49:33] [5/10] training 9.2%: Loss=0.522788, Accuracy=60.000%, MSE=0.269334
[2023-12-24-01:49:35] [5/10] training 10.6%: Loss=0.524562, Accuracy=59.750%, MSE=0.271416
[2023-12-24-01:49:37] [5/10] training 11.9%: Loss=0.526453, Accuracy=59.333%, MSE=0.273655
[2023-12-24-01:49:38] [5/10] training 13.2%: Loss=0.534152, Accuracy=59.000%, MSE=0.279267
[2023-12-24-01:49:40] [5/10] training 14.5%: Loss=0.527973, Accuracy=59.455%, MSE=0.275031
[2023-12-24-01:49:42] [5/10] training 15.8%: Loss=0.527199, Accuracy=59.083%, MSE=0.275856
[2023-12-24-01:49:44] [5/10] training 17.2%: Loss=0.531735, Accuracy=58.692%, MSE=0.279667
[2023-12-24-01:49:46] [5/10] training 18.5%: Loss=0.534201, Accuracy=58.500%, MSE=0.280596
[2023-12-24-01:49:48] [5/10] training 19.8%: Loss=0.533425, Accuracy=58.867%, MSE=0.279223
[2023-12-24-01:49:50] [5/10] training 21.1%: Loss=0.532683, Accuracy=58.875%, MSE=0.278983
[2023-12-24-01:49:52] [5/10] training 22.4%: Loss=0.535512, Accuracy=58.824%, MSE=0.280842
[2023-12-24-01:49:53] [5/10] training 23.8%: Loss=0.535629, Accuracy=58.667%, MSE=0.281196
[2023-12-24-01:49:55] [5/10] training 25.1%: Loss=0.534405, Accuracy=58.789%, MSE=0.280492
[2023-12-24-01:49:57] [5/10] training 26.4%: Loss=0.53724, Accuracy=58.300%, MSE=0.283699
[2023-12-24-01:49:59] [5/10] training 27.7%: Loss=0.538236, Accuracy=58.095%, MSE=0.284644
[2023-12-24-01:50:01] [5/10] training 29.0%: Loss=0.539311, Accuracy=58.000%, MSE=0.285825
[2023-12-24-01:50:03] [5/10] training 30.4%: Loss=0.538774, Accuracy=58.087%, MSE=0.285314
[2023-12-24-01:50:05] [5/10] training 31.7%: Loss=0.541722, Accuracy=57.708%, MSE=0.288014
[2023-12-24-01:50:07] [5/10] training 33.0%: Loss=0.537949, Accuracy=58.160%, MSE=0.284881
[2023-12-24-01:50:09] [5/10] training 34.3%: Loss=0.535692, Accuracy=58.269%, MSE=0.283382
[2023-12-24-01:50:11] [5/10] training 35.6%: Loss=0.533993, Accuracy=58.593%, MSE=0.281814
[2023-12-24-01:50:12] [5/10] training 37.0%: Loss=0.532668, Accuracy=58.821%, MSE=0.279598
[2023-12-24-01:50:14] [5/10] training 38.3%: Loss=0.529332, Accuracy=59.276%, MSE=0.276431
[2023-12-24-01:50:16] [5/10] training 39.6%: Loss=0.527854, Accuracy=59.533%, MSE=0.27499
[2023-12-24-01:50:18] [5/10] training 40.9%: Loss=0.529148, Accuracy=59.323%, MSE=0.276412
[2023-12-24-01:50:20] [5/10] training 42.2%: Loss=0.529145, Accuracy=59.156%, MSE=0.276468
[2023-12-24-01:50:21] [5/10] training 43.6%: Loss=0.52915, Accuracy=59.273%, MSE=0.276345
[2023-12-24-01:50:24] [5/10] training 44.9%: Loss=0.528868, Accuracy=59.382%, MSE=0.276138
[2023-12-24-01:50:25] [5/10] training 46.2%: Loss=0.530205, Accuracy=59.257%, MSE=0.277074
[2023-12-24-01:50:27] [5/10] training 47.5%: Loss=0.531241, Accuracy=59.000%, MSE=0.278404
[2023-12-24-01:50:29] [5/10] training 48.8%: Loss=0.530311, Accuracy=59.108%, MSE=0.277758
[2023-12-24-01:50:31] [5/10] training 50.2%: Loss=0.532529, Accuracy=58.868%, MSE=0.2796
[2023-12-24-01:50:33] [5/10] training 51.5%: Loss=0.532874, Accuracy=58.949%, MSE=0.279901
[2023-12-24-01:50:35] [5/10] training 52.8%: Loss=0.532402, Accuracy=58.975%, MSE=0.279801
[2023-12-24-01:50:37] [5/10] training 54.1%: Loss=0.531454, Accuracy=59.220%, MSE=0.278666
[2023-12-24-01:50:39] [5/10] training 55.4%: Loss=0.530836, Accuracy=59.095%, MSE=0.278627
[2023-12-24-01:50:40] [5/10] training 56.8%: Loss=0.530798, Accuracy=59.163%, MSE=0.278613
[2023-12-24-01:50:42] [5/10] training 58.1%: Loss=0.529823, Accuracy=59.273%, MSE=0.27766
[2023-12-24-01:50:44] [5/10] training 59.4%: Loss=0.529441, Accuracy=59.178%, MSE=0.277557
[2023-12-24-01:50:47] [5/10] training 60.7%: Loss=0.528249, Accuracy=59.435%, MSE=0.27634
[2023-12-24-01:50:49] [5/10] training 62.0%: Loss=0.526044, Accuracy=59.723%, MSE=0.274355
[2023-12-24-01:50:51] [5/10] training 63.4%: Loss=0.525259, Accuracy=59.979%, MSE=0.273192
[2023-12-24-01:50:52] [5/10] training 64.7%: Loss=0.525237, Accuracy=60.082%, MSE=0.272533
[2023-12-24-01:50:54] [5/10] training 66.0%: Loss=0.524182, Accuracy=60.240%, MSE=0.271356
[2023-12-24-01:50:56] [5/10] training 67.3%: Loss=0.523942, Accuracy=60.314%, MSE=0.27094
[2023-12-24-01:50:58] [5/10] training 68.6%: Loss=0.523654, Accuracy=60.346%, MSE=0.270497
[2023-12-24-01:51:00] [5/10] training 70.0%: Loss=0.523927, Accuracy=60.321%, MSE=0.270808
[2023-12-24-01:51:02] [5/10] training 71.3%: Loss=0.524698, Accuracy=60.222%, MSE=0.27123
[2023-12-24-01:51:04] [5/10] training 72.6%: Loss=0.52508, Accuracy=60.182%, MSE=0.271429
[2023-12-24-01:51:06] [5/10] training 73.9%: Loss=0.524477, Accuracy=60.179%, MSE=0.270959
[2023-12-24-01:51:08] [5/10] training 75.2%: Loss=0.523706, Accuracy=60.211%, MSE=0.270414
[2023-12-24-01:51:10] [5/10] training 76.6%: Loss=0.523191, Accuracy=60.155%, MSE=0.27024
[2023-12-24-01:51:11] [5/10] training 77.9%: Loss=0.522738, Accuracy=60.237%, MSE=0.269874
[2023-12-24-01:51:13] [5/10] training 79.2%: Loss=0.523591, Accuracy=60.117%, MSE=0.270846
[2023-12-24-01:51:15] [5/10] training 80.5%: Loss=0.523439, Accuracy=60.098%, MSE=0.270674
[2023-12-24-01:51:17] [5/10] training 81.8%: Loss=0.525057, Accuracy=59.984%, MSE=0.271915
[2023-12-24-01:51:19] [5/10] training 83.2%: Loss=0.525957, Accuracy=59.984%, MSE=0.272394
[2023-12-24-01:51:21] [5/10] training 84.5%: Loss=0.525561, Accuracy=59.953%, MSE=0.272203
[2023-12-24-01:51:23] [5/10] training 85.8%: Loss=0.525752, Accuracy=59.938%, MSE=0.272423
[2023-12-24-01:51:24] [5/10] training 87.1%: Loss=0.525986, Accuracy=59.955%, MSE=0.272529
[2023-12-24-01:51:26] [5/10] training 88.4%: Loss=0.526321, Accuracy=59.940%, MSE=0.272709
[2023-12-24-01:51:28] [5/10] training 89.8%: Loss=0.526909, Accuracy=59.868%, MSE=0.27331
[2023-12-24-01:51:30] [5/10] training 91.1%: Loss=0.526492, Accuracy=59.913%, MSE=0.273132
[2023-12-24-01:51:32] [5/10] training 92.4%: Loss=0.527073, Accuracy=59.886%, MSE=0.273734
[2023-12-24-01:51:34] [5/10] training 93.7%: Loss=0.526059, Accuracy=59.915%, MSE=0.273122
[2023-12-24-01:51:36] [5/10] training 95.0%: Loss=0.524991, Accuracy=60.069%, MSE=0.272268
[2023-12-24-01:51:38] [5/10] training 96.4%: Loss=0.523862, Accuracy=60.205%, MSE=0.271326
[2023-12-24-01:51:39] [5/10] training 97.7%: Loss=0.522709, Accuracy=60.378%, MSE=0.270361
[2023-12-24-01:51:41] [5/10] training 99.0%: Loss=0.521037, Accuracy=60.600%, MSE=0.26893
[2023-12-24-01:51:50] Finished Epoch 5/10: Loss=2.67586, Accuracy=49.171%, MSE=0.486945, Precision=0.260636, Recall=0.0157271, F1=0.0296641, AUPR=0.356904
[2023-12-24-01:51:50] Saving model to ./models/huang_7413_tt_rewired_epoch05.sav
[2023-12-24-01:51:52] [6/10] training 1.3%: Loss=0.47533, Accuracy=67.000%, MSE=0.233047
[2023-12-24-01:51:54] [6/10] training 2.6%: Loss=0.495178, Accuracy=62.000%, MSE=0.253072
[2023-12-24-01:51:56] [6/10] training 4.0%: Loss=0.520106, Accuracy=60.333%, MSE=0.272426
[2023-12-24-01:51:58] [6/10] training 5.3%: Loss=0.531147, Accuracy=60.750%, MSE=0.27799
[2023-12-24-01:52:00] [6/10] training 6.6%: Loss=0.520524, Accuracy=62.000%, MSE=0.269411
[2023-12-24-01:52:02] [6/10] training 7.9%: Loss=0.524424, Accuracy=62.000%, MSE=0.272112
[2023-12-24-01:52:04] [6/10] training 9.2%: Loss=0.521142, Accuracy=61.571%, MSE=0.270095
[2023-12-24-01:52:07] [6/10] training 10.6%: Loss=0.517971, Accuracy=61.875%, MSE=0.266987
[2023-12-24-01:52:08] [6/10] training 11.9%: Loss=0.508496, Accuracy=62.889%, MSE=0.260149
[2023-12-24-01:52:10] [6/10] training 13.2%: Loss=0.501448, Accuracy=63.700%, MSE=0.253901
[2023-12-24-01:52:12] [6/10] training 14.5%: Loss=0.494186, Accuracy=64.636%, MSE=0.247785
[2023-12-24-01:52:14] [6/10] training 15.8%: Loss=0.48976, Accuracy=65.167%, MSE=0.243338
[2023-12-24-01:52:15] [6/10] training 17.2%: Loss=0.486978, Accuracy=65.000%, MSE=0.24171
[2023-12-24-01:52:17] [6/10] training 18.5%: Loss=0.485373, Accuracy=65.071%, MSE=0.24101
[2023-12-24-01:52:19] [6/10] training 19.8%: Loss=0.482563, Accuracy=65.333%, MSE=0.238975
[2023-12-24-01:52:21] [6/10] training 21.1%: Loss=0.476768, Accuracy=66.000%, MSE=0.233831
[2023-12-24-01:52:23] [6/10] training 22.4%: Loss=0.475126, Accuracy=66.471%, MSE=0.232313
[2023-12-24-01:52:25] [6/10] training 23.8%: Loss=0.470527, Accuracy=67.000%, MSE=0.228087
[2023-12-24-01:52:27] [6/10] training 25.1%: Loss=0.468925, Accuracy=67.158%, MSE=0.227118
[2023-12-24-01:52:28] [6/10] training 26.4%: Loss=0.46815, Accuracy=67.400%, MSE=0.225874
[2023-12-24-01:52:30] [6/10] training 27.7%: Loss=0.471592, Accuracy=67.238%, MSE=0.228065
[2023-12-24-01:52:32] [6/10] training 29.0%: Loss=0.472776, Accuracy=67.045%, MSE=0.229112
[2023-12-24-01:52:34] [6/10] training 30.4%: Loss=0.475764, Accuracy=66.870%, MSE=0.230783
[2023-12-24-01:52:36] [6/10] training 31.7%: Loss=0.474108, Accuracy=67.042%, MSE=0.229483
[2023-12-24-01:52:38] [6/10] training 33.0%: Loss=0.476128, Accuracy=66.560%, MSE=0.232145
[2023-12-24-01:52:40] [6/10] training 34.3%: Loss=0.478343, Accuracy=66.192%, MSE=0.234523
[2023-12-24-01:52:42] [6/10] training 35.6%: Loss=0.477163, Accuracy=66.296%, MSE=0.233317
[2023-12-24-01:52:43] [6/10] training 37.0%: Loss=0.476259, Accuracy=66.536%, MSE=0.232109
[2023-12-24-01:52:45] [6/10] training 38.3%: Loss=0.475433, Accuracy=66.690%, MSE=0.231099
[2023-12-24-01:52:47] [6/10] training 39.6%: Loss=0.47455, Accuracy=66.900%, MSE=0.230057
[2023-12-24-01:52:49] [6/10] training 40.9%: Loss=0.474162, Accuracy=66.871%, MSE=0.229941
[2023-12-24-01:52:51] [6/10] training 42.2%: Loss=0.473408, Accuracy=66.906%, MSE=0.229234
[2023-12-24-01:52:53] [6/10] training 43.6%: Loss=0.473804, Accuracy=66.818%, MSE=0.229672
[2023-12-24-01:52:55] [6/10] training 44.9%: Loss=0.474837, Accuracy=66.618%, MSE=0.230961
[2023-12-24-01:52:57] [6/10] training 46.2%: Loss=0.476983, Accuracy=66.229%, MSE=0.233218
[2023-12-24-01:52:59] [6/10] training 47.5%: Loss=0.476642, Accuracy=66.222%, MSE=0.233209
[2023-12-24-01:53:01] [6/10] training 48.8%: Loss=0.475633, Accuracy=66.459%, MSE=0.231981
[2023-12-24-01:53:03] [6/10] training 50.2%: Loss=0.475012, Accuracy=66.605%, MSE=0.23126
[2023-12-24-01:53:05] [6/10] training 51.5%: Loss=0.475846, Accuracy=66.410%, MSE=0.232076
[2023-12-24-01:53:07] [6/10] training 52.8%: Loss=0.476945, Accuracy=66.125%, MSE=0.233483
[2023-12-24-01:53:09] [6/10] training 54.1%: Loss=0.47868, Accuracy=65.732%, MSE=0.235595
[2023-12-24-01:53:11] [6/10] training 55.4%: Loss=0.477852, Accuracy=65.690%, MSE=0.235093
[2023-12-24-01:53:13] [6/10] training 56.8%: Loss=0.478246, Accuracy=65.465%, MSE=0.235661
[2023-12-24-01:53:14] [6/10] training 58.1%: Loss=0.479755, Accuracy=65.250%, MSE=0.237127
[2023-12-24-01:53:16] [6/10] training 59.4%: Loss=0.480484, Accuracy=65.067%, MSE=0.238174
[2023-12-24-01:53:18] [6/10] training 60.7%: Loss=0.48168, Accuracy=64.891%, MSE=0.239486
[2023-12-24-01:53:20] [6/10] training 62.0%: Loss=0.481801, Accuracy=64.915%, MSE=0.239754
[2023-12-24-01:53:22] [6/10] training 63.4%: Loss=0.481287, Accuracy=64.979%, MSE=0.239346
[2023-12-24-01:53:24] [6/10] training 64.7%: Loss=0.479671, Accuracy=65.286%, MSE=0.237704
[2023-12-24-01:53:26] [6/10] training 66.0%: Loss=0.478592, Accuracy=65.420%, MSE=0.236917
[2023-12-24-01:53:28] [6/10] training 67.3%: Loss=0.478617, Accuracy=65.569%, MSE=0.236768
[2023-12-24-01:53:30] [6/10] training 68.6%: Loss=0.477145, Accuracy=65.712%, MSE=0.235498
[2023-12-24-01:53:32] [6/10] training 70.0%: Loss=0.476047, Accuracy=65.755%, MSE=0.234783
[2023-12-24-01:53:34] [6/10] training 71.3%: Loss=0.474899, Accuracy=65.852%, MSE=0.233964
[2023-12-24-01:53:36] [6/10] training 72.6%: Loss=0.473971, Accuracy=65.964%, MSE=0.233208
[2023-12-24-01:53:37] [6/10] training 73.9%: Loss=0.4741, Accuracy=65.929%, MSE=0.233421
[2023-12-24-01:53:39] [6/10] training 75.2%: Loss=0.474026, Accuracy=65.930%, MSE=0.233427
[2023-12-24-01:53:41] [6/10] training 76.6%: Loss=0.474145, Accuracy=65.845%, MSE=0.233777
[2023-12-24-01:53:43] [6/10] training 77.9%: Loss=0.474085, Accuracy=65.814%, MSE=0.233964
[2023-12-24-01:53:44] [6/10] training 79.2%: Loss=0.473363, Accuracy=65.900%, MSE=0.233446
[2023-12-24-01:53:46] [6/10] training 80.5%: Loss=0.472255, Accuracy=66.098%, MSE=0.232377
[2023-12-24-01:53:48] [6/10] training 81.8%: Loss=0.471164, Accuracy=66.242%, MSE=0.231414
[2023-12-24-01:53:50] [6/10] training 83.2%: Loss=0.469988, Accuracy=66.365%, MSE=0.230422
[2023-12-24-01:53:52] [6/10] training 84.5%: Loss=0.469243, Accuracy=66.469%, MSE=0.229765
[2023-12-24-01:53:54] [6/10] training 85.8%: Loss=0.468478, Accuracy=66.554%, MSE=0.229255
[2023-12-24-01:53:56] [6/10] training 87.1%: Loss=0.467716, Accuracy=66.652%, MSE=0.228633
[2023-12-24-01:53:58] [6/10] training 88.4%: Loss=0.46752, Accuracy=66.672%, MSE=0.228557
[2023-12-24-01:54:00] [6/10] training 89.8%: Loss=0.467846, Accuracy=66.632%, MSE=0.228788
[2023-12-24-01:54:02] [6/10] training 91.1%: Loss=0.468004, Accuracy=66.580%, MSE=0.229111
[2023-12-24-01:54:03] [6/10] training 92.4%: Loss=0.467743, Accuracy=66.571%, MSE=0.229007
[2023-12-24-01:54:05] [6/10] training 93.7%: Loss=0.468083, Accuracy=66.549%, MSE=0.229411
[2023-12-24-01:54:07] [6/10] training 95.0%: Loss=0.466465, Accuracy=66.750%, MSE=0.228002
[2023-12-24-01:54:09] [6/10] training 96.4%: Loss=0.465922, Accuracy=66.890%, MSE=0.227242
[2023-12-24-01:54:11] [6/10] training 97.7%: Loss=0.46621, Accuracy=66.878%, MSE=0.227424
[2023-12-24-01:54:13] [6/10] training 99.0%: Loss=0.466784, Accuracy=66.720%, MSE=0.228161
[2023-12-24-01:54:21] Finished Epoch 6/10: Loss=2.6431, Accuracy=49.171%, MSE=0.49142, Precision=0.332617, Recall=0.00895176, F1=0.0174343, AUPR=0.368054
[2023-12-24-01:54:21] Saving model to ./models/huang_7413_tt_rewired_epoch06.sav
[2023-12-24-01:54:24] [7/10] training 1.3%: Loss=0.549798, Accuracy=55.000%, MSE=0.304273
[2023-12-24-01:54:26] [7/10] training 2.6%: Loss=0.519285, Accuracy=59.500%, MSE=0.275794
[2023-12-24-01:54:27] [7/10] training 4.0%: Loss=0.519178, Accuracy=58.333%, MSE=0.278611
[2023-12-24-01:54:29] [7/10] training 5.3%: Loss=0.524083, Accuracy=57.250%, MSE=0.2829
[2023-12-24-01:54:31] [7/10] training 6.6%: Loss=0.533937, Accuracy=56.400%, MSE=0.293769
[2023-12-24-01:54:33] [7/10] training 7.9%: Loss=0.534813, Accuracy=56.500%, MSE=0.297274
[2023-12-24-01:54:35] [7/10] training 9.2%: Loss=0.517971, Accuracy=58.429%, MSE=0.282712
[2023-12-24-01:54:37] [7/10] training 10.6%: Loss=0.501095, Accuracy=60.750%, MSE=0.267487
[2023-12-24-01:54:40] [7/10] training 11.9%: Loss=0.492188, Accuracy=61.889%, MSE=0.258493
[2023-12-24-01:54:41] [7/10] training 13.2%: Loss=0.481302, Accuracy=63.700%, MSE=0.248111
[2023-12-24-01:54:43] [7/10] training 14.5%: Loss=0.4702, Accuracy=65.000%, MSE=0.237677
[2023-12-24-01:54:45] [7/10] training 15.8%: Loss=0.465933, Accuracy=65.667%, MSE=0.233148
[2023-12-24-01:54:47] [7/10] training 17.2%: Loss=0.46407, Accuracy=65.538%, MSE=0.232342
[2023-12-24-01:54:49] [7/10] training 18.5%: Loss=0.461764, Accuracy=65.857%, MSE=0.230711
[2023-12-24-01:54:51] [7/10] training 19.8%: Loss=0.461881, Accuracy=65.733%, MSE=0.230551
[2023-12-24-01:54:53] [7/10] training 21.1%: Loss=0.460013, Accuracy=66.062%, MSE=0.228408
[2023-12-24-01:54:55] [7/10] training 22.4%: Loss=0.461173, Accuracy=65.882%, MSE=0.229934
[2023-12-24-01:54:57] [7/10] training 23.8%: Loss=0.461147, Accuracy=65.778%, MSE=0.230264
[2023-12-24-01:54:58] [7/10] training 25.1%: Loss=0.463453, Accuracy=65.474%, MSE=0.232713
[2023-12-24-01:55:00] [7/10] training 26.4%: Loss=0.458894, Accuracy=66.100%, MSE=0.228376
[2023-12-24-01:55:02] [7/10] training 27.7%: Loss=0.454669, Accuracy=66.810%, MSE=0.224095
[2023-12-24-01:55:04] [7/10] training 29.0%: Loss=0.451742, Accuracy=67.182%, MSE=0.221245
[2023-12-24-01:55:06] [7/10] training 30.4%: Loss=0.449981, Accuracy=67.565%, MSE=0.219622
[2023-12-24-01:55:08] [7/10] training 31.7%: Loss=0.447202, Accuracy=68.000%, MSE=0.21693
[2023-12-24-01:55:09] [7/10] training 33.0%: Loss=0.447083, Accuracy=68.000%, MSE=0.217117
[2023-12-24-01:55:11] [7/10] training 34.3%: Loss=0.447188, Accuracy=68.077%, MSE=0.21712
[2023-12-24-01:55:13] [7/10] training 35.6%: Loss=0.447023, Accuracy=68.074%, MSE=0.217163
[2023-12-24-01:55:15] [7/10] training 37.0%: Loss=0.445528, Accuracy=68.250%, MSE=0.215676
[2023-12-24-01:55:17] [7/10] training 38.3%: Loss=0.444103, Accuracy=68.414%, MSE=0.214437
[2023-12-24-01:55:19] [7/10] training 39.6%: Loss=0.441996, Accuracy=68.700%, MSE=0.212314
[2023-12-24-01:55:20] [7/10] training 40.9%: Loss=0.4403, Accuracy=68.968%, MSE=0.210748
[2023-12-24-01:55:22] [7/10] training 42.2%: Loss=0.438613, Accuracy=69.344%, MSE=0.208749
[2023-12-24-01:55:24] [7/10] training 43.6%: Loss=0.437382, Accuracy=69.576%, MSE=0.207255
[2023-12-24-01:55:26] [7/10] training 44.9%: Loss=0.435625, Accuracy=69.765%, MSE=0.205609
[2023-12-24-01:55:28] [7/10] training 46.2%: Loss=0.433314, Accuracy=70.143%, MSE=0.20351
[2023-12-24-01:55:30] [7/10] training 47.5%: Loss=0.430869, Accuracy=70.472%, MSE=0.201346
[2023-12-24-01:55:32] [7/10] training 48.8%: Loss=0.429643, Accuracy=70.784%, MSE=0.199945
[2023-12-24-01:55:33] [7/10] training 50.2%: Loss=0.429289, Accuracy=70.789%, MSE=0.199809
[2023-12-24-01:55:35] [7/10] training 51.5%: Loss=0.428476, Accuracy=70.923%, MSE=0.198992
[2023-12-24-01:55:37] [7/10] training 52.8%: Loss=0.428096, Accuracy=71.000%, MSE=0.198511
[2023-12-24-01:55:39] [7/10] training 54.1%: Loss=0.426973, Accuracy=71.146%, MSE=0.197371
[2023-12-24-01:55:41] [7/10] training 55.4%: Loss=0.427731, Accuracy=71.143%, MSE=0.197616
[2023-12-24-01:55:43] [7/10] training 56.8%: Loss=0.427675, Accuracy=71.140%, MSE=0.197566
[2023-12-24-01:55:45] [7/10] training 58.1%: Loss=0.427585, Accuracy=71.205%, MSE=0.197514
[2023-12-24-01:55:47] [7/10] training 59.4%: Loss=0.427922, Accuracy=71.178%, MSE=0.197888
[2023-12-24-01:55:49] [7/10] training 60.7%: Loss=0.42673, Accuracy=71.391%, MSE=0.196634
[2023-12-24-01:55:51] [7/10] training 62.0%: Loss=0.427334, Accuracy=71.277%, MSE=0.1973
[2023-12-24-01:55:53] [7/10] training 63.4%: Loss=0.427541, Accuracy=71.208%, MSE=0.197776
[2023-12-24-01:55:54] [7/10] training 64.7%: Loss=0.427009, Accuracy=71.224%, MSE=0.19736
[2023-12-24-01:55:56] [7/10] training 66.0%: Loss=0.425404, Accuracy=71.420%, MSE=0.195957
[2023-12-24-01:55:58] [7/10] training 67.3%: Loss=0.423996, Accuracy=71.608%, MSE=0.194626
[2023-12-24-01:56:00] [7/10] training 68.6%: Loss=0.423231, Accuracy=71.712%, MSE=0.193712
[2023-12-24-01:56:02] [7/10] training 70.0%: Loss=0.422962, Accuracy=71.811%, MSE=0.193395
[2023-12-24-01:56:04] [7/10] training 71.3%: Loss=0.422836, Accuracy=71.796%, MSE=0.193371
[2023-12-24-01:56:05] [7/10] training 72.6%: Loss=0.422257, Accuracy=71.909%, MSE=0.192857
[2023-12-24-01:56:07] [7/10] training 73.9%: Loss=0.423196, Accuracy=71.875%, MSE=0.193456
[2023-12-24-01:56:09] [7/10] training 75.2%: Loss=0.422124, Accuracy=72.018%, MSE=0.1925
[2023-12-24-01:56:11] [7/10] training 76.6%: Loss=0.421078, Accuracy=72.155%, MSE=0.19138
[2023-12-24-01:56:13] [7/10] training 77.9%: Loss=0.418888, Accuracy=72.508%, MSE=0.189206
[2023-12-24-01:56:15] [7/10] training 79.2%: Loss=0.417146, Accuracy=72.750%, MSE=0.187545
[2023-12-24-01:56:16] [7/10] training 80.5%: Loss=0.416229, Accuracy=72.803%, MSE=0.186815
[2023-12-24-01:56:18] [7/10] training 81.8%: Loss=0.415489, Accuracy=72.839%, MSE=0.186372
[2023-12-24-01:56:20] [7/10] training 83.2%: Loss=0.414778, Accuracy=72.952%, MSE=0.185662
[2023-12-24-01:56:22] [7/10] training 84.5%: Loss=0.41464, Accuracy=72.953%, MSE=0.185579
[2023-12-24-01:56:24] [7/10] training 85.8%: Loss=0.414992, Accuracy=72.969%, MSE=0.185883
[2023-12-24-01:56:26] [7/10] training 87.1%: Loss=0.414666, Accuracy=73.091%, MSE=0.185561
[2023-12-24-01:56:27] [7/10] training 88.4%: Loss=0.414624, Accuracy=73.119%, MSE=0.185623
[2023-12-24-01:56:29] [7/10] training 89.8%: Loss=0.413758, Accuracy=73.221%, MSE=0.184908
[2023-12-24-01:56:31] [7/10] training 91.1%: Loss=0.413062, Accuracy=73.362%, MSE=0.184233
[2023-12-24-01:56:33] [7/10] training 92.4%: Loss=0.411938, Accuracy=73.543%, MSE=0.183299
[2023-12-24-01:56:34] [7/10] training 93.7%: Loss=0.4113, Accuracy=73.606%, MSE=0.182839
[2023-12-24-01:56:36] [7/10] training 95.0%: Loss=0.410179, Accuracy=73.764%, MSE=0.181849
[2023-12-24-01:56:38] [7/10] training 96.4%: Loss=0.40938, Accuracy=73.849%, MSE=0.181257
[2023-12-24-01:56:40] [7/10] training 97.7%: Loss=0.409914, Accuracy=73.784%, MSE=0.181772
[2023-12-24-01:56:42] [7/10] training 99.0%: Loss=0.409624, Accuracy=73.813%, MSE=0.181521
[2023-12-24-01:56:50] Finished Epoch 7/10: Loss=3.12664, Accuracy=49.171%, MSE=0.496419, Precision=0.189469, Recall=0.00384609, F1=0.00753913, AUPR=0.329785
[2023-12-24-01:56:50] Saving model to ./models/huang_7413_tt_rewired_epoch07.sav
[2023-12-24-01:56:53] [8/10] training 1.3%: Loss=0.435046, Accuracy=67.000%, MSE=0.205903
[2023-12-24-01:56:55] [8/10] training 2.6%: Loss=0.445885, Accuracy=69.000%, MSE=0.212289
[2023-12-24-01:56:57] [8/10] training 4.0%: Loss=0.434185, Accuracy=70.667%, MSE=0.204563
[2023-12-24-01:56:59] [8/10] training 5.3%: Loss=0.423507, Accuracy=71.750%, MSE=0.195273
[2023-12-24-01:57:01] [8/10] training 6.6%: Loss=0.409029, Accuracy=73.600%, MSE=0.181363
[2023-12-24-01:57:03] [8/10] training 7.9%: Loss=0.394731, Accuracy=75.333%, MSE=0.170123
[2023-12-24-01:57:05] [8/10] training 9.2%: Loss=0.384343, Accuracy=76.571%, MSE=0.161062
[2023-12-24-01:57:06] [8/10] training 10.6%: Loss=0.377835, Accuracy=77.250%, MSE=0.156751
[2023-12-24-01:57:08] [8/10] training 11.9%: Loss=0.376397, Accuracy=78.222%, MSE=0.154151
[2023-12-24-01:57:10] [8/10] training 13.2%: Loss=0.380952, Accuracy=78.100%, MSE=0.156202
[2023-12-24-01:57:12] [8/10] training 14.5%: Loss=0.390302, Accuracy=77.364%, MSE=0.162671
[2023-12-24-01:57:14] [8/10] training 15.8%: Loss=0.3924, Accuracy=76.917%, MSE=0.165341
[2023-12-24-01:57:16] [8/10] training 17.2%: Loss=0.396608, Accuracy=75.923%, MSE=0.170839
[2023-12-24-01:57:18] [8/10] training 18.5%: Loss=0.398562, Accuracy=75.500%, MSE=0.172638
[2023-12-24-01:57:20] [8/10] training 19.8%: Loss=0.405564, Accuracy=74.467%, MSE=0.178835
[2023-12-24-01:57:22] [8/10] training 21.1%: Loss=0.410036, Accuracy=73.688%, MSE=0.183018
[2023-12-24-01:57:24] [8/10] training 22.4%: Loss=0.414817, Accuracy=72.941%, MSE=0.188197
[2023-12-24-01:57:25] [8/10] training 23.8%: Loss=0.423347, Accuracy=71.889%, MSE=0.196533
[2023-12-24-01:57:27] [8/10] training 25.1%: Loss=0.421629, Accuracy=72.105%, MSE=0.195102
[2023-12-24-01:57:29] [8/10] training 26.4%: Loss=0.418858, Accuracy=72.350%, MSE=0.192908
[2023-12-24-01:57:31] [8/10] training 27.7%: Loss=0.417271, Accuracy=72.571%, MSE=0.191591
[2023-12-24-01:57:33] [8/10] training 29.0%: Loss=0.413872, Accuracy=73.136%, MSE=0.188328
[2023-12-24-01:57:35] [8/10] training 30.4%: Loss=0.408608, Accuracy=73.957%, MSE=0.183488
[2023-12-24-01:57:37] [8/10] training 31.7%: Loss=0.407766, Accuracy=74.458%, MSE=0.181616
[2023-12-24-01:57:38] [8/10] training 33.0%: Loss=0.4154, Accuracy=74.080%, MSE=0.186294
[2023-12-24-01:57:40] [8/10] training 34.3%: Loss=0.421665, Accuracy=73.308%, MSE=0.192157
[2023-12-24-01:57:42] [8/10] training 35.6%: Loss=0.422702, Accuracy=72.926%, MSE=0.19381
[2023-12-24-01:57:44] [8/10] training 37.0%: Loss=0.422961, Accuracy=72.607%, MSE=0.194785
[2023-12-24-01:57:46] [8/10] training 38.3%: Loss=0.423126, Accuracy=72.379%, MSE=0.195418
[2023-12-24-01:57:48] [8/10] training 39.6%: Loss=0.421168, Accuracy=72.700%, MSE=0.193729
[2023-12-24-01:57:50] [8/10] training 40.9%: Loss=0.42085, Accuracy=72.774%, MSE=0.193465
[2023-12-24-01:57:52] [8/10] training 42.2%: Loss=0.420917, Accuracy=72.719%, MSE=0.194098
[2023-12-24-01:57:53] [8/10] training 43.6%: Loss=0.420161, Accuracy=72.879%, MSE=0.193627
[2023-12-24-01:57:56] [8/10] training 44.9%: Loss=0.420961, Accuracy=72.765%, MSE=0.194457
[2023-12-24-01:57:57] [8/10] training 46.2%: Loss=0.420921, Accuracy=72.657%, MSE=0.194709
[2023-12-24-01:57:59] [8/10] training 47.5%: Loss=0.42026, Accuracy=72.694%, MSE=0.194411
[2023-12-24-01:58:01] [8/10] training 48.8%: Loss=0.419996, Accuracy=72.892%, MSE=0.193748
[2023-12-24-01:58:03] [8/10] training 50.2%: Loss=0.418902, Accuracy=73.053%, MSE=0.192737
[2023-12-24-01:58:05] [8/10] training 51.5%: Loss=0.418495, Accuracy=73.128%, MSE=0.192311
[2023-12-24-01:58:07] [8/10] training 52.8%: Loss=0.41649, Accuracy=73.375%, MSE=0.190538
[2023-12-24-01:58:08] [8/10] training 54.1%: Loss=0.415434, Accuracy=73.439%, MSE=0.189819
[2023-12-24-01:58:10] [8/10] training 55.4%: Loss=0.414764, Accuracy=73.429%, MSE=0.189446
[2023-12-24-01:58:12] [8/10] training 56.8%: Loss=0.414641, Accuracy=73.256%, MSE=0.189553
[2023-12-24-01:58:14] [8/10] training 58.1%: Loss=0.414043, Accuracy=73.205%, MSE=0.18918
[2023-12-24-01:58:16] [8/10] training 59.4%: Loss=0.412668, Accuracy=73.289%, MSE=0.188235
[2023-12-24-01:58:18] [8/10] training 60.7%: Loss=0.411647, Accuracy=73.413%, MSE=0.1874
[2023-12-24-01:58:20] [8/10] training 62.0%: Loss=0.411043, Accuracy=73.447%, MSE=0.186881
[2023-12-24-01:58:22] [8/10] training 63.4%: Loss=0.411173, Accuracy=73.458%, MSE=0.187084
[2023-12-24-01:58:24] [8/10] training 64.7%: Loss=0.409728, Accuracy=73.653%, MSE=0.185859
[2023-12-24-01:58:26] [8/10] training 66.0%: Loss=0.408127, Accuracy=73.860%, MSE=0.184411
[2023-12-24-01:58:28] [8/10] training 67.3%: Loss=0.406951, Accuracy=73.961%, MSE=0.183476
[2023-12-24-01:58:29] [8/10] training 68.6%: Loss=0.405654, Accuracy=74.096%, MSE=0.18228
[2023-12-24-01:58:31] [8/10] training 70.0%: Loss=0.403662, Accuracy=74.377%, MSE=0.18055
[2023-12-24-01:58:33] [8/10] training 71.3%: Loss=0.402726, Accuracy=74.500%, MSE=0.179697
[2023-12-24-01:58:35] [8/10] training 72.6%: Loss=0.40194, Accuracy=74.564%, MSE=0.179101
[2023-12-24-01:58:36] [8/10] training 73.9%: Loss=0.401069, Accuracy=74.625%, MSE=0.17832
[2023-12-24-01:58:38] [8/10] training 75.2%: Loss=0.400155, Accuracy=74.719%, MSE=0.177649
[2023-12-24-01:58:40] [8/10] training 76.6%: Loss=0.400049, Accuracy=74.707%, MSE=0.177642
[2023-12-24-01:58:42] [8/10] training 77.9%: Loss=0.399897, Accuracy=74.678%, MSE=0.177692
[2023-12-24-01:58:44] [8/10] training 79.2%: Loss=0.400157, Accuracy=74.600%, MSE=0.178105
[2023-12-24-01:58:46] [8/10] training 80.5%: Loss=0.4002, Accuracy=74.574%, MSE=0.178227
[2023-12-24-01:58:48] [8/10] training 81.8%: Loss=0.40012, Accuracy=74.565%, MSE=0.178295
[2023-12-24-01:58:50] [8/10] training 83.2%: Loss=0.399009, Accuracy=74.746%, MSE=0.177314
[2023-12-24-01:58:52] [8/10] training 84.5%: Loss=0.396696, Accuracy=75.031%, MSE=0.175335
[2023-12-24-01:58:54] [8/10] training 85.8%: Loss=0.39534, Accuracy=75.231%, MSE=0.174181
[2023-12-24-01:58:56] [8/10] training 87.1%: Loss=0.394422, Accuracy=75.394%, MSE=0.173274
[2023-12-24-01:58:57] [8/10] training 88.4%: Loss=0.394953, Accuracy=75.418%, MSE=0.173581
[2023-12-24-01:58:59] [8/10] training 89.8%: Loss=0.395517, Accuracy=75.368%, MSE=0.174157
[2023-12-24-01:59:01] [8/10] training 91.1%: Loss=0.396328, Accuracy=75.188%, MSE=0.175139
[2023-12-24-01:59:03] [8/10] training 92.4%: Loss=0.395936, Accuracy=75.100%, MSE=0.175018
[2023-12-24-01:59:06] [8/10] training 93.7%: Loss=0.395935, Accuracy=75.056%, MSE=0.175176
[2023-12-24-01:59:07] [8/10] training 95.0%: Loss=0.395748, Accuracy=75.000%, MSE=0.175107
[2023-12-24-01:59:09] [8/10] training 96.4%: Loss=0.396746, Accuracy=74.849%, MSE=0.176023
[2023-12-24-01:59:11] [8/10] training 97.7%: Loss=0.39712, Accuracy=74.851%, MSE=0.176299
[2023-12-24-01:59:13] [8/10] training 99.0%: Loss=0.396637, Accuracy=74.947%, MSE=0.175831
[2023-12-24-01:59:21] Finished Epoch 8/10: Loss=2.28924, Accuracy=27.610%, MSE=0.561714, Precision=0.180027, Recall=0.100866, F1=0.129292, AUPR=0.324089
[2023-12-24-01:59:21] Saving model to ./models/huang_7413_tt_rewired_epoch08.sav
[2023-12-24-01:59:24] [9/10] training 1.3%: Loss=0.34821, Accuracy=80.000%, MSE=0.135613
[2023-12-24-01:59:25] [9/10] training 2.6%: Loss=0.348296, Accuracy=81.500%, MSE=0.132393
[2023-12-24-01:59:27] [9/10] training 4.0%: Loss=0.341104, Accuracy=82.000%, MSE=0.126516
[2023-12-24-01:59:29] [9/10] training 5.3%: Loss=0.343668, Accuracy=81.750%, MSE=0.129929
[2023-12-24-01:59:31] [9/10] training 6.6%: Loss=0.34829, Accuracy=80.600%, MSE=0.136088
[2023-12-24-01:59:33] [9/10] training 7.9%: Loss=0.34736, Accuracy=80.500%, MSE=0.135923
[2023-12-24-01:59:36] [9/10] training 9.2%: Loss=0.353752, Accuracy=79.286%, MSE=0.143369
[2023-12-24-01:59:38] [9/10] training 10.6%: Loss=0.351363, Accuracy=79.375%, MSE=0.141466
[2023-12-24-01:59:39] [9/10] training 11.9%: Loss=0.35397, Accuracy=79.222%, MSE=0.14349
[2023-12-24-01:59:41] [9/10] training 13.2%: Loss=0.354554, Accuracy=79.000%, MSE=0.144451
[2023-12-24-01:59:43] [9/10] training 14.5%: Loss=0.356905, Accuracy=78.455%, MSE=0.146827
[2023-12-24-01:59:45] [9/10] training 15.8%: Loss=0.356322, Accuracy=78.500%, MSE=0.145582
[2023-12-24-01:59:47] [9/10] training 17.2%: Loss=0.355312, Accuracy=78.692%, MSE=0.145205
[2023-12-24-01:59:48] [9/10] training 18.5%: Loss=0.357962, Accuracy=78.571%, MSE=0.147452
[2023-12-24-01:59:50] [9/10] training 19.8%: Loss=0.356768, Accuracy=78.867%, MSE=0.146142
[2023-12-24-01:59:52] [9/10] training 21.1%: Loss=0.352446, Accuracy=79.000%, MSE=0.14299
[2023-12-24-01:59:54] [9/10] training 22.4%: Loss=0.350773, Accuracy=79.412%, MSE=0.141017
[2023-12-24-01:59:56] [9/10] training 23.8%: Loss=0.34983, Accuracy=79.667%, MSE=0.13997
[2023-12-24-01:59:58] [9/10] training 25.1%: Loss=0.345471, Accuracy=80.158%, MSE=0.136784
[2023-12-24-02:00:00] [9/10] training 26.4%: Loss=0.349584, Accuracy=80.150%, MSE=0.139139
[2023-12-24-02:00:02] [9/10] training 27.7%: Loss=0.352784, Accuracy=79.810%, MSE=0.141957
[2023-12-24-02:00:04] [9/10] training 29.0%: Loss=0.353966, Accuracy=79.545%, MSE=0.143552
[2023-12-24-02:00:05] [9/10] training 30.4%: Loss=0.352246, Accuracy=79.783%, MSE=0.141886
[2023-12-24-02:00:07] [9/10] training 31.7%: Loss=0.353388, Accuracy=79.333%, MSE=0.143469
[2023-12-24-02:00:09] [9/10] training 33.0%: Loss=0.352383, Accuracy=79.320%, MSE=0.14292
[2023-12-24-02:00:11] [9/10] training 34.3%: Loss=0.355191, Accuracy=78.962%, MSE=0.145582
[2023-12-24-02:00:13] [9/10] training 35.6%: Loss=0.35612, Accuracy=78.778%, MSE=0.146655
[2023-12-24-02:00:14] [9/10] training 37.0%: Loss=0.35797, Accuracy=78.571%, MSE=0.148277
[2023-12-24-02:00:16] [9/10] training 38.3%: Loss=0.356942, Accuracy=78.655%, MSE=0.147302
[2023-12-24-02:00:18] [9/10] training 39.6%: Loss=0.35614, Accuracy=78.600%, MSE=0.14686
[2023-12-24-02:00:20] [9/10] training 40.9%: Loss=0.35731, Accuracy=78.613%, MSE=0.14781
[2023-12-24-02:00:22] [9/10] training 42.2%: Loss=0.358843, Accuracy=78.656%, MSE=0.14851
[2023-12-24-02:00:24] [9/10] training 43.6%: Loss=0.357994, Accuracy=78.909%, MSE=0.147607
[2023-12-24-02:00:26] [9/10] training 44.9%: Loss=0.360152, Accuracy=78.794%, MSE=0.149181
[2023-12-24-02:00:28] [9/10] training 46.2%: Loss=0.362966, Accuracy=78.571%, MSE=0.151027
[2023-12-24-02:00:29] [9/10] training 47.5%: Loss=0.364287, Accuracy=78.472%, MSE=0.152123
[2023-12-24-02:00:32] [9/10] training 48.8%: Loss=0.365561, Accuracy=78.297%, MSE=0.153336
[2023-12-24-02:00:34] [9/10] training 50.2%: Loss=0.36548, Accuracy=78.263%, MSE=0.153326
[2023-12-24-02:00:36] [9/10] training 51.5%: Loss=0.366099, Accuracy=78.231%, MSE=0.15395
[2023-12-24-02:00:37] [9/10] training 52.8%: Loss=0.366026, Accuracy=78.225%, MSE=0.153847
[2023-12-24-02:00:39] [9/10] training 54.1%: Loss=0.366666, Accuracy=78.098%, MSE=0.154786
[2023-12-24-02:00:41] [9/10] training 55.4%: Loss=0.368483, Accuracy=77.952%, MSE=0.156334
[2023-12-24-02:00:43] [9/10] training 56.8%: Loss=0.368192, Accuracy=77.930%, MSE=0.156285
[2023-12-24-02:00:45] [9/10] training 58.1%: Loss=0.36798, Accuracy=77.955%, MSE=0.155967
[2023-12-24-02:00:47] [9/10] training 59.4%: Loss=0.36682, Accuracy=78.022%, MSE=0.155159
[2023-12-24-02:00:48] [9/10] training 60.7%: Loss=0.365951, Accuracy=77.978%, MSE=0.154612
[2023-12-24-02:00:50] [9/10] training 62.0%: Loss=0.364231, Accuracy=78.298%, MSE=0.153028
[2023-12-24-02:00:52] [9/10] training 63.4%: Loss=0.363404, Accuracy=78.396%, MSE=0.152434
[2023-12-24-02:00:54] [9/10] training 64.7%: Loss=0.362921, Accuracy=78.490%, MSE=0.152038
[2023-12-24-02:00:56] [9/10] training 66.0%: Loss=0.361895, Accuracy=78.600%, MSE=0.151163
[2023-12-24-02:00:58] [9/10] training 67.3%: Loss=0.360975, Accuracy=78.745%, MSE=0.150112
[2023-12-24-02:01:00] [9/10] training 68.6%: Loss=0.361242, Accuracy=78.712%, MSE=0.15045
[2023-12-24-02:01:02] [9/10] training 70.0%: Loss=0.36159, Accuracy=78.679%, MSE=0.150862
[2023-12-24-02:01:04] [9/10] training 71.3%: Loss=0.3629, Accuracy=78.519%, MSE=0.152003
[2023-12-24-02:01:05] [9/10] training 72.6%: Loss=0.362407, Accuracy=78.545%, MSE=0.151655
[2023-12-24-02:01:07] [9/10] training 73.9%: Loss=0.363402, Accuracy=78.393%, MSE=0.152659
[2023-12-24-02:01:09] [9/10] training 75.2%: Loss=0.362383, Accuracy=78.456%, MSE=0.151868
[2023-12-24-02:01:11] [9/10] training 76.6%: Loss=0.361206, Accuracy=78.586%, MSE=0.150922
[2023-12-24-02:01:13] [9/10] training 77.9%: Loss=0.361313, Accuracy=78.559%, MSE=0.151129
[2023-12-24-02:01:15] [9/10] training 79.2%: Loss=0.361732, Accuracy=78.550%, MSE=0.151529
[2023-12-24-02:01:17] [9/10] training 80.5%: Loss=0.361125, Accuracy=78.623%, MSE=0.150947
[2023-12-24-02:01:19] [9/10] training 81.8%: Loss=0.360364, Accuracy=78.710%, MSE=0.150397
[2023-12-24-02:01:21] [9/10] training 83.2%: Loss=0.35995, Accuracy=78.698%, MSE=0.150093
[2023-12-24-02:01:22] [9/10] training 84.5%: Loss=0.359169, Accuracy=78.734%, MSE=0.149543
[2023-12-24-02:01:24] [9/10] training 85.8%: Loss=0.358723, Accuracy=78.831%, MSE=0.149158
[2023-12-24-02:01:26] [9/10] training 87.1%: Loss=0.357865, Accuracy=78.909%, MSE=0.148363
[2023-12-24-02:01:28] [9/10] training 88.4%: Loss=0.358649, Accuracy=78.791%, MSE=0.149094
[2023-12-24-02:01:30] [9/10] training 89.8%: Loss=0.358252, Accuracy=78.824%, MSE=0.14879
[2023-12-24-02:01:32] [9/10] training 91.1%: Loss=0.35782, Accuracy=78.826%, MSE=0.148473
[2023-12-24-02:01:34] [9/10] training 92.4%: Loss=0.357674, Accuracy=78.814%, MSE=0.148442
[2023-12-24-02:01:36] [9/10] training 93.7%: Loss=0.357366, Accuracy=78.831%, MSE=0.148234
[2023-12-24-02:01:38] [9/10] training 95.0%: Loss=0.357463, Accuracy=78.778%, MSE=0.148377
[2023-12-24-02:01:40] [9/10] training 96.4%: Loss=0.357002, Accuracy=78.836%, MSE=0.148054
[2023-12-24-02:01:42] [9/10] training 97.7%: Loss=0.356471, Accuracy=78.865%, MSE=0.147622
[2023-12-24-02:01:44] [9/10] training 99.0%: Loss=0.355579, Accuracy=78.987%, MSE=0.146878
[2023-12-24-02:01:53] Finished Epoch 9/10: Loss=2.76962, Accuracy=49.171%, MSE=0.494048, Precision=0.215117, Recall=0.00642693, F1=0.012481, AUPR=0.325315
[2023-12-24-02:01:53] Saving model to ./models/huang_7413_tt_rewired_epoch09.sav
[2023-12-24-02:01:55] [10/10] training 1.3%: Loss=0.312409, Accuracy=83.000%, MSE=0.120158
[2023-12-24-02:01:57] [10/10] training 2.6%: Loss=0.304002, Accuracy=83.000%, MSE=0.113795
[2023-12-24-02:01:59] [10/10] training 4.0%: Loss=0.302098, Accuracy=85.333%, MSE=0.104949
[2023-12-24-02:02:01] [10/10] training 5.3%: Loss=0.304726, Accuracy=85.250%, MSE=0.107804
[2023-12-24-02:02:03] [10/10] training 6.6%: Loss=0.307299, Accuracy=85.600%, MSE=0.109046
[2023-12-24-02:02:05] [10/10] training 7.9%: Loss=0.311077, Accuracy=85.000%, MSE=0.112896
[2023-12-24-02:02:06] [10/10] training 9.2%: Loss=0.311016, Accuracy=85.286%, MSE=0.112117
[2023-12-24-02:02:08] [10/10] training 10.6%: Loss=0.315362, Accuracy=84.750%, MSE=0.11502
[2023-12-24-02:02:10] [10/10] training 11.9%: Loss=0.310311, Accuracy=85.444%, MSE=0.109613
[2023-12-24-02:02:12] [10/10] training 13.2%: Loss=0.305607, Accuracy=86.000%, MSE=0.105712
[2023-12-24-02:02:14] [10/10] training 14.5%: Loss=0.302434, Accuracy=86.364%, MSE=0.103367
[2023-12-24-02:02:15] [10/10] training 15.8%: Loss=0.302328, Accuracy=86.083%, MSE=0.104338
[2023-12-24-02:02:17] [10/10] training 17.2%: Loss=0.301496, Accuracy=86.231%, MSE=0.103692
[2023-12-24-02:02:19] [10/10] training 18.5%: Loss=0.299916, Accuracy=86.571%, MSE=0.102514
[2023-12-24-02:02:21] [10/10] training 19.8%: Loss=0.304365, Accuracy=85.800%, MSE=0.106941
[2023-12-24-02:02:23] [10/10] training 21.1%: Loss=0.303222, Accuracy=85.750%, MSE=0.106117
[2023-12-24-02:02:25] [10/10] training 22.4%: Loss=0.303281, Accuracy=85.765%, MSE=0.106128
[2023-12-24-02:02:27] [10/10] training 23.8%: Loss=0.303319, Accuracy=85.556%, MSE=0.106307
[2023-12-24-02:02:28] [10/10] training 25.1%: Loss=0.304782, Accuracy=85.211%, MSE=0.108198
[2023-12-24-02:02:30] [10/10] training 26.4%: Loss=0.305142, Accuracy=85.100%, MSE=0.108452
[2023-12-24-02:02:32] [10/10] training 27.7%: Loss=0.304249, Accuracy=85.048%, MSE=0.10751
[2023-12-24-02:02:34] [10/10] training 29.0%: Loss=0.307817, Accuracy=84.591%, MSE=0.110895
[2023-12-24-02:02:36] [10/10] training 30.4%: Loss=0.311483, Accuracy=84.261%, MSE=0.11341
[2023-12-24-02:02:38] [10/10] training 31.7%: Loss=0.310704, Accuracy=84.333%, MSE=0.112864
[2023-12-24-02:02:40] [10/10] training 33.0%: Loss=0.309981, Accuracy=84.440%, MSE=0.112083
[2023-12-24-02:02:42] [10/10] training 34.3%: Loss=0.309132, Accuracy=84.500%, MSE=0.111243
[2023-12-24-02:02:44] [10/10] training 35.6%: Loss=0.310394, Accuracy=84.296%, MSE=0.112353
[2023-12-24-02:02:46] [10/10] training 37.0%: Loss=0.310976, Accuracy=84.321%, MSE=0.112827
[2023-12-24-02:02:47] [10/10] training 38.3%: Loss=0.312649, Accuracy=84.138%, MSE=0.114423
[2023-12-24-02:02:49] [10/10] training 39.6%: Loss=0.317234, Accuracy=83.500%, MSE=0.119104
[2023-12-24-02:02:51] [10/10] training 40.9%: Loss=0.316451, Accuracy=83.581%, MSE=0.118431
[2023-12-24-02:02:54] [10/10] training 42.2%: Loss=0.317807, Accuracy=83.438%, MSE=0.119579
[2023-12-24-02:02:55] [10/10] training 43.6%: Loss=0.316737, Accuracy=83.545%, MSE=0.118662
[2023-12-24-02:02:57] [10/10] training 44.9%: Loss=0.317677, Accuracy=83.412%, MSE=0.119286
[2023-12-24-02:02:59] [10/10] training 46.2%: Loss=0.317816, Accuracy=83.257%, MSE=0.119427
[2023-12-24-02:03:01] [10/10] training 47.5%: Loss=0.317797, Accuracy=83.194%, MSE=0.119556
[2023-12-24-02:03:03] [10/10] training 48.8%: Loss=0.319776, Accuracy=82.811%, MSE=0.121693
[2023-12-24-02:03:05] [10/10] training 50.2%: Loss=0.319773, Accuracy=82.816%, MSE=0.121661
[2023-12-24-02:03:07] [10/10] training 51.5%: Loss=0.320245, Accuracy=82.846%, MSE=0.121771
[2023-12-24-02:03:09] [10/10] training 52.8%: Loss=0.320082, Accuracy=82.900%, MSE=0.121646
[2023-12-24-02:03:10] [10/10] training 54.1%: Loss=0.318982, Accuracy=82.951%, MSE=0.120948
[2023-12-24-02:03:12] [10/10] training 55.4%: Loss=0.318063, Accuracy=83.000%, MSE=0.120387
[2023-12-24-02:03:14] [10/10] training 56.8%: Loss=0.31921, Accuracy=82.930%, MSE=0.12121
[2023-12-24-02:03:16] [10/10] training 58.1%: Loss=0.322632, Accuracy=82.500%, MSE=0.124533
[2023-12-24-02:03:18] [10/10] training 59.4%: Loss=0.326243, Accuracy=81.956%, MSE=0.128258
[2023-12-24-02:03:20] [10/10] training 60.7%: Loss=0.326929, Accuracy=81.870%, MSE=0.129016
[2023-12-24-02:03:22] [10/10] training 62.0%: Loss=0.326748, Accuracy=81.809%, MSE=0.128946
[2023-12-24-02:03:24] [10/10] training 63.4%: Loss=0.328577, Accuracy=81.458%, MSE=0.130947
[2023-12-24-02:03:26] [10/10] training 64.7%: Loss=0.329794, Accuracy=81.204%, MSE=0.132055
[2023-12-24-02:03:28] [10/10] training 66.0%: Loss=0.331371, Accuracy=80.920%, MSE=0.133688
[2023-12-24-02:03:29] [10/10] training 67.3%: Loss=0.332196, Accuracy=80.765%, MSE=0.134629
[2023-12-24-02:03:31] [10/10] training 68.6%: Loss=0.332561, Accuracy=80.673%, MSE=0.135032
[2023-12-24-02:03:33] [10/10] training 70.0%: Loss=0.332316, Accuracy=80.623%, MSE=0.134946
[2023-12-24-02:03:35] [10/10] training 71.3%: Loss=0.332282, Accuracy=80.648%, MSE=0.134958
[2023-12-24-02:03:37] [10/10] training 72.6%: Loss=0.332338, Accuracy=80.655%, MSE=0.135069
[2023-12-24-02:03:39] [10/10] training 73.9%: Loss=0.331802, Accuracy=80.786%, MSE=0.134455
[2023-12-24-02:03:41] [10/10] training 75.2%: Loss=0.330805, Accuracy=80.895%, MSE=0.133625
[2023-12-24-02:03:43] [10/10] training 76.6%: Loss=0.331023, Accuracy=80.931%, MSE=0.133831
[2023-12-24-02:03:45] [10/10] training 77.9%: Loss=0.331707, Accuracy=80.881%, MSE=0.134446
[2023-12-24-02:03:47] [10/10] training 79.2%: Loss=0.333801, Accuracy=80.633%, MSE=0.136498
[2023-12-24-02:03:49] [10/10] training 80.5%: Loss=0.334245, Accuracy=80.557%, MSE=0.137096
[2023-12-24-02:03:51] [10/10] training 81.8%: Loss=0.334606, Accuracy=80.468%, MSE=0.137521
[2023-12-24-02:03:52] [10/10] training 83.2%: Loss=0.33454, Accuracy=80.476%, MSE=0.137471
[2023-12-24-02:03:54] [10/10] training 84.5%: Loss=0.334972, Accuracy=80.406%, MSE=0.137925
[2023-12-24-02:03:56] [10/10] training 85.8%: Loss=0.33474, Accuracy=80.462%, MSE=0.137665
[2023-12-24-02:03:58] [10/10] training 87.1%: Loss=0.335292, Accuracy=80.394%, MSE=0.13804
[2023-12-24-02:04:00] [10/10] training 88.4%: Loss=0.335609, Accuracy=80.388%, MSE=0.138298
[2023-12-24-02:04:02] [10/10] training 89.8%: Loss=0.336005, Accuracy=80.324%, MSE=0.138552
[2023-12-24-02:04:04] [10/10] training 91.1%: Loss=0.3361, Accuracy=80.362%, MSE=0.138448
[2023-12-24-02:04:06] [10/10] training 92.4%: Loss=0.33609, Accuracy=80.371%, MSE=0.13842
[2023-12-24-02:04:08] [10/10] training 93.7%: Loss=0.336243, Accuracy=80.437%, MSE=0.13849
[2023-12-24-02:04:10] [10/10] training 95.0%: Loss=0.335652, Accuracy=80.528%, MSE=0.138014
[2023-12-24-02:04:12] [10/10] training 96.4%: Loss=0.334751, Accuracy=80.630%, MSE=0.137291
[2023-12-24-02:04:14] [10/10] training 97.7%: Loss=0.333946, Accuracy=80.703%, MSE=0.136767
[2023-12-24-02:04:16] [10/10] training 99.0%: Loss=0.33316, Accuracy=80.840%, MSE=0.13597
[2023-12-24-02:04:24] Finished Epoch 10/10: Loss=2.97851, Accuracy=49.171%, MSE=0.496643, Precision=0.496962, Recall=0.00338231, F1=0.00671889, AUPR=0.49652
[2023-12-24-02:04:24] Saving model to ./models/huang_7413_tt_rewired_epoch10.sav
[2023-12-24-02:04:24] Saving final model to ./models/huang_7413_tt_rewired_final.sav
