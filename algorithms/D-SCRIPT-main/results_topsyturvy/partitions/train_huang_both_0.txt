[2023-04-27-10:43:41] D-SCRIPT Version 0.2.2
[2023-04-27-10:43:41] Called as: /nfs/home/students/jbernett/.conda/envs/dscript2/bin/dscript train --topsy-turvy --train data/partitions/huang_partition_both.txt --test data/partitions/huang_partition_0.txt --embedding /nfs/scratch/jbernett/human_embedding.h5 --save-prefix ./models/huang_both_0_tt_partitions -o ./results_topsyturvy/partitions/train_huang_both_0.txt -d 2
[2023-04-27-10:43:41] Using CUDA device 2 - NVIDIA A40
[2023-04-27-10:43:41] Loaded 4136 training pairs
[2023-04-27-10:43:41] Loaded 1496 test pairs
[2023-04-27-10:43:41] Loading embeddings...
[2023-04-27-10:44:03] Running D-SCRIPT Topsy-Turvy:
[2023-04-27-10:44:03] 	glider_weight: 0.2
[2023-04-27-10:44:03] 	glider_thresh: 92.5th percentile
[2023-04-27-10:44:03] Computing GLIDER matrix...
[2023-04-27-10:44:06] Initializing embedding model with:
[2023-04-27-10:44:06] 	projection_dim: 100
[2023-04-27-10:44:06] 	dropout_p: 0.5
[2023-04-27-10:44:06] Initializing contact model with:
[2023-04-27-10:44:06] 	hidden_dim: 50
[2023-04-27-10:44:06] 	kernel_width: 7
[2023-04-27-10:44:06] Initializing interaction model with:
[2023-04-27-10:44:06] 	do_poool: False
[2023-04-27-10:44:06] 	pool_width: 9
[2023-04-27-10:44:06] 	do_w: True
[2023-04-27-10:44:06] 	do_sigmoid: True
[2023-04-27-10:44:06] ModelInteraction(
  (activation): LogisticActivation()
  (embedding): FullyConnectedEmbed(
    (transform): Linear(in_features=6165, out_features=100, bias=True)
    (drop): Dropout(p=0.5, inplace=False)
    (activation): ReLU()
  )
  (contact): ContactCNN(
    (hidden): FullyConnected(
      (conv): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
      (batchnorm): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (conv): Conv2d(50, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): Sigmoid()
  )
  (maxPool): MaxPool2d(kernel_size=9, stride=9, padding=4, dilation=1, ceil_mode=False)
)
[2023-04-27-10:44:08] Using save prefix "./models/huang_both_0_tt_partitions"
[2023-04-27-10:44:08] Training with Adam: lr=0.001, weight_decay=0
[2023-04-27-10:44:08] 	num_epochs: 10
[2023-04-27-10:44:08] 	batch_size: 25
[2023-04-27-10:44:08] 	interaction weight: 0.35
[2023-04-27-10:44:08] 	contact map weight: 0.65
[2023-04-27-10:44:11] [1/10] training 2.4%: Loss=1.491, Accuracy=48.000%, MSE=0.518293
[2023-04-27-10:44:13] [1/10] training 4.8%: Loss=1.36496, Accuracy=53.000%, MSE=0.468222
[2023-04-27-10:44:15] [1/10] training 7.2%: Loss=1.36231, Accuracy=52.667%, MSE=0.471425
[2023-04-27-10:44:18] [1/10] training 9.6%: Loss=1.39441, Accuracy=50.750%, MSE=0.490331
[2023-04-27-10:44:20] [1/10] training 12.0%: Loss=1.35689, Accuracy=52.200%, MSE=0.475818
[2023-04-27-10:44:22] [1/10] training 14.5%: Loss=1.35471, Accuracy=52.000%, MSE=0.477701
[2023-04-27-10:44:24] [1/10] training 16.9%: Loss=1.38591, Accuracy=50.429%, MSE=0.493254
[2023-04-27-10:44:26] [1/10] training 19.3%: Loss=1.40869, Accuracy=49.000%, MSE=0.507364
[2023-04-27-10:44:28] [1/10] training 21.7%: Loss=1.41192, Accuracy=48.667%, MSE=0.510624
[2023-04-27-10:44:30] [1/10] training 24.1%: Loss=1.39624, Accuracy=49.200%, MSE=0.505234
[2023-04-27-10:44:32] [1/10] training 26.5%: Loss=1.39713, Accuracy=48.909%, MSE=0.508043
[2023-04-27-10:44:34] [1/10] training 28.9%: Loss=1.38021, Accuracy=49.500%, MSE=0.502105
[2023-04-27-10:44:36] [1/10] training 31.3%: Loss=1.36705, Accuracy=49.846%, MSE=0.49856
[2023-04-27-10:44:39] [1/10] training 33.7%: Loss=1.3597, Accuracy=50.000%, MSE=0.496966
[2023-04-27-10:44:41] [1/10] training 36.1%: Loss=1.36256, Accuracy=49.600%, MSE=0.500811
[2023-04-27-10:44:43] [1/10] training 38.6%: Loss=1.35129, Accuracy=49.812%, MSE=0.498512
[2023-04-27-10:44:45] [1/10] training 41.0%: Loss=1.34688, Accuracy=49.824%, MSE=0.49831
[2023-04-27-10:44:47] [1/10] training 43.4%: Loss=1.34399, Accuracy=49.889%, MSE=0.497611
[2023-04-27-10:44:49] [1/10] training 45.8%: Loss=1.34074, Accuracy=49.737%, MSE=0.498931
[2023-04-27-10:44:51] [1/10] training 48.2%: Loss=1.34266, Accuracy=49.500%, MSE=0.501214
[2023-04-27-10:44:53] [1/10] training 50.6%: Loss=1.33728, Accuracy=49.524%, MSE=0.500835
[2023-04-27-10:44:55] [1/10] training 53.0%: Loss=1.3357, Accuracy=49.455%, MSE=0.501463
[2023-04-27-10:44:58] [1/10] training 55.4%: Loss=1.32567, Accuracy=49.696%, MSE=0.49892
[2023-04-27-10:45:00] [1/10] training 57.8%: Loss=1.32576, Accuracy=49.458%, MSE=0.501134
[2023-04-27-10:45:02] [1/10] training 60.2%: Loss=1.33172, Accuracy=48.920%, MSE=0.506342
[2023-04-27-10:45:04] [1/10] training 62.7%: Loss=1.32693, Accuracy=49.038%, MSE=0.5051
[2023-04-27-10:45:06] [1/10] training 65.1%: Loss=1.32265, Accuracy=49.111%, MSE=0.504304
[2023-04-27-10:45:08] [1/10] training 67.5%: Loss=1.3116, Accuracy=49.429%, MSE=0.500987
[2023-04-27-10:45:10] [1/10] training 69.9%: Loss=1.30566, Accuracy=49.586%, MSE=0.49934
[2023-04-27-10:45:12] [1/10] training 72.3%: Loss=1.30216, Accuracy=49.633%, MSE=0.498799
[2023-04-27-10:45:14] [1/10] training 74.7%: Loss=1.296, Accuracy=49.645%, MSE=0.498452
[2023-04-27-10:45:16] [1/10] training 77.1%: Loss=1.29475, Accuracy=49.563%, MSE=0.499186
[2023-04-27-10:45:18] [1/10] training 79.5%: Loss=1.28977, Accuracy=49.636%, MSE=0.498331
[2023-04-27-10:45:20] [1/10] training 81.9%: Loss=1.28847, Accuracy=49.529%, MSE=0.499273
[2023-04-27-10:45:23] [1/10] training 84.3%: Loss=1.28418, Accuracy=49.629%, MSE=0.498217
[2023-04-27-10:45:25] [1/10] training 86.7%: Loss=1.27864, Accuracy=49.722%, MSE=0.497158
[2023-04-27-10:45:27] [1/10] training 89.2%: Loss=1.27195, Accuracy=49.892%, MSE=0.495334
[2023-04-27-10:45:29] [1/10] training 91.6%: Loss=1.26924, Accuracy=49.842%, MSE=0.495677
[2023-04-27-10:45:31] [1/10] training 94.0%: Loss=1.26785, Accuracy=49.795%, MSE=0.496067
[2023-04-27-10:45:33] [1/10] training 96.4%: Loss=1.25789, Accuracy=50.150%, MSE=0.492425
[2023-04-27-10:45:35] [1/10] training 98.8%: Loss=1.25698, Accuracy=50.000%, MSE=0.493732
[2023-04-27-10:45:50] Finished Epoch 1/10: Loss=2.46806, Accuracy=49.867%, MSE=0.490413, Precision=0.448766, Recall=0.00979979, F1=0.0191807, AUPR=0.439645
[2023-04-27-10:45:50] Saving model to ./models/huang_both_0_tt_partitions_epoch01.sav
[2023-04-27-10:45:52] [2/10] training 2.4%: Loss=1.10198, Accuracy=52.000%, MSE=0.470555
[2023-04-27-10:45:54] [2/10] training 4.8%: Loss=1.14484, Accuracy=47.500%, MSE=0.511316
[2023-04-27-10:45:56] [2/10] training 7.2%: Loss=1.12672, Accuracy=49.000%, MSE=0.497505
[2023-04-27-10:45:57] [2/10] training 9.6%: Loss=1.15119, Accuracy=48.000%, MSE=0.5077
[2023-04-27-10:45:59] [2/10] training 12.0%: Loss=1.13481, Accuracy=48.400%, MSE=0.50311
[2023-04-27-10:46:01] [2/10] training 14.5%: Loss=1.11265, Accuracy=49.333%, MSE=0.4936
[2023-04-27-10:46:03] [2/10] training 16.9%: Loss=1.09978, Accuracy=50.143%, MSE=0.485481
[2023-04-27-10:46:05] [2/10] training 19.3%: Loss=1.10697, Accuracy=49.375%, MSE=0.492629
[2023-04-27-10:46:06] [2/10] training 21.7%: Loss=1.09873, Accuracy=49.556%, MSE=0.490551
[2023-04-27-10:46:08] [2/10] training 24.1%: Loss=1.09515, Accuracy=49.400%, MSE=0.491515
[2023-04-27-10:46:10] [2/10] training 26.5%: Loss=1.09784, Accuracy=49.273%, MSE=0.492869
[2023-04-27-10:46:12] [2/10] training 28.9%: Loss=1.10621, Accuracy=48.250%, MSE=0.501814
[2023-04-27-10:46:13] [2/10] training 31.3%: Loss=1.10549, Accuracy=48.462%, MSE=0.499999
[2023-04-27-10:46:15] [2/10] training 33.7%: Loss=1.09311, Accuracy=49.000%, MSE=0.494565
[2023-04-27-10:46:17] [2/10] training 36.1%: Loss=1.08716, Accuracy=49.067%, MSE=0.493617
[2023-04-27-10:46:19] [2/10] training 38.6%: Loss=1.08498, Accuracy=49.062%, MSE=0.493489
[2023-04-27-10:46:21] [2/10] training 41.0%: Loss=1.0851, Accuracy=48.941%, MSE=0.494433
[2023-04-27-10:46:22] [2/10] training 43.4%: Loss=1.08621, Accuracy=48.667%, MSE=0.49679
[2023-04-27-10:46:24] [2/10] training 45.8%: Loss=1.08442, Accuracy=48.632%, MSE=0.496797
[2023-04-27-10:46:26] [2/10] training 48.2%: Loss=1.08396, Accuracy=48.600%, MSE=0.497091
[2023-04-27-10:46:28] [2/10] training 50.6%: Loss=1.08122, Accuracy=48.667%, MSE=0.49627
[2023-04-27-10:46:29] [2/10] training 53.0%: Loss=1.08121, Accuracy=48.591%, MSE=0.49691
[2023-04-27-10:46:31] [2/10] training 55.4%: Loss=1.07897, Accuracy=48.696%, MSE=0.495892
[2023-04-27-10:46:33] [2/10] training 57.8%: Loss=1.07328, Accuracy=48.875%, MSE=0.493948
[2023-04-27-10:46:34] [2/10] training 60.2%: Loss=1.06781, Accuracy=49.160%, MSE=0.491047
[2023-04-27-10:46:36] [2/10] training 62.7%: Loss=1.06082, Accuracy=49.538%, MSE=0.487247
[2023-04-27-10:46:38] [2/10] training 65.1%: Loss=1.05655, Accuracy=49.519%, MSE=0.486988
[2023-04-27-10:46:40] [2/10] training 67.5%: Loss=1.05338, Accuracy=49.714%, MSE=0.485102
[2023-04-27-10:46:42] [2/10] training 69.9%: Loss=1.04964, Accuracy=49.690%, MSE=0.484896
[2023-04-27-10:46:43] [2/10] training 72.3%: Loss=1.04513, Accuracy=49.767%, MSE=0.483768
[2023-04-27-10:46:45] [2/10] training 74.7%: Loss=1.04676, Accuracy=49.548%, MSE=0.485771
[2023-04-27-10:46:47] [2/10] training 77.1%: Loss=1.04273, Accuracy=49.688%, MSE=0.484295
[2023-04-27-10:46:49] [2/10] training 79.5%: Loss=1.03784, Accuracy=49.697%, MSE=0.483518
[2023-04-27-10:46:50] [2/10] training 81.9%: Loss=1.03375, Accuracy=49.794%, MSE=0.482132
[2023-04-27-10:46:52] [2/10] training 84.3%: Loss=1.0323, Accuracy=49.629%, MSE=0.483081
[2023-04-27-10:46:54] [2/10] training 86.7%: Loss=1.03012, Accuracy=49.722%, MSE=0.482042
[2023-04-27-10:46:55] [2/10] training 89.2%: Loss=1.03026, Accuracy=49.622%, MSE=0.482975
[2023-04-27-10:46:57] [2/10] training 91.6%: Loss=1.02546, Accuracy=49.711%, MSE=0.481695
[2023-04-27-10:46:59] [2/10] training 94.0%: Loss=1.02329, Accuracy=49.718%, MSE=0.481319
[2023-04-27-10:47:01] [2/10] training 96.4%: Loss=1.02336, Accuracy=49.675%, MSE=0.481862
[2023-04-27-10:47:03] [2/10] training 98.8%: Loss=1.01716, Accuracy=49.927%, MSE=0.479189
[2023-04-27-10:47:14] Finished Epoch 2/10: Loss=1.50245, Accuracy=49.400%, MSE=0.447463, Precision=0.422828, Recall=0.0621832, F1=0.108421, AUPR=0.41045
[2023-04-27-10:47:14] Saving model to ./models/huang_both_0_tt_partitions_epoch02.sav
[2023-04-27-10:47:16] [3/10] training 2.4%: Loss=0.80335, Accuracy=50.000%, MSE=0.44461
[2023-04-27-10:47:18] [3/10] training 4.8%: Loss=0.829416, Accuracy=48.500%, MSE=0.449135
[2023-04-27-10:47:20] [3/10] training 7.2%: Loss=0.856874, Accuracy=47.000%, MSE=0.454957
[2023-04-27-10:47:22] [3/10] training 9.6%: Loss=0.890161, Accuracy=46.250%, MSE=0.467183
[2023-04-27-10:47:23] [3/10] training 12.0%: Loss=0.897672, Accuracy=46.600%, MSE=0.467429
[2023-04-27-10:47:25] [3/10] training 14.5%: Loss=0.900411, Accuracy=46.333%, MSE=0.471675
[2023-04-27-10:47:27] [3/10] training 16.9%: Loss=0.875237, Accuracy=47.429%, MSE=0.458219
[2023-04-27-10:47:29] [3/10] training 19.3%: Loss=0.87165, Accuracy=47.375%, MSE=0.457115
[2023-04-27-10:47:31] [3/10] training 21.7%: Loss=0.875415, Accuracy=47.667%, MSE=0.458484
[2023-04-27-10:47:32] [3/10] training 24.1%: Loss=0.89376, Accuracy=47.100%, MSE=0.466386
[2023-04-27-10:47:34] [3/10] training 26.5%: Loss=0.897442, Accuracy=46.909%, MSE=0.469043
[2023-04-27-10:47:36] [3/10] training 28.9%: Loss=0.899942, Accuracy=46.667%, MSE=0.471524
[2023-04-27-10:47:37] [3/10] training 31.3%: Loss=0.89736, Accuracy=46.769%, MSE=0.470246
[2023-04-27-10:47:39] [3/10] training 33.7%: Loss=0.894998, Accuracy=46.714%, MSE=0.469773
[2023-04-27-10:47:41] [3/10] training 36.1%: Loss=0.893445, Accuracy=46.600%, MSE=0.470284
[2023-04-27-10:47:43] [3/10] training 38.6%: Loss=0.885397, Accuracy=46.938%, MSE=0.466165
[2023-04-27-10:47:44] [3/10] training 41.0%: Loss=0.877771, Accuracy=47.176%, MSE=0.46326
[2023-04-27-10:47:46] [3/10] training 43.4%: Loss=0.87045, Accuracy=47.222%, MSE=0.460515
[2023-04-27-10:47:48] [3/10] training 45.8%: Loss=0.860796, Accuracy=47.368%, MSE=0.456619
[2023-04-27-10:47:50] [3/10] training 48.2%: Loss=0.858772, Accuracy=47.150%, MSE=0.456959
[2023-04-27-10:47:52] [3/10] training 50.6%: Loss=0.854082, Accuracy=47.190%, MSE=0.455042
[2023-04-27-10:47:54] [3/10] training 53.0%: Loss=0.857455, Accuracy=46.864%, MSE=0.458043
[2023-04-27-10:47:55] [3/10] training 55.4%: Loss=0.860281, Accuracy=46.739%, MSE=0.459892
[2023-04-27-10:47:57] [3/10] training 57.8%: Loss=0.863747, Accuracy=46.542%, MSE=0.462185
[2023-04-27-10:47:59] [3/10] training 60.2%: Loss=0.860892, Accuracy=46.640%, MSE=0.461168
[2023-04-27-10:48:01] [3/10] training 62.7%: Loss=0.857682, Accuracy=46.500%, MSE=0.460906
[2023-04-27-10:48:02] [3/10] training 65.1%: Loss=0.848086, Accuracy=46.556%, MSE=0.456609
[2023-04-27-10:48:04] [3/10] training 67.5%: Loss=0.842313, Accuracy=46.714%, MSE=0.452548
[2023-04-27-10:48:06] [3/10] training 69.9%: Loss=0.851272, Accuracy=46.828%, MSE=0.453851
[2023-04-27-10:48:07] [3/10] training 72.3%: Loss=0.852769, Accuracy=47.300%, MSE=0.451392
[2023-04-27-10:48:09] [3/10] training 74.7%: Loss=0.858217, Accuracy=47.516%, MSE=0.451347
[2023-04-27-10:48:11] [3/10] training 77.1%: Loss=0.86521, Accuracy=47.594%, MSE=0.452497
[2023-04-27-10:48:12] [3/10] training 79.5%: Loss=0.873529, Accuracy=47.515%, MSE=0.455023
[2023-04-27-10:48:14] [3/10] training 81.9%: Loss=0.876285, Accuracy=47.765%, MSE=0.454257
[2023-04-27-10:48:16] [3/10] training 84.3%: Loss=0.879493, Accuracy=47.971%, MSE=0.453834
[2023-04-27-10:48:18] [3/10] training 86.7%: Loss=0.882422, Accuracy=48.194%, MSE=0.453173
[2023-04-27-10:48:19] [3/10] training 89.2%: Loss=0.886318, Accuracy=48.324%, MSE=0.45331
[2023-04-27-10:48:21] [3/10] training 91.6%: Loss=0.888856, Accuracy=48.474%, MSE=0.453134
[2023-04-27-10:48:23] [3/10] training 94.0%: Loss=0.892751, Accuracy=48.513%, MSE=0.453961
[2023-04-27-10:48:25] [3/10] training 96.4%: Loss=0.898365, Accuracy=48.425%, MSE=0.455953
[2023-04-27-10:48:26] [3/10] training 98.8%: Loss=0.900783, Accuracy=48.537%, MSE=0.455967
[2023-04-27-10:48:38] Finished Epoch 3/10: Loss=3.01575, Accuracy=49.867%, MSE=0.496062, Precision=0.515557, Recall=0.00398009, F1=0.0078992, AUPR=0.508618
[2023-04-27-10:48:38] Saving model to ./models/huang_both_0_tt_partitions_epoch03.sav
[2023-04-27-10:48:40] [4/10] training 2.4%: Loss=1.00995, Accuracy=51.000%, MSE=0.474734
[2023-04-27-10:48:41] [4/10] training 4.8%: Loss=0.98064, Accuracy=53.500%, MSE=0.450817
[2023-04-27-10:48:43] [4/10] training 7.2%: Loss=1.01776, Accuracy=51.667%, MSE=0.46903
[2023-04-27-10:48:45] [4/10] training 9.6%: Loss=1.04417, Accuracy=49.500%, MSE=0.489205
[2023-04-27-10:48:47] [4/10] training 12.0%: Loss=1.03428, Accuracy=49.800%, MSE=0.485738
[2023-04-27-10:48:49] [4/10] training 14.5%: Loss=1.03979, Accuracy=49.333%, MSE=0.490177
[2023-04-27-10:48:50] [4/10] training 16.9%: Loss=1.04889, Accuracy=48.429%, MSE=0.498514
[2023-04-27-10:48:52] [4/10] training 19.3%: Loss=1.04984, Accuracy=48.375%, MSE=0.498939
[2023-04-27-10:48:54] [4/10] training 21.7%: Loss=1.02801, Accuracy=49.556%, MSE=0.486896
[2023-04-27-10:48:56] [4/10] training 24.1%: Loss=1.00428, Accuracy=51.100%, MSE=0.471941
[2023-04-27-10:48:57] [4/10] training 26.5%: Loss=1.00425, Accuracy=50.818%, MSE=0.47426
[2023-04-27-10:48:59] [4/10] training 28.9%: Loss=0.999616, Accuracy=50.917%, MSE=0.472909
[2023-04-27-10:49:01] [4/10] training 31.3%: Loss=1.01166, Accuracy=50.077%, MSE=0.481088
[2023-04-27-10:49:03] [4/10] training 33.7%: Loss=1.00305, Accuracy=50.500%, MSE=0.476704
[2023-04-27-10:49:05] [4/10] training 36.1%: Loss=1.0063, Accuracy=50.200%, MSE=0.479539
[2023-04-27-10:49:07] [4/10] training 38.6%: Loss=1.00143, Accuracy=50.438%, MSE=0.477049
[2023-04-27-10:49:08] [4/10] training 41.0%: Loss=0.995384, Accuracy=50.588%, MSE=0.475181
[2023-04-27-10:49:10] [4/10] training 43.4%: Loss=0.996507, Accuracy=50.278%, MSE=0.477778
[2023-04-27-10:49:12] [4/10] training 45.8%: Loss=0.987929, Accuracy=50.737%, MSE=0.473073
[2023-04-27-10:49:14] [4/10] training 48.2%: Loss=0.984597, Accuracy=50.800%, MSE=0.472126
[2023-04-27-10:49:15] [4/10] training 50.6%: Loss=0.984378, Accuracy=50.667%, MSE=0.473187
[2023-04-27-10:49:17] [4/10] training 53.0%: Loss=0.985108, Accuracy=50.409%, MSE=0.475279
[2023-04-27-10:49:19] [4/10] training 55.4%: Loss=0.98833, Accuracy=50.000%, MSE=0.478838
[2023-04-27-10:49:21] [4/10] training 57.8%: Loss=0.987831, Accuracy=49.833%, MSE=0.479971
[2023-04-27-10:49:23] [4/10] training 60.2%: Loss=0.981937, Accuracy=50.160%, MSE=0.476663
[2023-04-27-10:49:25] [4/10] training 62.7%: Loss=0.977328, Accuracy=50.269%, MSE=0.475131
[2023-04-27-10:49:26] [4/10] training 65.1%: Loss=0.979174, Accuracy=49.963%, MSE=0.477644
[2023-04-27-10:49:28] [4/10] training 67.5%: Loss=0.977141, Accuracy=50.036%, MSE=0.476776
[2023-04-27-10:49:29] [4/10] training 69.9%: Loss=0.976079, Accuracy=49.931%, MSE=0.477336
[2023-04-27-10:49:31] [4/10] training 72.3%: Loss=0.973595, Accuracy=50.067%, MSE=0.475982
[2023-04-27-10:49:33] [4/10] training 74.7%: Loss=0.97094, Accuracy=50.065%, MSE=0.47553
[2023-04-27-10:49:34] [4/10] training 77.1%: Loss=0.96703, Accuracy=50.250%, MSE=0.473534
[2023-04-27-10:49:36] [4/10] training 79.5%: Loss=0.965987, Accuracy=50.242%, MSE=0.473486
[2023-04-27-10:49:38] [4/10] training 81.9%: Loss=0.963454, Accuracy=50.147%, MSE=0.473607
[2023-04-27-10:49:40] [4/10] training 84.3%: Loss=0.960007, Accuracy=50.257%, MSE=0.472241
[2023-04-27-10:49:42] [4/10] training 86.7%: Loss=0.958265, Accuracy=50.222%, MSE=0.472156
[2023-04-27-10:49:43] [4/10] training 89.2%: Loss=0.9566, Accuracy=50.243%, MSE=0.471649
[2023-04-27-10:49:45] [4/10] training 91.6%: Loss=0.95538, Accuracy=50.132%, MSE=0.472181
[2023-04-27-10:49:47] [4/10] training 94.0%: Loss=0.953983, Accuracy=50.103%, MSE=0.472121
[2023-04-27-10:49:48] [4/10] training 96.4%: Loss=0.95109, Accuracy=50.075%, MSE=0.4717
[2023-04-27-10:49:50] [4/10] training 98.8%: Loss=0.948571, Accuracy=50.073%, MSE=0.471162
[2023-04-27-10:50:01] Finished Epoch 4/10: Loss=1.88848, Accuracy=49.867%, MSE=0.469563, Precision=0.546459, Recall=0.0319066, F1=0.0602928, AUPR=0.555659
[2023-04-27-10:50:01] Saving model to ./models/huang_both_0_tt_partitions_epoch04.sav
[2023-04-27-10:50:03] [5/10] training 2.4%: Loss=0.779058, Accuracy=56.000%, MSE=0.39659
[2023-04-27-10:50:05] [5/10] training 4.8%: Loss=0.792795, Accuracy=55.500%, MSE=0.40432
[2023-04-27-10:50:07] [5/10] training 7.2%: Loss=0.844084, Accuracy=50.333%, MSE=0.44707
[2023-04-27-10:50:09] [5/10] training 9.6%: Loss=0.836844, Accuracy=51.500%, MSE=0.438018
[2023-04-27-10:50:11] [5/10] training 12.0%: Loss=0.825583, Accuracy=51.400%, MSE=0.436126
[2023-04-27-10:50:12] [5/10] training 14.5%: Loss=0.820877, Accuracy=51.333%, MSE=0.435545
[2023-04-27-10:50:14] [5/10] training 16.9%: Loss=0.820817, Accuracy=52.000%, MSE=0.431813
[2023-04-27-10:50:16] [5/10] training 19.3%: Loss=0.82547, Accuracy=51.750%, MSE=0.43456
[2023-04-27-10:50:18] [5/10] training 21.7%: Loss=0.835058, Accuracy=51.222%, MSE=0.440421
[2023-04-27-10:50:19] [5/10] training 24.1%: Loss=0.832459, Accuracy=50.800%, MSE=0.442197
[2023-04-27-10:50:21] [5/10] training 26.5%: Loss=0.834571, Accuracy=50.636%, MSE=0.444013
[2023-04-27-10:50:23] [5/10] training 28.9%: Loss=0.835638, Accuracy=50.333%, MSE=0.446124
[2023-04-27-10:50:25] [5/10] training 31.3%: Loss=0.837425, Accuracy=50.077%, MSE=0.447907
[2023-04-27-10:50:26] [5/10] training 33.7%: Loss=0.836184, Accuracy=50.143%, MSE=0.447301
[2023-04-27-10:50:28] [5/10] training 36.1%: Loss=0.836515, Accuracy=49.933%, MSE=0.448376
[2023-04-27-10:50:30] [5/10] training 38.6%: Loss=0.839532, Accuracy=49.375%, MSE=0.452489
[2023-04-27-10:50:31] [5/10] training 41.0%: Loss=0.842122, Accuracy=49.294%, MSE=0.453652
[2023-04-27-10:50:33] [5/10] training 43.4%: Loss=0.836492, Accuracy=49.667%, MSE=0.44995
[2023-04-27-10:50:34] [5/10] training 45.8%: Loss=0.837911, Accuracy=49.316%, MSE=0.452411
[2023-04-27-10:50:36] [5/10] training 48.2%: Loss=0.836208, Accuracy=49.350%, MSE=0.451724
[2023-04-27-10:50:38] [5/10] training 50.6%: Loss=0.833083, Accuracy=49.714%, MSE=0.448749
[2023-04-27-10:50:40] [5/10] training 53.0%: Loss=0.834605, Accuracy=49.500%, MSE=0.450198
[2023-04-27-10:50:41] [5/10] training 55.4%: Loss=0.833835, Accuracy=49.522%, MSE=0.449852
[2023-04-27-10:50:43] [5/10] training 57.8%: Loss=0.829119, Accuracy=49.750%, MSE=0.447139
[2023-04-27-10:50:45] [5/10] training 60.2%: Loss=0.827627, Accuracy=49.760%, MSE=0.446531
[2023-04-27-10:50:47] [5/10] training 62.7%: Loss=0.824659, Accuracy=50.000%, MSE=0.444358
[2023-04-27-10:50:49] [5/10] training 65.1%: Loss=0.825485, Accuracy=49.852%, MSE=0.445389
[2023-04-27-10:50:51] [5/10] training 67.5%: Loss=0.821903, Accuracy=49.893%, MSE=0.443922
[2023-04-27-10:50:53] [5/10] training 69.9%: Loss=0.819072, Accuracy=49.966%, MSE=0.442626
[2023-04-27-10:50:54] [5/10] training 72.3%: Loss=0.818895, Accuracy=49.933%, MSE=0.4429
[2023-04-27-10:50:56] [5/10] training 74.7%: Loss=0.819734, Accuracy=49.839%, MSE=0.443722
[2023-04-27-10:50:58] [5/10] training 77.1%: Loss=0.81781, Accuracy=49.812%, MSE=0.44325
[2023-04-27-10:51:00] [5/10] training 79.5%: Loss=0.816417, Accuracy=49.818%, MSE=0.442803
[2023-04-27-10:51:02] [5/10] training 81.9%: Loss=0.814987, Accuracy=49.853%, MSE=0.442282
[2023-04-27-10:51:03] [5/10] training 84.3%: Loss=0.813897, Accuracy=49.829%, MSE=0.441993
[2023-04-27-10:51:05] [5/10] training 86.7%: Loss=0.813695, Accuracy=49.750%, MSE=0.4426
[2023-04-27-10:51:07] [5/10] training 89.2%: Loss=0.8101, Accuracy=49.865%, MSE=0.440738
[2023-04-27-10:51:08] [5/10] training 91.6%: Loss=0.811433, Accuracy=49.579%, MSE=0.442676
[2023-04-27-10:51:10] [5/10] training 94.0%: Loss=0.810121, Accuracy=49.590%, MSE=0.442224
[2023-04-27-10:51:12] [5/10] training 96.4%: Loss=0.806297, Accuracy=49.825%, MSE=0.439703
[2023-04-27-10:51:14] [5/10] training 98.8%: Loss=0.804199, Accuracy=50.000%, MSE=0.438165
[2023-04-27-10:51:25] Finished Epoch 5/10: Loss=1.30943, Accuracy=49.667%, MSE=0.407894, Precision=0.515002, Recall=0.111383, F1=0.183154, AUPR=0.515579
[2023-04-27-10:51:25] Saving model to ./models/huang_both_0_tt_partitions_epoch05.sav
[2023-04-27-10:51:27] [6/10] training 2.4%: Loss=0.699128, Accuracy=52.000%, MSE=0.379939
[2023-04-27-10:51:29] [6/10] training 4.8%: Loss=0.74868, Accuracy=49.000%, MSE=0.420879
[2023-04-27-10:51:31] [6/10] training 7.2%: Loss=0.790505, Accuracy=45.333%, MSE=0.452668
[2023-04-27-10:51:32] [6/10] training 9.6%: Loss=0.764783, Accuracy=47.250%, MSE=0.431471
[2023-04-27-10:51:34] [6/10] training 12.0%: Loss=0.767377, Accuracy=46.800%, MSE=0.43434
[2023-04-27-10:51:36] [6/10] training 14.5%: Loss=0.765954, Accuracy=46.667%, MSE=0.435742
[2023-04-27-10:51:38] [6/10] training 16.9%: Loss=0.751534, Accuracy=47.286%, MSE=0.428371
[2023-04-27-10:51:39] [6/10] training 19.3%: Loss=0.749555, Accuracy=47.125%, MSE=0.427528
[2023-04-27-10:51:41] [6/10] training 21.7%: Loss=0.742473, Accuracy=47.556%, MSE=0.422331
[2023-04-27-10:51:43] [6/10] training 24.1%: Loss=0.738433, Accuracy=47.800%, MSE=0.41941
[2023-04-27-10:51:45] [6/10] training 26.5%: Loss=0.733217, Accuracy=47.909%, MSE=0.417435
[2023-04-27-10:51:47] [6/10] training 28.9%: Loss=0.730146, Accuracy=48.000%, MSE=0.415929
[2023-04-27-10:51:48] [6/10] training 31.3%: Loss=0.72902, Accuracy=48.231%, MSE=0.414097
[2023-04-27-10:51:50] [6/10] training 33.7%: Loss=0.727208, Accuracy=48.214%, MSE=0.412886
[2023-04-27-10:51:52] [6/10] training 36.1%: Loss=0.721714, Accuracy=48.533%, MSE=0.408589
[2023-04-27-10:51:53] [6/10] training 38.6%: Loss=0.713309, Accuracy=48.687%, MSE=0.402775
[2023-04-27-10:51:55] [6/10] training 41.0%: Loss=0.711021, Accuracy=48.706%, MSE=0.401384
[2023-04-27-10:51:57] [6/10] training 43.4%: Loss=0.708288, Accuracy=48.778%, MSE=0.400274
[2023-04-27-10:51:59] [6/10] training 45.8%: Loss=0.703386, Accuracy=49.105%, MSE=0.396827
[2023-04-27-10:52:00] [6/10] training 48.2%: Loss=0.698361, Accuracy=48.750%, MSE=0.394599
[2023-04-27-10:52:02] [6/10] training 50.6%: Loss=0.692382, Accuracy=48.524%, MSE=0.391709
[2023-04-27-10:52:04] [6/10] training 53.0%: Loss=0.684977, Accuracy=48.545%, MSE=0.387526
[2023-04-27-10:52:06] [6/10] training 55.4%: Loss=0.676508, Accuracy=48.957%, MSE=0.381512
[2023-04-27-10:52:07] [6/10] training 57.8%: Loss=0.673443, Accuracy=49.083%, MSE=0.378781
[2023-04-27-10:52:09] [6/10] training 60.2%: Loss=0.672885, Accuracy=48.960%, MSE=0.377893
[2023-04-27-10:52:11] [6/10] training 62.7%: Loss=0.673996, Accuracy=48.846%, MSE=0.37806
[2023-04-27-10:52:12] [6/10] training 65.1%: Loss=0.673924, Accuracy=48.815%, MSE=0.37708
[2023-04-27-10:52:14] [6/10] training 67.5%: Loss=0.67087, Accuracy=49.036%, MSE=0.374611
[2023-04-27-10:52:16] [6/10] training 69.9%: Loss=0.673979, Accuracy=49.000%, MSE=0.376158
[2023-04-27-10:52:18] [6/10] training 72.3%: Loss=0.67277, Accuracy=49.200%, MSE=0.374933
[2023-04-27-10:52:20] [6/10] training 74.7%: Loss=0.670812, Accuracy=49.323%, MSE=0.373989
[2023-04-27-10:52:22] [6/10] training 77.1%: Loss=0.669616, Accuracy=49.344%, MSE=0.373218
[2023-04-27-10:52:24] [6/10] training 79.5%: Loss=0.675004, Accuracy=49.273%, MSE=0.376222
[2023-04-27-10:52:25] [6/10] training 81.9%: Loss=0.676884, Accuracy=49.176%, MSE=0.377561
[2023-04-27-10:52:27] [6/10] training 84.3%: Loss=0.679057, Accuracy=49.057%, MSE=0.379247
[2023-04-27-10:52:29] [6/10] training 86.7%: Loss=0.67993, Accuracy=48.972%, MSE=0.379985
[2023-04-27-10:52:31] [6/10] training 89.2%: Loss=0.678676, Accuracy=48.973%, MSE=0.379459
[2023-04-27-10:52:32] [6/10] training 91.6%: Loss=0.676971, Accuracy=49.053%, MSE=0.378334
[2023-04-27-10:52:34] [6/10] training 94.0%: Loss=0.672163, Accuracy=49.487%, MSE=0.374488
[2023-04-27-10:52:36] [6/10] training 96.4%: Loss=0.670398, Accuracy=49.750%, MSE=0.372192
[2023-04-27-10:52:37] [6/10] training 98.8%: Loss=0.669093, Accuracy=49.707%, MSE=0.371489
[2023-04-27-10:52:49] Finished Epoch 6/10: Loss=2.0561, Accuracy=49.400%, MSE=0.46488, Precision=0.36429, Recall=0.0478705, F1=0.0846211, AUPR=0.412799
[2023-04-27-10:52:49] Saving model to ./models/huang_both_0_tt_partitions_epoch06.sav
[2023-04-27-10:52:51] [7/10] training 2.4%: Loss=0.774981, Accuracy=53.000%, MSE=0.4047
[2023-04-27-10:52:52] [7/10] training 4.8%: Loss=0.785826, Accuracy=48.500%, MSE=0.423862
[2023-04-27-10:52:54] [7/10] training 7.2%: Loss=0.757961, Accuracy=49.667%, MSE=0.408226
[2023-04-27-10:52:56] [7/10] training 9.6%: Loss=0.728072, Accuracy=49.250%, MSE=0.396124
[2023-04-27-10:52:57] [7/10] training 12.0%: Loss=0.703344, Accuracy=48.200%, MSE=0.388496
[2023-04-27-10:52:59] [7/10] training 14.5%: Loss=0.685942, Accuracy=49.333%, MSE=0.370828
[2023-04-27-10:53:01] [7/10] training 16.9%: Loss=0.686781, Accuracy=51.714%, MSE=0.358992
[2023-04-27-10:53:02] [7/10] training 19.3%: Loss=0.704475, Accuracy=52.000%, MSE=0.367125
[2023-04-27-10:53:04] [7/10] training 21.7%: Loss=0.741399, Accuracy=50.778%, MSE=0.388583
[2023-04-27-10:53:06] [7/10] training 24.1%: Loss=0.761463, Accuracy=50.300%, MSE=0.400508
[2023-04-27-10:53:08] [7/10] training 26.5%: Loss=0.765946, Accuracy=50.727%, MSE=0.402066
[2023-04-27-10:53:09] [7/10] training 28.9%: Loss=0.779473, Accuracy=50.333%, MSE=0.410061
[2023-04-27-10:53:11] [7/10] training 31.3%: Loss=0.785347, Accuracy=50.077%, MSE=0.41456
[2023-04-27-10:53:13] [7/10] training 33.7%: Loss=0.78229, Accuracy=50.571%, MSE=0.412314
[2023-04-27-10:53:14] [7/10] training 36.1%: Loss=0.77897, Accuracy=50.200%, MSE=0.413864
[2023-04-27-10:53:16] [7/10] training 38.6%: Loss=0.768953, Accuracy=50.062%, MSE=0.410272
[2023-04-27-10:53:18] [7/10] training 41.0%: Loss=0.767061, Accuracy=49.471%, MSE=0.412481
[2023-04-27-10:53:20] [7/10] training 43.4%: Loss=0.764023, Accuracy=49.056%, MSE=0.412641
[2023-04-27-10:53:22] [7/10] training 45.8%: Loss=0.759182, Accuracy=48.895%, MSE=0.411756
[2023-04-27-10:53:23] [7/10] training 48.2%: Loss=0.753731, Accuracy=48.700%, MSE=0.410011
[2023-04-27-10:53:25] [7/10] training 50.6%: Loss=0.748657, Accuracy=48.667%, MSE=0.408234
[2023-04-27-10:53:27] [7/10] training 53.0%: Loss=0.744386, Accuracy=48.455%, MSE=0.407018
[2023-04-27-10:53:29] [7/10] training 55.4%: Loss=0.737956, Accuracy=48.609%, MSE=0.4039
[2023-04-27-10:53:31] [7/10] training 57.8%: Loss=0.731963, Accuracy=48.500%, MSE=0.401081
[2023-04-27-10:53:32] [7/10] training 60.2%: Loss=0.727811, Accuracy=48.120%, MSE=0.400274
[2023-04-27-10:53:34] [7/10] training 62.7%: Loss=0.723947, Accuracy=48.038%, MSE=0.399052
[2023-04-27-10:53:36] [7/10] training 65.1%: Loss=0.718197, Accuracy=48.222%, MSE=0.395035
[2023-04-27-10:53:38] [7/10] training 67.5%: Loss=0.712844, Accuracy=48.250%, MSE=0.392334
[2023-04-27-10:53:39] [7/10] training 69.9%: Loss=0.709024, Accuracy=48.207%, MSE=0.390537
[2023-04-27-10:53:41] [7/10] training 72.3%: Loss=0.705112, Accuracy=48.033%, MSE=0.388864
[2023-04-27-10:53:43] [7/10] training 74.7%: Loss=0.701925, Accuracy=47.903%, MSE=0.387667
[2023-04-27-10:53:45] [7/10] training 77.1%: Loss=0.699657, Accuracy=47.906%, MSE=0.387204
[2023-04-27-10:53:47] [7/10] training 79.5%: Loss=0.69681, Accuracy=47.848%, MSE=0.386365
[2023-04-27-10:53:49] [7/10] training 81.9%: Loss=0.694606, Accuracy=47.971%, MSE=0.385045
[2023-04-27-10:53:50] [7/10] training 84.3%: Loss=0.691725, Accuracy=48.029%, MSE=0.383689
[2023-04-27-10:53:52] [7/10] training 86.7%: Loss=0.689229, Accuracy=48.083%, MSE=0.382131
[2023-04-27-10:53:54] [7/10] training 89.2%: Loss=0.688428, Accuracy=48.000%, MSE=0.382214
[2023-04-27-10:53:56] [7/10] training 91.6%: Loss=0.68469, Accuracy=48.158%, MSE=0.37993
[2023-04-27-10:53:57] [7/10] training 94.0%: Loss=0.682916, Accuracy=48.282%, MSE=0.379098
[2023-04-27-10:53:59] [7/10] training 96.4%: Loss=0.681679, Accuracy=48.125%, MSE=0.379072
[2023-04-27-10:54:01] [7/10] training 98.8%: Loss=0.679148, Accuracy=48.195%, MSE=0.377664
[2023-04-27-10:54:12] Finished Epoch 7/10: Loss=1.98761, Accuracy=49.867%, MSE=0.463755, Precision=0.448361, Recall=0.0408305, F1=0.0748452, AUPR=0.467337
[2023-04-27-10:54:12] Saving model to ./models/huang_both_0_tt_partitions_epoch07.sav
[2023-04-27-10:54:15] [8/10] training 2.4%: Loss=0.593332, Accuracy=51.000%, MSE=0.3312
[2023-04-27-10:54:16] [8/10] training 4.8%: Loss=0.602212, Accuracy=49.500%, MSE=0.3326
[2023-04-27-10:54:18] [8/10] training 7.2%: Loss=0.599587, Accuracy=48.000%, MSE=0.337396
[2023-04-27-10:54:20] [8/10] training 9.6%: Loss=0.615309, Accuracy=47.000%, MSE=0.348127
[2023-04-27-10:54:22] [8/10] training 12.0%: Loss=0.614054, Accuracy=47.200%, MSE=0.345681
[2023-04-27-10:54:24] [8/10] training 14.5%: Loss=0.623578, Accuracy=45.167%, MSE=0.354552
[2023-04-27-10:54:26] [8/10] training 16.9%: Loss=0.614182, Accuracy=46.000%, MSE=0.34838
[2023-04-27-10:54:27] [8/10] training 19.3%: Loss=0.612725, Accuracy=46.750%, MSE=0.347434
[2023-04-27-10:54:29] [8/10] training 21.7%: Loss=0.601285, Accuracy=48.444%, MSE=0.337464
[2023-04-27-10:54:31] [8/10] training 24.1%: Loss=0.597733, Accuracy=48.600%, MSE=0.33564
[2023-04-27-10:54:33] [8/10] training 26.5%: Loss=0.593155, Accuracy=48.727%, MSE=0.333172
[2023-04-27-10:54:34] [8/10] training 28.9%: Loss=0.599441, Accuracy=48.000%, MSE=0.339617
[2023-04-27-10:54:36] [8/10] training 31.3%: Loss=0.595468, Accuracy=48.769%, MSE=0.335144
[2023-04-27-10:54:38] [8/10] training 33.7%: Loss=0.595263, Accuracy=48.786%, MSE=0.334986
[2023-04-27-10:54:40] [8/10] training 36.1%: Loss=0.592995, Accuracy=49.133%, MSE=0.33347
[2023-04-27-10:54:42] [8/10] training 38.6%: Loss=0.591784, Accuracy=49.375%, MSE=0.331858
[2023-04-27-10:54:44] [8/10] training 41.0%: Loss=0.589071, Accuracy=49.588%, MSE=0.329428
[2023-04-27-10:54:45] [8/10] training 43.4%: Loss=0.587721, Accuracy=49.556%, MSE=0.32852
[2023-04-27-10:54:47] [8/10] training 45.8%: Loss=0.584764, Accuracy=49.421%, MSE=0.327044
[2023-04-27-10:54:49] [8/10] training 48.2%: Loss=0.58611, Accuracy=49.200%, MSE=0.328022
[2023-04-27-10:54:50] [8/10] training 50.6%: Loss=0.58504, Accuracy=49.190%, MSE=0.327697
[2023-04-27-10:54:52] [8/10] training 53.0%: Loss=0.584909, Accuracy=49.136%, MSE=0.328028
[2023-04-27-10:54:54] [8/10] training 55.4%: Loss=0.584994, Accuracy=49.217%, MSE=0.328568
[2023-04-27-10:54:55] [8/10] training 57.8%: Loss=0.584882, Accuracy=48.833%, MSE=0.329019
[2023-04-27-10:54:57] [8/10] training 60.2%: Loss=0.583735, Accuracy=49.000%, MSE=0.328206
[2023-04-27-10:54:58] [8/10] training 62.7%: Loss=0.580418, Accuracy=49.423%, MSE=0.324964
[2023-04-27-10:55:00] [8/10] training 65.1%: Loss=0.578851, Accuracy=49.667%, MSE=0.323488
[2023-04-27-10:55:02] [8/10] training 67.5%: Loss=0.575243, Accuracy=50.000%, MSE=0.32063
[2023-04-27-10:55:04] [8/10] training 69.9%: Loss=0.572891, Accuracy=50.172%, MSE=0.318552
[2023-04-27-10:55:05] [8/10] training 72.3%: Loss=0.571459, Accuracy=50.300%, MSE=0.317442
[2023-04-27-10:55:07] [8/10] training 74.7%: Loss=0.569499, Accuracy=50.677%, MSE=0.315437
[2023-04-27-10:55:08] [8/10] training 77.1%: Loss=0.569796, Accuracy=50.469%, MSE=0.315825
[2023-04-27-10:55:10] [8/10] training 79.5%: Loss=0.56809, Accuracy=50.636%, MSE=0.314485
[2023-04-27-10:55:12] [8/10] training 81.9%: Loss=0.565791, Accuracy=50.853%, MSE=0.312886
[2023-04-27-10:55:14] [8/10] training 84.3%: Loss=0.564612, Accuracy=50.886%, MSE=0.311971
[2023-04-27-10:55:16] [8/10] training 86.7%: Loss=0.562447, Accuracy=51.083%, MSE=0.310289
[2023-04-27-10:55:18] [8/10] training 89.2%: Loss=0.56007, Accuracy=51.568%, MSE=0.308028
[2023-04-27-10:55:19] [8/10] training 91.6%: Loss=0.557092, Accuracy=52.000%, MSE=0.30555
[2023-04-27-10:55:21] [8/10] training 94.0%: Loss=0.555112, Accuracy=52.256%, MSE=0.304113
[2023-04-27-10:55:23] [8/10] training 96.4%: Loss=0.554938, Accuracy=52.225%, MSE=0.30423
[2023-04-27-10:55:24] [8/10] training 98.8%: Loss=0.554703, Accuracy=52.293%, MSE=0.303924
[2023-04-27-10:55:36] Finished Epoch 8/10: Loss=0.999622, Accuracy=44.467%, MSE=0.339095, Precision=0.477938, Recall=0.411485, F1=0.442229, AUPR=0.440545
[2023-04-27-10:55:36] Saving model to ./models/huang_both_0_tt_partitions_epoch08.sav
[2023-04-27-10:55:38] [9/10] training 2.4%: Loss=0.533105, Accuracy=56.000%, MSE=0.290862
[2023-04-27-10:55:40] [9/10] training 4.8%: Loss=0.592468, Accuracy=48.000%, MSE=0.348834
[2023-04-27-10:55:41] [9/10] training 7.2%: Loss=0.593722, Accuracy=47.333%, MSE=0.347785
[2023-04-27-10:55:43] [9/10] training 9.6%: Loss=0.570451, Accuracy=49.000%, MSE=0.327395
[2023-04-27-10:55:45] [9/10] training 12.0%: Loss=0.54074, Accuracy=53.000%, MSE=0.299464
[2023-04-27-10:55:46] [9/10] training 14.5%: Loss=0.529006, Accuracy=55.167%, MSE=0.288057
[2023-04-27-10:55:48] [9/10] training 16.9%: Loss=0.528726, Accuracy=55.000%, MSE=0.287971
[2023-04-27-10:55:50] [9/10] training 19.3%: Loss=0.532199, Accuracy=54.000%, MSE=0.291888
[2023-04-27-10:55:52] [9/10] training 21.7%: Loss=0.528538, Accuracy=54.778%, MSE=0.287581
[2023-04-27-10:55:54] [9/10] training 24.1%: Loss=0.53027, Accuracy=54.900%, MSE=0.288791
[2023-04-27-10:55:56] [9/10] training 26.5%: Loss=0.528889, Accuracy=55.091%, MSE=0.288423
[2023-04-27-10:55:57] [9/10] training 28.9%: Loss=0.52582, Accuracy=55.417%, MSE=0.28594
[2023-04-27-10:55:59] [9/10] training 31.3%: Loss=0.521844, Accuracy=55.846%, MSE=0.282457
[2023-04-27-10:56:01] [9/10] training 33.7%: Loss=0.520169, Accuracy=56.000%, MSE=0.281284
[2023-04-27-10:56:02] [9/10] training 36.1%: Loss=0.524665, Accuracy=56.000%, MSE=0.284554
[2023-04-27-10:56:04] [9/10] training 38.6%: Loss=0.539219, Accuracy=55.813%, MSE=0.292678
[2023-04-27-10:56:06] [9/10] training 41.0%: Loss=0.555218, Accuracy=55.471%, MSE=0.301638
[2023-04-27-10:56:08] [9/10] training 43.4%: Loss=0.563307, Accuracy=55.278%, MSE=0.306474
[2023-04-27-10:56:10] [9/10] training 45.8%: Loss=0.574265, Accuracy=54.316%, MSE=0.315448
[2023-04-27-10:56:12] [9/10] training 48.2%: Loss=0.578866, Accuracy=53.950%, MSE=0.319421
[2023-04-27-10:56:13] [9/10] training 50.6%: Loss=0.579645, Accuracy=53.905%, MSE=0.319835
[2023-04-27-10:56:15] [9/10] training 53.0%: Loss=0.578915, Accuracy=54.136%, MSE=0.319572
[2023-04-27-10:56:17] [9/10] training 55.4%: Loss=0.576936, Accuracy=54.043%, MSE=0.318581
[2023-04-27-10:56:19] [9/10] training 57.8%: Loss=0.571952, Accuracy=54.583%, MSE=0.314363
[2023-04-27-10:56:20] [9/10] training 60.2%: Loss=0.569718, Accuracy=54.760%, MSE=0.312922
[2023-04-27-10:56:22] [9/10] training 62.7%: Loss=0.569154, Accuracy=54.346%, MSE=0.313303
[2023-04-27-10:56:24] [9/10] training 65.1%: Loss=0.566676, Accuracy=54.296%, MSE=0.311654
[2023-04-27-10:56:26] [9/10] training 67.5%: Loss=0.566077, Accuracy=54.143%, MSE=0.311508
[2023-04-27-10:56:27] [9/10] training 69.9%: Loss=0.563673, Accuracy=54.069%, MSE=0.310123
[2023-04-27-10:56:29] [9/10] training 72.3%: Loss=0.563204, Accuracy=53.933%, MSE=0.310066
[2023-04-27-10:56:31] [9/10] training 74.7%: Loss=0.562726, Accuracy=53.903%, MSE=0.309872
[2023-04-27-10:56:32] [9/10] training 77.1%: Loss=0.561595, Accuracy=53.937%, MSE=0.309303
[2023-04-27-10:56:34] [9/10] training 79.5%: Loss=0.561228, Accuracy=53.848%, MSE=0.30924
[2023-04-27-10:56:36] [9/10] training 81.9%: Loss=0.560488, Accuracy=53.794%, MSE=0.309034
[2023-04-27-10:56:38] [9/10] training 84.3%: Loss=0.55925, Accuracy=53.800%, MSE=0.308144
[2023-04-27-10:56:39] [9/10] training 86.7%: Loss=0.558836, Accuracy=53.639%, MSE=0.308028
[2023-04-27-10:56:41] [9/10] training 89.2%: Loss=0.557416, Accuracy=53.838%, MSE=0.306749
[2023-04-27-10:56:43] [9/10] training 91.6%: Loss=0.556793, Accuracy=53.711%, MSE=0.3066
[2023-04-27-10:56:45] [9/10] training 94.0%: Loss=0.555739, Accuracy=53.692%, MSE=0.305843
[2023-04-27-10:56:46] [9/10] training 96.4%: Loss=0.555424, Accuracy=53.725%, MSE=0.305572
[2023-04-27-10:56:48] [9/10] training 98.8%: Loss=0.554658, Accuracy=53.780%, MSE=0.305003
[2023-04-27-10:56:59] Finished Epoch 9/10: Loss=4.45063, Accuracy=49.867%, MSE=0.499862, Precision=0.42097, Recall=0.000138276, F1=0.000276462, AUPR=0.409634
[2023-04-27-10:56:59] Saving model to ./models/huang_both_0_tt_partitions_epoch09.sav
[2023-04-27-10:57:02] [10/10] training 2.4%: Loss=0.485083, Accuracy=62.000%, MSE=0.250646
[2023-04-27-10:57:03] [10/10] training 4.8%: Loss=0.509765, Accuracy=55.000%, MSE=0.275234
[2023-04-27-10:57:05] [10/10] training 7.2%: Loss=0.508265, Accuracy=54.333%, MSE=0.275032
[2023-04-27-10:57:06] [10/10] training 9.6%: Loss=0.522922, Accuracy=53.000%, MSE=0.286515
[2023-04-27-10:57:08] [10/10] training 12.0%: Loss=0.519717, Accuracy=53.800%, MSE=0.281588
[2023-04-27-10:57:10] [10/10] training 14.5%: Loss=0.521338, Accuracy=52.500%, MSE=0.284704
[2023-04-27-10:57:11] [10/10] training 16.9%: Loss=0.518309, Accuracy=52.429%, MSE=0.282605
[2023-04-27-10:57:13] [10/10] training 19.3%: Loss=0.513241, Accuracy=53.000%, MSE=0.27796
[2023-04-27-10:57:15] [10/10] training 21.7%: Loss=0.512162, Accuracy=53.333%, MSE=0.277687
[2023-04-27-10:57:16] [10/10] training 24.1%: Loss=0.507519, Accuracy=54.300%, MSE=0.273133
[2023-04-27-10:57:18] [10/10] training 26.5%: Loss=0.503363, Accuracy=54.909%, MSE=0.268754
[2023-04-27-10:57:20] [10/10] training 28.9%: Loss=0.501782, Accuracy=55.500%, MSE=0.266948
[2023-04-27-10:57:22] [10/10] training 31.3%: Loss=0.503292, Accuracy=55.538%, MSE=0.268442
[2023-04-27-10:57:23] [10/10] training 33.7%: Loss=0.499861, Accuracy=56.071%, MSE=0.264746
[2023-04-27-10:57:25] [10/10] training 36.1%: Loss=0.497813, Accuracy=56.600%, MSE=0.26312
[2023-04-27-10:57:27] [10/10] training 38.6%: Loss=0.497298, Accuracy=56.562%, MSE=0.262835
[2023-04-27-10:57:29] [10/10] training 41.0%: Loss=0.497275, Accuracy=56.412%, MSE=0.263241
[2023-04-27-10:57:31] [10/10] training 43.4%: Loss=0.496848, Accuracy=56.889%, MSE=0.262404
[2023-04-27-10:57:32] [10/10] training 45.8%: Loss=0.498259, Accuracy=56.526%, MSE=0.26388
[2023-04-27-10:57:34] [10/10] training 48.2%: Loss=0.497862, Accuracy=56.400%, MSE=0.263833
[2023-04-27-10:57:36] [10/10] training 50.6%: Loss=0.496414, Accuracy=56.571%, MSE=0.262725
[2023-04-27-10:57:38] [10/10] training 53.0%: Loss=0.495795, Accuracy=56.682%, MSE=0.262384
[2023-04-27-10:57:39] [10/10] training 55.4%: Loss=0.495141, Accuracy=56.826%, MSE=0.261657
[2023-04-27-10:57:41] [10/10] training 57.8%: Loss=0.496474, Accuracy=56.667%, MSE=0.26325
[2023-04-27-10:57:43] [10/10] training 60.2%: Loss=0.496987, Accuracy=56.600%, MSE=0.263996
[2023-04-27-10:57:45] [10/10] training 62.7%: Loss=0.495676, Accuracy=56.846%, MSE=0.262543
[2023-04-27-10:57:46] [10/10] training 65.1%: Loss=0.496003, Accuracy=56.926%, MSE=0.262766
[2023-04-27-10:57:48] [10/10] training 67.5%: Loss=0.495768, Accuracy=56.857%, MSE=0.262668
[2023-04-27-10:57:49] [10/10] training 69.9%: Loss=0.496875, Accuracy=56.552%, MSE=0.263794
[2023-04-27-10:57:51] [10/10] training 72.3%: Loss=0.497246, Accuracy=56.567%, MSE=0.264143
[2023-04-27-10:57:53] [10/10] training 74.7%: Loss=0.496676, Accuracy=56.548%, MSE=0.26366
[2023-04-27-10:57:55] [10/10] training 77.1%: Loss=0.496251, Accuracy=56.625%, MSE=0.263233
[2023-04-27-10:57:57] [10/10] training 79.5%: Loss=0.496528, Accuracy=56.576%, MSE=0.263584
[2023-04-27-10:57:59] [10/10] training 81.9%: Loss=0.496375, Accuracy=56.441%, MSE=0.263594
[2023-04-27-10:58:00] [10/10] training 84.3%: Loss=0.495243, Accuracy=56.543%, MSE=0.262585
[2023-04-27-10:58:02] [10/10] training 86.7%: Loss=0.49586, Accuracy=56.278%, MSE=0.263357
[2023-04-27-10:58:04] [10/10] training 89.2%: Loss=0.495268, Accuracy=56.324%, MSE=0.262902
[2023-04-27-10:58:06] [10/10] training 91.6%: Loss=0.49577, Accuracy=56.289%, MSE=0.263271
[2023-04-27-10:58:08] [10/10] training 94.0%: Loss=0.496169, Accuracy=56.179%, MSE=0.263769
[2023-04-27-10:58:10] [10/10] training 96.4%: Loss=0.496364, Accuracy=56.250%, MSE=0.263825
[2023-04-27-10:58:12] [10/10] training 98.8%: Loss=0.496279, Accuracy=56.049%, MSE=0.264012
[2023-04-27-10:58:23] Finished Epoch 10/10: Loss=4.6045, Accuracy=49.867%, MSE=0.499899, Precision=0.384874, Recall=0.000101353, F1=0.000202653, AUPR=0.332045
[2023-04-27-10:58:23] Saving model to ./models/huang_both_0_tt_partitions_epoch10.sav
[2023-04-27-10:58:23] Saving final model to ./models/huang_both_0_tt_partitions_final.sav
